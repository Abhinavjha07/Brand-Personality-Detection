{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Brand_Personality_Det.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrJSHQBm5j7n",
        "colab_type": "code",
        "outputId": "670bcbea-a564-4a8f-abe5-e0cd363be6ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        }
      },
      "source": [
        "!git clone https://github.com/Abhinavjha07/ML_Datasets/\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ML_Datasets'...\n",
            "remote: Enumerating objects: 20114, done.\u001b[K\n",
            "remote: Counting objects: 100% (20114/20114), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20069/20069), done.\u001b[K\n",
            "remote: Total 60707 (delta 39), reused 20113 (delta 38), pack-reused 40593\n",
            "Receiving objects: 100% (60707/60707), 1.38 GiB | 46.06 MiB/s, done.\n",
            "Resolving deltas: 100% (1290/1290), done.\n",
            "Checking out files: 100% (61107/61107), done.\n",
            "--2019-05-30 12:47:34--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2019-05-30 12:47:34--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2019-05-30 12:47:34--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  12.2MB/s    in 85s     \n",
            "\n",
            "2019-05-30 12:49:00 (9.63 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zt7YjKDL48y",
        "colab_type": "code",
        "outputId": "91c262e2-cab2-48ba-e2a6-ab4d94d1e188",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "!ls \"/content/drive/My Drive/ML_Datasets/genData/MTdata\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "com_mt_essays_16thMay.csv  sinc_mt_essays_16thMay.csv\n",
            "com_mt_mrs_16thMay.csv\t   sinc_mt_mrs_16thMay.csv\n",
            "exc_mt_essays_16thMay.csv  sop_mt_essays_16thMay.csv\n",
            "exc_mt_mrs_16thMay.csv\t   sop_mt_mrs_16thMay.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfAKhrNOQQor",
        "colab_type": "code",
        "outputId": "8144d49a-4856-4a17-b47c-188b60ded10e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4550
        }
      },
      "source": [
        "\n",
        "!pip install contractions\n",
        "import nltk\n",
        "nltk.download('all')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: contractions in /usr/local/lib/python3.6/dist-packages (0.0.18)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Package abc is already up-to-date!\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Package alpino is already up-to-date!\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Package brown is already up-to-date!\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Package chat80 is already up-to-date!\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package city_database is already up-to-date!\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Package cmudict is already up-to-date!\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
            "[nltk_data]    |       date!\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    |   Package comtrans is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Package crubadan is already up-to-date!\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Package dolch is already up-to-date!\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Package floresta is already up-to-date!\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Package genesis is already up-to-date!\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Package ieer is already up-to-date!\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Package inaugural is already up-to-date!\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Package indian is already up-to-date!\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    |   Package jeita is already up-to-date!\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Package kimmo is already up-to-date!\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    |   Package knbc is already up-to-date!\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    |   Package machado is already up-to-date!\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Package names is already up-to-date!\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Package paradigms is already up-to-date!\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Package pil is already up-to-date!\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Package pl196x is already up-to-date!\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Package ppattach is already up-to-date!\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    |   Package propbank is already up-to-date!\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Package ptb is already up-to-date!\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Package qc is already up-to-date!\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    |   Package reuters is already up-to-date!\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Package rte is already up-to-date!\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    |   Package semcor is already up-to-date!\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Package senseval is already up-to-date!\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Package smultron is already up-to-date!\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Package state_union is already up-to-date!\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Package swadesh is already up-to-date!\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Package switchboard is already up-to-date!\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Package timit is already up-to-date!\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Package toolbox is already up-to-date!\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Package treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Package udhr is already up-to-date!\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n",
            "[nltk_data]    |       date!\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package verbnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Package verbnet3 is already up-to-date!\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Package webtext is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Package words is already up-to-date!\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Package ycoe is already up-to-date!\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Package rslp is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sample_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package spanish_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Package tagsets is already up-to-date!\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package word2vec_sample is already up-to-date!\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
            "[nltk_data]    |       up-to-date!\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package perluniprops is already up-to-date!\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Package porter_test is already up-to-date!\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Package wmt15_eval is already up-to-date!\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8Vpt7u7e2gt",
        "colab_type": "code",
        "outputId": "5bf1689c-bd7a-4568-f362-f8bcb86a0615",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4830
        }
      },
      "source": [
        "# Preprocessing the train_data\n",
        "import os \n",
        "import numpy as np\n",
        "import csv\n",
        "import pandas as pd\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Model\n",
        "from keras.utils import to_categorical,plot_model\n",
        "from keras.layers import Activation, Dense, Dropout,Input,Add,concatenate\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split,StratifiedKFold\n",
        "from keras.layers import Conv1D,MaxPooling1D,Embedding,GlobalMaxPooling1D\n",
        "from keras.initializers import Constant\n",
        "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
        "import pickle\n",
        "!pip install -U nltk\n",
        "import os\n",
        "import nltk\n",
        "nltk.download('all')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "from keras.preprocessing.text import Tokenizer,text_to_word_sequence\n",
        "import re, string, unicodedata\n",
        "import contractions\n",
        "import inflect\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
        "\n",
        "\n",
        "#preprocessing the texts\n",
        "\n",
        "def strip_html(text):\n",
        "    soup = BeautifulSoup(text, \"html.parser\")\n",
        "    return soup.get_text()\n",
        "\n",
        "def remove_between_square_brackets(text):\n",
        "    return re.sub('\\[[^]]*\\]', '', text)\n",
        "\n",
        "def denoise_text(text):\n",
        "    text = strip_html(text)\n",
        "    text = remove_between_square_brackets(text)\n",
        "    return text\n",
        "\n",
        "def replace_contractions(text):\n",
        "    \"\"\"Replace contractions in string of text\"\"\"\n",
        "    return contractions.fix(text)\n",
        "\n",
        "def remove_non_ascii(words):\n",
        "    \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "        new_words.append(new_word)\n",
        "    return new_words\n",
        "\n",
        "def to_lowercase(words):\n",
        "    \"\"\"Convert all characters to lowercase from list of tokenized words\"\"\"\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        new_word = word.lower()\n",
        "        new_words.append(new_word)\n",
        "    return new_words\n",
        "\n",
        "def remove_punctuation(words):\n",
        "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
        "        if new_word != '':\n",
        "            new_words.append(new_word)\n",
        "    return new_words\n",
        "\n",
        "def replace_numbers(words):\n",
        "    \"\"\"Replace all interger occurrences in list of tokenized words with textual representation\"\"\"\n",
        "    p = inflect.engine()\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        if word.isdigit():\n",
        "            new_word = p.number_to_words(word)\n",
        "            new_words.append(new_word)\n",
        "        else:\n",
        "            new_words.append(word)\n",
        "    return new_words\n",
        "\n",
        "def remove_stopwords(words):\n",
        "    \"\"\"Remove stop words from list of tokenized words\"\"\"\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        if word not in stopwords.words('english'):\n",
        "            new_words.append(word)\n",
        "    return new_words\n",
        "\n",
        "def stem_words(words):\n",
        "    \"\"\"Stem words in list of tokenized words\"\"\"\n",
        "    stemmer = LancasterStemmer()\n",
        "    stems = []\n",
        "    for word in words:\n",
        "        stem = stemmer.stem(word)\n",
        "        stems.append(stem)\n",
        "    return stems\n",
        "\n",
        "def lemmatize_verbs(words):\n",
        "    \"\"\"Lemmatize verbs in list of tokenized words\"\"\"\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemmas = []\n",
        "    for word in words:\n",
        "        lemma = lemmatizer.lemmatize(word, pos='v')\n",
        "        lemmas.append(lemma)\n",
        "    return lemmas\n",
        "\n",
        "def normalize(words):\n",
        "    words = remove_non_ascii(words)\n",
        "    words = to_lowercase(words)\n",
        "    words = remove_punctuation(words)\n",
        "    #words = replace_numbers(words)\n",
        "    words = remove_stopwords(words)\n",
        "    words = lemmatize_verbs(words)\n",
        "    return words\n",
        "\n",
        "\n",
        "#path of the training files\n",
        "\n",
        "train_path =  '/content/drive/My Drive/ML_Datasets/genData/MTdata'\n",
        "\n",
        "#columns which are used for training the model\n",
        "col_names = ['X.AUTHID','site.content','cSIN_tag','cEXC_tag','cCOM_tag','cRUG_tag','cSOP_tag']\n",
        "\n",
        "#training file names\n",
        "file_names = ['com_mt_essays_16thMay.csv','rug_mt_essays_27thMay.csv','exc_mt_essays_16thMay.csv','sinc_mt_essays_16thMay.csv','sop_mt_essays_16thMay.csv']\n",
        "\n",
        "#file name for ruggedess trait\n",
        "f_names = ['rug_mt_essays_27thMay.csv']\n",
        "\n",
        "#processing each file and separating the train text and label\n",
        "for files in os.listdir(train_path):\n",
        "    if files in f_names:\n",
        "        reader = csv.DictReader(open(train_path+'/'+files,encoding='latin-1'))\n",
        "        \n",
        "        datalist = []\n",
        "        for raw in reader:\n",
        "            datalist.append((raw['X.AUTHID'],raw['site.content'],raw['cSIN_tag'],raw['cEXC_tag'],raw['cCOM_tag'],raw['cRUG_tag'],raw['cSOP_tag']))\n",
        "\n",
        "\n",
        "train_data = np.array(datalist)\n",
        "data = pd.DataFrame.from_records(datalist, columns=col_names)\n",
        "print(train_data.shape)\n",
        "\n",
        "#pickling the train data\n",
        "pickle_out = open(\"train_data_rug.pickle\",\"wb\")\n",
        "pickle.dump(data, pickle_out)\n",
        "pickle_out.close()\n",
        "\n",
        "\n",
        "#preprocessing the texts\n",
        "words = []\n",
        "for texts in data['site.content']:\n",
        "    text = denoise_text(texts)\n",
        "    text = replace_contractions(text)\n",
        "    word = nltk.word_tokenize(text)\n",
        "    word = normalize(word)\n",
        "    words.append(word)\n",
        "\n",
        "words = np.array(words)\n",
        "print(words.shape)\n",
        "\n",
        "new_text = []\n",
        "for i in range(len(words)):\n",
        "    text = \" \".join(str(x) for x in words[i])\n",
        "    new_text.append(text)\n",
        "\n",
        "print(len(new_text))\n",
        "\n",
        "\n",
        "#pickling the preprocessed text.\n",
        "pickle_out = open(\"text_RUG.pickle\",\"wb\")\n",
        "pickle.dump(new_text, pickle_out)\n",
        "pickle_out.close()\n",
        "\n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting nltk\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8d/5d/825889810b85c303c8559a3fd74d451d80cf3585a851f2103e69576bf583/nltk-3.4.3.zip (1.4MB)\n",
            "\r\u001b[K     |▎                               | 10kB 15.5MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 3.3MB/s eta 0:00:01\r\u001b[K     |▊                               | 30kB 4.8MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 3.1MB/s eta 0:00:01\r\u001b[K     |█▏                              | 51kB 3.8MB/s eta 0:00:01\r\u001b[K     |█▍                              | 61kB 4.5MB/s eta 0:00:01\r\u001b[K     |█▋                              | 71kB 5.2MB/s eta 0:00:01\r\u001b[K     |█▉                              | 81kB 5.8MB/s eta 0:00:01\r\u001b[K     |██                              | 92kB 6.5MB/s eta 0:00:01\r\u001b[K     |██▎                             | 102kB 4.9MB/s eta 0:00:01\r\u001b[K     |██▌                             | 112kB 4.9MB/s eta 0:00:01\r\u001b[K     |██▊                             | 122kB 4.9MB/s eta 0:00:01\r\u001b[K     |███                             | 133kB 4.9MB/s eta 0:00:01\r\u001b[K     |███▏                            | 143kB 4.9MB/s eta 0:00:01\r\u001b[K     |███▍                            | 153kB 4.9MB/s eta 0:00:01\r\u001b[K     |███▋                            | 163kB 4.9MB/s eta 0:00:01\r\u001b[K     |███▉                            | 174kB 4.9MB/s eta 0:00:01\r\u001b[K     |████                            | 184kB 4.9MB/s eta 0:00:01\r\u001b[K     |████▎                           | 194kB 4.9MB/s eta 0:00:01\r\u001b[K     |████▌                           | 204kB 4.9MB/s eta 0:00:01\r\u001b[K     |████▊                           | 215kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████                           | 225kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 235kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 245kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 256kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 266kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████                          | 276kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 286kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 296kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 307kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████                         | 317kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 327kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 337kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 348kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████                        | 358kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 368kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 378kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 389kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 399kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████                       | 409kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 419kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 430kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 440kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████                      | 450kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 460kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 471kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 481kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 491kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████                     | 501kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 512kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 522kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 532kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████                    | 542kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 552kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 563kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 573kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 583kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 593kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 604kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 614kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 624kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 634kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 645kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 655kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 665kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 675kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 686kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 696kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 706kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 716kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████                | 727kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 737kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 747kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 757kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 768kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 778kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 788kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 798kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 808kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 819kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 829kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 839kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 849kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 860kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 870kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 880kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 890kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 901kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 911kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 921kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 931kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 942kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 952kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 962kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 972kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 983kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 993kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 1.0MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.0MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.0MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.0MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.0MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 1.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 1.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 1.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.3MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.3MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.3MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.3MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.3MB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.3MB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.3MB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.3MB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 1.3MB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.4MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.4MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.4MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.4MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.4MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.4MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.4MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.4MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.4MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.4MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.5MB 4.9MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n",
            "Building wheels for collected packages: nltk\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/54/40/b7/c56ad418e6cd4d9e1e594b5e138d1ca6eec11a6ee3d464e5bb\n",
            "Successfully built nltk\n",
            "Installing collected packages: nltk\n",
            "  Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "Successfully installed nltk-3.4.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Package abc is already up-to-date!\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Package alpino is already up-to-date!\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Package brown is already up-to-date!\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Package chat80 is already up-to-date!\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package city_database is already up-to-date!\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Package cmudict is already up-to-date!\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
            "[nltk_data]    |       date!\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    |   Package comtrans is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Package crubadan is already up-to-date!\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Package dolch is already up-to-date!\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Package floresta is already up-to-date!\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Package genesis is already up-to-date!\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Package ieer is already up-to-date!\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Package inaugural is already up-to-date!\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Package indian is already up-to-date!\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    |   Package jeita is already up-to-date!\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Package kimmo is already up-to-date!\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    |   Package knbc is already up-to-date!\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    |   Package machado is already up-to-date!\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Package names is already up-to-date!\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Package paradigms is already up-to-date!\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Package pil is already up-to-date!\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Package pl196x is already up-to-date!\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Package ppattach is already up-to-date!\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    |   Package propbank is already up-to-date!\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Package ptb is already up-to-date!\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Package qc is already up-to-date!\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    |   Package reuters is already up-to-date!\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Package rte is already up-to-date!\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    |   Package semcor is already up-to-date!\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Package senseval is already up-to-date!\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Package smultron is already up-to-date!\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Package state_union is already up-to-date!\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Package swadesh is already up-to-date!\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Package switchboard is already up-to-date!\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Package timit is already up-to-date!\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Package toolbox is already up-to-date!\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Package treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Package udhr is already up-to-date!\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n",
            "[nltk_data]    |       date!\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package verbnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Package verbnet3 is already up-to-date!\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Package webtext is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Package words is already up-to-date!\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Package ycoe is already up-to-date!\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Package rslp is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sample_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package spanish_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Package tagsets is already up-to-date!\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package word2vec_sample is already up-to-date!\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
            "[nltk_data]    |       up-to-date!\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package perluniprops is already up-to-date!\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Package porter_test is already up-to-date!\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Package wmt15_eval is already up-to-date!\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(2781, 7)\n",
            "(2781,)\n",
            "2781\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkGiP9UQdnHr",
        "colab_type": "code",
        "outputId": "8eb2c773-4d5f-49ad-91a3-73ba1669059e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4639
        }
      },
      "source": [
        "#Preprocessing the heldout test data\n",
        "\n",
        "import os \n",
        "import numpy as np\n",
        "import csv\n",
        "import pandas as pd\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Model\n",
        "from keras.utils import to_categorical,plot_model\n",
        "from keras.layers import Activation, Dense, Dropout,Input,Add,concatenate\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split,StratifiedKFold\n",
        "from keras.layers import Conv1D,MaxPooling1D,Embedding,GlobalMaxPooling1D\n",
        "from keras.initializers import Constant\n",
        "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
        "import pickle\n",
        "from nltk.corpus import stopwords\n",
        "import os\n",
        "import nltk\n",
        "nltk.download('all')\n",
        "nltk.download('wordnet')\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "from keras.preprocessing.text import Tokenizer,text_to_word_sequence\n",
        "import re, string, unicodedata\n",
        "import contractions\n",
        "import inflect\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
        "\n",
        "\n",
        "def strip_html(text):\n",
        "    soup = BeautifulSoup(text, \"html.parser\")\n",
        "    return soup.get_text()\n",
        "\n",
        "def remove_between_square_brackets(text):\n",
        "    return re.sub('\\[[^]]*\\]', '', text)\n",
        "\n",
        "def denoise_text(text):\n",
        "    text = strip_html(text)\n",
        "    text = remove_between_square_brackets(text)\n",
        "    return text\n",
        "\n",
        "def replace_contractions(text):\n",
        "    \"\"\"Replace contractions in string of text\"\"\"\n",
        "    return contractions.fix(text)\n",
        "\n",
        "def remove_non_ascii(words):\n",
        "    \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "        new_words.append(new_word)\n",
        "    return new_words\n",
        "\n",
        "def to_lowercase(words):\n",
        "    \"\"\"Convert all characters to lowercase from list of tokenized words\"\"\"\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        new_word = word.lower()\n",
        "        new_words.append(new_word)\n",
        "    return new_words\n",
        "\n",
        "def remove_punctuation(words):\n",
        "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
        "        if new_word != '':\n",
        "            new_words.append(new_word)\n",
        "    return new_words\n",
        "\n",
        "def replace_numbers(words):\n",
        "    \"\"\"Replace all interger occurrences in list of tokenized words with textual representation\"\"\"\n",
        "    p = inflect.engine()\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        if word.isdigit():\n",
        "            new_word = p.number_to_words(word)\n",
        "            new_words.append(new_word)\n",
        "        else:\n",
        "            new_words.append(word)\n",
        "    return new_words\n",
        "\n",
        "def remove_stopwords(words):\n",
        "    \"\"\"Remove stop words from list of tokenized words\"\"\"\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        if word not in stopwords.words('english'):\n",
        "            new_words.append(word)\n",
        "    return new_words\n",
        "\n",
        "def stem_words(words):\n",
        "    \"\"\"Stem words in list of tokenized words\"\"\"\n",
        "    stemmer = LancasterStemmer()\n",
        "    stems = []\n",
        "    for word in words:\n",
        "        stem = stemmer.stem(word)\n",
        "        stems.append(stem)\n",
        "    return stems\n",
        "\n",
        "def lemmatize_verbs(words):\n",
        "    \"\"\"Lemmatize verbs in list of tokenized words\"\"\"\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemmas = []\n",
        "    for word in words:\n",
        "        lemma = lemmatizer.lemmatize(word, pos='v')\n",
        "        lemmas.append(lemma)\n",
        "    return lemmas\n",
        "\n",
        "def normalize(words):\n",
        "    words = remove_non_ascii(words)\n",
        "    words = to_lowercase(words)\n",
        "    words = remove_punctuation(words)\n",
        "    #words = replace_numbers(words)\n",
        "    words = remove_stopwords(words)\n",
        "    words = lemmatize_verbs(words)\n",
        "    return words\n",
        "\n",
        "#test data path\n",
        "test_path = '/content/drive/My Drive/ML_Datasets/genData/heldout_essays_16thMay.csv'\n",
        "col_names = ['X.AUTHID','TEXT','cSIN','cEXC','cCOM','cRUG','cSOP']\n",
        "\n",
        "#loading test_data\n",
        "reader = csv.DictReader(open(test_path,encoding='latin-1'))\n",
        "        \n",
        "datalist = []\n",
        "\n",
        "#creating a array of text files\n",
        "for raw in reader:\n",
        "    datalist.append((raw['X.AUTHID'],raw['TEXT'],raw['cSIN'],raw['cEXC'],raw['cCOM'],raw['cRUG'],raw['cSOP']))\n",
        "\n",
        "\n",
        "train_data = np.array(datalist)\n",
        "data = pd.DataFrame.from_records(datalist, columns=col_names)\n",
        "print(train_data.shape)\n",
        "\n",
        "#pickling the test data\n",
        "pickle_out = open(\"test_data.pickle\",\"wb\")\n",
        "pickle.dump(data, pickle_out)\n",
        "pickle_out.close()\n",
        "\n",
        "\n",
        "#preprocessing the test texts\n",
        "words = []\n",
        "for texts in data['TEXT']:\n",
        "    text = denoise_text(texts)\n",
        "    text = replace_contractions(text)\n",
        "    word = nltk.word_tokenize(text)\n",
        "    word = normalize(word)\n",
        "    words.append(word)\n",
        "\n",
        "words = np.array(words)\n",
        "print(words.shape)\n",
        "new_text = []\n",
        "for i in range(len(words)):\n",
        "    text = \" \".join(str(x) for x in words[i])\n",
        "    new_text.append(text)\n",
        "    \n",
        "print(new_text)\n",
        "\n",
        "print(len(new_text))\n",
        "\n",
        "\n",
        "#pickling the test text\n",
        "pickle_out = open(\"test_text.pickle\",\"wb\")\n",
        "pickle.dump(new_text, pickle_out)\n",
        "pickle_out.close()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Package abc is already up-to-date!\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Package alpino is already up-to-date!\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Package brown is already up-to-date!\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Package chat80 is already up-to-date!\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package city_database is already up-to-date!\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Package cmudict is already up-to-date!\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
            "[nltk_data]    |       date!\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    |   Package comtrans is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Package crubadan is already up-to-date!\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Package dolch is already up-to-date!\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Package floresta is already up-to-date!\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Package genesis is already up-to-date!\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Package ieer is already up-to-date!\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Package inaugural is already up-to-date!\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Package indian is already up-to-date!\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    |   Package jeita is already up-to-date!\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Package kimmo is already up-to-date!\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    |   Package knbc is already up-to-date!\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    |   Package machado is already up-to-date!\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Package names is already up-to-date!\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Package paradigms is already up-to-date!\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Package pil is already up-to-date!\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Package pl196x is already up-to-date!\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Package ppattach is already up-to-date!\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    |   Package propbank is already up-to-date!\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Package ptb is already up-to-date!\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Package qc is already up-to-date!\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    |   Package reuters is already up-to-date!\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Package rte is already up-to-date!\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    |   Package semcor is already up-to-date!\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Package senseval is already up-to-date!\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Package smultron is already up-to-date!\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Package state_union is already up-to-date!\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Package swadesh is already up-to-date!\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Package switchboard is already up-to-date!\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Package timit is already up-to-date!\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Package toolbox is already up-to-date!\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Package treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Package udhr is already up-to-date!\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n",
            "[nltk_data]    |       date!\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package verbnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Package verbnet3 is already up-to-date!\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Package webtext is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Package words is already up-to-date!\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Package ycoe is already up-to-date!\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Package rslp is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sample_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package spanish_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Package tagsets is already up-to-date!\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package word2vec_sample is already up-to-date!\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
            "[nltk_data]    |       up-to-date!\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package perluniprops is already up-to-date!\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Package porter_test is already up-to-date!\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Package wmt15_eval is already up-to-date!\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "(336, 7)\n",
            "(336,)\n",
            "['regularly declare take village raise child shoe x creation process always complex collaborative involve interdisciplinary partnerships everything waffle iron freeze foam company remit help make athletes faster persistent mission similarly serve catalyst behind x air zoom disruptive form function new everyday run shoe employ speedinducing propulsion lockdown system similar see recently unveil x zoom superfly flyknit sprint spike arrive progressive solution require three years cooperation multiple x team range x run footwear product team cushion innovation experts flyknit engineer athletes together continuously tweak test refine design shoe development start aforementioned company mission meet new run footwear team charge evolve x zoom air bag make larger visible still applicable performance footwear specifically meet overarch speed mandate time team dig propulsion need sprint events collaboration champion 200 400meter runner allyson felix experiment energy return spike plat exploration lead discover centrifugal force track curve push sprinter plate turn minimize propulsive pop set design lockdown system would work tandem new stiffer x superfly elite plate join force company flyknit engineer felix team create custom midcollar flyknit upper integrate flywire cable across entire midfoot broader wider ever think hand wrap around foot due malleability flyknit make superior performance material take 70 iterations crack comfortcontrol equation collar high low arrive ideal height balance plate force', 'use x web service medicalimaging pioneer save money concentrate matter science patients earl schultz go surgery look like would need another operation time valve two chamber heart earl cardiologists tell faster better scan method develop startup call arterys scan would give clearer look heart valve blood flow earl get result good news need surgery say even need another scan couple years give great comfort know look surgery next week next year maybe never scan like one change course earl treatment rely gather process huge amount data prohibitively expensive turn x web service aws arterys able lower cost put medical advance within reach patients way could do cloud aws say cofounder john axeriocilies', 'vision create technology make life better everyone everywhere every person every organization every community around globe motivate us inspire us make make invent reinvent engineer experience amaze stop push ahead stop push ahead reinvent work play live technology reinvent world innovation blood create technology create technology purpose make life better everyone everywhere', 'life always change grow complex need priorities specific family work health home continuously evolve impact financial life decisions need make since finance deeply connect rest life deserve strategies solutions specific unique need goals advisor help someone first foremost meet regularly take time understand hope achieve keep night advisor put financial experience work sort complexities offer financial insights strategies help manage financial life move confidently towards goals x help prioritize goals matter whether transition next generation customize financial strategies help pursue desire outcomes simply provide advice guidance help stay inform 100 years people business get importance last relationship expect x advisors transparency fee risk outcomes advice customize discipline wealth investment process responsible service personalize preferences team advisors understand need goals', 'vision x strive make world healthier sustainable innovation mission improve quality people live technologyenabled meaningful innovations cocreator strategic partner x businesses complementary open innovation ecosystem participants impact innovation today x diversify health wellbeing company diversity also reflect organization allow us address challenge need people unique way touch many aspects people live true impact innovations combination solutions support people throughout entire life whether solutions baby even prenatal care systems optimize light school offices image systems improve healthcare bring together experts different discipline include experience across broad innovation portfolio x work together company believe innovations really make difference people empower people improve life', 'support energy transition world limit natural resources businesses able ensure longterm survival dint constant efforts control energy consumption preserve fragile climate balance x commit reduce greenhouse gas emissions 20 2006 2020 real challenge within context rapidly grow usage relentless increase data traffic plan action concern technical infrastructure also premise way travel work go even act player energy transition bring customers expertise technology search today answer energy ecology issue tomorrow cut co2 emissions mean deal source energy consumption link operations seek optimal energy efficiency every innovative mean disposal addition cut direct energy consumption x also strive reduce indirect impact connection customers use products service ecodesign environmental label innovative solutions help customers reduce carbon footprint mean information communication technologies icts play major role combat climate change via solutions design encourage teleworking paperless procedures smart management build network cities x firmly commit alongside key players ngos governments put technology service climatedriven innovation group involve example cop21 21st session conference party unfccc bring together 194 state discuss climaterelated issue paris 2015', 'x trust manage money investment firm business invest behalf clients large institutions parent grandparents doctor teachers entrust save us work clientsperiod promise offer insight money products service help plan better financial future company institutions global governments come us help meet biggest financial challenge create worldclass capabilities around clients greatest need comprehensive range products service across asset class geographies investment strategies root deep every region around world 135 investment team 30 countries share best think order seek better return clients come nearly every corner globe governments company foundations millions individuals save retirement children educations better life passionate work intensely focus perform highest level get strive outthink outwork competitors find best balance risk return across investment style behalf clients responsibility heart businessresponsibility clients extension communities live work invest communities neighbor signature focus education build better financial futures world largest investor work behalf millions clients size x embrace strong commitment transparency financial market sound corporate governance also one world largest responsible investors 225 billion mandate explicitly address social ethical environmental considerations', 'excite week welcome new wave intern college grad hire also fire girls code gwc immersion program 40 high school girls arrive san jose site eager explore like work tech summer total 100 young women san jose san francisco new york seattle locations work alongside technologists 150 employees include 100 female mentor across country contribute time gwc make summer success four employees work fulltime teachers summer introduce girls everything graphics animation mobile app development veterans program lead gwc first time say janice peters program manager orchestrate immersion program past three years technical nontechnical common interest support next generation girl coders participation gwc part x foundation youth cod initiative program expand access cod education underserved youth also component diversity inclusion commitment', 'x hereby declare security policy ensure security constant improvement operational condition course activities include passenger transportation cargo transportation train conduct accord national international regulations standards x develop implement process prevent act unlawful interference may occur grind flight establish security objectives security performance standards implement process x provide periodic policy review ensure continue relevance organizational need requirements security performance standards x ensure clear statement organization security objectives measure take order conform security regulations execute corporate security management system provide security activities constant improvement x determine responsibilities employees regard securityrelated issue ensure commitment security senior management fundamental priority throughout organization x provide assistance employees identify prevent vulnerabilities risk may occur result interaction people machine environment duties x promote culture flow information communication carry objectively senior management employees order support activities communication execute secure manner include nonpunitive report procedures encourage report inadvertent human error x ensure necessary arrangements make establish improve corporate security culture promote activities increase security awareness make security integral part corporate management system x ensure provision resources necessary successful implementation security policy', 'today excite share x enter agreement acquire microsoft join force microsoft realize common mission empower people organizations x vision create economic opportunity every member global workforce change members still come first company world lead professional cloud network deal allow us keep grow invest innovate x drive value members customers members continue develop skills find job great job use platform continue help customers hire top talent market brand sell customers x know value get better x retain distinct brand culture independence change way world professionals connect opportunity 13 years opportunity us truly change way world work massive scale incredibly energize mean members employees personal perspective news encourage read influencer post find detail agreement microsoft news center x newsroom', 'vision heart x way vision global energy company admire people partnership performance vision mean safely provide energy products vital sustainable economic progress human development throughout world people organization superior capabilities commitment partner choice earn admiration stakeholders investors customers host governments local communities employees goals achieve achieve deliver worldclass performance value company foundation build value distinguish us guide action conduct business socially responsible ethical manner respect law support universal human right protect environment benefit communities work', 'mom try secure home kid know tomorrow bring say maria torresleon single mother four torresleon overcome breast cancer domestic violence unemployment come situation stronger woman battle cancer vow leave legacy children stable home past may 300 women team habitat humanity greater orlando help torresleon realize dream family fourbedroom house one four new home build butler preserve new habitat community national women build week x heroes employee volunteer help construct home one 600 house build repair nationwide annual weeklong event lead mother day see wall roof still believe real torresleon say addition begin able move apartment ada compliant make difficult care son bear cerebral palsy torresleon able invest future help nointerest habitat mortgage afford purchase home final touchups complete x volunteer candace hartley overhear torresleon tell local reporter something never forget interview tell reporter actually look children say go home hartley say really hit home everything do past two weeks women build actually put roof head children pretty powerful', 'light stylish delightfully easy use wonder tablets become popular years ago handful model today market lot choose find right one need 3 simple question get start size best suit tablets generally come 3 size small 7 83 medium 89 101 large 101 advantage prefer use pick right size really depend need tablet look something light compact read ebooks small tablet ideal mediumsized tablets generally good choice game read magazines watch movies largesized tablet frequently find detachable screen hybrid 2 1 laptop may cost larger screen productive get work do especially use keyboard use entertainment work want tablet mostly game entertainment androidbased one may good choice wide variety apps available work windows power tablet may smart choice compatibility software like microsoft office office laptop desktop device run latest version windows 10 may also enjoy great battery life crystal clear graphics allaround performance really need something get business consider 2 1 hybrid laptop combine responsiveness tablet power fullsize laptop convenient little device joy use much look spend variety tablets available mean broad price range make possible anyone find price point suit', 'x wake think market revolutionize way company engage customers think journey get start work best brightest industry challenge think work new creative ways celebrate employees entrepreneurial spirit take collaboration new level environment limit fast career grow health wellness addition offer comprehensive benefit package support healthy active lifestyles really important us offer onsite group exercise gym facilities reimbursement personal gym membership involvement team sport league stock kitchens healthy snack time realize life work want support success happiness areas offer generous time new parent employees need aid family members stay within x family able take advantage sabbatical program learn development want see excel career provide tool help continue grow offer leadership management train tuition reimbursement career development coach employee affinity group connect likeminded peer give back believe duty make positive impact communities x give back program enable employees get involve give back organizations matter offer unique volunteer opportunities pay time volunteer match employee donations', 'edge nowhere intense thirdperson actionadventure title insomniac game x studios live x store traverse mountains antarctica victor howard search mysteriously vanish expedition edge nowhere blend adventure gameplay elements lovecraftian horror nothing seem treacherous wilds crumble sanity design develop specifically vr edge nowhere put right 1920s rescue operation remote part world every scramble tower cliff ice sprint across crumble bridge feel like cling dear life start rescue mission take turn worse delve deeper terrify world reality twist warp around shadow trick eye quickly find unexpected lurk everywhere explore alien cave uncover terrible secrets use wits makeshift weapons survive monstrous entities madness await front line vr exhilarate say ted price insomniac ceo devise ways tell stories new technology something magical appeal us edge nowhere build grind vr work x take advantage possible vr help us discover novel ways engage players edge nowhere part classic genre game radically potential thank immersion vr insomniac one best industry create sort experience wait see think latest game madness await', 'partner x partner mean opportunity something employee tobeapartner gigantic possibilities lie aheadto grow person career community live x mission leader opportunity become personal best connect something bigger meaningful world recognize connect something bigger connect customers communities part foster deep sense purpose x believe become part something bigger inspire positive change world around us go community service team throughout year extrashotofgood partner organizations revitalize enhance neighborhoods serve benefit x total pay package call special blend benefit package tailor need partner design benefitseligible partner work 20 hours week get wide range perk benefit assistance special blend might include bonuses 401 k match discount stock purchase options offer adoption assistance health coverage dependents include domestic partner x college achievement plan opportunity benefit eligible yous partner brand complete bachelor degree full tuition reimbursement every year college arizona state university topranked degree program deliver online addition show gratitude partner military service members veterans may extend additional scap benefit spouse child learn partner also appreciate recognition program career sabbaticals timeoff program plus take advantage partner perk 30 instore online discount one free pound coffee box kcup pack tea week diversity inclusion x strive create culture value respect diversity inclusion goal build diverse workforce increase competencies shape culture inclusion develop diverse network suppliers welcome work environment encourage partner engage one another make x place look forward work day', 'provide train key success day day functional skills employees require also broader life skills like acquire another language develop employee language skills example help improve communication also provide intrinsic value employee business accord new study x benefit include increase productivity motivate employees overall improvement retention recent study x show nine 10 employees believe language train relevant job duties 86 per cent report direct positive impact job performance employees also report increase job satisfaction loyalty due company investment professional personal development businesses want improve employee performance trade model change world move ever faster productivity collaboration make break company survey tell us employees find learn new language improve performance work help serve customers effectively 80 per cent employees report gain proficiency second language make productive overall increase confidence communicate necessary perform job function leaders understand value demonstrate commitment people invest holistic talent management program survey find support idea provide language train engage 89 per cent respondents say feel positively toward current employer 84 percent say feel engage work perhaps importantly since recruitment train cost new employees notoriously higher cost retain exist employees 70 per cent respondents say likely stay employer result provide opportunity build lifelong language skills x', 'life insurance provide protection love ones also help preserve wealth supplement retirement income take care family protect unforeseen events important part longterm financial plan recognize important role life insurance play protect assets also family help secure matter offer range solutions provide choice flexibility coverage options term life insurance temporary coverage universal life insurance flexible coverage variable universal life insurance flexible coverage addition growth potential beyond provide guarantee benefit family event death life insurance also offer financial protection love ones business income replacement supplemental retirement income account value growth use financial resource taxdeferred asset protection accumulation efficient mean transfer wealth source fund business owners', 'commit make drive easier safer vision one kill seriously injure new x 2020 today intellisafe technologies support drive help prevent accidents protect one occur safer journey make enjoyable every journey effortless adaptive cruise control automatically maintain safe distance vehicle front speed 50 kmh pilot assist technology work alongside help stay lane gentle steer input 360a surround view technology get birdseye view car surround see obstacles around make park maneuver tight space simple get drowsy inattentive wheel driver alert control alert prompt take break rest stop guidance function even tell safe stop give best view active high beam control allow drive high beam time without dazzle others detect road users ahead automatically shade part high beam would dazzle get optimal light safety improve everyone change lanes confidence safe blind spot information system use radar sensors alert traffic around vehicle keep car safely course lane keep aid sense start leave lane unintentionally gently steer back track cars protect outside well inside vehicle pedestrian airbag xfirst technology automatically inflate impact cover windscreen lessen injuries latest worldfirst safety belt technology protect car leave road common dangerous accident keep firmly strap system electrically retractable safety belt tighten prevent spine compress rough land unique seat structure absorb vertical load give world threepoint safety belt 1959 save countless live vote one mankind important inventions always innovate offer safety belt automatically tighten within thousandths second collision never stop work improve safety everyone cars provide better protection children develop world first rearfacing child seat 2015 celebrate 25th anniversary one important safety innovations integrate booster cushion', 'diamond gemstone precious metal supply chain long complex often lack transparency result jewelry purchasers many jewelry retailers traditionally know little origins precious materials contain jewelry today change dramatically jewelry industry commit better understand social economic environmental impact mine process precious materials well work better ensure activities conduct responsibly x believe traceability key ensure mine operate environmentally socially responsible ways establish rigorous standards responsible mine guide decisions mine directly source end direct source relationships mine around world many case output mine deliver straight x jewelry manufacture diamond cut polish facilities x craft majority jewelry workshops workshops among finest jewelry industry meet highest standards safety cleanliness productive welcome environment craftspeople hire local communities pay fair wag better ensure manufacture operations create positive impact along supply chain way mine customers', 'simple mission think better solutions create better products help people enjoy things love everything support mission point us forward start dr x found company 1964 continue today innovative passionate employees around globe true company build scientific research vision guide human interestshow better sound affect us mean find joy products work exactly want solid customer service nicetohave promise keep maybe important principle live innovation destination journey require new ideas new players invite creators inventors dreamers talented people walk life bring big ideas passion enthusiasm x see part innovation never lose imagination always dream things better think ways reach things dr amar x x always dream reach something better always forever dedicate create better products research', 'household formation essential growth yous house market generate demand three four new house units census bureau fourth quarter 2014 house vacancy survey hvs report annual household formation jump nearly 2 million analysts become hopeful fundamental market driver finally break postcrisis doldrums unfortunately optimism shortlived last two quarterly estimate hvs show household growth plummet half million per year level far worst read great recession new edition house insights x economic strategic research group explore factor underlie recent volatility hvs household growth estimate develop alternative household growth series base smooth trend house unit occupancy rat new set house stock estimate', 'x everything start people mission make people live easier safer better something come naturally us x way today still focus ever three core value safety quality care environment protect important make people feel special take pride help world become better place', 'stevia sturdy green plant whose leave contain unique source natural sweetness grow world fast become one popular crop market food drink manufacturers look use stevia plant extract zerocalorie sweetener reduce amount sugar products x company currently use stevia brand like sprite x life glaceau vitaminwater stevia change way make drink also change world economy famers previously draw irregular income land stevia improve families live story mr stevia kericho county kenya reveal purecircle lead supplier stevia ingredients first introduce stevia new source income farmers kericho initially sell idea kericho kenya tea capital farmers prefer use land tea plant alongside grow food drink need fee families charles langat hardworking farmer kericho drive need provide improve economic lifeline family unexpected think outside box one day hear local radio show new crop name stevia say could help small farmers like make decline income recent years say give chance say father three year ago stevia form backbone income first seed get purecircle company introduce complementary crop us tea growers able pull seed charles explain video share x life farmers kenya stevia use grow stevia grow best upland areas subtropical climate well suit soil charles field best require small amount fertiliser water leave ready harvest three months despite face challenge begin charles sheer determination lead work extra hard yield reap benefit potential stevia help income gap unmatched crop say charles h', 'x manufacture passion passion drive us set worldclass manufacture facilities extreme operational efficiencies record time years earn enviable reputation flawless project execution management perhaps best example manufacture prowess jamnagar manufacture division jmd project titanic proportion require millions engineer manhours spread many international engineer offices thousands tonnes equipment material procure suppliers across globe highly advance mammoth construction equipment workforce 75000 work round clock months great number innovative techniques project execution result jmd establish record time less three years way life mega plant patalganga hazira locations manufacture divisions x create thousands job skilled workforce also train unskilled workers help create strong talent pool every product create make india tag source great honour pride unwavering commitment safety operations stateoftheart occupational health centre ohc equip diagnostic therapeutic equipment man qualify specialists manufacture divisions jamnagar vadodara nagothane patalganga fullfledged modern hospitals look employees also families manufacture divisions iso 140012004 ohsas 180012007 compliant', 'scientific knowledge skin hair accumulate x century open way great innovations active ingredients formulation procedures evaluation technologies x research constantly invent innovate x history mark milestone discoveries take science beauty forward active ingredients derive research regularly contribute enrich products offer consumers around world milestone innovations protection treatment hair skin today constitute exceptional capital enhance expertise group techniques formulation make progress x researchers rely major technological discoveries noninvasive imagery robotics 3d model considerably enrich approach', '225000 businesses use x customers love x fastest reliable way make every agreement approval process simple digital actionfrom mobile device anywhere world say goodbye administrative hassle like scan fax overnighting forever intuitive experience simple setup people love convenience business fastest way get electronic signature approval back customer vendor anywhere anytime x fit right exist systems productive instantly use x 300 popular service like google salesforce box access awardwinning app mobile device work virtually kind document 85 million people rely x esignature standard around world bankgrade security alwayson availability agreements approvals sign send never lose x easily prepare agreements use exist document form virtually file type save time flexible workflow capabilities allow automate standardize critical process ability set order step roles recipients transaction robust data control help eliminate data entry errors prepopulate field gather validate data sign push data gather systems customers vendors quickly access sign legally bind document device 43 languages ensure signers say fully integrate authentication options also option collect payment information key data need complete transaction get instant visibility status agreement know exactly sign keep process move forward save execute agreement x cloud access complete digital record time transfer systems comply company policies x change business get do empower 225000 company 85 million users 188 countries send sign manage document anytime anywhere device trust confidence x replace print fax scan overnighting paper document transact business x enable organizations every size industry geography make every decision approval workflow signature fully digital x go keep life business move forward', 'x shape grow electric transportation et industry nonroad onroad find ways help customers choose purchase electric vehicles evs offer lower electricity rat program offpeak usage customers save charge cost help commercial industrial customers reduce cost environmental impact increase efficiencies use electricity rather traditional fuel transport cargo commit research development market et since early 1990s currently test evs charge technologies use operations electric bucket truck gm ford tesla nissan vehicles study impact et grid reliability develop mitigation strategies lessen eliminate impact help develop charge infrastructure standards include standards vehicletohome vehicletogrid technologies well fast charge wireless standards work vehicle manufacturers maximize benefit customers work vehicle manufacturers epri bring economically technologically viable onroad et technologies marketplace', 'delight x announce finalist elearning award 2016 elearning age outstanding learn organisation category shortlist prestigious award continuously successful result sustain period learn development technology industry strength language learn programme business education use digital learn approach help businesses meet learn goals deliver train interactive convenient convince judge panel effectiveness solutions able take case study examples positive outcomes school businesses work include walgreens boot alliance frankfurt international school harrogate grammar school demonstrate effectiveness impact x work also strengthen survey reveal crosssection 12000 global enterprise customers find respondents felt company take interest development provide language train turn improve future job prospect give opportunity career advancement 89 felt positively toward employer 84 felt engage work 70 say likely stay employer result provide opportunity build lifelong language skills x proud take part elearning award wellknown industry event guests represent organisations uk company around world award ceremony 25th november london', 'unman aerial vehicles uavs may know drone ready soar hit hobbyists become important tool business shoot videos photos inspect hardtoreach locations like oil pipelines research weather scratch surface network connectivity could give drone major boost mobile world congress say work others industry test network higher altitudes study network address today challenge support tomorrow opportunities change faa regulations govern uavs may require achieve full potential capabilities faa also refer drone unman aircraft systems uas right know much network coverage grind heights drone fly foundry engineer use predictive analysis measurement tool study urban rural suburban areas sky like grind plan use balloon drone tall build gather data safely data better understand strength characteristics network coverage drone flight potential opportunities see connect drone drone pilot use shortrange radio frequency rf wifi communicate vehicles today lte connection drone would cellular network smartphone use give longer range communications also give stronger security x wireless network signal require authentication encryption drone research conduct x foundry palo alto collaboration internet things solutions group stay tune news drone project get grind', 'key vector help x grow establish global stage strong business excellence movement group excellence continual quest x x support efforts achieve worldclass standards aspects operations grouplevel process systems encourage enable business excellence model x use x business excellence model xbem cover business aspects range strategy leadership safety climate change adapt renowned malcolm baldrige model xbem encourage continuous improvements formal system benchmarking assessment support xbem initiative fall aegis x business excellence group xbexg inhouse organisation mandate help different x company achieve business excellence improvement goals forum x business excellence convention forum bring together champion excellence x world global experts speak challenge opportunities recognition jrd qv award function hold annual group leadership conference aglc recognise x company achieve significant improvement excel quality journey', 'food safety supply x food safety top priority restaurant food safety systems include rigorous standards train employee health product handle ingredient product temperature management prevention cross contamination food safety train focus illness prevention food safety regulation adherence daytoday restaurant operations commit operate great restaurants strive meet highest food safety standards demonstrate every aspect businessfrom raw material procurement include animal proteins produce food preparation serve customers', 'challenge face alone ones confront world today demand come together us need access opportunity go reach fullest potential also need healthy environment order thrive connections inspire us even create opportunities protect world live aim act larger scale way sustainable longterm test new ideas invest new solutions commit continue journey help create better future everyone', 'x one influential research advisory firm world work business technology leaders develop customerobsessed strategies drive growth x unique insights ground annual survey 500000 consumers business leaders worldwide rigorous objective methodologies share wisdom innovative clients proprietary research data custom consult exclusive executive peer group events x experience singular powerful purpose challenge think clients help lead change organizations x clients want make impact want challenge futurefocused think drive growth result value bridge manage today reality realize tomorrow potential challenge clients provocative original ideas offer path forward improve business result x core value guide us everything client x clients come first better job never stop work collaboration collaborate one another clients share ideas honestly work problems together courage always easy make tough call clients colleagues expect value x integrity practice truth clients employees shareholders count us honest trust us quality often use clients describe x service employees critically important company attribute', 'razor evolve dramatically past century first safety razora razor handle house doubleedge razor bladeto proshield lubrication technology x forefront shave innovation see x innovation produce better shave century century begin system razor 1903 x introduce world first system razora twopiece safety razor thin strong sharp doubleedge blade attach reusable handle x system razor hit market take long blade sales reach millions fact still get x platinumplus doubleedge blade era safety razor innovation 1971 x push razor innovation launch trac ii first safety razor twin blades long 1977 x step safety razor yet atracontour system give men power first twinblade cartridge pivot head allow blades better follow contour face even closer shave x introduce world first system razora twopiece safety razor thin strong sharp doubleedge blade attach reusable handle think outside blade 1985 x ability innovate safety razor go beyond steel blades handle introduction atra pluscontour plus x first razor lubricate strip hit market incorporate strip blades improve glide safety razor skin increase comfort level shave 1990 twin blades sensor safety razor individually mount highly responsive spring automatically adjust contour shaver face break performance barrier 1998 x rocket men even smoother closer shave launch mach3 first safety razor threeblade technology x continue innovate mach3 system expand capabilities razor present mach3 turbo feature lubricants larger skin guard versus mach3 today technology work 2006 fusion safety razor debut manual power versions feature five blades surpass mach3 comfort fusion proglide arrive 2010 take precision performance thinner finer blades gillette body introduce 2014 alter landscape manscaping first razor build male terrain year also bring next evolution shavingfusion proglide flexball technology multipivoting razor build maximize contact every contour man face finally fusion proshield bring lubrication next level 2015 lubrication blades proshield shield shave help protect irritation next safety razor always get closer x never stop look ways improve shave experience want help look feel perform best every day drive quest give men closest precise shave world century ago king c x say stop make razor blades keep make better', 'scrapbook online platform launch channel 4 build channel 4 x 19 weeks global custom software company reveal service award best technical innovation prestigious online media award last month scrapbook allow channel 4 present viewers curated bookmarks group interest relevant link key program presenters allow users collect store favourite bookmarks viewers quickly easily gain channel 4 talent show find anything recipes latest gordon ramsay cookalong house buy tip location location location platform build 19 weeks x team london india use continuous delivery design techniques also pioneer project c4 design base open source nosql database system mongodb x collaborate inhouse team design consultancy clearleft frontend design barry areilly consultant x comment long relationship channel 4 work closely number past project delight choose help build scrapbook scrapbook great example achieve combine continuous delivery lean product development approach extremely proud result especially scalability enable cloud allow site easily grow develop future scrapbook attract many register users since launch last year build deal extremely high volume traffic expect one nation popular tv channel host entirely cloud site capable handle 2500 page view second', 'x allow quickly securely make every agreement approval process digitalfrom device anywhere world simple use implement even complex workflows quickly automate keep business move forward faster intuitive experience simplest implementation available x enable accelerate transactions reduce manual paperwork day one provide handson expert support guide success digital initiatives every step way get run immediately x bestinclass esignature application connect exist systems 300 prebuilt integrations industryleading esignature api build custom endtoend workflows highly secure encryption standards alwayson availability complete digital audit trail x give total confidence every transaction 225000 customers 85 million users worldwide rely platform execute protect even sensitive transactions customers look onpremises sign regulate industries market offer x signature appliance x easily prepare agreements use exist document data systemsno need create new form rekey data flexible workflow capabilities let share agreements right people right order define roles recipient automate use slow manual process ensure signers say use advance authentication methods match need customers quickly sign legally bind contract device 43 languages provide key data like phone number credit card complete transaction plus standardize scale process across team entire organization brand experience users get instant visibility status every digital agreement full report functionality across organizationno blind spot transactions securely retain document data x cloud transfer systems complete digital audit trail ensure compliance confirm validity legal enforceability transactions', 'industry interest point history today convergence operational information technology itot sometimes term fourth industrial revolution enable confluence industrial internet things iiot big data analytics cloud mobile pace change opportunity within industry beginnings exponential phase within realm asset performance management apm begin see company develop new level intelligence visibility operations case lead toward wholesale transformationssuch development new revenue stream business modelscreated technology revolution form smart connect assets level opportunity smart connect assets present within apm cost inaction extremely high critical importance company take part iiot education investment begin build smart connect asset capabilities avoid leave behind sure top competitors smart connect assets allow company unprecedented visibility intelligence state production assets creation smart network embed sensors associate software automate operations predict issue arise present information realtime already manufacturers move away reactive maintenance past years toward predictive model achieve new level uptime cost save go certain case company alter business model offer capacity instead capital goods flight hours rather jet engines guarantee asset uptime scenarios transformation infancy represent major come differentiator businesses outmaneuver competition offer customers amount essentially riskfree operational environment around products recent research confirm market begin realize importance apm improve operational excellence still lag smart technology investments need make smart connect assets reality 70 respondents lns research asset performance management survey respond apm investment increase within year 15 say would increase significantly early adopters additional advantage forgive market rule engagement users vendors much negotiation collaborative environment involve giveandtake allow experimentation data ownership service level establishment issue though company begin focus apm tool improve operational performance slower activity investment around iot technology necessary smart connect assets accord data nearly half respondents yet invest smart technology date 20 complete investment leverage data full effect value smart connect assets demonstrate marketplace expect balance change time firm able develop realtime intelligence capabilities smart connect advantage distinct advantage vs improve operational performance lower cost deliver products input nascent relationships facilitate new products business modelsservices conversely organizations fail educate invest appropriately around smart connect assets near future run risk leave far behind', 'pride duty honor discipline foundations military service x serve country turn military train opportunity serve 45 million customers veterans natural fit x culture military industry similar exemplify dedication commitment safety teamwork excellence many veterans join x participants leaders company veterans currently account 10 percent company 27000 employees company military recruitment development efforts earn x designation highestranked utility gi job top 100 military friend employers list six consecutive years company also recognize top 10 company veterans diversityinc valuable employer civilianjobs best vet employer military time edge additionally x found partner troop energy job program support join force initiative participate annually 30 military recruitment events partner military transition center across country today x subsidiaries electric utilities nation partner yous army yous navy yous marine corps yous air force develop innovative energy project base', 'x inc nyse x dedicate change way world learn company innovative technologydriven language literacy brainfitness solutions use thousands school businesses government organisations millions individuals around world found 1992 x pioneer use interactive software accelerate language learn today company offer course 24 languages commonly speak english spanish mandarin less prominent include irish swedish tagalog company found 1992 core beliefs learn speak language natural instinctive process interactive technology activate language immersion method powerfully learners age since 2013 x expand beyond language deeper educationtechnology acquisitions livemocha lexia learn vivity labs tell x base arlington va offices around world', 'uncompromised clarity razor sharp focus x high definition optics hdo lenses optimize safety performance meet uncompromising demand professional athletes settle nothing less clearest sharpest accurate vision offer truer accurate vision versus conventional lenses magnify image make object appear shift true position hdo x lenses meet exceed test standards american national standards institute yardstick performance eyewear industry clarity test measure sharpness image view lens refractive power test measure inferior lenses distort vision magnify image prism test measure lenses bend light make object appear shift true position test show conventional lenses compromise vision', 'atlanta x today announce 10th consecutive year idg computerworld recognize company one best workplaces information technology professionals year annual rank 100 best place work x highestrated large utility company technology important deliver products service customers serve ever say x executive vice president chief information officer martin b davis particularly honor recognize full decade one best place technology professionals work underscore longstanding commitment innovation culture employee excellence growth computerworld 2016 best place work feature rank top 100 work environments technology professionals base comprehensive questionnaire regard company offer categories benefit career development train retention addition computerworld conduct extensive survey workers account approximately half total score 23000 employees final 100 company across country complete computerworld survey employee survey include topics satisfaction train development program compensation benefit work life balance organizations year best place work list excel create dynamic satisfy work environment say scot finnie editor chief computerworld competitive market tech talent outstanding employers able attract highly skilled pros offer great benefit new learn opportunities access cuttingedge technologies challenge businesscritical project', 'x unique company culture center best people world empower excel make us leader diversify manufacture industry nurture culture carefully years deeply gratify way people world readily accept work hard preserve unique characteristics x culture would like remind everyone important part culture conduct business highest regard integrity business ethics grow formalize aspects company culture train x learn development team rule road believe equally important us formalize expectations regard business integrity ethics x code serve purpose well pride creative flexible open empower daytoday business interactions guide x rule road look set guidelines appreciation unique empower company culture cultural creed portion particularly helpful regard believe minimize bureaucracy maximize control destiny make best decisions business case business decisions must strive accordance highest degree professional business ethics obligation shareholders conduct business lawfully utmost integrity look x code guidance meet important obligation x code list thou shall nots simply impossible envisage possible business scenarios might encounter draft code expect look code begin point chart right ethical course follow x code explicit doubt need employ one essential principle right thing sincerely mark mondello chief executive officer', 'patrol high seas poachers conservationists come across unexpected treasure two blue whale frolic southern ocean soon crew members aboard sea shepherd australia steve irwin realize stumble upon dispatch dronemounted camera get bird eye view gentle giants footage return absolutely stun film endanger blue whale calf drone unbelievable spot blue whale deck steve irwin thrill able film biggest animals planet air truly aweinspiring gavin garrison drone pilot say statement blue whale balaenoptera musculus largest live animal find throughout world oceans creatures grow nearly 100 feet long weigh approximately 420000 pound nineteenth twentieth centuries blue whale hunt nearly extinction thank international ban blue whale hunt however populations stabilize slowly begin recover', 'us better health care system start simpler process one let us see behind scenes find procedure cost get example better health care system save money course keep healthy work doctor hospitals health network align economic incentives everyone focus stay health finally think better system one connect right technology connect health care team seamlessly put valuable information need get right care right time everything x start value clear strongly hold set core beliefs reflect expect us create core value together company guidance customers value carry thoughts action every day inspire innovation products service drive commitment excellence integrity right thing right reason excellence strive deliver highest quality value possible simple easy relevant solutions care listen respect customers act insight understand compassion inspiration inspire explore ideas make world better place health care system build around nation waste 765 billion dollars year inefficient unnecessary health care better way better health care system focus health ailments support everyone journey wellness make health care decisions choose doctor convenient simple mobile device reinvent health care system build healthier world around', 'engage audience efficiently reply single click anyone teamain region departmentacan quickly respond message mention comment single dashboard identify influencers lead listen closely people matter business create import share list social influencers important clients save time prewritten responses quickly respond common question customer request save preapproved onbrand responses future use manage engagement workflows mirror exist workflows people see post matter themaensuring responsive engagement avoid miss message track interaction history see interactions contactaacross organizationaso conversations context consistent matter engage search location language monitor social conversations across globe around neighbourhoodain multiple languagesaand exactly audience', 'processors brain machine important get one powerful enough need 5th generation x core processors x offer suite amaze builtin feature save money let us find performance boost demand x turbo boost technology 20 automatically provide greater boost speed reduce lag time meet heavy process demand highend apps additional performance need buy powerful processor maximize occasionally builtin graphics every 5th gen x core processor group technology feature design enhance visual experience get 20 better graphics performance enjoy 4k movies smooth seamless video chat without additional hardware external graphics card videos finish minutes builtin visual feature x quick sync video speed hardware performance video edit burn share reduce wait time hours minutes things enjoy keep wait pc builtin security protect identity online secure data guard malware without purchase additional software get choose 5th gen x core processor many threats online security measure offer greater peace mind', 'retrain reskilling workforce daunt even startup handful employees nearly 140year old company 280000 employees globally seem impossible often need things seem impossible time technology wait one x know want pivot softwarecentric network know mean reorient workers softwarecentric career get softwarecentric network talk quite bite blog check andre fuetsch update network demand trend update software journey year mobile world congress short future back network traffic increase slowly predictably mostly voice call build network hardware send truck technicians install new gear like appliances routers switch appliance equipment makers build stuff last years even decades luxury anymore demand network capacity boom turn network hardware appliances software apps similar probably swap separate camcorder alarm clock cd player apps smartphone move network cloud need workers specific skills make happen set ambitious goal move 75 network software 2020 hit 57 2015 accelerate plan hit 30 end year keep pace help employees learn skills need need softwarecentric need experts variety software specialties include network function virtualization software define network security data analytics internet things many technologies run open source software even need nontechnical workers verse areas salespeople lawyers accountants recruiters market experts also need understand go know need rather wholesale hire new talent outside choose place bet reskilling people human resource experts outline plan continue drive effort help employees expand learn skills future train internal x know also need outside help join force organizations like georgia tech udacity university oklahoma pace university champlain college others furthermore x provide target tuition discount 32 universities like stanford boston university nyupoly know go need data scientists next years interest great give us call reality slot folks job market fill plus tremendous benefit take someone know x culture heritage employees view hire trend job link directly data science certification train take step transform data scientists depend current skillset could mean secure specialize credentials call nanodegrees take 49 months complete even collaborate georgia tech udacity create firstever massive online open course platformbased master computer science let students learn pace program open students beyond x support program x aspire ongoing commitment prepare learners success school 21st century workforce use power network build better tomorrow use innovative solutions widen develop diversify talent pipeline address shortage current future technology experts aware company retrain workforce grand scale know ask lot employees think opportunities great inspire stories come employees go skills pivot look blog frequently ask really possible workers make pivot truth take us years complete transformation legacy systems need maintain interim clearly need go think industry need go want help employees get', 'compassion walk shoe people serve work believe order achieve full potential enterprise purpose help people live healthier live must fully understand align need realities value compassion walk shoe people serve work celebrate role serve people society area vitally human health must truly compassionate genuinely understand feel identify need behave actively listen fully understand genuinely empathize people realities respond service advocacy individual group community society whole', 'last week explore ways email personalization x social media integrations could help business make money week focus revenueboosting benefit incentivizing campaign send cart abandonment message customers online shop cart abandon number reason maybe customer second thoughts maybe website time orand let us real heremaybe customer get distract cute animal video whatever case might connect store x plenty integrations make easy follow encourage customers complete purchase send followup email wouldbe patron navigate away store followup email help keep products fresh mind make easy jump back buy process pick leave also make sure sensitive time send immediately chance might annoy come across desperate wait long chance lose interest forget want item buy someone else many industry experts recommend send email within first 24 hours abandonment test help identify resonate customers remind shoppers abandon may seem like nobrainer send cart abandonment email forget clearly state intention message mention actual items customer leave cart include picture item price maybe even brief description satisfaction guarantee customer add item cart reason give little nudgewithout pushy remind get might seem counterintuitive offer discount freebies make money consider big picture customers use coupons discount still spend money products case might even incline spend know get something else lower price plus build brand loyalty ways incentivize email campaign reengage inactive customers customers make purchase past since become inactive maybe need little extra nudge come back create segment everyone make purchase within specific period time send email promote new products store upcoming events special subscriberonly sales plan future could even offer limitedtime coupon discount encourage act quickly', 'serve america since 1928 1928 two men share dream provide quality insurance product reasonable price decades follow grow adapt meet change need americans one constant remain unwavering commitment uphold found ideals provide industryleading products firstrate service customers privilege serve x pride help plan wisely unexpected also help restore order occur keep move along road life plan 1959 x customer write us letter surprise gratitude car battery replace hour steal letter couple 2002 write x agent claim adjuster awere exceptional handle grief need helpful many waysa year hurricane rita strike beaumont texas x send 300 agents assess damage policy holders evacuate x also donate 100000 city emergency operations center two megawatt generators restore power beaumont whatever year decade disaster occur count us today company comprise x insurance group company make one country largest insurers vehicles home small businesses provide wide range insurance financial service products x proud serve 10 million households 19 million individual policies across 50 state efforts 48000 exclusive independent agents nearly 21000 employees x exchange three reciprocal insurers x insurance exchange fire insurance exchange truck insurance exchange own policyholders together subsidiaries affiliate comprise x insurance group company x group inc subsidiaries capacity attorneysinfact provide administrative management service x exchange story begin simple goal insure vehicles rural farmers world change', 'inspections repair even put ton miles vehicle inspect tyres least month always long trip important keep eye excessive irregular tread wear inflation damage like scrap bulge crack puncture present experience continuous pressure loss tyre dismount inspect damage train professional see repair make tyre wear tear misalignment front rear tyre rapid even wear frontwheeldrive vehicles independent rear suspension require alignment four wheel instead two get alignment check specify vehicle owner manual recommend way prolong tyre life sometimes irregular tyre wear correct rotate tyres consult vehicle owner manual visit store location near find appropriate rotation pattern vehicle tyres show uneven wear ask goodyear expert check correct misalignment imbalance mechanical problems involve rotation tyre tread directly affect grip road important regularly inspect visually sign uneven wear sign include high low areas unusually smooth ones', 'wonder x realsense technology help make school life better well look turn amaze video presentations create 3d model ease ensure every shoot project great may find answer x realsense technology make possible depth sense 3d camera technology let see things like human eye mean camera distinguish different object frame recognize gesture adjust photos even taken1 read see feature help make schoolwork fun create dynamic video presentations spice group work x realsense technology ability distinguish surround replace background excite locations graphics need green screen postproduction software next geography class take classmates journey sahara explain desertification also great collaboration especially pair personify app let work others virtual space use skype webex hangout share slide content friends almost room together use app fun stuff like plan tactics next football match friends create 3d model get whole lot easier x realsense also make 3d scan pc reality take image sculpture flower toy turn 3d object ready manipulate even print 3d technology also let us get measurements instantly snap picture draw line object screen see length distance could help make design workshop class breeze tap edit photos perfect shoot still struggle get perfectly focus photo x realsense camera change focus one quick tap even take shoot single shoot shift focus different subject image photo presentation look way want also use snap note class worry focus shoot control presentations gesture device x realsense technology control without ever touch 22 track point per hand may able change slide play video wave hand front class tell everyone project attention device also make fun much like kinect depthsensing technology allow play motion game device lecture hang friends without need accessories', 'start 1982 one restaurant columbus oh since grow store every state yous continue open bdubs around world welcome earth really need know us three things wing beer sport three things matter us much fan want aboutmaking fan happy matter many locations open corporate headquarter many years around one thing remain x wild wing ultimate place get together friends watch sport drink beer eat wing still read wow must bore trivia baseball hat use make straw oldest recipe ever discover beer x wing invent samurai make one love wing beer sport like place like things still might something would like', 'x believe serve communities integral run business successfully part individual responsibilities citizens world mission program bring life x value good corporate citizenship support communities ways enhance company reputation employees customers business partner stakeholders support visionary nonprofit organizations historic preservation long hallmark x involvement community reflect recognition contribution historic sit monuments sense national local identity role preservation play attract visitors revitalize neighborhoods today leaders navigate world undergo continuous change landscape change tool leaders need harness change improve organizational individual performance appreciate impact talented leaders business society whole x service hallmark company throughout 160year history service ethos come life every time help customer whether simple everyday request emergency situation show care commitment service communities', 'today x director social impact lindy stephens join civil liberties environmental digital right organisations senator scott ludlam internet society australia canberra call australian internet users say mass dragnet surveillance member citizens suspect x australia name former x aaron swartz back global effort pressure lawmakers end mass surveillance blacken display banner websites today lindy stephens x director social impact say dragnet surveillance compatible democratic governance new rule must set protect privacy digital agea day fight back chance australians call lawmakers understand difference technically possible legal acceptablea action part legislators need restore trust internet stop misuse technology mass surveillancea plenty viable human right civil liberties arguments mass surveillance also know bad business witness firsthand adverse effect nsa interception data confidence us cloud study point 45 billion opportunity costa activities australian signal directorate also demonstrate need australian government take note today stand mass surveillancea time laws standard operate procedures catch technology australian businesses vulnerable confidence use internet conduct private conversations secure financial transactions falter ms stephens continue', 'look flexible convenient way manage cash flow loan management account lma account flexible line credit use almost purpose whether look help family member remodel kitchen pay tax cover education cost lma account help lma account generate cash consolidate outstanding loan desire gain clearer picture balance sheet use lma account use lma account convenient way pursue variety personal business finance need include personal investment real estate purchase luxury purchase tax payments education cost medical expense weddings debt consolidation business startup expansion acquisitions diversification concentrate securities position emergency expense borrow make simple guarantee benefit insurance policy back claimspaying ability issue insurance company back x affiliate x affiliate make representations guarantee regard claimspaying ability issue insurance company lma account secure line credit use exist securities stock bond collateral fee establish minimum balance annual fee access fund need access fund generally within one day approval access credit form fix rate variable rate loan financial advisor help choose loan term work best individual situation', 'use imaginatively light dramatically increase potency beautiful iconic structure change whole community strike attraction vietnamese port city da nang dragon bridge create entirely new tourist attraction spawn many businesses around giant sculpture snake harbor cross curve metallic spine form enormous arch traffic road strike enough sight day night dragon bridge become national mustsee put da nang firmly country tourist map city attract three million tourists year part thank display 900 lead light instal x dark surround brilliant lead light show make appear golden dragon fly cloud biggest thrill giant iron creature breathe real fire enormous mouth thrill sight crowd flock see weekend even time visit specially see flame dragon bridge shoot night sky colorful film one south east asia intrigue countries show dragon bridge change one local woman life create excite new job opportunity le thi vinh ditch factory job become bridgeside juice vendor thrive business perfect illustration way vibrant lead light cities transform space turn generate tourism stimulate economic growth', 'ever since arabica bean introduce costa rica 1700 country economy culture steep coffee today costa rica roughly 70000 coffee farmers nearly third country workforce employ industry costa rica coffee crop way life despite relatively small country production size costa rica important within industry government strongly commit quality sustainability coffee country influential among coffeegrowing countries region often pioneer best practice support producers addition active role take government organizations like costa rican coffee institute icafe help improve profitability farm provide resources like agronomy costa rica particularly special x 2004 x open first farmer support center capital san jose team agronomists cuppers quality experts work directly farmers local government officials help improve production highquality coffee implement better grow conservation techniques anything endure success costa rica coffee industry boil passion people coffee soul country x offer coffee costa rica since open doors 1971 feature many finest blend offer limit edition x reserve coffees thankful growers like la candelilla estate bella vista continue inspire us passion incredible coffee', 'get shape combination effective exercise 30 minutes fitness trainer kit rich incorporate traditional circuit yoga pilates fullbody workout benefit combine get cardio stretch strengthen one workout kit say first section intend get heart rate blast calories second part routine inspire yoga flow part three inspire pilates focus core warm light cardio 23 minutes home office lightly jog place begin make sure also circle arm forward back wake shoulder chest back click full detail description exercise ready let us go break 30 second repeat exercise one time total two round', 'amaze small computers get even donglesized device put pc palm hand meet x compute stick plug tv transform screen computer x compute stick look like normal flash drive inside truly remarkable stick tv hdmi slot enjoy benefit quad core x atom processor 32gb ram micro sd slot wifi connectivity also come usb bluetooth port keyboard mouse give pc experience big screen1 add together great companion device basic feature regular computer mean 5 reason get x compute stick get smart tv without buy smart tv enjoy cool feature smart tv regular hd tv one small addon simply plug x compute stick connect social media browse photo albums surf web even play game save money could possibly use new sound system make experience better experience online entertainment big screen nothing better watch favorite show movies home tv x compute stick become media entertainment center download stream music videos play x compute stick imagine stream sit youtube netflix available full hd desk space problem x compute stick give large screen experience desktop pc without need tower unit may less performance focus great need connect internet write email basic task mount screen wall plug stick good go stay connect travel imagine travel pc pocket get x compute stick simply plug hotel room hd screen log wifi instantly connect internet work even home even need bring along charger batteries require familiar pc experience tv x compute stick run windows 8 free upgrade windows 10 operate system os many regular pcs mean use windows already know use plug access internet watch videos browse photo albums moments', 'tablets seem rage nowadays use watch movies bed play game daily commute surf net comfort couch good apart usual ways use tablets great reason tablet second screen pc tire switch document notebook try keep tablet open second screen easy reference view note tablet type work report notebook check game tip middle excite adventure universal remote devices home imagine able control everything tv volume home security system one device tablet apps apps like smart things control 4 let control various aspects home app media center windows android turn phone universal entertainment remote creative tool music paint write tablets generally bigger screen compare regular smartphone may even powerful processors make tablets nifty device draw something put together new beat never know inspiration strike portability tablet help let capture export share creativity friends tap interactive picture frame home instead bore old photo frame prop tablet coffee table turn interactive slideshow next time use need dig heavy photo albums show latest vacation integrate car dashboard tablet probably already portable jukebox navigation system roll one make sense use feature car well need dashboard mount might get lose bore tablets powerful versatile devices lot potential might surprise capable take look latest tablets market', 'little adrenaline flow arena postseason year mobile data flow since pro hockey basketball playoffs start april millions fan pack arenas witness action share favorite play postgame celebrations friends family via mobile devices many venues instal specialty instadium network call distribute antenna systems das das support additional mobile data demand network provide perfect assist tens thousands people try share slap shoot slam dunk interest data traffic stats year hockey basketball playoffs total cellular data usage network game 164tb equal 469m social media post photos average cellular data usage network game 118gb increase 53 compare average data usage per game month march across venues basketball fan use average 122gbgame compare hockey fan use average 111gbgame 10 data use basketball fan per game playoffs postseason hockey game best save last highest single game total cellular data usage chicago arena june 15 386gb data cross network postseason basketball game highest single game total cellular data usage arena oakland june 7 249gb data cross network final round hockey playoffs fan use average 221gbgame 151 data average game first round hockey playoffs mobile data breakaway network last years especially big sport events brag friend quicker easier ever many use video announce earlier week 2014 video double wireless network keep work constantly improve experience stay top stand', 'throughout history x fuel hardbody fitness core align worldclass athletes combat arena x quickly become synonymous dedication hard work passion root combat sport x evolve focus train fitness athletes discipline x remain commit essence discipline determination motivationand today inspire athlete every individual', 'come success mound power pitch two word go handinglove softball expert jennie finch begin pitch career eight years old share three simple yet effective tip help throw harder feel stronger start focus leg drive powerful pitch start firm foundation legs every time establish solid base allow put incredible force behind ball next come arm speed faster arm move faster ball reach plate maintain straight arm follow inline circle finish strong focus resistance resist forward motion front side body particular front thigh spin power torque ball originate watch learn jennie demonstrate three key pitch power', 'x global consult development custommade software release latest technology radar study look key trend impact software development business strategies report base practical experience company offices around world structure around four areas techniques platforms tool languages frameworks company challenge best way confront rapid change say craig gorsline coo president x technology radar tool help company stay current landscape constantly evolve company use software fit need customers ones create competitiveness solve current future business problems 2015 software security continue gain importance say dr claudia melo technology director x brazil many still rely traditional security approach base specifications validations development cycle advocate inclusion safety practice throughout cycle start design delivery customer main topics edition technology radar areexplosive growth devops arena much work radar involve evaluation various technologies relate devops grow swiftly innovation area constant believe likely go next generation data platforms gain traction big data nothing new even advise buy hype time start see relate technologies excel useful businesses developers focus security tool every week new stories data leakage misuse demand secure systems respect privacy data grow tool mention edition technology radar help developers build secure systems infrastructures', 'choose right tyre choose right tyre depend vehicle drive style road condition drive tyres meet exact goodyear standards focus pick tyre right need sure take drive style account choose tyres make frequent long journey find economical tyre give mileage consideration sportier drive style consider tyres good corner grip evaluate performance characteristics tyre help find tyre better suit style oe original equipment tyres fit car factory vehicle manufacturer select oe tyres vehicle manufacturers usually choose one serve widest range buyers may recommendations replacement tyres owner manual typically oe tyre well suit vehicle also consider alternatives impossible tell exactly long tyre last much fuel help save dealer advise best value tyre drive need budget', 'offer everyone better way forward time many new employees join group worldwide team work hard tremendous commitment jeandominique senard management team become convince x need set share statement bring employees together beyond individual missions give rise draft group purpose share first time april 2013 3000 managers paris x believe mobility essential human development innovate passionately make safer efficient environmentally friendly firmly commit offer customers uncompromising quality priority x believe personal fulfilment want enable everyone best want turn differences valuable asset proud value journey build better way forward everyone', '10 million users count power effect positive change hootgiving use software skills power social media change world live make easier nonprofit harness power social media offer nonprofit discount 50 social media solutions take advantage personalize education one social media coach optimize social media strategy learn measure direct social media roi endtoend track delegate task manage permissions collaborate efficiently team members next big thing program dedicate inspire facilitate next generation entrepreneurship give young innovators tool education need bring ideas life build better future nonprofit able dedicate social media managers x platform couple personalize education x social media coach let us us leverage regional lead engage social organization behalf', 'us address world greatest health need x expertise prove pharmaceutical leader focus passion entrepreneur innovator result something rare health care today global biopharmaceutical company ability discover advance innovative therapies meet health need people societies around globe commit patientcentered innovation come innovate x start patient draw deep expertise difficulttotreat diseases understand patient journey identify opportunities create better outcomes every stage patientcentered approach discovery development ensure remain focus goal improve live far reach focus people today live longer healthier live along longer life expectancy come higher prevalence chronic disease take broad perspective improve healthcare commit new think approach strive find new solutions enable healthcare systems bring medical innovation patients cost effectively', 'chicago business wire philadelphia cream cheese take line sweet savory spread next level two new flavor olive peach make real ingredients include farm fresh milk cream real fruit vegetables philadelphia cream cheese spread provide creamy canvas breakfast also spreadable snack option aphiladelphia cream cheese recognizably know breakfast spread atop favorite bagel appetizer crowdpleasing dip say ken padgett associate director philadelphia cream cheese anow want inspire cream cheese lovers think beyond bagel 12 flavorful spread jalapeno peach blueberry olive flavor everyone pair perfectly snack time favoritesa inspire consumers think endless snack combinations philadelphia cream cheese spread brand launch phillyflavors contest run july 6 philadelphia encourage fan share photo creative snack ideas feature philadelphia cream cheese spread use phillyflavors contest twitter instagram chance win big fun stop july 13 july 21 fan vote favorite combinations help determine top three finalists lucky three receive allexpenses pay trip new york city compete ultimate snack showdown official philadelphia spokespersons celebrity judge haylie duff brandi milloy select grand prize winner recipient 5000 check ultimate brag right ai thrill partner philadelphia cream cheese find new excite snack options family challenge say duff aphiladelphia many different flavor choose wait see everyone come philadelphia cream cheese spread feature fresh fruit vegetables contain artificial flavor spread available 12 flavor varieties include strawberry smoke salmon pineapple spicy jalapeno honey pecan garden vegetable chive onion brown sugar cinnamon blueberry newest additions portfolio olive peach well black cherry debut last fall philadelphia olive cream cheese spread feature real spanish olives red bell pepper savory snack spread pita sprinkle feta philadelphia peach cream cheese spread feature real peach pair well banana cinnamon sweet snack philadelphia black cherry cream cheese spread feature real black cherries go perfectly chocolate wafer cookies asnacks fun way roll sleeves get creative kitchen say milloy athe new philadelphia cream cheese spread bring delicious flavor whether look something savory sweet make easy create snack perfect youa philadelphia cream cheese newest spread available major grocery retailers nationwide msrp 279', 'x style may fresh tomorrow go way back 1853 x begin later man partner jacob davis invent blue jean innovate ever since x one world largest apparel company global leader jeans x brand part story also home dockers denizen 500 store products available 110 countries around world empathy begin pay close attention world around us listen respond need customers employees stakeholders integrity mean right employees brand company society whole ethical conduct social responsibility characterize way business pioneer spirit start 1873 first pair blue jeans still permeate aspects business innovative products practice break mold take courage great courage willingness tell truth challenge hierarchy accept practice conventional wisdom mean stand convictions act beliefs', 'publish feb 9 2016 zika virus catastrophic death toll mosquitoborne viruses hypothesis exist factual evidence connection zika virus microcephaly cause world health organization declare global public health emergency declaration imply prove link zika virus various neurological diseases mean association bear study possible link bring resources bear aid development zika diagnostic test vaccines treatment options although zika virus new status expedite development vaccine process often long tedious typically take many years many scientists say zika vaccine could ready test two years yet could another decade regulators approve zika spread quickly important type mosquitoes capable carry virus present within entire southern region unite state february 2 2016 first locally transmit yous case zika confirm dallas county though patient infect sexual transmission mosquito bite tell zika virus spread mosquitoes think mosquitoes traditionally active dusk dawn zika virus actually spread mosquito call aedes active day make difficult prevent contact people several precautions take help lower risk contract zika virus think may symptoms zika virus contact healthcare provider assistance', 'greece continue undergo economic hardships many countries company organizations try help country carve path recovery x foundation one focus support aspire greek entrepreneurs make ideas business reality x foundation donate 50000 venture garden greek entrepreneurship education program support hellenic initiative thi found 2012 x chairman ceo muhtar kent four business leaders thi aim galvanize support greek diaspora philhellene community assist greece economic hardship believe power every individual act changemaker greece path toward recovery x efforts gear toward reignite support greek entrepreneurial spirit turn stimulate economy employment venture garden program give emerge entrepreneurs opportunity discover unleash true potential say nectaria metrakos senior public affairs communications manager x hellas responsible greece cyprus malta', 'revolutionise first class first apartment seat large leather armchair separate bed 6 feet 10 inch even space walk around close privacy doors six first apartments interconnect perfect travel companion alternatively might want invite travel partner first class join apartment meal meet apartment find vanity unit light makeup mirror first class amenity kit bag inspire rich heritage artistry emirati people feature pattern sadou colourful centuriesold abu dhabi weave craft guests enjoy luxurious fragrances new york brand le labo fresh sensual bergamote 22 range include hand balm lip balm facial moisturiser refresh towelette dental kit sock eyeshades earplugs mint pillow mist pulse point oil also provide comfort convenience inflight chefs fullyqualified internationally train chefs use culinary expertise invent individual din experience 35000ft inflight chefs passion cook exclusive din experience could include dish extensive la carte menu steak cook like grill menu something special use fresh ingredients pantry first suite exclusive private space timeless luxury reimagined close slide doors enjoy personal space first class amenity kit bag inspire rich heritage artistry emirati people feature pattern sadou colourful centuriesold abu dhabi weave craft guests enjoy luxurious fragrances new york brand le labo fresh sensual bergamote 22 range include hand balm lip balm facial moisturiser refresh towelette dental kit sock eyeshades earplugs mint pillow mist pulse point oil also provide comfort convenience inflight chefs fullyqualified internationally train chefs use culinary expertise invent individual din experience 35000ft inflight chefs passion cook exclusive din experience could include dish extensive la carte menu steak cook like grill menu something special use fresh ingredients pantry', 'already spend time make sure salesforce record information need need reenter information send document signature one helpful powerful tool x salesforce toolbox merge field simple configuration step connect salesforce data field field document allow data automatically appear without manually reenter besides obvious benefit automatically populate data onto form implement merge field save time users longer go painstaking task manually enter information onto document prior send reduce errors information longer manually enter populate onto document exactly exist salesforce realtime update merge field configure simple checkbox allow data flow ways mean data appear document automatically recipient fill form field data automatically push correspond field salesforce', 'uk voters decide june country stay european union eu exit bloc upcoming referendum represent critical juncture uk eu alike come time global outlook cloud unusual uncertainty uk voters often reluctant europeans clear economic benefit integration world largest common market yet benefit come perceive cost leave camp example point thicket burdensome eu regulations large eu budget contributions big inflows migrants eu member state publication focus potential impact economy financial market leave stay vote newly independent uk would likely reduce leverage fashion trade deal crucial service sector potentially less clout negotiate regulatory standards unimpeded eu market access eu part would lose major budget contributor lead voice free market easy access worldclass financial centre see volatility uk european assets rise ahead referendum actual brexit would hit global risk assets believe whereas vote stay would likely reassure market sterling vulnerable brexit fear liquid uk market brexit could pressure uk budget current account deficits hurt currency potentially trigger credit downgrade leave vote would likely increase gild yield portfolio inflows could falter pressure domestic source fund budget deficit could see brexit deal blow domestically focus uk company would expect large cap overseas earners outperform sterling fall brexit would cut financial industry outsized contributions uk economy tax revenues trade balance believe offset apparent fiscal gain leave eu', 'day x make easier safer reward consumers businesses purchase things need merchants sell goods service engine commerce x provide innovative payment travel expense management solutions individuals businesses size help customers realize dream aspirations industryleading benefit access unique experience businessbuilding insights global customer care enable customers achieve world largest card issuer purchase volume process millions transactions daily premium network highspending cardmembers help small business owners succeed deliver purchase power flexibility financial control provide commercial payment tool expertise help company control spend save billions dollars offer market information management insights help merchants build businesses customer loyalty experts industryleading reward program platforms operate one world largest travel network recognize innovative company industries dedicate serve customers 247 around world', 'wonder fico score think may error credit report x commit help better manage credit provide resources need understand credit score work improve credit score right credit dispute report credit dispute much start know contact credit bureaus responsible report much information credit bureau resources section x financial education web site develop fair isaac corporation company invent fico credit risk score lenders use information intend help understand action take achieve protect overall financial health also include credit information relate x account x send fico score late payments affect credit score learn specific credit health contact three major credit bureaus report wise contact credit bureaus may receive differ information could impact report render bureau request one free credit report bureau per year may occasionally want contact credit bureaus ensure information universally accurate also right free credit report deny credit experience adverse reaction base credit report help file dispute make necessary update fix credit better position next time', 'see new office 2016 apps best work office 2016 apps new feature help get things do quickly fewer step easily create others take document go office 2016 make easier share document work others time see others edit coauthoring word powerpoint onenote improve version history let us refer back snapshots document edit process share right document click button use new modern attachments outlookattach file onedrive automatically configure permission without leave outlook review edit analyze present office 2016 document across devicesfrom pc mac windows apple android phone tablets stay task office 2016 new faster ways achieve result want simply tell word excel powerpoint want tell guide command smart lookup use term highlight contextual information document deliver search result web within document use oneclick forecast quickly turn historical data analysis future trend new chart help visualize complex data', 'x card protect fraud unauthorised charge ways available form payment like cash x cardholder protect x zero liability policy unauthorised transactions could transactions make store telephone internet follow five condition meet exercise vigilant care safeguard card risk loss theft unauthorised use immediately without delay notify card issuer upon discovery loss theft unauthorised use report two incidents unauthorised use precede 12 months account good stand comply term condition cardholder agreement meet five condition state liability shall govern accordance cardholder agreement zero liability policy applyto card issue entities natural persons card issue primarily business commercial agricultural purpose card issue outside asiapacific region personal identification number pin use cardholder verification method unauthorised transaction unauthorised use mean use card person authority use receive benefit protect must take reasonable step notify card issuer provide pertinent information loss theft possible unauthorised use x card', 'continue build world class organization x attract talented people work partner innovative suppliers help us grow business 820 dealers nationwide provide customers great purchase experience x value inclusion diversity connect unique individual contributions across company challenge conventional think remain firmly commit goal continuous improvement diversity initiatives x know understand draw strength diversity inclusion mean work together meet need customers build strong relationships many communities serve fully engage talents people x diversity efforts unite state span support local communities business diversity organizations national scope', 'one important monuments turkey commemorate battle gallipoli world war 1 show bath extraordinary mix ledlights take breath away x create lead light system powerful intelligent agile provide 16 million color instantly lead light system example light design innovation really bring history life touch people live surprisingly emotional ways martyr monument commemorate live lose gallipoli fierce bloody battle effectively create modern turkish republic especially proud project x nextgeneration light research development team largely consign history martyr know rejuvenate innovative light scheme see gallipoli monument inundate visitors want pay respect fall heroes remember past one turkey finest writers sunay akin create poem especially newlylit monument say look like dress costume light like nightgown', 'personalize education everyone learn different ways first time history analyze millions people learn create effective educational system possible tailor student ultimate goal give everyone access private tutor experience technology make learn fun hard stay motivate learn online make x fun people would prefer pick new skills play game universally accessible 12 billion people learn language majority gain access better opportunities unfortunately learn language expensive inaccessible create x everyone could chance free language education hide fee premium content free x use richest man world many hollywood star time public school students develop countries believe true equality spend buy better education', 'snapshots success isani castro preschool mom notice one eye turn little girl struggle simple task take isani dr altagracia tolentino children health fund south bronx health center remember really worry recall isani parent worry automatically worry dr tolentino diagnose amblyopia lazy eye treatable condition children age 5 prescribe glass correct condition isani wear kindergarten fifth grade treat early age permanent vision loss prevent glassesfree selfconfidence beyond years sight set columbia university parent ahead curve come kid healthcare many families unable obtain necessary treatments economic hardship result devastate outcomes time kid see many health challenge say dr wendy williams children health fund chf really overwhelm parent', 'x value people background part role make sure society take inclusive approach celebrate promote diversity major part work stream employee network run six network represent focus women faith belief disability ethnicity sexual orientation members military community june plan launch group dedicate employees care someone carers agenda increase issue organisations employees often find support younger family members well elderly sick disable relatives stressful try balance work family life also sometimes quite isolate wellbeing employees something take seriously network aim raise awareness support developmental network opportunities also course provide support people similar experience perhaps face similar challenge membership open belong community interest represent network also every employee interest take veteran reservist community network recently set exarmed force personnel join society felt colleagues would benefit network dedicate support veterans reservists military families group run chair members support senior sponsor group offer support members also harness enthusiasm specialist knowledge drive activity benefit various communities across country network dual purpose support members use specialist skills knowledge help shape x activity mean employeeled group real positive impact employee members colleagues customers relatively speak spend lot time workplace important therefore feel able bring whole selves work x network enable us make sure create environment employees feel comfortable also society reflect diverse makeup customers need', 'billions maybe trillions time day often many think impossible often people around world touch something make better x could smartphone pocket tablet coffee table wireless modem briefcasea could even navigation system car action camera strap chest x engineer scientists business strategists many different countries speak many different languages come diverse culture unique perspectives together focus single goalainvent mobile technology breakthroughs pioneer risk takers many inventions breakthroughs reside aunder hooda consumer electronics transform world big way help propel mobile forefront technology world top consumers wish list create new opportunities mobile ecosystem playersathe wireless device makers operators developers content creators world recently inventions breakthroughs inspire fresh new ideas companiesalarge smallanew wireless space call dreamers inventors rebel risk takers pioneer geeks embrace label many ways true dream big invent bigger importantly often many think impossible', 'team respond message twitter facebook network receive notifications task complete assign social media task responses appropriate team department region let us team address message relevant themsaving time improve quality responses create workflows designate team leaders approve outgo content team twitter facebook post align goals brand strategy map x organization exist workflows manage team members project department region confidently manage workflows even complex organizations give employees much little access necessary assign team admins oversee entire group efficiently allow restrict access specific profile social network twitter facebook many people involve stream need good communication x enable team manage workflow collaboration maintain secure permissions', 'x condominium insurance allow select coverage want things value like condo cover accidental damage improvements make unit association policy cover condo insurance policy limit possessions insurance cover personal belong policy limit assets condo insurance help protect assets liability claim sue much would need cover financial investment disaster strike would cost replace personal belong home someone threaten take court would assets cover liability insurance coverage enough protect value assets sue leave financially expose many people make mistake underestimate content home take inventory personal property help get condo insurance quote online get start today', 'meatandpotatoes kind guy leafy green take leave like many grow chide eat vegetables every include todaynational eat vegetables dayi make effort get recommend daily serve produce one thing appreciate vegetables today role technology play get plate peak today thank internet things iot food grow ship prepare condition closer ideal ever mean flavor variety maybe help sow seed technology iot help growers seed even put grind iotconnected sensors gather transmit information soil condition year round let farmers keep track moisture dirt water efficiently crop plant sensors monitor temperature condition also provide farmers data help improve grow environment maximize yield vegetables harvest prepped pack ship cherry tomatoes face hazardous trip field california grocery store restaurant suppliers market state delay along way variations temperature pressure light shock rough roadsall things could potentially damage delicate produce faster transit fresher vegetables solutions like x cargo view flightsafe help reduce risk detect warn change cargo environment iotconnected devices include freight stream information back farmers shippers help monitor events might produce bruise spoil arrive less acceptable condition faacompliant airplane mode turn devices flight reconnects land whether tomatoes travel train plane semi grower know issue transit better deal problems x fleet management solutions also help get produce destination faster fresher iot devices send data truck headquarter help drivers management vegetables reach final destination iot also use cargo handoff electronic form available iot devices record share detail arrival manage paperwork help streamline operations next time load veggies local salad bar remember iot technology play role get carrots bean lettuce tomatoes plate get back office mark calendar national cheeseburger day september 18', 'company profile locate clients need us addition headquarter tysons virginia usa major offices across globe 66000 professionals serve clients 60 countries x lead clients digital transformation journey provide innovative nextgeneration technology solutions service leverage deep industry expertise global scale technology independence extensive partner community view company profile infographic amaze things people help commercial international public sector clients solve toughest challenge modernize business process applications infrastructure nextgeneration technology solutions browse hundreds client success stories fifty years success start two men dream moment x bear april 16 1959 ingenuity drive force behind success explore rich history management team senior management team average 25 years domestic international experience strong history business academic technological accomplishments financial performance x report revenue 81 billion 12 months end october 2 2015 combine think leadership strengths partner enhance expand business technology offer available clients', 'hp work weave diversity inclusion worklife fabric company reflect everything examples put differences work create inclusive environment focus connect people power technology throughout world technology unleash human potential assistive technology remove barriers help create independence home work community assistive technology help increase maintain improve functional capabilities electronic information technology include desktop notebook computers tablets mobile phone printers', 'species fish find touchsensitive fin along cellular structure resemble key sense touch mammals university chicago uc scientists paper publish feb 10 journal proceed royal society b find pictus catfish bottomdweller amazon river neurons cells pectoral fin ones behind gills extremely sensitive touch surprise us similar mammalian skin fish fin able sense light pressure subtle motion say uc graduate student adam hardy author study use flat end pin brush hardy team stimulate fish pectoral fin measure result neural activity find fish neurons respond touch also convey information pressure apply well motion brush meanwhile cell structure pectoral fin scientists learn resemble crucial sense touch mammals like us fish able feel environment around fin say uc graduate mentor melina hale touch sensation may allow fish live dim environments use touch navigate vision limit raise lot excite question add sensory cells shape brain perception environmental feature may provide insight evolution sensation vertebrates furthermore researchers think sense touch quite common among seafloor fish suggest touchsensitive fin may widespread fish maintain close association bottom substrate write currently team experiment species fish see touchsensitivity present predict touchsensitive fin would useful bottomdwelling fish hardy say imagine utility nocturnal deepsea environments well researchers think new find could also aid design future undersea robots toil dark environments example offer hale envision fishinspired sensory membranes use scan surface underwater environments light may obscure', 'past years drumbeat think piece automation take jobyes jobhas get louder incessant smart people like folks oxford martin gartner forecast job gobble mechanical overlords president obama make pass reference otherwise upbeat final state union address technological unemployment around forever actually go back ancient greeks famous example english luddites throw shoe weave machine felt destroy textile industry fun fact shoe call sabots yes word sabotage come point societies forever deal technological unemployment even automation continuesand make mistake absolutely willdo buy chicken littles say jobyes jobis next automation come take job rather come take bore part sure technology forever drive mean get steampowered tricycle mean use handcrank start engine time wend drivers cede different part vehicle control technology lot subtle may even think ittake automatic windows transmissions examplewhile recent advancements feel even like relinquish controlcars parallel park improvements require different technologies course moore law still march unabated bet drive experience become automate oppose less bring us logical conclusion selfdriving cars point surrender car mean truck drivers cabbies delivery men mail carriers job require human behind wheel suddenly wink existence really first consider particulars job selfdriving mail truck deliver mail robot drive get physically bring overnighted package door make judgment whether leave stoop car protect thieve deliver mail follow around snatch everyone amazon shipments get idea let us get back real actual question selfdriving become actual reality plenty smart company invest lot equity idea create fully automate selfdriving car still ways reason end boil data specifically train data car need train data maintain cruise control roll windows need scads parallel park need understand close car front behind right trajectory back curb machine learn things find pattern massive amount train data case parallel park scenarios selfparking car train scenarios even happen fail drive exam flatten orange cone sixteen park far far rudimentary drive drive require understand quickly judge set mammoth set input know best route gauge weather condition judge whether debris road flatten cardboard box wayward boxspring mattress list manifold trip car difficult pull head store come back home machine analyze learn hundreds thousands trip make solid judgments high confidence navigate trip least plenty train data simple errand local grocer train data machine feed better able make good decisions edge case drive boxspring mention detour thing roll across street aluminum soccer ball ten yearold chase soccer ball fairly novel scenarios simply happen often machine smart new situations confidence train machine know new input make safe sound decision case decision leave driver call humanintheloop machine learn something go time time continue use case certainly conceivable see car make intelligent autonomous decisions large majority time nottoodistant future percent would okay relinquish controlentirely relinquish controlto machine 80 would catastrophic 95 mean five trip hundred could dicey even 99 leave much chance accidents happen good drivers something strange unusual happen pizza guy run red pedestrian run catch bus icy road someone fishtail exact type scenarios machine unlikely see mean exact type scenarios machine data make smart choices mean would better able take wheel steer lot forecasters miss trumpet new age automate everything yes automation come happen faster faster yes automation ramifications real job hold real people always case always case even something like automatic sport write machine analyze raft gamers aka stories write actual game spit cliches press coach call terrible play answer get clarity scuffle two marque point guard simply simple example smart machine getand make mistake whoop ken jennings jeopardy beginningthere things simply like ask probe question game watch yet react exact sort situations humans innately good fact split second decisions base lifetime experience decisions happen sometimes without us even know decide thing first place yet deal novel scenarios things train data scant nonexistent car see enough data distinguish cardboard box person see simply object would cede control say nothing course job human touch important veritable prerequisite yes machine eventually able diagnose diseases base preexist data x symptoms disease people want machine deliver news incurable disease extrapolate anything state senator preschool teacher person call mysterious charge appear cell phone bill get heart thing machine take control part job frankly much fun even something simple blog post sort ersatz machine editorthere squiggly red line underneath word misspell examplebut machine go say hey long wrap human judgment take fairly mundane annoy part job ie spellchecking automation machine learn tool leverage increasingly near future push career obsolescence give us time work part job humans excel machine handle annoy bits like spellchecking come smart route point point b people handle dynamic task like write actually drive things get extra interest judgments machine make best mention objective commonplace model train machine smart best way improve model train harder judgments let us explain take fairly typical machine learn practice like sentiment analysis even box sentiment solution hit 65 70 accuracy phrase like hate commercial coffee sooooooo good really quite easy sentiment model understand something like hate commercial really want drink coffee soooooo bad trickier right person parse phrase instantaneously need look bigrams thousands similar judgments know dissect language whole live give machine learn model stick 65 exact kind human judgments machine start see pattern judgments learn hate different hate want conjunction bad always negative machine learn system systems hysterical pundits forecast take job way start handle 65 humans handle 35 time feed difficult judgments back automation systems yes machine encroach little workforce job really bad thing machine confidently help doctor make intelligent diagnose simply make connections millions rare disease research paper something celebrate mean doctor suddenly cease exist rather mean spend time patients time research word automation mean mass technological unemployment mean mass employment augmentation job requirements change change maximize skills people good machine require us learn work machine fight job actually really good thing', 'global agricultural processor food ingredient provider x serve vital need food energy throughout world commitment deliver right result right way right way us include work help ensure crop source responsibly grow mean strive lessen environmental impact transportation process distribution operations mean contribute quality life communities live work mean keep colleagues safe past year make significant progress toward environmental goals adopt strong supplychain policies help ensure human right ecologically sensitive forest land respect protect continue make grant support education hunger relief sustainable agriculture important cause safest year ever extend momentum 2015 continue innovate improve efficiency environmental footprint operations', 'x lead international financial service company build strengths 150 years know dawn history serve us well years commitment customers unwavering objective deliver best customer experience every touch point every market business want customers achieve peace mind come lifetime financial security centre mission vision value dna organization commitments drive us forward touch every business decision culture products service offer around globe company dedicate customers financial success mission help customers achieve lifetime financial security vision international leader protection wealth management value foundation daytoday business operations x integrity commit highest standards business ethics good governance engagement value diverse talented workforce encourage support reward contribute full extent potential customer focus provide sound financial solutions customers always work interest mind excellence pursue operational excellence dedicate people quality products service valuebased risk management value deliver value customers shareholders serve communities operate innovation listen customers provide better experience innovative products exceptional service', 'x x largest division daimler truck north america one recognizable respect name truck industry fleet managers owneroperators alike associate x efficient dependable vehicles business tool rely upon day day even punish condition x commit innovative technologies help customers run efficient businesses road job site fuel efficiency become greater part keep cost engineer respond natural gas hybrid vehicles largest commercial vehicle fullscale wind tunnel headquarter portland oregon allow us design aerodynamic vehicles deliver power customers load demand reduce fuel consumption throughout innovative process maintain reliability durability customers count years onhighway product lineup lead x cascadia truck design grind maximize efficiency inside owneroperator prefer coronado combine efficiency traditional style create bold truck turn head product offer also include broad range vocational truck highly customizable serve variety applications versatile business class m2 well suit local pickup delivery tow utility applications rugged 108sd 114sd 122sd offer higher horsepower rat heavier suspensions frame handle construction refuse heavyhaul duties x commitment support also unparalleled 247 customer support include one largest dealer service network industry solid warranties finance options account intricacies transportation industry x support extend well beyond vehicles additionally provide answer customer frequently ask question', 'ever students go college want get job good job end students parent want know school give best chance get desirable job graduation help analyze employment pattern 300 million x members around world figure desirable job within several professions graduate get desirable job result able rank school base career outcomes graduate define desirable job define desirable job job desirable company relevant profession example define desirable finance job finance job company desirable finance professionals start identify desirable company professionwe let career choices members tell us desirable work company illustrate imagine two company b finance professionals choose leave company work company b data indicate get finance job b desirable base hypothesis professional move one company another give company move strong vote confidence similarly ability company retain employees strong indicator employer attractiveness hypothetically b attract external employees similar rat much larger employee turnover b data would show b desirable employer word desirable company profession best attract retain talent profession identify relevant graduate since every graduate interest profession fair define relevant graduate end work career example rank school category investment bankers consider graduate school work investment bankers addition want university rank reflect recent employment trend therefore consider graduate obtain degrees within past eight years rank universities piece puzzle graduate relevant particular profession desirable job profession university profession calculate percentage relevant graduate obtain desirable job percentages allow us rank universities base career outcomes across different professional areas professional world evolve continually look provide university rank increasingly broad spectrum career paths stay tune', 'one million mobile payments make month x customers figure grow almost 60 per cent last year growth perhaps unsurprising year society introduce number new ways pay include apple pay paym alongside rollout wearable bank apple watch mean offer payment methods ever growth transactions also partly attribute increase micro payments people make small transactions eg buy music extra live favourite iphone game expectation digital mobile payments increase simply things available buy become comfortable use new payment methods think 2016 go really excite period move towards mass adoption digital payments traditional ways pay cheque receive 21st century makeover eg introduction cheque image speed adoption ever increase mobile payments reach massmarket level faster payment method one example speed technology adoption spring mind july 2014 20 months launch service transactions mobile app internet bank around since 1997 first financial service 2015 x issue three millionth contactless card execute billion transactions enable millions mobile payments month look beyond year seem like use biometrics provide safe secure convenient way authenticate payments become reality already millions people use fingerprint unlock devices initiate mobile payments organisations explore facial recognition voice map even signature someone blood flow potential ways authenticate transactions biometrics continue evolve highly personal ways pay transform payments landscape', 'x global technology leader design manufacture customer support premium light medium heavyduty truck kenworth peterbilt daf nameplates x also design manufacture advance diesel engines provide financial service information technology distribute truck part relate principal business kenworth truck company build premium commercial vehicles sale yous canada mexico australia export throughout world peterbilt motor also design manufacture distribute premium commercial vehicles us canada daf truck manufacture truck netherlands belgium brasil unite kingdom sale throughout western eastern europe export asia africa north south america x deliver products service customers worldwide extensive dealer network nearly 2000 locations x global sell company products 100 countries expand dealer network asia throughout world approximately half x revenues profit generate outside unite state x part operate network part distribution center offer aftermarket support kenworth peterbilt daf dealers customers around world aftermarket support include customer call center operate 24 hours day throughout year technologically advance systems enhance inventory control expedite order process x financial service provide finance lease insurance service dealers customers 22 countries include portfolio 175000 truck trailers total assets excess 12 billion group include x lease major fullservice truck lease company north america fleet 39000 vehicles environmental responsibility one x core value company regularly develop new program help protect preserve environment x establish ambitious goals reduce emissions enhance fuel efficiency truck model x headquarter bellevue washington usa company employees charitable contributions demonstrate strong commitment communities work live x foundation grant millions dollars year education social service arts', 'adventurer heart spellbind mix passions fire burn explore limit nature self push passions max every single time take outside x know every adventurer need believe every single thing pack start pack reliable functional outerwear gear begin us value also valuable begin great people product design process expert guidance practical application across great outdoors share passions outdoor heritage sell authentic adventure elevate everything start whole thing 1967 continue push seek new adventure proud favorite outdoor playgrounds heritage sell', 'say journey 1000 miles begin single step one x employee journey lose 100 pound also begin single step metabolic test deep emilee know healthy 34yearold mother two morbidly obese 10 years never think affect wellbeing result test metabolic syndrome open eye test number include 50inch waist triglyceride level nearly 115 point healthy target range short fail find unnerve also inspire give three days mope never look back say october 24 2011 woulday one begin eat better walk treadmill mile time regularly every friday morning weigh keep record goal strive see smaller number follow week continue months later emilee begin run clock 15minute mile start time start work x wellness coach phone sessions coach offer encouragement helpful tip one best suggestions download app smartphone keep track food intake exercise say emilee little step become big successes june 2012 stilloverweight emilee run first 5k race next year metabolic syndrome test roll around pass fly color cry say never felt better stay newfound healthy habit keep run incorporate strength exercise continue embrace healthy eat october 2012 full year day one emilee complete 131mile hartford half marathon half marathon belt emilee go big may 2013 run first 262 mile marathon 4 hours year emilee also hit weightloss goal 100 pound complete two marathons develop newfound confidence abilities note start run always use think could possibly get next level never stop push know days find emilee train first 50k yes zero five', 'x spyder rid reinvent x believe world everyone experience exhilaration open road since 2007 tens thousands people discover thrill choose x spyder firstever onroad vehicle ride choice yframe design seven automotive technologies like abs traction control stability control x spyder roadsters grip road tightly enjoy confident ride full exhilaration whether head across town across country matter rid style sport tour somewhere x spyder push innovation since 1942 ever since j x found company 1942 name synonymous quality creativity pioneer spirit legacy keep us grow explore new frontiers today americas europe asiapacific 6500 people keep spirit alive recreational vehicles engines x innovation passion heart commitment products brand whether seadoo watercraft skidoo lynx snowmobile rotax engines x atvs sidebyside vehicles spyder roadsters evinrude outboard engines value come alive technology design inspire single common compel mission deliver ultimate powersports experience customers', 'business employ people greatest asset employees routinely work near energize wire intense heat nuclear fuel heavy equipment move vehicles pressurize pip condition require exceptional safety attitudes measure business build value safety core value throughout company though vitally important provide electricity customers occupation worth risk safety individual employee target zero practice target zero company philosophy aim create environment achieve sustain safety excellence goal complete every day every job safely use various metrics track trend progress toward ultimate goal eliminate injuries safety brief first order business employee meet employees whose job carry higher risk injury start job matter job function level risk job carry every x employee remind often work safely requirement key philosophies company job identify hazard determine avoid go safety detail employees perform work work watch take action correct unsafe condition behaviors identify report safety concern appreciate protect remove fear employees encourage open communication', 'x origin experience take partner employees behind counter store corporate offices roast plant bring work alongside farmers coffee grow regions experience nopparat yong arpornsuwan soon forget 2016 china asia pacific regional barista champion recently travel sumatra part x origin trip sumatra group partner learn coffee journey farm cup chance visit newest x farmer support center along coffee tree nursery smallholder coffee farm love way connect farmer arpornsuwan say one farmer help pick coffee cherry yeah think amaze almost cry return home trip desire share learn come trip feel oh must inspire care coffee love coffee share customer partner arpornsuwan say arpornsuwan join x thailand 2002 parttime barista currently store manager bangkok also train become district manager', 'x use less 400 tons palm oil per year purchase derivatives quantity equivalent 60000 tons palm oil derivatives glycerol fatty acids fatty alcohols ingredients use products emollient foam properties even though consumption remain low represent 01 worldwide palm production want among responsible company world lead example issue palm oil since 2012 100 palm certify rspo certification challenge company like x traceability supply chain palm oil derivatives improve practice within supply chain pursue threefold innovative approach trace back derivatives make full transparency x go one step rspo certification order ensure deforestationfree sustainable palm production since 2014 deploy unprecedented approach within oleochemicals sector start map entire supply chain trace derivatives back origin 2015 x achieve trace back 80 derivatives level refineries 50 mill encourage first outcome demonstrate trace back derivatives feasible end 2016 achieve 100 traceability first step ensure compliance zero deforestation among concern suppliers support independent smallholders x also commit support independent smallholders face challenge deforestation difficult live condition multistakeholder partnership x help connect independent smallholders market demand zero deforestation palm oil foster sustainable agricultural practice drive change palm sector transform purchase policies x create sustainable palm index new evaluation criteria assess palm derivatives suppliers base commitments achievements regard supply chain knowledge sustainable source practice compliance x zero deforestation policy end 2016 publish new sustainable palm index make available company business partner palm sector aim support effort stakeholders commit sustainable palm source achieve zero deforestation', 'dr david walton director global health x global technology company select one good magazine 2016 good 100 currently fifth installment list celebrate 100 people across 37 countries improve world creative innovative ways range press important cause help build solutions campaign change ultimately refuse accept status quo first quarter 2015 dr walton serve clinical advisor director kerry town ebola treatment centre etc sierra leone provide clinical care patients help implement tabletbased application improve clinical care ebola patients near end epidemic dr walton take role district director port loko partner health goal strengthen health systems prevent future epidemics sierra leone x drwalton lead global health practice distribute team healthcare professionals technologists focus create software improve patient care keep mission practice expand access healthcare poor marginalize team demonstrate tangible success create nextgeneration healthrecord systems west africa india haiti nepal david dedicate life eliminate health disparities poor marginalize experience make x perfect choice spearhead work intersection healthcare technology social justice say tiffany lentz manage director office social change initiatives x david truly embody humility servant leadership continually fight health human right honor work alongside hail 37 different countries 100 visionaries span wide spectrum field discipline say caroline pham good magazine deputy editor individuals honor tackle presentday problems issue offer creative tangible solutions push world forward honor humble include list alongside many brave women men front line fight positive change say dr walton share honor esteem colleagues friends family work do continue keep focus help need gain access health care matter location economic stand', 'second largest municipality florida orlando utilities commission ouc responsible provide 310000 customers across orlando st cloud orange counties water electricity 24 hours day seven days week utility serve large number customers across wide range cities ouc management find difficult keep different branch locations connect use outdated data center infrastructure vision develop centralize structure better serve customers ouc decide time explore data center network equipment options longstanding customer x nexus series switch user ouc trust x help pinpoint exactly need improve network learn variety data center options ouc decide deploy x nexus 9000 series switch data center solution would update current infrastructure centralize information across multiple branch however would also help ouc employees collaborate communicate efficiently addition automate many daily process although still deployment phase ouc already experience variety positive result 9000 series data center use x nexus switch ouc instantaneously connect several branch share platform minimize technical complications ouc also greater room data usage redundant network reconverge milliseconds faster response time ultimately better customer service increase business efficiency network automation two key factor oucs decision continue work x new x nexus data center solution ouc continue serve customers uphold last reputation reliable one', 'internal operations modest carbon footprint take important step evolve workspaces reduce climate change impact hometown new york city corporate offices consolidate accord leed green build certification program offices leed certify platinum level highest level possible recognize efforts reduce energy use environmental impact manufacture distribution facilities implement variety energysaving program include use solar array also respond company cdp climate change request since 2006 work continuously reduce carbon footprint follow successful completion 2006a2011 yous emissions reduction goal commit reduce total global greenhouse gas emissions 15 2013 2020 emphasis x retail locations', 'customer focus customer true north customers delight power success exceed customer expectations belief matter big small project deliver highest quality every associate know customer place unwavering focus customer satisfaction passion collective cando attitude enthusiasm commitment go extra mile everything x passionfor clients communities organization associate drive commitment whatever take help customers succeed apply passion help sustain communities environment collaboration work together achieve common goal cornerstone x success interconnectivity associate team across business units believe better share knowledge work together achieve clients empowerment figure get things do make happen dene ability deliver result mean take initiative nd new ways get job do encourage endtoend ownership responsibility accountability recognition x entrepreneurial fastgrowing offer numerous opportunities shape roles career transparency succeed open exchange information x build foundation open honest communication believe way ensure success clients operate fully transparent manner encourage associate listen ideas share feedback make us better stronger able company integrity act integrity every decision make never compromise integrity take every decision accordingly integrity mean right things always integrity also mean treat colleagues clients respect value opinions', 'code basic work condition human right represent commitment x company fundamental standards make x good place work people x vital asset individual collective contributions x people level essential success company recognition x develop policies practice design assure employees enjoy protections afford concepts set forth code x commit protection advancement human right worldwide operations concepts code generally derive x policies practice already place previously summarize single document part code reflect review work standards human right concepts advance group international labor organization universal declaration human right global sullivan principles code represent x statement standards subject rather third party x worldwide operations take place increasingly diverse universe circumstances arise legal regulatory requirements may necessitate apply interpret code ways assure compliance applicable local law event however believe concepts code represent important fundamental value underlie aspects employment relationship policy x company attract retain best qualify people available without regard race color religion national origin gender sexual orientation gender identity age physical mental disability veteran status nondiscrimination policy apply applicants well employees cover term condition employment include recruit hire transfer promotions terminations compensation benefit discrimination harassment base factor prohibit retaliation person make complaint give information regard possible violations policy recognize respect employee right join join lawful organization choose commit comply laws pertain freedom association privacy collective bargain commit provide employees safe healthful workplace protect environment wherever conduct business strive excellence safety health environment stewardship commit promote work environment foster communication productivity creativity teamwork employee engagement global company seek provide employees compensation benefit fair equitable type work geographic location local market work perform competitive worldclass company x organization establish work shift schedule appropriate meet business need comply applicable laws andor collective bargain agreements commit highest standards ethical business conduct relate procurement goods service relationships thirdparty providers include consultants contract labor define contract base lawful ethical fair efficient practice company outline expectations basic work condition human right supply chain x believe employment relationship voluntary term employment must comply applicable laws regulations therefore oppose slavery human traffic force labor child labor commit comply applicable laws prohibit exploitation inform employees code also encourage partner suppliers worldwide supply chain adopt enforce concepts similar code employees believe may violation code report establish channel retaliatory action tolerate anyone come forward raise genuine concern possible violations code x may conduct assessments need measure compliance relate commitments use systems process choose x periodically review code determine whether revisions appropriate revisions shall promptly publish x website', 'help community employees planet x understand thousands people embrace responsibility communities planet result astound good news get start vision value define culture act foundation relationships guests suppliers communities value innovation collaboration diversity behave integrity core value beliefs also hold accountable vision want x within framework organize efforts three areas support communities value employees care environment learn area see x commit make difference inside restaurants', 'x business focus help customers achieve lifetime financial security toronto tianjin goal help ensure life brighter millions people already trust products service financial wellbeing provide range protection wealth products service key market include canada unite state unite kingdom ireland hong kong philippines japan indonesia india china malaysia vietnam bermuda long history financial service experience financial strength global vantage point powerful combination market help us provide clients relevant smart life insurance health dental disability insurance education save medical insurance invest retirement plan service annuities host financial security products specifically design various life stag goals commit great products also commit operate socially responsible way act good corporate citizens everywhere live business', 'much x success attribute simple belief founder instill culture great ideas come everywhere company today ultracompetitive environment critical cultivate strong diverse workforce bring best ideas work every day commit make x great place work everyone contribute succeed x x foundation work diversify tech industry youth cod initiative genheration sponsorship strategic investments begin partner girls code 2013 grow commitment sponsor five sit five employee instructors organization alumnae summer immersion program also partner nonprofits include black girls code codenow urban arts partnership technovation 2015 add three new partner chicktech city year code second language drive global impact partner jopwell linkedin identify recruit hire exceptional diverse talent sponsor recruit grace hopper celebration women compute society hispanic professional engineer national society black engineer conferences design program expand ways find interact candidates recently partner neuroleadership institute develop course employees aim mitigate unconscious bias decisionmaking employee network accessx xproud lgbtq x women asian employee network black employee network hispanic latino employee network veterans employee network help foster inclusive work environment receive perfect score 100 distinction best place work lgbt equality human right campaign corporate equality index development program female employees include women executive shadow program worldwide field operations leadership circle women unlimited partner stanford university clayman institute gender research well catalyst access resources research events community diversity inclusion leaders', 'contribute economical social development centre vast industrial economic ecosystem privilege access 263 million customers work strong territorial position europe africa middleeast x make digital technology catalyst progress everyone digital technologies change world contribute societal development important consider fundamental right experience show much digital technology particularly africa speed socioeconomic cultural development country however global local level numerous source digital divide provide access largest number people deploy essential digital service adapt person need support ecosystems entrepreneurship social innovation three drivers action local social development', 'x fastest reliable way fill form sign document onlinefrom device anywhere world whether sign school permission slip contract kitchen remodel use x easy never go back paper sign documentait always free x upload virtually document complete sign return signatures legally bind ink work anywhere x smartphone tablet computer work apps use every day like gmail google drive outlook dropbox microsoft word microsoft outlook send document signature prep send document others sign guide sign experience set sign order place sign tag trust 50 million users worldwide complete document securely store easy anytime accessfar safer paper transactions x change business get do empower 225000 company 85 million users 188 countries send sign manage document anytime anywhere device trust confidence x replace print fax scan overnighting paper document transact business x enable organizations every size industry geography make every decision approval workflow signature fully digital x go keep life business move forward', 'new x company comprise 200 beloved brand sell nearly 200 countries include 8 billiondollar brand x company unparalleled portfolio 200 powerful iconic brand ready seat table learn culture see take work x company x company thirdlargest food beverage company north america fifthlargest food beverage company world eight 1 billion brand globally trust producer delicious foods x company provide high quality great taste nutrition eat occasion whether home restaurants go', 'challenge mankind face technology help contribution x x mission empower every person every organization planet achieve deliver mission start great technology great technology alone enough many technology benefit yet reach people need extremely effective commercial ecosystem bring promise technology life marketplace must strong societal ecosystem bring promise technology life community space fulfill company mission truly empower every person every organization planet achieve need empowerment begin inclusion x philanthropies invest x strongest assets drive greater inclusion empowerment people access technology opportunities offer enable build foundation x 30plus years give seek new ways achieve greater outcomes broader segment world population', 'desire share passion outdoors catalyst behind company reason work manage products operations responsibly new headquarter office california 100 electricity provide renewable source develop industryleading strategies responsible standard clothe loop apparel footwear recycle program athletes empower students take action climate change hot planet cool athletes presentations explore fund help young people across country experience explore outdoors', 'sustainability x sustainability high strategic priority x addition core business development production sale fascinate sport cars accept responsibility people environment society one key missions objectives company business customers satisfy customers drive form basis every business undertake customers enable x step future confidently continue company commitment sustainability three dimension economic environmental social responsibility employees community success business build motivation workforce x able pass appreciation society act responsibly environment energy business areas x incorporate environment strategic operational considerations product responsibility x represent consistent alliance resourceefficient mobility one hand fascinate sporty drive experience', 'influential innovative progressive x reinvent wholly modern approach fashion new vision creative director alessandro michele house redefine luxury 21st century reinforce position one world desirable fashion house eclectic contemporary romanticx products represent pinnacle italian craftsmanship unsurpassed quality attention detail x part kering group world leader apparel accessories own portfolio powerful luxury sport lifestyle brand', 'x fulfil dream personal freedom phrase purpose passion bring commitment exceptional customer experience everything innovation products precision manufacture culminate strong supplier dealer network x commentary news feature business behind iconic brand stories inside x', 'x trust mean everything us respect privacy protect strong encryption plus strict policies govern data handle security privacy fundamental design hardware software service include icloud new service like x pay continue make improvements twostep verification encourage customers use addition protect x id account information also protect data store keep date icloud believe tell front exactly go happen personal information ask permission share us change mind later make easy stop share us every x product design around principles ask use data provide better user experience publish website explain handle personal information collect go make sure get update privacy x least year whenever significant change policies years ago users internet service begin realize online service free customer product x believe great customer experience come expense privacy business model straightforward sell great products build profile base email content web browse habit sell advertisers monetize information store iphone icloud read email message get information market software service design make devices better plain simple one small part business serve advertisers iad build advertise network app developers depend business model want support well free itunes radio service iad stick privacy policy apply every x product get data health homekit map siri imessage call history icloud service like contact mail always opt altogether finally want absolutely clear never work government agency country create backdoor products service also never allow access servers never commitment protect privacy come deep respect customers know trust come easy always work hard earn keep ceo x inc', '5g remain one buzz topics wireless world industry focus next big technological development surprise however crucial grind truths getgo declare age 5g let us start understand requirements quick claim plan deploy 5g ahead standards however claim quite vague clear actual 5g technology spectrum use requirements 5g yet define understandable even optimistic believe 5g standards completion still years away come claim 5g deployment 2016 little market ploys hype technology available deploy widely 2020 beyond say let us delve 5g truths speed 5g speed driver define criteria among gs speed important 5g well true 5g promise much 5g network make connect world society possible enable technology aspectsfrom massive internet things iot 10 gbps speed mobile device 1 gbps speed nice truth despite announcements may see speed really part 4g definition obtainable today evolve lte standards require move 5g simply put true 5g speed go far beyond 1 gbps standards 5g requirements creation 5g standards begin target first phase 5g standards 2018 expect complete 5g standard late 2019 deploy ahead standard happen often industry blueprint need create network infrastructure devices use beyond speed mention 5g much speed bring great opportunity iot include smart grids connect cars home cities connect health recommend cnn money article sum possibilities quite well 5g still years away make hype upside industry look forward technology evolve work make sure network continue deliver need also focus x labs already trialing new wireless antenna technologies unlicensed spectrum capabilities lead way network function virtualization nfv software define network sdn foundational 5g early trials new technologies help shape 5g requirements ultimately standards market race 5g may unavoidable greater value encourage industry consensus around 5g standards effort pave way truly revolutionary breakthroughs years come', 'week onsite user conference momentum 16 london big story europe unveil new solutions innovations include standardsbased signatures x hybrid cloud help european customers accelerate digital transformations stop part x summer 16 release also make enhancements android application advance authentication lineup let us dive earlier today momentum 16 london unveil new capability call standardsbased signatures capability allow users sign document electronically easily comply esignature standards around world highlight week momentum 16 london organizations able support eu signature type order run business efficiently effectively x platform word get power x plus compliance eu esignatures standards choice use digital certificate x trust third party fall launch x hybrid cloud allow customers enjoy robust endtoend fully digital workflows control signer authentication data security data residency behind firewall simply put global enterprises able one consistent easytouse experience achieve additional level control compliance business google challenge create visual language users synthesize classic principles good design innovation possibility technology call material design like good challenge follow suit bring material design android application delight customers like users notice update look feel pervasive float action button make easier kick sign send experience flow navigation remain make advance authentication lineup even better add persistent authentication say lend company client need sign multidocument loan instead client reauthenticating identity persistent authentication allow skip authentication access subsequent document result simple streamline experience let us seal loan together shall well wrap x summer 16 release happy xing', 'linda luks love come work matter weather would walk x arrive store 1543 east albuquerque cashier shift usually early would bring sunshine always look linda always guarantee smile linda say karen meyer sales specialist store luks enjoy talk customers project whenever talk x would talk positiveness say lucy walker friend x albuquerque contact center much family luks member x family 16 years sept 8 2015 die ovarian cancer pass sit sister sandy schauer talk want save luks mention x employee relief fund since inception 1999 x employee relief fund help 23000 x employees 26 million financial assistance support contributions x employees x match dollarfordollar fund assist employees experience significant unforeseen hardships never need apply assistance linda felt important thing x people work sister say main reason make donation oct 13 behalf sister schauer visit x east albuquerque present 20000 check x employee relief fund x match largest employee donation ever make add 20000 fund available help employees need donation fit legacy someone view coworkers family say jean dowling pro service account executive everybody embrace say learn care coworkers care people serve', 'art skateboard los angeles city thrive original think whether movie director musician athlete entrepreneur place reward will follow path skateboarders begin nonconformists never need direction blueprint always look landscape park lot elementary school planters outside courthouse react improvise progress never guidelines skateboard would become leave decide will take risk figure possible start wood plank roller skate wheel grow slowly first couple strange tangents see 70s pre zboys eventually discover identity depend los angeles style preferences vary spot skate influence skateboarder person become celebrate heritage skateboard city angels go finest creative mind illustrators culture collective crew girl skateboard know art dump eight seminal skate spot identify artists task translate spot history character symbol spot flag flag hang popup skate park studio west hollywood x residence los angeles place design skaters skaters heart la', 'x believe good corporate citizenship start home work important support local communities work across business responsible partner place trust us know behavior affect stakeholders include customers shareholders employees communities suppliers partner seek ensure voice consider decisions make engagements range consult lead human right experts parent concern online safety children align work internationally recognize priorities frameworks unite nations guidelines business human right unite nations global compact allow stakeholders understand policies practice performance base citizenship report standards provide global report initiative finally recognize many issue large complex one organization solve help form number partnerships advance responsible practice across industry include global network initiative electronics industry citizenship coalition', 'familiar fizz coke fruit juices thirstquenching bottle water x constantly expand beverage portfolio provide consumers choice china plantbased protein drink make highquality agricultural source include green bean red bean walnuts join company lineup diverse flavor plantbased protein drink popular china category quickly grow thank part x latest acquisition deal close week make xiamen culiangwang officially part x china system xiamen culiangwang sell products brand china green culiangwang china green agreement part x system threeyear 4 billion investment plan china top company total investment 9 billion 1979 2014 investment fully reflect strategy continue provide full portfolio highquality beverages chinese consumers demonstrate x confidence commitment china say henrique braun president x greater china korea xiamen culiangwang own hong konglisted china culiangwang beverages hold ltd production sales business locate china x china previously announce intention make cash offer acquire 100 percent equity interest xiamen culiangwang braun add xiamen culiangwang continue expand plant protein beverages business along development beverage market china confident business prosperity china currently x thirdlargest market volume since return china 1979 x rapidly expand product portfolio sparkle beverages categories juice dairy drink bottle water coffee flavor water x offer chinese consumers wide variety beverage choices 15 brand 50 products x company world largest beverage company refresh consumers 500 sparkle still brand 3800 beverage choices lead x one world valuable recognizable brand company portfolio feature 20 billiondollar brand 18 available reduce low nocalorie options billiondollar brand include diet coke x zero fanta sprite dasani vitaminwater powerade minute maid simply del valle georgia gold peak world largest beverage distribution system 1 provider sparkle still beverages 19 billion serve beverages enjoy consumers 200 countries day endure commitment build sustainable communities company focus initiatives reduce environmental footprint create safe inclusive work environment associate enhance economic development communities operate together bottle partner rank among world top 10 private employers 700000 system associate', 'x commit highest standards integrity believe business relationships customers employees regulators physicians health care providers investors stakeholders must rest foundation honesty integrity core value company compliance laws regulations applicable business uphold highest ethical standards always fundamental goals x end compliance ethics program design promote compliance legal requirements inform employees contractors standards ethical business conduct', 'like flexibility access cash management service investment account cash management account cma account offer convenience flexibility cash management service check write visa defer debit card bill pay service combine investment account manage everyday financial need support longterm investment goals broad range investment optionsall single account plus benefit automatic cash sweep feature x bank deposit program mlbdp uninvested cash balance', 'favorite summer holiday summer fridays summer fridays phenomenon workplaces start embrace image months june july august without sure talk sorry hope get experience gift walk work early every friday summer soon help make hours gain list 10 ways spend summer friday visit museum lucky enough live city multiple museums visit little knowledge never hurt anyone might surprise learn hours walk around museum typically time weekend earlyout friday great way fit visit schedule check baseball game pump little excitement start weekend check baseball game baseball sport summer thrill game amaze food um nachos anyone really think reason go least one game per season try newtoyou restaurant warm weather equal porch season grab friends work school go restaurant never try preferably outdoor seat summer perfect time try trendy foods like avocado toast acai bowl know eatingfortheinsta go bike ride get move sun still shin midday take bike spin lot cities even offer bike rental service park hubs around city excuse take ride aeostyle see free concert park one best perk summer free concert seem like free festivals pop ever chill friends listen music beautiful way spend friday afternoon grab blanket sit snack earn bonus point bffs take last minute minivacation gain extra hours summer fridays make plan quick last minute getaway leave soon work whether end camp nearby drive night find beach sure make memories last longer season volunteer hours get give since get time everyday activity take time give back community volunteer local organization fun expect feel great action need inspiration recommend visit volunteer match website check local farmer market huge fan support local communities one way buy local wander around farmers market great way spend afternoon able try fresh pastries local veggies fruit even meet new people ice cream cone hand optional head pool wind long week head pool need member exclusive club go swim community pool great option catch ray pack aerie swim work bag easy access day do hang park kid day hang park afternoon jump around playground take walk ground', 'understand people feel brand easily filter result location language genderfor multidimensional view market segment conversation around brand start trend negatively within specific segmentsuch women twitter spanishspeaking menyou act quickly understand manage issue go beyond social channel tap conversations happen news sit blog forums public place x insights access realtime data 100 million source 50 languages across 25 social network platforms need run complicate query wait people run report dashboard always date realtime data insights sleep night know set alert notify instantly unusual spike volume sentiment measure customer complaint go viral first hear get ahead data make difference organization get use x insights drive wider adoption social media analytics across organization compel easytounderstand graphics give people information need act x insights automatically surface important conversations would find tool see commonly use word phrase relate searchto really understand people talk brand products company contextwith intuitive conversation map feature get information need role organize way make sense flexible board feature pull widgets tell story need follow cut noise stop fuss slide spreadsheets intuitive report let create template set frequency report refresh uptodate data email specify listautomatically x insights social team intuitive easytograsp report bring power realtime social media analytics every department organization x insights make easy find social buzz build strategy discover influencers report campaign success', 'x consider great barrier reef global environmental treasure need care protect proactively encourage guests host region familiarize ongoing health reef understand things humans contribute longterm sustainability great barrier reef marine park authority publish official report reef health pressure future authority provide report regular reliable mean assess health management great barrier reef accountable transparent way latest report authority state athe greatest risk reef still climate change landbased runoff coastal development remain impact fish illegal fish poachinga opportunity live one spectacular place earth even night experience unrivaled beauty location understand humans better help support special environment bedroom x construct experience make local recycle materials sustainably source local pine wood repurposed turtle hatch facility partnership local marine biologists also contribute ongoing tiger shark tag project marine biologists scientists jam cook university tiger shark near threaten status understand animals use ocean critical step toward effective conservation species additionally x contribute local notforprofit organization greenfleet plant mangroves salt marsh wetland plant every guest visit region rest year tree wetlands play important role filter sediment runoff mainland reduce carbon improve quality water flow seas reef allow new coral grow information environmental partner efforts ways donate visit remember reef together help preserve natural wonder generations come x continue promote efficient use exist resources environmentally sustainable way travel whether australia around world see environmental impact home share', 'x serve people house america lead source finance mortgage lenders provide access affordable mortgage finance market time finance make sustainable homeownership workforce rental house reality millions americans listen customers partner understand need put center everything apply experience expertise deliver innovative smart solutions help customers succeed also help make possible popular 30year fixedrate mortgage provide homeowners stable predictable mortgage payments life loan tool resources help homebuyers homeowners renters understand house options x people pour hearts everything know make real difference others live commit make company better move forward partner build stronger safer efficient house finance system one continue create house opportunities homebuyers renters communities across nation', 'motto agrowth lifea aptly capture everevolving spirit x activities span hydrocarbon exploration production petroleum refine market petrochemicals retail telecommunications areas commit innovationled exponential growth vision push us achieve global leadership many businesses include position largest polyester yarn fibre producer world x fortune 500 company largest private sector corporation india x set sight even ambitious goals remain inspire guide story philosophy founder chairman dhirubhai ambani hail modest mean follow dream create india largest company x organisation adopt ethos convert adversity opportunity make impossible possible challenge conventional wisdom ultimate aim always always touch live people positive way', 'headquarter teaneck new jersey yous x combine passion client satisfaction technology innovation deep industry business process expertise global collaborative workforce embody future work 50 delivery center worldwide approximately 233000 employees march 31 2016 x member nasdaq100 p 500 forbes global 2000 fortune 500 rank among top perform fastest grow company world x enable global enterprises address dual mandate make current operations efficient costeffective possible invest innovation unleash new potential across organizations make x unique ability help clients meet challenge help enhance productivity ensure vital business function work faster cheaper better ability conceptualize architect implement new expand capabilities allow clients transform legacy model take business next level', 'x inc emc corporation sign definitive agreement x together owners michael x founder chairman chief executive officer x msd partner silver lake global leader technology invest acquire emc corporation maintain vmware publiclytraded company transaction create industryleader extremely attractive highgrowth areas 2 trillion market complementary product solutions portfolios sales team r investment strategies transaction combine two world greatest technology franchise leadership position servers storage virtualization pcs bring together strong capabilities fastest grow areas industry include digital transformation software define data center hybrid cloud converge infrastructure mobile security customer partner benefit combination x emc provide unmatched ability address large small customers rapidly change critical need digital transformation drive disruption across industries transition traditional onpremise hybrid publicprivate cloud infrastructure need balance agility mobile workforces persistent security threats company offer customers broad endtoend product portfolio span key compute network storage segment legacy emerge address customers face technologydriven disruption x executive quote combination x emc create enterprise solutions powerhouse bring customers industryleading innovation across entire technology environment say michael x new company exceptionally wellpositioned growth strategic areas next generation include digital transformation software define data center converge infrastructure cloud security investments r innovation along privatelycontrolled structure give us unmatched scale strength flexibility deepen relationships customers size incredibly excite partner emc vmware pivotal vce rsa virtustream team personally commit success new company customers partner excite honor invest outstanding businesses build joe tucci worldclass management team extraordinary opportunity continue expand partnership iconic technology entrepreneur michael x talented team say egon durban manage partner silver lake believe strategic integration emc x generate unparalleled depth breadth across servers storage virtualization next era converge infrastructure create global technology platform poise sustain long term growth innovation years come double increase investment differentiate market leader next paradigm enterprise compute emc executive quote tremendously proud everything build emc humble beginnings bostonbased startup global worldclass technology company unyielding dedication customers say joe tucci emc chairman ceo wave change see industry unprecedented navigate change must create new company new era truly believe combination emc x prove win combination customers employees partner shareholders', 'enterprises could better use analytics prevent fraud give digital economy millions transactions complete electronically every hour one might expect enterprises aggressively leverage technology combat fraud instead beat technology punch fraud artists accord recent survey kpmg international almost quarter fraudsters rely technology report say company contrast could great deal use technology tool prevent detect respond wrongdoing unfortunately data analytics appear fully deploy company proactive data analytics search fraud amid anomalies suspicious business activity account 3 percent frauds detect frauds north america often detect descend order tipoffs complaints management review accidentally suspicious superiors internal audit one common obstacle enterprises often buy offtheshelf solutions integrate well eventually scrap far better look comprehensive solution cover company important surveillance detection need absolutely true want job do right need right tool job mean determine frauddetection need conduct research compare vendor solutions choose right partner oh actually deploy data analytics tool', 'endure principles think every day make decisions big small innovation technology deliver demonstrable benefit customers teamwork collaboration inspire best people stay others join growth reach customers benefit technology provide opportunity employees financial viability business selffund research innovation growth long run qualities every employee know expect qualities make foundation x culture x passion things better apply highest level scientific inquiry invention discovery new concepts development new products create experience customers enlighten unique delightful seek develop environment challenge us pursue excellence reach fullest human potential conduct business integrity must demonstrate highest standard business ethics deal customers suppliers must gain support trust others build reputation individual integrity respect x employees expect open honest business matter act consistently value share company pursue excellence everything excellence way life always integral business expect products people practice leadership exemplify attitude always challenge better encourage innovation aspects work research innovation invention essence company success result explore new methods ideas beyond conventional boundaries innovation must drive across company every aspect work must foster environment encourage individuals stretch imaginations abilities give freedom pursue ideas passion x stand passion enthusiasm enable us achieve high standards performance innovation set believe people focus internally motivate energize spread enthusiasm others derive great benefit individuals champion ideas leaders inspire us higher level achievement treat others respect mutual respect trust form foundation effective work relationships recognize cooperation group vital success mean every one us must communicate openly value different opinions treat fairness respect together create value customers must work concert colleagues ensure contributions add value customer customer perspective always try understand need create products service last quality delight unexpected ways', 'trust digital world digital technology change world x want everyone experience change confidence trust assert must earn work every level company see stakeholders external internal partner trust peace mind positive simple safe digital world everyone first customers wish give matchless experience quality course offer products service also offer support guide enjoyment digital world proliferate innovation instance help protect personal data watch security individuals families professionals company connect need simply complete peace mind meet commitment must responsible employer count colleagues fulfil within company profession proud progress within group social quality economic performance inextricably link take concern like radiowave exposure seriously respond clearly implement necessary precautionary measure finally end chain trust make sure industry actor manage purchase process responsibly', 'nowadays nearly must every student pc school computers become essential learn tool help complete daily study project course homework look great computer school new 2 1 pc smart choice 2 1 device start notebook transform tablet mean use way want notebook create paper presentations tablet great web browse read outstanding battery life student spend much time school classroom make battery life vital luckily latest 2 1 model fit energyefficient 5th generation x core processors help stretch battery life light enough carry everywhere school bag heavy enough 2 1 light computer bring everywhere still enjoy full notebook performance even better model let detach screen use tablet leave keyboard bag locker need great graphics mean great multimedia project need create video project school 2 1 right tool job x processors mention also come pack performance graphics create awesome videos come time show teacher switch tablet mode make presentation slick possible kid play work play make jack dull boy say go 2 1 prevent ever case come amaze graphics make game fun immersive homework course even better 2 1 run new windows 10 operate system may get crystal clear graphics directx 12 ability stream xbox game pc enjoy best game one versatile device', 'x governance model aim enable x shape industry trend monetize intellectual property build order deliver predictable revenue highmargin profit growth five businesses report x president chief executive officer rajeev suri businesses mobile network fix network applications analytics ipoptical network x technologies business run group president report mr suri business group strategic operational financial responsibility portfolio fully accountable meet target addition business group respective leaders seven additional unit leaders report directly president ceo seven additional unit leader position chief financial officer chief customer operations officer chief innovation operate officer chief human resources officer chief strategy officer chief market officer chief legal officer primary operative decisionmaking body company x group leadership team group leadership team responsible group level matter include execution company strategy overall business portfolio financial report purpose q1 2016 x expect align financial report two areas overall network business comprise mobile network fix network applications analytics ipoptical network secondly x technologies x provide selective financial data separately four network business group ensure transparency investors performance group addition various financial data x technologies business', 'day help millions people path better health company purpose inspiration behind everything 50 years cvs pharmacy offer customers products service need stay path better health addition pharmacies store feature ontrend beauty departments photo labs general merchandise cvs caremark offer pharmacy benefit management prescription mail order service employ combination clinical interventions discount drug purchase arrangements formulary management strategies help manage drug cost members clients cvs minuteclinic offer convenient access care 1100 locations nurse practitioners diagnose illnesses injuries skin condition provide variety wellness service include vaccinations physicals chronic condition monitor diagnose rare complex condition daunt cvs specialty help addition fill specialty prescriptions provide tool service patients need effectively manage medication therapy achieve best health cvs health serve millions people every day company thrive important workforce reflect customers also communities live work hard develop diverse workforce provide workplace empower colleagues regardless age ethnicity background millions time day help people path better healthfrom advise prescriptions help manage chronic specialty condition present many moments big small active supportive role shape future health care', 'path perfect touch decide need time release ship touch second half 2016 preorders open months prior launch remain schedule ship q1 preorders launch soon touch hardware make significant advance ergonomics implement many change make touch even comfortable reliable natural also implement change improve hand pose recognition also output larger number preproduction run mean get lot touch hardware hand developers need huge amount groundbreaking new content launch alongside touch share handful early preview x connect 2 september wait show come next feedback touch incredibly positive know new timeline produce even better product one set bar vr input appreciate patience promise touch worth wait', 'vision mission value principles vision make people live better unleash power x simple yet ambitious statement serve guide vision x 54000 employees company take pride manufacture technologies serve vary need customers worldwide x unleash power employees energy commitment make possible company maintain leadership position market serve x also recognize role corporate leader come responsibility help improve communities employees work live responsibility company bring life action activities employees mission unleash power x motivate people act like owners work together exceed customer expectations always first market best products partner customers make sure succeed demand everything lead cleaner healthier safer environment create wealth stakeholders value integrity strive right say innovation apply creative ingenuity necessary make us better faster first deliver superior result exceed expectations consistently corporate responsibility serve improve communities live diversity embrace diverse perspectives people honor dignity respect global involvement seek world view act without boundaries strategic principles leverage complementary businesses x family complementary businesses create value customers leverage relationships apply innovative technology across business boundaries increase shareholder value x financial success measure growth shareholder value focus roe roana earn growth revenue growth principal drivers shareholder value seek profitable growth x seek profitable growth leverage assets capabilities grow market segment favorable industry dynamics x establish advantage relentlessly pursue cost leadership x pursue operational strategy cost leadership lead critical technologies x market leader technologies critical customers success company performance create right work environment x assure physical cultural work environment conducive excellent performance continuous improvement', 'modernization paradox force play healthcare wellrecognized wellunderstood payers need modernize modernization high risk know megatrends healthcare medical advance deliver new treatments shift demographics mean rise chronic condition change patient expectations require consumeroriented approach add drive improve health outcomes control cost reimbursement value approach clear pressure view reach end road stepwise efficiency improvement pretty much everyone make yesterday systems work well cost leader table stake game transformation key shift need drive digital innovation take lot organizational agility happen csuite embrace chief innovation officer challenge chief innovation officer payer organization know press need modernize claim system reflect new market norms replace missioncritical system might riskiest thing career right approach patch play rip replace one thing sure need something things think winners new healthcare ecosystem highly differentiate highly efficient mean take best systems market offer change address need consumers even know lot implications course mean advance mobile multichannel access members also mean participate api economy integrate wider healthcare ecosystem drive coordination increasingly business partner even members expect access interoperate systems matter good data analytics almost certainly need better deliver actionable insights business leaders criticism reflection incredibly rapid pace change happen world big data payers already valuable data even valuable drive better care reduce percapita cost correlate institutionally personally own health data could time shift business model take look web site probably find range healthy live resources increase level direct digital engagement members mean take lead drive healthy behavior directly target members particular need risk profile could mean stronger relationships better health outcomes lower cost one thing conclude one standard approach represent gold standard consumer expectations move fast', 'x view diversity crucial competitive advantage globalizationcoupled profound demographic social economic change spur internethave bring diversity inclusion center business activity people associate ambassadors diversity represent x commitment rich dynamic work environment culture purposefully design culture empower employees leaders become catalysts diversity clients diversity provide broad foundation support global clients help us span cultural political social differences community commit create educational opportunities strengthen develop diverse global work force continue integrate diversity inclusion fabric business culture completely x initiative foster collaborative supportive work force x commitment diversity inclusion unwavering', 'understand social media engagement pattern across facebook twitter linkedin pinterest google account add insights google analytics pinpoint key influencers brand drive important conversations generate buzz measure click like retweets learn content work content quickly easily build intuitive report keep team uptodate automatic report share tag message tie specific campaign events easily analyze content volume sentiment track performance individual team levelincluding message send resolution time x analytics provide us excellent opportunity gauge customer sentiment adjust conversations accordingly', 'mobile data come gate run year kentucky oaks kentucky derby set new peakhour mobile data usage record sport venue open night thrill final 2minute horse race customers share derby action friends family make sure customers great coverage could share derby hat selfies churchill down work mobilitie increase capacity distribute antenna system das past year network team work hard give customers triplecrown worthy mobile experience number show deliver saw customers use das network churchill down first leg triple crown behind us bet x continue roll latest network innovations help keep connect like horse data race data usage include total data use x customers invenue distribute antenna system das churchill down x cell wheel cow deploy kentucky derby', 'protection environment one fundamental topics time order minimize environmental impact future protection environment firmly root x company policy x protect environment mean contribute sustainable relief environment target define x environmental policy wish minimize environmental impact cause development manufacture use products environment protection something concern us implement environment protection measure also aim safeguard success company aware responsibility environment future generations wish make active contribution climate protection conserve natural resources protection environment ie sustainable thoughtful behaviour succeed mean many small step x employees therefore request constantly question behaviour practical guidance implementation internally provide mean process instructions also environmental protection flyer via bulletin email intranet everybody course free address relevant specialists production sit wennebostel germany tullamore ireland albuquerque new mexico usa nominate officer occupational health safety well environmental protection wennebostel site addition hold responsibility xs productrelated environmental protection reach officer also nominate', '83 lob decision makers express need digital transaction management dtm solution research study highlight include 80 interview decision makers note clear press need digital transaction management dtm solution 98 company report revenue impact poor transaction management 37 company estimate revenue loss 11 25 400 business leaders around world weigh responsibilities documentintensive business process select manage transactional technologies study reveal keep night', 'x express invent express distribution industry global leader provide rapid reliable timedefinite delivery 220 countries territories connect market comprise 90 percent world gross domestic product within one three business days unmatched air route authorities transportation infrastructure combine leadingedge information technologies make x express world largest express transportation company provide fast reliable service 36 million shipments business day x express invent express distribution remain industry global leader provide rapid reliable timedefinite delivery 220 countries territories since 1973 throughout history x leader transportation information industry 40th anniversary good reason look back past little nostalgia start entrepreneurial dream grow one respect global company', 'integrity honor commitments never compromise ethics believe must enterprise represent highest level personal institutional integrity integrity people institutions want work us core purpose compromise value integrity honor commitments never compromise ethics know live highest form standards ethical behavior make honest commitments consistently honor commitments behave speak truth deliver promise courage acknowledge mistake whatever need address', 'today market businesses need make every opportunity continue expansion across europe deliver advantage x customers later collection time deliveries noon faster transit time across europe worldwide 100 new locations 3600 new team members x closer ever customers mean take business place service options easily ever europe next day expand air grind network allow connect next day market across europe x ship 20 million businesses europe overnight need ship afield count x world largest express transportation network connect reliably efficiently service options choice urgent less urgent light heavyweight intracountry intraeurope intercontinental choice whatever ship need x service fit bill constantly work enhance expand products service portfolio give even choices match specific business requirements one example wideranging efforts ongoing introduction development new domestic service several countries make easy save time x ship tool let handle whole process online reassurance realtime track help stay top every delivery inbound outbound customer one thing tick todo list focus grow business instead plan europe find reliable service provider exactly ideas', 'time another new year another doover best involve trim little pad dadbod finally claim brag right benchpressing body weight want help figure guy already get best shave experience deserve workout match go four myths would path shred situps shred belly fat unfortunately spot reduction myth take bore old diet exercise make gut flat suck abs hold breath hey work middleaged men beach sixpack abs take commit exercise eh sort may pretty shred 6 weeks grueling workouts abs hide unless get body fat 10 think worldclass marathon runner strong abs benefit though go body hair make less aerodynamic ok totally myth reason never see hairy olympic swimmers speed average weekend athlete move manly haircovered chest issue still sure whip gillette bodytm razor make chest smooth turn stopwatch test theory always pay top dollar workout gear gear equally worth major investment piece big impact performance health mean last good shoe def worth extra buck years scientists toil away labs go make gear put top game stuff like run shoe fitness tracker know four less myths stand way get shape go get nothing lose love handle', 'one point another thereawalking crowd gym stop dead track unsure go next equipment seem foreign every person appear know exactly use might fun feel x trainer ashley horner assure us normal ayou walk gym even know barbell job say horner teach clients virginia beach va train facility american sled dog across globe individuals like horner dedicate career become trainers roles stretch much deeper simply teach clients nail uppercut reach downward dog trainers heartbeat fitness communityathe ones kick start health push limit build confidence ones see potential us even see begin problem belief say x trainer jen widerstrom one today recognizable celebrity trainers athey necessarily sense potential think deserve amount investment take turn things around way believe us start understand doubt give support need reignite hope continue x recognize trainer worth trainers around world give time sweat maybe even tear help clients best selves show us potential truly limitless even see thank tribute power strengthen us', 'give locally x believe involve communityafrom donations give directly tens thousands nonprofits across unite state xsmile direct donations support local national nonprofits cash product donations continue donate across unite state come years x employees also active community proud support efforts activities run gamutaemployeerun toy drive around holiday food bank clothe collection campaign sponsor coach little league team serve board invest time ensure favorite local organizations help many people possible', 'x found 1919 x one world largest providers products service energy industry approximately 55000 employees represent 140 nationalities approximately 80 countries company serve upstream oil gas industry throughout lifecycle reservoirafrom locate hydrocarbons manage geological data drill formation evaluation well construction completion optimize production life field visit company website connect x facebook twitter linkedin youtube new applications demonstrate value major operator houston may 4 2016 landmark x business line lead provider e p software today announce release edta 500014 engineer desktop major upgrade industry complete integrate suite well construction applications awith industry face severe pressure lower cost per well manage risk edt respond add functionality improve usability allow engineer better design execute optimize well construction operations say nagaraj srinivasan landmark vice president aour well construction suite industry comprehensive prove solution plan drill complete oil gas well worldwidea twentyfour top 25 global producers use edt design well straightforward highly complex integration among different engineer applications help reduce technical operational risk entire drill department work information scientific model', 'x recognizable regional park brand national scale localize affinity deliver diverse audience reach demographic look families check kid doublecheck grownups people age ethnicities love thrill fun x park offer lead ooh x leader digital home media national network nielsenmeasured own multiple industry award include deployer year digital screen media association mediapost best brand campaign promotions x deliver 360 partnership market plan allow brand take advantage full range benefit help drive brand awareness loyalty sales promotions nearpack ticket discount offer instant win customize onceinalifetime sweepstakes prize provide customer value make great retail display secure premier shelf spaceendcaps enhance grocer sellin consumer sellthrough', 'energy never lose redistribute julius robert von mayer 1814a1878 naturally x production global distribution need energy thus cause environmental impact x aware environmental responsibility constantly strive improvement recycle take 95 less energy produce new one red bull can light weight 100 recyclable x make conscious decision use aluminium can today x can weigh significantly less years ago save precious raw material collect fully recyclable without loss quality walltowall production save resources short distance apart use 80 energy renewable source implement call walltowall production production site mean can manufacture fill site help us save many miles transport since transport empty can fill plant reduce footprint significantly smart transport produce less co2 emissions x energy drink travel destination predominantly train ship use truck absolutely necessary since can compact shape light weight efficient transport package pet glass bottle efficient cool ecofriendly coolers know x energy drink taste best ice cold develop environmentally friendly x ecocoolers use 45 less energy conventional refrigerators', 'x energy drink functional beverage provide wing whenever need stay sharp energetic focus time whether tough session water x help robby naish drink x 30 minutes every race drive time get tire x give extra boost need lindsey vonn x energy drink great functional drink really handy train competition x give wing mark webber drink road lecture study sessions work sport play video game go day night inside caffeine taurine bgroup vitamins sucrose glucose alpine spring water x energy drink special formula contain high quality ingredients', 'x bring together deliver advance mobile service nextgeneration tv highspeed internet smart solutions people businesses stand alone fully integrate solution provider fast highly secure mobile connectivity everything internet everywhere every moment every device drive us reflect mission connect people world everywhere live work play better anyone else customers stay connect nearly anywhere matter drive home work travel across country beyond customers want enjoy favorite movies tv show music sport screen largest provider pay tv unite state world set standard deliver video customers want unite state offer tv wireless nationwide plus large highspeed internet footprint offer wide choice internet speed meet customers need x gigapowersm customers 22 market download hd movie 36 second tv episode 3 second 25 songs 1 second plan expand gigapower speed 34 metro areas also offer pay tv 11 latin american countries offer solutions help businesses every industry serve customers better deliver advance service 35 million businesses 6 continents include nearly fortune 1000 well neighborhood businesses across unite state highspeed mobile internet network cover 365 million people businesses across north america include 51 million mexico also wirelessly connect cars machine ship containers part leadership call internet things never stop innovate brightest mind business x labs foundry center develop new technologies apps products service envision world everything everyone work together envision world work', '30 years x commit provide best part price customer service automotive aftermarket industry rich culture history go extra mile customers community today x lead retailer lead distributor automotive replacement part accessories yous', 'core value x build foundation integrity culture define value like respect transparency live value every day drive treat customers associate customer focus respect teamwork communication diversity associate development fun quality pride continuous improvement code business conduct embodiment value provide tool resources guide associate ensure x conduct business integrity x social responsibility x commit make positive impact society connect communities respectful environment great place work commit customer x foundation x foundation promote education youth leadership children healthy live communities associate live work foundation grant program match gift program associate volunteer make difference communities', 'innovation invent future learn past believe fundamental role make health care work everyone health care environment must engage constant change yet embody positive dynamic must change progressively turn must thoughtful advocate change must value proficient adapt change pursue course continuous positive practical innovation core competency within enterprise value innovation learn experience past use insights invent better future make health care environment work serve everyone fairly productively consistently behave continue respectfully challenge status quo encourage invest new ideas curious afraid fail honest efforts focus practical purposeful innovation build value benefit entire health care system truly work everyone', 'april 12 2016 nothing captivatingor elusivethan scent feel like soulmate let us introduce latest greatest love leitmotiv aromatic note leitmotiv library craft layer custom symphonies scent lesson composition turn fragrance guru letimotiv creator melissa h share insights tip leitmotiv recur theme music literature associate particular character idea inspiration use term name collection think many similarities music fragrance fragrances make note term use describe particular essential oilslike rise cedarwood amber gardenia perfumers like composers assemble note different concentrations create unique scent composition collection wearer composer spray layer fragrances create scentor wear one explain difference top middle base note fragrances make three class note relative evaporation process passage time spray scent first thing smell top notestypically lighter fresher note like citrus next smell middle notestypically mellow smooth florals finally base notesheavier deeper scent like sandalwood musksettle dry skin leitmotiv focus top base notedominant fragrances although fragrance fully develop beautiful specifically create idea layer mind layer approach help women transition fragrance day night one reason create leitmotiv always top fragrance late day always mood wear thing often daytime scent clash nighttime choice leitmotiv take guesswork layer spritz deeper base note daytime pick add intensity add top note make sparkle vibrant depend mood share application howto help scent last longer moisturize fragrance last longer wellhydrated skin recommend use nonscented lotion right shower spray fragrance onto two pulse pointsthe neck wrists inside elbow ankles back knees prefer apply mine scent rise throughout day leave subtle scent trail walk apply fragrance get dress scent skin clothe spray fragrance air walk mistthat last long personal favorite leitmotiv mix like ask pick favorite child still find new combinations love today hook fleur de lune splash figuier moderne think summer throw neroli toujours rotation splash fresh citrus personal history fragrance stay loyal particular perfume forever switch hard stay loyal give profession need test try hundreds fragrances say taste evolve years heavily heady designer florals twenties experiment unisex men cologne early thirties forties would say find palette scent note work well skinlike patchouli cedarwood bergamot neroli gardenia shop leitmotiv collection feature single scent pair', 'healthy workforce want employees want online tool program help employees make confident decisions health care help retain skilled workforce world mobile whether employees desk go important information fingertips provide employees online selfservice tool make easy check claim locate network provider compare quality hospitals print id card even estimate cost care secure online source information available time day night want encourage network participation docfind make easy members find participate doctor hospitals network providers members search location specialty languages speak search result customize members see network choices specific plan emergency members question medical condition call tollfree number speak register nurse time day night inform health line nurse provide information 5000 health topics typical online health record simple repository information one person enter information flu shoot another keep track get mammograms x personal health record little different different mean better tool sync person claim data mean information prefilled recent doctor visit awful migraine tool often know person prescriptions send alert potential drug interactions side effect', 'mission please people since first x old country storea open back 1969 lebanon tennessee pride keep things pretty simple way see mission please people simple try greet everyone walk front doors warm welcome serve good meals fair price whether stop homestyle cook stop browse country store want everyone treat fairly respect figure take care guests well business take care fortunately far', 'new 2 1s powerful pcs transform notebook tablet computers sometimes call hybrid pcs great today mobile worker let us find versatile notebook tablet one device enjoy advantage use notebook mode get work do switch tablet mode make impression meet time replace old notebook get two devices price one easy carry around work take place whether meet conventions site visit great lightweight pc like 2 1 take everywhere 2 1s even screen detach use tablet let would excess weight need powerful performance work hard need device keep 2 1 power 5th generation x core processor let us move effortlessly applications get burst speed whenever need wake flash access file instantly performance count os work apps 2 1 devices commonly run windows operate system common office apps new windows 10 may also get incredible battery life great multitasking capabilities responsive apps windows hello facial iris fingerprint recognition instant secure logins without passwords better still access work document spreadsheets presentation slide anywhere make note directly onto web page improve productivity microsoft edge even tablet mode make impression course 2 1s sleek modern devices look good perform leave impression clients company uptodate technology', 'victor stroe learn english x company vodafone romania share us like language learn solution first little nervous take tutor session know expect english coach would treat would understand learn need realize sessions work real professionals coach understand quick really put lot effort help learn progress tutor sessions far really interactive dynamic also useful learn goals manage find coach work good usually schedule tutor sessions time day time work coach like special learnercoach collaboration coach get know well enough personalize session little bite conclusion like x tool learn foreign language core grammar write listen lessons choose one would definitely pick tutor sessions many reason close real life experience must combine almost learn part listen speak read interactive experience tutor sessions fun learningimproving foreign language important coach always supportive give useful advices encourage every time', 'relationships build trust collaboration believe order achieve full potential enterprise efforts help people make health care work everyone understand believe never achieve goal alone must positively engage efforts interest everyone touch contribute effort value relationships build trust collaboration order take action find solutions understand relationships critical help people work together even interest fully align fulfil realize relationships bind people organizations trust trust earn preserve truthfulness integrity active engagement collaboration colleagues clients behave approach people respect humility confidence energy confront issue people differences confront direct way passively resolve issue drive differences actively engage people institutions share information ideas resources order help others achieve goals encourage variety thoughts perspectives reflect diversity market customers workforce', 'witness sheer look terror go hand hand shatter iphone screen hear ominous crack cue panic well panic introduce smart phone repair x begin today x deliver technician directly door repair iphone crack screen replace battery help 14 million x customers nut bolt home entertainment skilled technicians simplify smartphone repair consumers nationwide whether x customer iphone repair simple x visit wwwdishcomsmartphonerepair tell us phone want us meet available phone never leave side come wherever gym office even local coffee shop fix phone disrupt entire life repair service make wait quote ship phone away days end eliminate hassle upfront price consistent across country onsite repair take 3045 minutes worry one millions americans swipe across shatter screen get cover launch team repair crack screen replace batteries apple iphone 5 5c 5s 6 6 plus devices come stay tune', 'part pride month cities across unite state celebrate contributions spirit lgbtq community proud join new york seattle host onsite pride kickoff activities organize participation citywide parade week site lehi utah first place corporate entries best overall proud cloud float 25th utah pride parade parade 150 entries thousands walkers float riders make largest utah pride parade history x stand lgbtq right believe equality state washington recently endorse i1515 initiative endorsers note i1515 would repeal state nondiscrimination protections 10 years help ensure transgender family members friends coworkers neighbor treat fairly equally law learn australia x sign open letter marriage equality practice strive diverse inclusive workplace hire career journey fact past two years receive perfect score 100 distinction best place work lgbt equality human right campaign corporate equality index show pride check pridethemed remix imagery spark team create make available everyone use pride imagery ready customize post social network', 'x today announce contribution 250000 star code asc tech education nonprofit provide computer science train qualify young men color significant investment fund 60 rise high school juniors seniors participate year asc summer intensive fund double last year 100000 contribution asc x aspire x signature initiative drive innovation education support student success school beyond proud e support star code put 60 e young men path career stem say place top priority narrow gender racial gap tech program like star code introduce young people opportunities essential part effort look forward work star code stem program support summer connect high school students tech industry drive innovative young men ready create technologies essential future nation economy x donation largest single corporate gift help us keep summer intensive free year class 80 students say asc 2016 summer intensive unique sixweek program design empower young men skills network mindsets need create new futures technology year program include site visit well e top e industry asc summer intensive prove record success accord independent research firm wested 70 percent graduate plan major computer science three quarter say decide work harder school e star code wested research also show 100 percent collegeage alumni attend fouryear colleges twothirds top 50 universities unite state roughly 40 percent receive full scholarships school choice along sponsor asc summer x continue sponsorship girls code stem summer education program five boroughs include continue support brooklyn science innovation initiative kingsborough community college summer stem collaboratory program pace university program continue reach new mind teach stem concepts new york city students also first time summer x support young women leadership school astoria tech e program teach 8 grade 12th grade girls design program develop market video game apps social change x also partner college staten island office continue education offer first ever summer stem program staten island high school students addition x help qsac steam program launch stem education initiative provide adults autism bronx valuable educational tool foster development techrelated skills star code nonprofit initiative prepare qualify young men color fulltime employment technology industry provide mentorship industry e intensive train computer science star code dedicate close opportunity gap young men color tech industry visit information x commit advance education strengthen communities improve live community initiatives x long history invest project create learn opportunities promote academic economic achievement address community need x aspire x signature philanthropic initiative drive innovation education bring diverse resources bear issue include fund technology employee volunteerism mentor aspire pass 250 million mark plan invest 350 million education 20082017 liz debold 5162875208 ldebold skdknickcom kate mackinnon km9822 attcom', 'small business solutions x provide business technology solutions include internet mobility service learn x small business service x understand unique need small businesses owners come run businesses know important role technology play help small businesses grow keep revenue high cost check know important technology reliable current lose data network disruptions underperform technology include devices equipment could mean huge losses big corporations small businesses mean mortgage get pay may 12 2017 apr 25 2017 nov 23 2016 nov 21 2016 jul 06 2016 smallbusinessweek x netbond x real stories sharpe suit x long live eaker barber shop keep customers connect gourmet gift shop turn wifi wish national mom pop business owners day small businesses lean smartphones tablets mobile apps save time money x cloud architect portal overview sing better business', 'share x customers enrol mobile insurance mobile protection pack mobile protection pack business multidevice protection pack may able get crack screen repair instead receive replacement device screen repair perform certify technician visit convenience screen repair appointments make soon day claim approve launch screen repair option available select areas select devices e additional areas soon find list eligible areas devices crack screen repair option automatically include insurance plan eligible device 89 deductible crack screen repair screen repair deductible may less deductible replace cover device purchase new one crack screen eligible repair file claim online phoneclaimcomatt call 8885628552 customers must enrol x device protection plan order get screen repair service enroll within 30 days device activation upgrade enroll screen repair new 12month warranty device provide asurion question warranty screen repair call asurion 8885628662 share', 'jul 14 2015 x announce today company secondquarter 2015 result release new york stock e close thursday july 23 2015 apr 24 2015 annual stockholders meet today x announce 12 nominees company board directors reelect apr 22 2015 e cost synergies directv transaction increase significantly 25 billion mar 23 2015 x firstquarter 2015 earn release wednesday april 22 430 pm et learn x investor relations dec 26 2014 x release fourth quarter 2014 financial result tuesday january 27 2015 430 pm et learn x investor relations', 'share twohundred students diverse background receive scholarships fund online degree help prepare career tech industry announce today scholarships cover cost students earn new type credential students anywhere access affordable train earn credential soon become key part x train talent acquisition model hope recognize employers similar fashion say scott smith senior vice president human resources operations x collaboration x design deliver nanodegrees first industry support deserve students eager gain relevant skills advance tech career say clarissa shen vice president business development udacity x signature education initiative company introduce program capabilities appro 10 national regional nonprofits select award scholarships x aspire bring together x employees nonprofit organizations community members help equip students skills need e digital global economy organization receive scholarships help students focus school success career readiness organizations include limit opportunity students receive train entrylevel software development job say anne wintroub director social innovation x scholarships empower students across country high quality affordable train tech skills need today businesses x udacity launch nanodegrees later year topperforming graduate eligible 100 pay internships offer x nanodegree scholarships give students access new e opportunities say casey recupero national director partnerships innovation year make education affordable talented motivate young adults like ones serve able gain technical skills necessary gain sustainable career reach economic selfsufficiency nanodegree course deliver massive open online course mooc platform design complete within 612 months course selfpaced personalize coach access industry e every step way degrees efficient focus affordable make e applicable need today techcentric world x inc premier communications hold company one honor company world subsidiaries affiliate x operate company providers x service unite state internationally powerful array network resources include nation reliable x lead provider wireless wifi high speed internet voice cloudbased service leader mobile internet x also offer best global base offer roam countries yous base carrier offer wireless phone work countries also offer advance tv service brand company suite ipbased business communications service one advance world additional information x inc products service provide x subsidiaries affiliate available follow news twitter att facebook youtube 2014 x intellectual property x x logo mark contain herein trademark x intellectual property andor x affiliate company mark contain herein property respective owners reliability claim base data transfer completion rat nationwide 4g lte network 4g lte availability vary udacity mission bring accessible affordable engage highly effective learn world company headquarter silicon valley work industry leaders include x google facebook xcom cloudera build technology class design advance lifelong learn information go x inc commit advance education strengthen communities improve live community initiatives x long history invest project create learn opportunities promote academic economic achievement address community need 2013 130 million contribute direct corporate employee social investment x foundationgiving program x aspire x signature education initiative drive innovation education bring diverse resources bear issue include fund technology employee volunteerism mentor share x name dow jones sustainability north america index 20 million pledge count black x leaders grace cover pivot magazine intern e launchability', 'lot buzz socalled chalky paint confuse ultramatte finish paint chalkboard paint something totally different chalky paint perfect finish furniture decorative piece without need sand prim x decoart great give fabulous saturate distress look flea market discount store find want find diyers could chalky paint send americana decor chalky finish paint favorite home improvement bloggers special chalkyfinish paint edition paint style challenge cassie freeman hi sugarplum make freshly paint nightstand centerpiece complete makeover previously unappreciated nook home see chalky paint make nightstand look absolutely smash believe power paint transform space object participate paint challenge nobrainer especially since involve chalky paint medium yet try victim bangedup nocharacter laminatecoated tooorange old nightstand look familiar virtually every bedroom set come one use little hall storage chestbut really spacefiller could find something better hence never take time sand prime paint seal bother know destine curb chalky paint need sand prime laminate surface like sweet baby since paint latex virtually smell able paint inside prepping choose teal color call job paint consistency pudding avoid lick brush though actually pudding run drip dry almost instantly little wait time like magic paint stick laminate finish chest coat buff satin sheen let cure overnight add find online get busy style favorite part much curbsidedestiny pretty little chest find forever home us create tableau top follow blog pssst paper think simple diy well fun show afters little nook live back door right photo yep power paint strike thank read little makeover cassie diy designobsessed te girl love travel fashion sarcasm food hang sweet funny family find kick home one budget project time see makeovers like one blog learn tip use create beautiful age distress look read design bloggers use chalky paint series sure follow board pinterest festive diy wreath make pinecones greenery patio decorate ideas chic colorful patio refresh chalky paint rescue old nightstand destine curb choose perfect washer dryer set laundry room tower timbers block stack game choose new kitchen range feature consider buy tell us little bite find article fit taste start select options bedroom ideas kitchen ideas bathroom ideas patio ideas live room ideas storage ideas home office ideas basement ideas pantry ideas din room ideas backyard ideas nursery ideas', 'tabletop christmas tree cutout make cute creative holiday decoration rustic paint splatter look piece truly distinctive holiday gift family member carry special mean make tree display name small photos everyone family use christmas tree cutout way display small ornament decorations pretty simple diy project mostly cut wood paint drill hole even kid join fun paint splatter follow stepbystep tutorial use piece pack paper create treeshaped template trace shape onto wood miter saw table saw local x store make cut tip cut tree shape jig saw tree many hard angle start straight line base get corner branch come side plywood make hard angle use jig saw wrist like would cut tree paper keep wrist rela move saw wood slowly follow pattern cut complete lightly sand cut eliminate rough edge dip stain pad minwax special walnut stain wipe stain onto board direction woodgrain let stain sit 10 minutes wipe use clean end stain pad good idea wear vinyl gloves stain wood protect skin always best map hardware placement drill hole project recommend layout map install base due shape project lay design also mark placement hole hardware help drill accuracy placement hole mark use 532 drill bite predrill application ease apply wood glue bottom tree trunk center 4in top base board finish side face use nail gun 1in brad nail attach base tree pin bottom base center tree trunk tip rest tree board height base board easily center apply top board base tree apply wood glue bottom top base board center 7in bottom base board finish side face set tree upright center use nail gun 1in brad nail attach bottom board base top board base pin top take clean rag apply wax quickly sporadically hit areas know want reveal tip quick random stroke create truer rustic feel final piece use uneven stroke along front side top edge help better achieve desire rustic look involve process apply generous first coat paint use behr evergreen bough cover entire shape tree rich wintery feel apply paint liberally across tree include areas apply wax sure brush e globs paint sweep brush direction wood grain allow paint fully dry move onto ne step use sand block lightly sand surface sand paint wa areas paint remove easily fully peel add moderate pressure brush areas sand block fully remove peel e take turn splatter start light coat fire cracker red look like holly berry get splatter affect apply light amount paint tip brush hold small block wood one hand tap paint brush begin metal frame wood block direction area want splatter note artist splatter large gobs instead light sprinkle carefully blot paper towel allow paint fully dry move onto ne step repeat process step 12 behr frost paint intention make frost white paint look like snow cover christmas tree splatter white green stain reveal red berry freshlysnowed look allow paint fully dry move onto ne step use phillipshead screw driver provide mount screw attach bubble glass knobs christmas tree cutout start back tree push installation screw connect thread cabinet hardware make family tree display use small picture frame ornament family name write could also display small family photos frame family grow add cabinet knobs keep add christmas tree cutout x blog follow board pinterest diy tutorials ideas browse x everything need decorate holiday bathroom makeover budget diy box stock holders 3 craft ideas thanksgiving tablescape diy trick treat skeleton porch meet bloggers 2017 halloween style challenge six vintage light bulb update home tell us little bite find article fit taste start select options bedroom ideas kitchen ideas bathroom ideas patio ideas live room ideas storage ideas home office ideas basement ideas pantry ideas din room ideas backyard ideas nursery ideas', 'gloribell lebron knack bring natural look decor ingenious idea add strip succulents turn urban space virtual garden author blog create christmas decor shine sparkle holiday along clever additions greenery add organic spirit room use christmas decorations x holiday live room arrive mystery bo holiday items send part series talented design bloggers internet share christmas decorate ideas like many fellow blogger friends ecstatic part year x holiday style challenge last summer join great group create urban space small balcony definitely one best e life liberty create always bring much fun time around holiday season big surprise area assign work magic fireplace mantel recently buy 1938 mediterranean revivalstyle house come one impressive fireplaces ever see engrave stone detail beautiful know moment area go great focal point mystery bo arrive x thrill see ornament golden color match perfectly small vein stone already select metallic accent soft sand color stone basic scheme rest design concept easily unfold cozy invite space make mantel really stand start join together two base rustic eclectic design securely fasten remove red poinsettias attach garland add e faux greenery make look fuller also add piece grapevine couple silk plant similar famous dusty miller plant garland ready start decorate come box also add home decorators collection copper silver finish also make star use different size cookie cutters hammer easy peasy grapevine star already hand add touch whimsy fireplace focal point room mantel become stage rustic eclectic christmas fantasy come life garland create three focal point use group ornament two corner one center cluster golden copper silver accent different size finish mi color able recreate rustic feel want center big engrave one group add emphasize area focal point eye jump big mirror create visual illusion triangle area since mantel already statement place accent without distract viewer garland reindeer figurines elegant e season outdoors main stage spread gold copper christmas ornament pinecones mantel random organic way emphasize natural look scene course mantel major focal point room tie rest christmas decor add mini grapevine wreath along faux evergreen garland x send cork star live miami weather seldom cold enough fire fireplace good spot greenery though inside two also x plant remind christmas holly bush real seem frost accentuate area scatter floor behind urns also add giant shatter resistant ornament pass mercury glass place christmas ornament decorative lantern use previously patio challenge easy way add sparkle place pot ne lantern balance metallic finish ornament place tray coffee table ottoman perfect spot small flower arrangement book items add clean touch create invitation seat relax also use trays serve guests warm drink sweet snack thank x include holiday style challenge merry christmas everyone see photos blog gloribell lebron graphic interior designer miami write decorate blog find decorate ideas easy tutorials decorate space holiday decor ideas x blog follow pinterest visit x online everything need decorate thanksgiving christmas outdoor accessories create green natural patio look corner bench flower add charm patio create rustic eclectic christmas decor diy trick treat skeleton porch meet bloggers 2017 halloween style challenge six vintage light bulb update home tell us little bite find article fit taste start select options bedroom ideas kitchen ideas bathroom ideas patio ideas live room ideas storage ideas home office ideas basement ideas pantry ideas din room ideas backyard ideas nursery ideas', 'bookshelves generally play two roles functional aesthetic home office makeover diy bookshelves add much need shelf space certainly make previously bare room look warm comfortable sophisticate diy bookshelves create tracy laverty husband steve tracy author diy lifestyle blog diy bookshelf tutorial home office makeover part ongoing series x blog pick particular material case challenge favorite bloggers come useful diy project inspiration share readers impress tracy steve woodworking skills see photos home office makeover result bright elegant wellorganized work space home office condition since day contractor finish build contractorgrade wall curtain essentially storage room put things home see photo also unorganized ready revamp steve decide build bookshelves start work get home office functional organize classic look plan steve draw look ideas brainstorm would work space great thing build bookshelves customize size look fit style fit minivan wood one bookshelf cost 155 x cut plywood sometimes charge small fee per cut worry put full sheet plywood car issue first thing plan cut piece plywood since sheet cost close 50 make sense think start cut two shelve make cut plan rip plywood part width use table saw templates guide cut piece length use skill saw deep along backinside edge shelf perimeter piece two side top use router cut allow back recess shelf see end grain plywood look complete bookshelf side notice shelve less wide bookcase side recess back add rabbet completely optional ok see end grain back simply nail back back shelf recess back use rabbet remember shelve width bookshelf side ne step cut slot shelf use router shelve use router bite make dado deep another way add shelve without use dado glue nail shelf support make 1 x 2 pine use shelf style e directly insides bookcase side support would length width bookshelf shelve would nail support also add countersink pilot hole screw hold shelve place drill two small hole 2 either side center shelf dado flip side use countersink bite allow screw head recess surface easily fill wood filler paint put piece together fun part use glue screw hold together also see rabbet back go ne step cut add back use rabbet recess back back essentially dimension assemble bookshelf helpful hint plan paint back different color insides case suggest add back do paint paint back add bookcase lot easier way ask know plan paint trim color insides bookcase could add trim decide paint trim different color prim paint bookshelf trim separately add trim everything dry lot nooks crannies bookshelf complete lot easier paint point use paint sprayer first time ever paint everything use primer follow coat neutral white insides bookcase trim outside x also colormatch brand paint say e x ralph lauren paint back store many great paint choices use 1in thick pine trim cut fit 30 sure measure x sell select pine better quality wood normal pine dollars need worry knot wood board tend straighter higher quality well totally worth project like two vertical piece along side 2in wide make rip single 1in x 6 piece table saw thin strip wood leave save use later shelf rail 1in x 2in 1in x 6in bottom rail rip top edge flush bottom shelf add arch top rail use thin strip scrap wood table saw bend shape want trace result curve take e set hand one person hold strip wood cross bottom corner person trace hard see pencil mark wood cover board trace line tape also protect face board cut arch cut arch use jig saw sure touch paint scratch add paint newly cut edge allow dry paint dry time add trim use wood glue finish nail gun first add stiles either side shelf add rail stiles top bottom rail use pocket hole e strength kreg jig toenail nail angle rail stiles see bottom rail upsidedown show pocket hole add decorative trim top fill nail hole use wood filler touch paint scratch do bookshelves add baskets bin organize magazines paper things also build chalkboard plywood find x little ago hang hook containers hold chalk girls love come draw us funny face love fiddle leaf fig x plant low maintenance need water every days kind plant side room hang old shutter use letter organizer hang quote inspirational image sure get cover little girl art work roman shade also diy say right thumb tack fabric glue friends see make help organize ideas room steve love room turn super sturdy complicate make buy bookshelves like ones look e go diy route definitely save money make feel pride home tracy laverty live countryside maryland husband steve four daughters along fulltime domestic goddess like eat chocolate run due previous passion art history diy project blog focus diy make house home things relate interior design stop check blog see x blog follow pinterest diy project anything else need make home better tracy receive complete diy bookshelves project ideas opinions e check diy bookshelves home office makeover choose perfect washer dryer set laundry room tower timbers block stack game choose new kitchen range feature consider buy tell us little bite find article fit taste start select options bedroom ideas kitchen ideas bathroom ideas patio ideas live room ideas storage ideas home office ideas basement ideas pantry ideas din room ideas backyard ideas nursery ideas', 'chelsea mohrman create warm invite familyfriendly holiday theme use supply x diy funky bold decorations fit personal style invite take part send chelsea mystery box x christmas decorations get start christmas decorate chelsea add handmade tomato cage christmas tree uniquely wrap gift diy frame pop green along traditional decor bring holiday spirit home always love warmth creative come holiday season holiday remind take time celebrate love family give birth first son shortly christmas last year unable spend much time enjoy holiday typically due impend due date 9 months pregnant year holiday e special many reason important first year celebrate family three year family kid friendly holiday son start walk e things force intentional holiday decor ask participate know go theme center around family friendly holiday love diys especially budget friendly decorate want space feel crafty cozy place inspire creativity warmth family prompt year style challenge create christmas tree tomato cage perfect theme real even faux christmas tree easily knock pull wander little hand kid friendly tree work perfectly family friendly space course stop go little spray paint paint chip crazy hand craft everything space read full detail cut tomato cage desire length make short one cut top tier tap prongs together wrap ram board create base adhere shims tape ram board place painter tape begin hot glue shims ram board start bottom even layer begin stagger different lengths cover towards top cone finish shims top tree come together point cut shims half diagonally saw create thin triangular shape shims use top christmas tree finish glue shims place ram board pretty much cover let glue dry paint tree various fun shade green use quarts interior paint various shade green brush onto larger tree tree smaller side spraypaint couple coat green let wood shim christmas tree dry overnight decorate tree ribbons light leave simplify look tree pretty indestructible withstand bite beat 9 month old try pull shims attempt drag tree around floor use plywood cut size paint make super easy custom chalkboard thank friend great chalk letter deliver seasonal welcome room old frame fun spray paint color wall decor present wrap crafty leftover sew trim pom poms make space feel youthful crafty round crafty tree spray thin coat match bright green color scheme create paint chip tree wall hang craft little mini tree handmade holiday banner create white paint chip round paper punch adorn vintage mirror little spray paint frame dear keep crafty feel color scheme throughout room cohesive also create faux stack log fireplace insert simply cut backyard branch onto piece plywood paint black x associate cut wood desire dimension finish insert coat finish wood end piece really add cozy feel space crafty tree terrarium station complete room great activity older kid get holiday spirit foster creativity forage glass mini brush tree hot glue gun quickly whip terrariums time embellish paint dip pinecones spray paint deer inside terrarium add colorful ribbon outside line dresser cozy plaid white paint burlap role thin brown paper finally wreath simple faux green wreath hack little white paint brush bottom snow make wreath look snow glaze little spray paint olive green color hot glue wreath keep color scheme consistent personalize basic green wreath wish creative crafty holiday year hope post inspire handmake holiday cheer chelsea mohrman live columbus ohio handy husband young son evan chelsea freelance diy writer stylist blog farm fresh therapy home diy blog achieve lay back midwest style budget follow pinterest christmas decorate ideas take look blog post x need decorate christmas diy colorful holiday decor choose perfect washer dryer set laundry room tower timbers block stack game choose new kitchen range feature consider buy tell us little bite find article fit taste start select options bedroom ideas kitchen ideas bathroom ideas patio ideas live room ideas storage ideas home office ideas basement ideas pantry ideas din room ideas backyard ideas nursery ideas', 'dream deck quite achievement see work need do make backyard ready deck chelsey curtis husband start backyard pretty severe slope patience hard work clever ideas truly impressive outdoor space chelsey e manage get amaze deck build share clever ways make outdoor space order truly appreciate something sometimes go way back start average backyard give us day close house something tell easily picture actually slop nearly 45degree angle highest point side house almost completely level street side photo take lot severely slop one lot remain neighborhood neighbor saw build hear comment like backyard would great sled winter luck hill deter us one bite big plan overall vision beautiful dream backyard upper angle look photo really show high slop side upper cement pad highest e point start hire landscaper help us phase 1 transformation add cement pad upper level storage connect path outdoor fireplace see look finish fireplace landscaper finish retain wall position cement block gravel area deck remove nearly 10 dump truck full dirt mostly rock bring topsoil finish leave us enough sod us cover quarter acre lot time pick color deck come overall design decide build deck composite material call amorguard make veranda choose bite nervous husband want take project would build deck alone mind ease visit associate x prohelp desk create full blueprint detail booklet deck plan make specifications stepbystep instructions e number materials need complete project technology amaze within five weeks husband build beautiful 32 x 15 ft twolevel dream deck leave last summer gorgeous deck need finish touch decide start stairs come deck angle edge deck go toward hot tub decide keep things uniform go length shorter angle see cinder block photo create two problems throw idea build 12foot long planter box e full length remain meet step back forth serious hesitation husband finally agree yay start build project alone take almost 8 hours cut part lawn move sprinkler build planter add vinyl cover finish work filladd plant build finish white vinyl sheet look like white paint wood lot work end glad end love turn really finish side add much visually space past 18 months adventure home ownership learn lowmaintenance yard kind girl since one care plant yard find keep alive longer limit flower one large pot lot shrubs e work really well really want add something break flat buildergrade back house decide add trellis slide glass door build 4 x 4s 2 x 6s 2 x 2s paint bright white tie white rail deck e paint hardest part find stud secure luckily us able find use inside wall photos frame build house house build highly recommend take photos progress come handy une ways also swap dinky light fi larger threebulb one big project do time give deck set patio furniture make space ready entertain choose put din table upper level since right kitchen put conversation set side create path walk cozy spot us visit friends barbecue make last memories transformation phase 2 complete elate outdoor space turn oh case wonder recent backyard comment make us look buy lot one choose absolutely love participate x patio style challenge wait another one ne time may backyard dream come true chelsea curtis author lifestyle blog up life stayathome mom see share beauty passion chelsey emphasis organization host diy home decor beauty live salt lake city utah area husband little girl browse least 16 fabric color choices plenty coordinate outdoor accessories follow board pinterest great outdoor decorate ideas talented bloggers internet dream deck arise despite backyard obstacles diy ideas christmas mantel diy trick treat skeleton porch meet bloggers 2017 halloween style challenge six vintage light bulb update home tell us little bite find article fit taste start select options bedroom ideas kitchen ideas bathroom ideas patio ideas live room ideas storage ideas home office ideas basement ideas pantry ideas din room ideas backyard ideas nursery ideas', 'grace mitchell one wonderful front porches ever see share e front porch decorate ideas take part interest see make change porch since surprise creative mind behind would make number tweak big small freshen look front porch e front porch refresh would include fun day summer activities children front porch see lot activity especially warmer months many thank fact live te spend countless hours space past year since live area full old home porch central culture community neighborhood love fact know neighbor neighbor know us chat walk back forth porches really quite nice finish porch makeover last year felt like gain e room enjoy season happy say still look beautiful day get survive lot little hand meals project ease summer months bring lot popsicle sprinkler time love quality time get kid change decor porch time time think would fun wall awhile bright colorful super easy project kid help would really cute garden party see blog cheapie flower local craft store colorful tape need turquoise chandelier latest diy e share see blog particular day set table afternoon art make watercolor paint serious silly work enjoy new crayon best markers color pencil overall colorful ball great afternoon together heart melt fiveyearold say best summer ever afternoon artistry leave hungry make sure snack ready even start fun activities simply much easier everything ready run back house every little thing pitcher lemon mint water healthy treat keep little ones happy definitely still love recently update indoor acrylic rods see get hot difficult time keep plant front porch alive helpful plant associate x assure would hearty would survive water days forget still favorite get move porch depend need set something someone need e seat firm believer make outdoor space feel like much possible whether space cover something patio deck feel make utilize add pillow softness plant turn may seem like cold area stone concrete something beautiful something feel like home course mama need break two younger kid nap oldest two time room retreat porch little read time really great little book way dennis gee hope kid remember long summer days porch know treasure memories heart best summer ever grace mitchell say think care husband four children think things home often find hunt incredible antique vintage furniture always debate whether keep sell treasure write renovation vintage home te design diy project write previously x blog front porch decorate ideas see well browse everything need enhance outdoor space grace receive complete front porch refresh ideas opinions e front porch decorate ideas flower wall turquoise chandelier christmas decorate ideas cozy family room diy trick treat skeleton porch meet bloggers 2017 halloween style challenge six vintage light bulb update home tell us little bite find article fit taste start select options bedroom ideas kitchen ideas bathroom ideas patio ideas live room ideas storage ideas home office ideas basement ideas pantry ideas din room ideas backyard ideas nursery ideas', 'typically house try keep christmas decorations functional minimal mind find awesome little glass terrariums local x store decide give seasonal look start cut string air plant terrarium remove air plant moss container ne fill hole container paper paint go inside roll small piece long paper two top hole wad larger piece largest hole toward bottom ne tape pattern glass containers area block tape remain clear spray paint e areas coat glitter paint tip make sure press tape firmly along e edge ensure crisp line spray paint container rustoleum glitter spray paint well ventilate area accord instructions package wait spray paint dry completely add second coat necessary spray paint completely dry carefully remove painter tape container remove paper wrap inside add air plant moss back container finally add long string piece twine container hang individually around house dress read nook entryway etc glitter dip glass containers ready hang finish project turn course prefer hang glittery terrariums skip step 8 use decorate table fireplace mantel brittni mehlhoff editor founder write diy home decor fashion small business take look project x blog browse x online paint products check everything need holiday celebrations make unique dip terrarium christmas ornament choose perfect washer dryer set laundry room tower timbers block stack game choose new kitchen range feature consider buy tell us little bite find article fit taste start select options bedroom ideas kitchen ideas bathroom ideas patio ideas live room ideas storage ideas home office ideas basement ideas pantry ideas din room ideas backyard ideas nursery ideas', 'ask favorite bloggers around web surprise us ideas create stylish functional space use x products start point front door might important element create great curb appeal home paint door bright new color easy ine way brighten look home e camila blog mind style challenge show us e paint door replace trim door see result easy front door makeover quite strike imagine e open email x ask participate style challenge focus outdoor paint know right away want take challenge see couple years ago paint front door black since get lot direct sunlight mould door start crack pop due heat house look like paint door damage door pretty noticeable originally go get brand new front door mean lot labor hire someone special woodwork trim plan quickly go window realize could work order new window insert pick new wood replace trim start remove old trim door prim door get work cut new trim piece adhere door do able get work paint behr marquee new line behr offer e resistance dirt fade must e door decide go bite bold go start paint brush first coat decide remove door hinge spray get nice brushfree coat matter minutes door paint close paint job pretty elephant door knocker treat walk home green envy diy serve tray copper pipe acrylic din room christmas decorations teal red mint green paint door great curb appeal diy trick treat skeleton porch meet bloggers 2017 halloween style challenge six vintage light bulb update home tell us little bite find article fit taste start select options bedroom ideas kitchen ideas bathroom ideas patio ideas live room ideas storage ideas home office ideas basement ideas pantry ideas din room ideas backyard ideas nursery ideas', 'ale politis challenge come fun doable weekend project stipulation use lumberale side table scoot right ne sofa make convenient useful clever way stack wood piece give sophisticate modern look follow ale stepbystep instructions make cbase side table desperate need cute side table near couch coffee table cushion mean set drink food fear topple x ask create something lumber know need create end table decide make table perfect addition modern yet natural family room really versatile appearance would gorgeous leave unstained still seal could lightly paint would recommend water paint still see grain though could stain even darker cbase side table oneweekend project perseverance sand one sit believe cut tosize use dimension specific height couch alter accordingly match couch height cut 15 beam 8 15 beam 10 30 beam 25 table together apply line wood glue piece lay go quickly two people would easier wood move around glue basically interlace beam end fit together lengths match every layer e start leave would lay 10 beam perpendicularly butt long 25 beam perpendicularly butt 8 right side come reference image start leave lie top first layer would lay 8 lie top previous 10 beam completely cover obviously shorter last 1 cover long 25 beam time hang previous long 25 beam 1 fit last layer 10 beam perpendicularly match flush edge comment blog question layout bet get start understand right away align wood perfectly go easier go really fast stack piece together wood tightly perfectly meticulous step use e pair hand still help make rest step easier let wood dry accord instructions wood glue use fill large hole small wood piece wood glue meticulous glue wood together gap see table larger would like nothing wood glue fix let spot dry thoroughly move step 4 sand like lot part annoy reward like rip bandage power sand one session want start rough sand disk use 60 grit first sufficiently sand rough groove mismatch areas want fill hole sometimes might need add skinny wood piece large gap like wood glue dry back sand 60 grit sand disk sand 100 grit sufficiently smooth move 150 grit table probably feel like smooth smooth butt love table feel stage wood dry rag sawdust go condition wood treat wood stain apply evenly paint evenly let sit 10 minutes wipe e dry rag apply apply generously paint brush let sit 515 minutes depend dark want wipe e dry rag want darker repeat step finally side table sealant scuff floor new cbase side table see tell pretty easy weekend project 5 master bathroom update complete time wooden star decoration fourth july make simple diy black pipe light fi one afternoon build giant pegboard accent wall build small wooden would water heater closet turn open shelve pantry tell us little bite find article fit taste start select options bedroom ideas kitchen ideas bathroom ideas patio ideas live room ideas storage ideas home office ideas basement ideas pantry ideas din room ideas backyard ideas nursery ideas', 'welcome x blog source inspiration diy project home improvements seasonal project help make home ontrend bathroom ideas three ways style bedroom nook new decor trend hardware 10 inspire mood board sort article interest select include tell us little bite find article fit taste start select options bedroom ideas kitchen ideas bathroom ideas patio ideas live room ideas storage ideas home office ideas basement ideas pantry ideas din room ideas backyard ideas nursery ideas', 'meat smoke necessarily hardest world definitely involve make hot dog grill cheese sandwich wellsmoked pull pork roast get temperature time right proper fuel keep heat steady hours recommend use wood choice smoke pork roast soak wood bowl water least hour add flame dry wood burn away pretty quickly soak wood smolder hours great smoke pull pork roast recipe mouth water may take little time patience prepare tender juicy smoke pull pork roast worth wait check grill make sure temperature remain constant grill instructions need adjust cook temperature time accord preferences e rush use higher temperature cook less time suggest adopt steady method best result 7 laundry tip guarantee make life easier 5 musthave appliance upgrade new decor trend hardware 10 inspire mood board choose perfect washer dryer set laundry room tower timbers block stack game choose new kitchen range feature consider buy tell us little bite find article fit taste start select options bedroom ideas kitchen ideas bathroom ideas patio ideas live room ideas storage ideas home office ideas basement ideas pantry ideas din room ideas backyard ideas nursery ideas', 'tongue groove wall add visual insterest room super durable simple clean also fairly simple diy home improvement project alix adams ruffle life build brighten din room inspire room home look terrific alix stepbystep tutorial show e instal tongue groove wall love detail home move house immediately begin brainstorm creative ways add detail character home add kid room love way turn also bonus beadboard forgive sticky kiddo hand pick wall treatment hightraffic din room decide go another durable millwork option tongue groove board see image dark gray din room wall problem several reason first dark gray color soak brightness din room make whole room feel dark dingy second every hand print scratch indent obviously visible need face lift soon possible tongue groove plank perfect choice easy install naturalwood look pine forgive decide paint tongue groove wall white higher gloss paint whip hand print breeze first step optional relevant project wall vent wall cover tongue groove board like wall replace wall vent homecrafted option lot online tutorials short nail wall returnair vent trim 2 trim nail gun add 3 trim side din room wall end tongue groove plank would visible trim give tongue groove wall finish clean look time fun part tongue groove board fun kind millwork name tongue groove plank piece side groove cut along length board side tongue run length board instal nail one board top wall choose install wall tongue side face groove side face may choose install direction second piece slide tongue side second board groove edge board already nail wall nail second piece wall repeat pattern entire wall note leave natural wood paint tongue groove wall could nail board wall tongue area add groove ne board would hide nail hole wall couple areas detail cut make sure cut areas around light switch plug instal tongue groove board wood trim instal time patch nail hole caulk small gap tongue groove board side trim baseboards putty use fill nail hole best apply small mound hole use caulk caulk gun apply line caulk crack need caulk sandable apply caulk use finger smooth wood putty dry sand smooth surround wood prep work complete time move paint new tongue groove wall first step paint painters call basically us cing paint brush paint detail areas roller get include areas wall meet ceiling baseboards also include around vent light switch plug tongue groove specifically important use brush paint board bevel edge difficult reach roller paint two coat areas allow coat dry completely move step 7 use roller apply thick coat paint wall baseboards vent two coat paint let first coat dry completely add second coat second coat paint dry reinstall light plug cover emphasize enough much love new din room wall tongue groove make feel structural substantial cool way plus bright white paint open space much fresher feel every time walk din room see new tongue groove wall make smile alix adams always makerdoer say would literally lose mind create things blog alix write craft entertain raise family life general live husband two children near salt lake city visit x supply build tongue groove wall diy project follow board pinterest diy tutorials ideas outdoor holiday crate decorations build tongue groove wall kid room organization solutions practical attractive choose perfect washer dryer set laundry room tower timbers block stack game choose new kitchen range feature consider buy tell us little bite find article fit taste start select options bedroom ideas kitchen ideas bathroom ideas patio ideas live room ideas storage ideas home office ideas basement ideas pantry ideas din room ideas backyard ideas nursery ideas', 'might guess erika batista blue wonder patio makeover blue patio makeover mi different shade blue various print create stylish look also stay within budget take look beautiful blue patio stick around valuable tip decorate budget patio din set break one thunderstorms early year help set blue patio makeover motion glass table completely shatter head x find new one go love swivel end chair comfortable family weather resistant easy clean maintain super easy assemble love mi color print patio style also want decorate outdoor space stick budget might see throughout style house budget find clear vision want style rest easy cake add warmth coziness backyard add contrast turquoise cushion seat din set balance add love blue shade especially contrast blue pink completely opposite color spectrum e accomplish blue patio makeover mi print color truly love way backyard turn one reason love shop x appreciate variety style choices price point offer style size outdoor furniture matter size backyard look spruce outdoor space budget recommend start mood board go pinterest get inspire realistic important best fit space make list must have may able spend little patio din set budget little less accessories e importantly set budget stick believe possible beautiful home budget like splurge aim get creative make space feel like million buck add right detail five tip work come decorate home indoors outdoors long cohesive way believe mi print te truly make room indoor outdoor feel lu outdoor area rug make difference patio something cozy piece make space come together get picture decide mix print keep color tone turn patio set already beautiful print colorful pillow truly make stand feel comfortable take look use candle e light night e storage double side table always must check store throw pillow even kid toy get obsess hope enjoy outdoor decor tip spring erika batista fashion lifestyle blogger bear miami raise guayaquil equador live new jersey founder editor blog share life wife modern mom two littles follow patio decorate ideas inspiration check browse x online section patio set fit style budget trendy blue patio makeover choose perfect washer dryer set laundry room tower timbers block stack game choose new kitchen range feature consider buy tell us little bite find article fit taste start select options bedroom ideas kitchen ideas bathroom ideas patio ideas live room ideas storage ideas home office ideas basement ideas pantry ideas din room ideas backyard ideas nursery ideas', 'intel earth day every day part empower employees integrate sustainability work life years xhas several program encourage fund reward employees without power passion employees get far ideas make xand community greener wirsig one employee turn passion sustainability action positive impact intel sydney join xin 2014 market organization day one look ways get involve sustainability efforts feel responsibility good global citizen make sustainable choices live well help others personal journey live sustainably realize want help encourage others look opportunity xpopped inbox corporate responsibility team look passionate employee develop pilot sustainable live discussion course employees sydney jump opportunity select lead effort work northwest earth institute nwei create discussion course book sustainability topics sydney launch course 200 employees nwei course book cover everything food transportation article data variety source give people think allow decide information format course allow open discussions reactions course content collective problem solve sydney reflect course say incredibly gratify hear stories group things try work long term know anyone would make change sustainable base learn turn efforts everyone outstanding facilitate two offer course engage 450 employees total even though longer facilitate course start sydney sustainability efforts intel realize opportunities lead sustainability project around take initiative pursue sydney recall aha moment lead ne project want e access local healthy food search ways lower food miles sydney want start community garden xcampus find sustainability action grant intel determine make happen grant fund employee ideas make xor community sustainable hours research plan proposal development receive news grant recipient real work begin garden full bloom recruit volunteer plan raisedbed build days coordinate vendors bring 38 raisedbed organic garden life result first grow season garden club 50 employees participate beat food donation goal host garden educational event 300 kid upon reflection sydney reveal reward challenge side project ever do even know challenge would since garden completion 2016 sydney continue help run garden enjoy share learn process others want start community garden glad able bring sustainable food source employees community support intel may grasp sydney always new sustainability idea brew ne interest look ways divert waste go landfills start collect hardtorecycle package send organizations properly recycle love try larger scale community share clearly sydney true champion sustainability xand always look new ways help employees reduce footprint planet want take action today sustainable life sydney suggest less meat water grain resources save every meatless meal tremendous mention personal health benefit enjoy look give hamburger yet sydney also advocate use fewer plastic grocery bag note millions years take break suggest get reusable bag groceries share tip remember reusable bag one fold clip purse always even unplanned trip store way togo sydney', 'e see tremendous potential deliver e entertainment e connect home last month xtechnologies together robust ecosystem partner demonstrate power advance video audio solutions highquality media creation delivery amaze time live reinvent compute landscape video service providers broadcasters make everything smart connect integrate innovative revenueboosting media solutions rapid uhd content delivery highperformance video capture transcoding negeneration connect home e make possible intelbased gateways hardware software empower tomorrow transformative media e personal perspectives key takeaways one big trend see home gateways act foundation connect home transform users digital live trust effortless access new valueadded service evere range devices amaze user e e provide highestperformance lowestpower mostfle application platform bring service providers xhas wifi solution industry today support 100 clients provide performance consumption scalability support grow range mediacentric applications iot devices users home great technical capabilities also come tremendous opportunities creativity enable content service providers quickly deliver innovation connect home save cost simplify operations create new service applications xanywan grx750 family provide oems fle connect wire wireless technology include optical fiber dsl gfast 4g5g allintelbased solution available combination xxway wav500 wifi ethernet dect voice connect home become ever robust powerful combination arria 10 xxeon processors virtualization orchestration provide bestinclass uhd h265 video compression lowest total cost ownership tco make amaze consumer e really enjoy e new hardwareaccelerated hevc transcoding capabilities performance efficiency xmedia server studio run latest xxeon processor e3 familybased servers enable superfast highquality video stream video conferencing e see technologies power ne generation e audio video e look forward continue thrill avenue home connectivity together xiot developments email notifications blog update visit comment close', 'think protect environment often think faraway issue like melt ice cap dwindle rainforests reality however much closer home world health organization estimate 92 percent world population', 'recent conference china confirm quiet revolution digital signage moment ripe transformation cost sensors bandwidth compute decrease significantly cloud stream media remote management increase performance', 'live computex 2008 taipei favorite demo guy get hand real deal never say demo guy perk today get privilege hand brand spank', 'last week invite panel interact 2008 washington dc lot great social media pioneer dc event include newmediajim twitter somewhat frank aol', 'since turn millennium see advance chip manufacture process circuitry measure 180 nanometers 130 90 65 45 32nm new architectural design every time', 'attend ces earlier month simply follow news event may hear noise stream tv bo xreaders fairly major announcement xrelease 2010 consumer electronics show xlabs get spotlight one many promise innovations xceo paul otellini keynote light peak code name new highspeed optical cable technology design connect glen shires principal engineer chief architect speech technologies pc client group specialize integration internet speechrecognition video voicecommunications glen bring systemwide approach architecting platforms e development e xreader name one top 10 cool new toy ces cnn top 10 gadget last gadget stand new mobile device take picture print material like placement hdtv family room never design let hook laptop hdtv internet feed laptop parallel digital universes sure could sit placement hdtv family room never design let hook laptop hdtv internet feed laptop parallel digital universes sure could sit overwhelm interest receive initial post light peak months ago plenty question ideas raise potential single io port multiple protocols support power xcentrino brand represent xwireless products target broader range users ever three new centrino wireless feature advance 80211n multistream capabilities dualband support wifi offer users 8 time greater speed xcentrino brand represent xwireless products target broader range users ever three new xcentrino wireless adapters feature advance 80211n multistream capabilities dualband support wifi offer users 8 time today launch new xcore processor family base westmere code name 32nm project great time discuss 32nm process technology communities response technology traditionally', 'currently transition phase cloud move beyond trendy reputation evolve become quiet omnipresent force drive way people company seamlessly share store data recent forrester show cloud market see continue growth total cloud market include private virtual private public cloud market predict reach 61 billion end 2012 e include insights market research e insights lab discuss future cloud continue improve society become universal look advance mobile technology consumer mobile device usage affect wide variety industries include art business culture social network e design photography film music viewers get glimpse think leaders various industries background leverage mobile technology innovate ultimately impact consumers live ways use technology date videos focus everything mobility impact society spur innovation security privacy risk associate mobile device use comment close', 'video series spotlight think leaders vision mobile technology change world debut week showroom floor mobile world congress barcelona spain new mobile insights build video series launch last year mwc 2012 bring together variety perspectives e entertainment art technology business culture e always connect technologies change live interview include pandora fashion designer dreamworks discuss mobility innovation series aim bring understand rapid evolution mobile technologies impact healthcare emerge market entertainment daily live people mobile world congress bring together world lead mobile technology innovators mobile insights focus capture trend visuals define year ahead follow mwc series feature interview lead software developers academia researchers e popular phone manufacturers highlight 60 second insights store new mobile insights series start monday february 25 catch new episodes twitter follow intel mobileinsights mwc13 mobile technologies change area e daily life comment close', 'many common myths industry like chinese idiom myth like leaf front eye block view mountain myths block larger view go industry vice president general manager xsystem software division take stage address myths discuss company vision modernize compute enhance user e message resonate really well idf attendees would like share highlight make show boom smartphone sales rise time environment many people quick question relevance pc sensationalistic pc steady sales far less interest boom smartphones tablets fisher e keynote thursday however personal compute rapidly transform take many different form desktop notebooks today convertibles detachables accord fisher xand industry modernize compute e new feature touch interface fast boot connectivity security available devices acknowledge xhas always deliver great performance windows point company equally focus power great user e require robust performance battery life showcased xprocessors lead performance competitive battery life provide best e windows consumers plenty options disposal fisher e mission xsoftware service group ensure best compute e xprocessors across operate systems os include android chrome os tizen windows include make sure users get performance great battery life anything everything xprocessor inside matter os environment use also include work ecosystem application choice e help application developers target emulate xarchitecture ia armbased platforms write applications android apps build android ndk xis also largest e contributor chrome os ecosystem support operate system 4th generation xcore processor family open development technology help application developers lower total cost improve timetomarket crossplatform application development deployment ensure technology continue evolve remain open innovation fisher announce launch crossplatform development environment develop test deploy applications run across multiple device type operate environments well available across various application store zhao bo director ministry industry information technology china electronic standards institute join fisher stage talk development html5 china constantly work innovate evolve applications e introduce new hardware form processors also work developer community modernize pc applications business consumer use recently focus concentrate touch interfaces sensor technology past year xhas work application developers grow e perceptual compute technologies include facial voice gesture recognition enable humanlike interactions modernize compute security always important factor consider particularly users enter personal information conduct financial transactions social media activities mobile devices use latest technologies include near field communications nfc mobile payments xidentity protection technology xhas collaborate global bankcard network unionpay make mobile payments easy secure speak fisher keynote hongfeng chai e vice president unionpay introduce unionpay quick pass service consumers use nfc smartphone power xprocessor pay products stage two speakers demonstrate realtime secure transaction soda machine use latest technology sometimes feel like alone industry support become successful fisher point xunderstanding developers success translate company success xhas number program resources build developers include offer technical support software development tool market assistance community forums work developers deliver new feature software advancements xis work create foundation everyone compel e compute device choose interest get information keynote idf beijing news come show click comment close', 'new data breach pop news regular basis secret people e network vulnerabilities find large company credit card processors hot target hackers home wifi properly secure thankfully home wireless network security improve dramatically recent years advance technology make tougher hackers access network boil use use mitigate security risk keep device firmware date swap device default settings wireless network name ssid reflect location router type e routers default broadcast manufacturer name leave factory settings unsecured network leave e poorly secure network much better default router passwords e easy hackers break wep security settings many e weaknesses switch device security mode wpa2 choose long password combination capital letter special character number put better shield protect wifi hackers beyond router basic settings additional change make secure network things replace router factory firmware opensource alternative novice user advisable unfamiliar technical aspects wireless network however advance settings filter mac address disable upnp outline may offer additional layer security wifi network', 'much anticipate big game weekend whether avid sport fan throw fantastic party one many people recently cut cable cord need find new way watch time consumers stand demand nothing less fastest reliable wireless technology new devices xnew wireless site offer wealth information benefit xwirelessac 2015 full swing many us hold onto resolutions promise least carry february recent years technology play central role help us keep resolutions fitness end 2014 marriott american hospitality lodge association make wave petition fcc right block personal wifi hotspots venues backlash immediate fierce everyone consumer advocate let face cord cute every time connect laptop 2in1 e display spend precious time fumble around clumsy cord rummage around bin full random adapters look wireless display capabilities grow leap bound recent months take new cordcutting technology ne level xpartnered lg release industry first wireless display support full 4k uhd video stream industryleading many emerge trend year 2015 consumer electronics show ces products mean capture playback ever increase resolutions video image data ever technology put consumers ces 2015 catch glimpse e technology year like new compute e devices truly intelligent innovative applications like xrealsense true key announce travel internationally may familiar difficulties associate connect wifi network wireless standards regulatory requirements differ country country incompatible wifi hardware laptop mobile device may adversely affect know wifi could cost buy new 2in1 new device include latest 80211ac wifi able take advantage incredible new speed stability', 'mean skills change generation generation consider paramount talent overlook art form children today naturally use tablet laptop 2 1 allinone pc smartphone accomplish almost task may never learn knit bake tie slipknot like grandma grandpa grow generations learn lot x encourage grandparents grandchildren even parent get together grandparents day share favorite talents howto nationwide skill swap september 13 gather family together enjoy quality time learn engage useful skills best teach grandparent grandchild addition teach new tech skills novice tech members family use favorite intelpowered tablet laptop 2 1 allinone pc smartphone capture grandparents day moments photo video format chronicle day jot note newfound skills even great distance separate celebrate day remote locations use technology communicate virtually swap skills stories e video chat grandma grandpa show cook favorite meal kitchen virtually teach play digital card game though miles apart feel close together thank reliable powerful video chat capabilities intelpowered devices limit fun e september 13 continue practice throughout year take look x activity list inspiration send invitation grandparents grandchildren proudly post skillswap badge show participation happy grandparents day grandmothers grandfathers comment close', 'technology become closely daytoday live apparel accessories even e e watch ne iteration marriage fashion technology come life year week xis team industry leaders like wmeimg well designers creators behind collections showcase technology possibilities infuse fashion intelligent feature modern consumer smart fabrics connect accessories digital mirror help reimagine shop e nyfw showcase number e technology head help enable new e opportunities across fashion technology industries consumers seek seamless shop e much ability e individuality personal style year technology feature catwalk demonstrate shop e revolutionize take e memorymirror platform memomi power xtechnology display alongside nyfw presentation calia athleisure collection today memorymirror use xrealsense technology iris graphics xcore i7 processors transform way people shop allow virtually try clothe additionally nyfw attendees opportunity throughout week interact memorymirror technology img nyfw hq space memorymirror memomi already fi select neiman marcus retail store e additional store ne two months nyfw recently become know showcasing latest inventive wearables diane von furstenberg google glass year new products blend fashion functionality make appearance collaboration label chromat xwill demonstrate responsive chromat runway show make fashion week september 11 xand fossil showcase products alongside collection emerge designer baja east present make fashion week september 12 spectators miss anything year nyfw chance drone cover fashionistas entirely new view nyfw season 360degree view rebecca minkoff also collaborate xto drone capture aerial shots guest arrivals look come catwalk ss 16 show designer nyfw 2015 whose runway show capture drone technology electric aviation manufacturer yuneec week drone also film inside venues nyfw hq space moynihan station clarkson square capture arrivals several fashion show include public school prabal gurung bcbg max azria monique lhuillier intel want partner fashion take lead believe collaborative approach key successfully advance wearables partner bring table product e consumer insights bring know best advance cuttingedge technology take unique approach work collectively fashion brand designers innovators retailers bring market smart products line customers e add layer innovation afternoon september 12 marie claire creative director nina garcia moderate discussion xceo brian krzanich chromat founder becca mccharen future fashion see chromat runway show even brian discuss challenge opportunities fashion industry seek push boundaries fashion technology provide detail behind technologyenabled fashion show runway chromat september 11 presentation springsummer 2016 collection stay uptodate xnyfw activities get close personal view activities visit press kit update throughout week drone capture events videos image nyfw comment close', '2in1 devices offer productivity laptop fle tablet one unique piece hardware combine fast innovative xcore processor lightningquick data transfer speed 80211ac wireless holiday fill fun e favorite traditions also hectic sometimes stressful time year amidst shop cook entertain often feel though might benefit e helper technology intimidate us want device long list fancy feature learn trouble shoot come along simplicity ease use important factor despite advance cellular data transfer speed coverage wifi continue primary hub mobile device data addition dominant method connectivity current mobile users trend like internet things set fast stable wifi network home difference smile frown speakers tvs game console printers laptops smartphones tablets plethora additional wireless accessories compete precious slice advance wireless technology create opportunities people declutter live remove cord xvision create completely wirefree e home office one first step linkin park use intelpowered technology demonstrate tech significant presence creative industries today recent video park mike shinoda share fan technology help unleash creative mind use advance technology produce comfortable wireless compute e allow us ability move beyond tether ethernet cable still step confidently say wire free holiday busy time preparations get ready intelpowered tablets lend hand make holiday halloween memorable fun without much pain behind select costume enterprise integrate byod mobility strategies burden place wireless access point company increase e past employees connect wireless network one primary device laptop 80211bgn routers', 'mobile world congress take place barcelona past week remind mobile technology infiltrate nearly every part human life across world early stag innovations', 'since turn millennium see advance chip manufacture process circuitry measure 180 nanometers 130 90 65 45 32nm new architectural design every time always amaze incredible work xmanufacturing group especially come major technology transitons like one upon us shrink 32nm require massive investment', 'nothing like e maybe virtually x cto justin rattner idf keynote get see live 3d demonstrations show businesses doctor turn virtual worlds x begin pump ne generation chip design use energy efficient 45nm transistors vital today future software program run smoothly harness potential performance new processors', 'may see announcement today privatelyheld achronix plan start manufacture future line fpga products forthcoming 22 nanometer chipmaking process many know xenjoys multiyear lead manufacture', 'set fast stable wifi network home difference smile frown speakers tvs game console printers laptops smartphones tablets plethora additional wireless accessories compete precious slice', 'e media relations contact answer news media inquiries 9724441107 call 8326254000 inquiries concern eastern canada 902 490 9700 northerncentral canada 587 476 7010 907 564 3734 brazil 55 21 2546 7700 inquiries 44 1372 22 2261 44 1372 22 2274 australia 61 39270 3124 62 21 5798 6299 603 2380 2484 603 2380 2715 65 6885 8275 angola 244 333058 e 2201 cameroon 44 207 07 41439 44 207 07 41414 guinea 713 656 4376 234 1 262 1726 234 1 2621640 e 2086 azerbaijan 994 12 982460 713 767 9307 7 3272 503 002 7 495 980 5650 7 4242 726732 7 4242 727160 qatar 974 4497 8467 arabia 9661 273 8425 receive news release contact us aviation fuel lubricants asphalt basestocks crude oil sales commercial vehicle lubricants e chemical industrial lubricants marine fuel marine lubricants passenger vehicle lubricants retail technology license catalysts wa white oil wholesale fuel', 'x na lasalle na lasalle bank midwest na announce today primelending rat 650 percent 725 percent january 22 2008 x lasalle loan documentation term reference rate use refer lend rate term prime rate reference rate refer rate x one world largest financial institutions individual consumers small middle market businesses large full range bank invest asset management financial riskmanagement products service company unmatched convenience unite state serve 59 consumer small business relationships 6100 retail offices nearly 19000 atms awardwinning online bank 12 million active users x 1 overall small administration sba lender unite state 1 sba minorityowned small businesses company serve clients 175 relationships 99 percent yous fortune 500 80 percent fortune global 500 x stock x list new york stock e x acquire lasalle bank october 1 2007 x contact sarah whitmire x 17043878164 whitmire xcom', 'x nc prnewswirefirstcall today announce commence offer e million share common stock outstanding depositary share series prefer stock e offer subject term condition describe e date relate letter transmittal file e offer e midnight time unless e earlier terminate holders depositary share eligible e able tender share withdraw previously tender depositary share time prior e e offer e offer would increase tier 1 common capital amount equal aggregate liquidation preference depositary e share issuable e offer part previously announce plan e common stock nongovernment perpetual prefer stock believe action assist meet indicate supervisory assessment program scap buffer set federal reserve offer issue share common stock offer applicable consideration amount per depositary share table number share common stock issuable e depositary share equal consideration amount average daily per share volumeweighted average price common stock five consecutive trade days include second business day prior e date e offer common stock average price later one condition e offer must satisfy waive common stock average price number share common stock issuable e share validly tender properly withdraw e date e 200 million accept number depositary share result number common stock issue e offer e 200 event acceptance validly tender depositary share base priority level assign series prefer stock priority level 1 accept depositary share also may subject proration describe e e offer subject number condition must waive prior e date offer e term e offer procedures validly tender depositary share describe detail offer e relate materials copy may obtain without charge agent e offer call 800 8296551 toll free 212 2695550 collect offer e available free charge sec website file e tender offer schedule e offer make holders depositary share upon e registration requirements act 1933 amend securities act provide section 9 securities act press release offer purchase offer e solicitation acceptance offer securities e offer make pursuant term offer e relate materials one world largest financial institutions individual consumers small middlemarket businesses large full range bank invest asset management financial risk management products service company unmatched convenience serve appro 55 consumer small business relationships 6100 retail offices 18500 atms awardwinning online bank 30 million active users among world lead management company global leader corporate investment trade across broad range asset class serve governments institutions individuals around world offer industryleading support 4 million small owners suite innovative easytouse online products company serve clients 150 countries stock nyse bac component dow jones average list forwardlooking statements management may make certain statements forwardlooking statements within mean private litigation reform act 1995 statements historical instead represent current e plan plan raise capital similar matter guarantee future result performance involve risk uncertainties assumptions difficult predict often beyond control actual outcomes result may materially e imply theselooking statements place undue reliance forwardlooking statement consider follow uncertainties risk well fully discuss item 1a risk factor 2008 report form 10k subsequent sec negative economic condition adversely affect general house price job market consumer confidence spend level volatility capital market interest rat value market indices change consumer investor confidence relate impact financial market credit rat credit rat estimate fair value certain assets legislative regulatory action impact litigation regulatory investigations cost e settlements judgments various monetary policies regulations yous nonyous governments change account standards rule interpretations impact financial statements increase globalization financial industry competition yous international financial ability attract new employees retain motivate e employees mergers acquisitions reputation decisions downsize sell close units otherwise change business mix forwardlooking statements speak date undertake obligation update anylooking statement reflect impact circumstances events arise date forwardlooking statement make contact investors 17043865667 17043886780 12124497323 reporters 19803889921', 'charlotte nc oct 18 prnewswire x corporation nyse bac today report record third quarter earn 215 billion 125 per share 123 dilute result far surpass 374 million 21 per share 21 dilute earn year earlier impact global financial turbulence e 725 million pretax mergerrelated charge operate earn year ago 893 million 51 per share 50 dilute dilute operate earn per share 7 percent second quarter year company return equity rise 1840 percent third quarter return assets increase 140 percent cash operate earn e amortization intangibles mergerrelated charge 237 billion 138 per share 135 dilute return tangible equity 2948 percent year earlier cash operate earn 112 billion 64 per share 63 dilute x make solid progress third quarter say hugh l mccoll jr chairman chief e officer merger transition continue go smoothly remain schedule successfully build investment bank platform deliver service huge middle market customer base refocus number businesses achieve greater value customers higher profitability shareholders accomplish initiatives increase earn improve return first nine months 1999 operate earn 25 percent 613 billion 353 per share 345 dilute compare 489 billion 281 per share 273 dilute year earlier net income 49 percent higher 598 billion 345 per share 337 dilute compare 400 billion 230 per share 224 dilute year earlier third quarter earn highlight compare year ago revenue rise 21 percent noninterest income increase 55 percent fullyta equivalent net interest income 3 percent average manage consumer loan increase 17 percent feebased income record strong improvement almost areas rise 45 percent revenue efficiency ratio improve 54 percent net chargeoffs decline 51 percent loan net interest income fully taequivalent net interest income 460 billion 3 percent higher year earlier due solid loan growth somewhat offset impact securitizations loan sales fund cost share repurchase net interest yield earn assets 346 percent compare 360 percent year earlier noninterest income noninterest income increase 55 percent 373 billion due widespread gain across spectrum x feebased businesses primary gain record credit card trade investment bank mortgage bank service charge income fee income rise 45 percent revenue securities gain 44 million compare 280 million third quarter 1998 efficiency noninterest e decline 1 percent 453 billion reflect cost save result recent mergers offset increase revenuebased incentives accelerate spend merger transition project continue e investment bank business efficiency ratio improve 54 percent credit quality provision credit losses third quarter 450 million compare 14 billion year earlier net chargeoffs 460 million well 902 million year ago include 372 million chargeoff relate de shaw relationship net chargeoffs represent 51 percent loan lease latest period nonperforming assets 304 billion 84 percent loan lease foreclose properties september 30 1999 compare 258 billion 73 percent year earlier allowance credit losses total 708 billion september 30 1999 equal 252 percent nonperforming loan 196 percent loan lease allowance 721 billion 315 percent nonperforming loan 205 percent loan lease year earlier capital strength shareholders equity stand 459 billion september 30 1999 tier 1 capital ratio 771 percent company market capitalization 95 billion june 23 company authorize repurchase 130 million common share 24 months e complete program within 18 months september 30 company purchase 43 million share business segment result consumer bank serve individuals small businesses earn 110 billion commercial bank serve company 10 million 500 million revenue earn 216 million together represent 61 percent company operate income global corporate investment bank serve large corporate customers earn 530 million represent 25 percent company earn principal invest asset management encompass private bank trust investment management mutual fund retail brokerage principal invest earn 244 million represent 11 percent x 621 billion assets largest bank unite state company serve 30 million households 2 million businesses across country offer customers largest convenient delivery network offices atms telephone internet access also provide comprehensive international corporate financial service clients business around world company create financial relationships feature wide array financial service traditional bank products investments capital raise within securities market x stock ticker bac list new york pacific london stock e certain share list tokyo stock e investor information find wwwbankofamericacominvestor wwwbankofamericacom x corporation x corporation', 'load san francisco mckesson corporation nyse mck release financial result second fiscal quarter end september 30 2011 tuesday october 25 2011 follow market close appro 400 pm eastern time 100 pm pacific time company schedule conference call 500 pm eastern time 200 pm pacific time john hammergren chairman chief e officer jeff campbell e vice president chief financial officer review result dialin number individuals wish participate call 7192347317 ana schrank vice president investor relations leader call password join call conference call also available live archive company investor relations website mckesson corporation currently rank 15th fortune 500 healthcare service information technology company dedicate make business healthcare run better partner payers hospitals physician offices pharmacies pharmaceutical company others across spectrum care build healthier organizations deliver better care patients every set mckesson help customers improve financial operational clinical performance solutions include pharmaceutical medicalsurgical supply management healthcare information technology business clinical service', 'load san francisco mckesson corporation nyse mck release financial result third fiscal quarter end december 31 2011 monday january 30 2012 follow market close appro 400 pm eastern time 100 pm pacific time company schedule conference call 500 pm eastern time 200 pm pacific time john hammergren chairman chief e officer jeff campbell e vice president chief financial officer review result dialin number individuals wish participate call 7192347317 ana schrank vice president investor relations leader call password join call conference call also available live archive company investor relations website mckesson corporation currently rank 15th fortune 500 healthcare service information technology company dedicate make business healthcare run better partner payers hospitals physician offices pharmacies pharmaceutical company others across spectrum care build healthier organizations deliver better care patients every set mckesson help customers improve financial operational clinical performance solutions include pharmaceutical medicalsurgical supply management healthcare information technology business clinical service', 'chicago april 27 2011 prnewswire boeing company nyse ba report firstquarter net income 06 billion 078 per share revenue 149 billion margin 67 percent reflect strong core performance across company businesses e lower volumes higher pension e yearago quarter include 020 per share tax charge health care legislation table 1 company also reaffirm 2011 revenue earn per share operate cash flow outlook good start important year company say jim mcnerney boeing chairman president chief e officer deliver strong operate performance make significant progress 787 7478 flight test score major win yous air force tanker program outlook remain positive people focus meet customer commitments drive productivity competitiveness gain capture growth opportunities commercial airplanes defense space security businesses less additions property plant equipment 417 186 boeing quarterly operate cash flow 10 billion e lower volumes continue investment development program cash flow 14 billion quarter table 2 marketable securities 1 21 51 boeing company boeing capital corporation cash investments marketable securities total 78 billion quarterend table 3 105 billion yearend 117 billion 124 billion yearend primarily due boeing capital corporation maturities total company backlog quarterend 329 billion 321 billion yearend quarter 23 billion include strong commercial order mix yous air force kc46a tanker contract yous navy p8a lowrate initial production contract boeing commercial airplanes firstquarter revenue decrease 5 percent 71 billion plan lower 777 deliveries margin 72 percent reflect lower deliveries higher r table 4 flight test 787 program continue quarter surpass 3500 hours 1250 flight delivery e third quarter 2011 total firm order 787 quarterend 835 airplanes 56 customers 7478 program flight test also progress quarter surpass 2500 hours 900 flight flight 7478 intercontinental achieve march first 7478 freighter plan mid2011 commercial airplanes book 153 gross order quarter 47 order remove order book bring net order 106 yearago period net order 83 airplanes remain strong 3400 airplanes value 263 billion boeing military aircraft network space systems global service support boeing military aircraft network space systems global service support boeing defense space security bds firstquarter revenue 76 billion operate margin 88 percent table 5 boeing military aircraft bma firstquarter revenue increase 02 billion 34 billion due higher deliveries margin 109 percent reflect improve performance mix global strike program lower r quarter bma complete full scale static test p8a achieve first flight f15 radar modernization program network space systems n ss firstquarter revenue 23 billion margin 61 percent reflect less favorable mix lower earn satellite business quarter n ss successfully complete inmarsat5 satellite milestone final acceptance skyterra satellite global service support gs firstquarter revenue decrease 02 billion 19 billion due conclusion kc10 support program 2010 delivery time integrate logistics train systems service margin 85 percent reflect lower earn integrate logistics maintenance modifications upgrade quarter gs award performance base logistics contract c17 globemaster iii sustainment partnership followon e f22 sustainment contract backlog bds increase slightly 66 billion appro two time unit e 2011 revenue capital corporation segment items eliminations capital corporation segment items eliminations quarter boeing capital corporation bcc portfolio balance decline 45 billion 47 billion begin year runoff asset sales debttoequity ratio unchanged 50to1 segment consist primarily boeing engineer operations technology well certain result relate financial consolidation business units total pension e first quarter 526 million compare 284 million period last year total 431 million allocate operate segment quarter 305 million period last year 95 million recognize unallocated items compare benefit 21 million period last year company income tax e 295 million quarter 531 million period last year yearago quarter include 150 million 020 per share tax charge health care legislation company 2011 financial guidance table 7 reaffirm reflect solid core operate performance higher pension e plan deliveries development program current defense contract environment 2 485 500 36 38 margin 75 85 military aircraft 142 147 space systems 9 95 service support 83 88 bds revenue 315 33 margin military aircraft 9 space systems 7 service support 105 bds operate margin 85 9 size lower 05 assets 1 research development 37 39 capital e 23 pension e 18 management believe nongaap generally accept account principles measure indicate asterisk use report provide investors important perspectives company ongoing business performance company intend information consider isolation substitute relate gaap measure company may define measure differently follow definitions provide free cash flow free cash flow define gaap less capital e believe free cash flow provide investors important perspective cash available shareholders debt repayment acquisitions make capital investments require support ongoing business operations long term value creation cash flow represent residual cash flow available discretionary e e certain mandatory e repayment mature debt management use free cash flow internally assess business performance overall liquidity 2 provide reconciliation gaap operate cash flow free cash flow document contain forwardlooking statements within mean private securities litigation reform act 1995 may e intend project plan believe estimate target anticipate similar e use identify forwardlooking statements forwardlooking statements include statements relate future financial condition operate result well statement directly relate historical current fact look statements base current e assumptions may prove accurate statements guarantee subject risk uncertainties change circumstances difficult predict many factor could actual result differ materially adversely forwardlooking statements factor risk relate 1 general condition economy industry include due regulatory change 2 reliance commercial customers suppliers worldwide market 3 commercial development program include 787 7478 commercial aircraft program 4 change acquisition priorities yous government 5 dependence yous government contract 6 reliance fiprice contract 7 reliance costtype contract 8 uncertainties concern contract include inorbit incentive payments 9 change account estimate 10 change competitive landscape market 11 nonyous operations include sales nonyous customers 12 potential adverse developments new pending litigation andor government investigations 13 customer aircraft concentration boeing capital corporation customer finance portfolio 14 change ability obtain debt commercially reasonable term competitive rat order fund operations contractual commitments 15 realize anticipate benefit mergers acquisitions joint venture strategic alliances divestitures 16 adequacy insurance coverage cover significant risk e 17 potential business disruptions relate physical security threats information technology attack natural disasters 18 work stoppages labor disruptions 19 significant change discount rat actual investment return pension assets 20 potential environmental liabilities additional information concern factor find file securities e commission include recent annual report form 10k quarterly report form 10q current report form 8k forwardlooking statement speak date make assume obligation update revise forwardlooking statement whether result new information future events otherwise e require law contact unaudited 2010 sales products 12316 sales service 2900 15216 cost products 9822 cost service 2281 boeing capital corporation interest e 41 12144 3072 income operate investments net 59 general administrative e 953 research development e net 1000 loss dispositions net 4 1174 income e net 2 interest debt e 122 1050 income tax e 531 519 net loss disposal discontinue operations net ta 1 519 071 net loss disposal discontinue operations net ta 071 070 net loss disposal discontinue operations net ta 070 042 7401 unaudited december 31 2010 cash cash equivalents 359 shortterm investments 5158 account receivable net 5422 current portion customer finance net 285 defer income ta 31 inventory net advance progress bill 24317 40572 customer finance net 4395 property plant equipment net accumulate depreciation 13516 13322 8931 goodwill 4937 acquire intangible assets net 2979 defer income ta 4031 investments 1111 pension plan assets net 6 assets net accumulate amortization 614 630 1603 68565 account payable 7715 accrue liabilities 13802 advance bill e relate cost 12323 defer income ta income ta payable 607 shortterm debt current portion longterm debt 948 35395 accrue retiree health care 8025 accrue pension plan liability net 9800 noncurrent income ta payable 418 longterm liabilities 592 longterm debt 11473 shareholders equity common stock par value 500 1200000000 share authorize 012261159 share issue 5061 additional paidin capital 3866 treasury stock cost 274304690 277002059 share 17187 retain earn 24784 accumulate comprehensive loss 13758 total shareholders equity 2766 noncontrolling interest 96 2862 68565 unaudited 2010 earn 519 reconcile net earn net cash use operate activities cash items sharebased plan e 66 depreciation 350 amortization acquire intangible assets 55 amortization debt discountpremium issuance cost 5 investmentasset impairment charge net 15 customer finance valuation provision 12 loss disposal discontinue operations loss dispositions net 4 charge credit net 30 e tax benefit sharebased payment arrangements 8 change assets liabilities account receivable 572 inventory net advance progress bill 1833 account payable 225 accrue liabilities 136 advance bill e relate cost 221 income ta receivable payable defer 429 longterm liabilities 246 pension postretirement plan 355 customer finance net 221 47 285 plant equipment additions 186 plant equipment reductions 3 net cash acquire 24 investments 4744 investments 910 economic development program fund 4041 borrow 19 repayments 51 distribution right finance 13 options e 23 tax benefit sharebased payment arrangements 8 ta certain sharebased payment arrangements 15 pay 318 347 effect e rate change cash cash equivalents 25 4698 cash cash equivalents begin year 9215 4517 unaudited 2010 revenues commercial airplanes 7468 boeing defense space security military aircraft 3241 space systems 2323 service support 2049 total boeing defense space security 7613 boeing capital corporation 162 segment 36 unallocated items eliminations 63 15216 earn operations commercial airplanes boeing defense space security military aircraft 270 space systems 174 service support 220 total boeing defense space security 664 boeing capital corporation 46 segment 50 unallocated items eliminations 165 1174 income e net 2 interest debt e 122 1050 income tax e 531 519 net loss disposal discontinue operations net ta 1 research development e net commercial airplanes boeing defense space security military aircraft 162 space systems 106 service support 34 total boeing defense space security 302 segment 000 unallocated items eliminations sharebased plan e 47 defer compensation e 81 pension 21 postretirement 11 capitalize interest 10 eliminations 37 165 unaudited commercial airplanes 2010 737 86 767 3 777 19 108 boeing defense space security boeing military aircraft fa18 model 13 f15e eagle 3 c17 globemaster 3 kc767 international tanker ch47 chinook 2 ah64 apache 4 network space systems delta iv 1 commercial civil satellite 1 military satellite 1 december 31 dollars billions 2010 commercial airplanes 2556 boeing defense space security boeing military aircraft 251 network space systems 96 global service support 137 total boeing defense space security 484 3040 169 3209 160500 nyse', 'core eps nongaap rise 19 percent 214 strong operate performance gaap eps 186 revenue increase 7 percent 238 billion reflect higher deliveries backlog grow record 490 billion 5500 commercial airplane order solid operate cash flow pension contributions 17 billion repurchase 8 million share 1 billion 2014 core eps guidance increase 020 810 830 prnewswire boeing company report thirdquarter revenue increase 7 percent higher deliveries table 1 core earn per share nongaap increase 19 percent drive strong performance across company businesses thirdquarter core operate earn nongaap increase 13 percent period prior year gaap earn per share gaap earn operations core earn per share guidance 2014 increase continue strong operate performance gaap earn per share guidance 2014 increase operate cash flow pension contributions guidance increase greater commercial airplanes operate margin guidance increase appro 105 percent continue strong operate performance across production service businesses drive significant growth earningspershare enable us continue capture new business push order backlog record say boeing chairman ceo add net new order 501 commercial airplanes launch highcapacity 737 max 200 capture sa contract commercial crew program return shareholders dividends share repurchase three solid quarter behind us confidence ongoing performance increase earn per share outlook 2014 team remain focus provide value customers shareholders profitably ramp airplane production e development program drive productivity affordability throughout enterprise mcnerney say operate cash flow pension contributions quarter reflect commercial airplane production rat strong operate performance time receipt e table 2 quarter company repurchase 8 million share leave remain current repurchase authorization e complete appro ne one two years company also pay dividends quarter cash investments marketable securities total quarterend table 3 begin quarter debt unchanged begin quarter total company backlog quarterend record begin quarter include net order quarter commercial airplanes thirdquarter revenue increase 15 percent record higher deliveries thirdquarter operate margin 112 percent reflect dilutive impact 787 7478 deliveries higher period cost partially offset delivery volume continue strong operate performance table 4 quarter company launch 737 max 200 commitment ryanair 100 airplanes 737 program nearly 2300 firm order 737 max since launch due continue strong demand 737 family airplanes company intend increase 737 production rate 42 47 per month 2017 recently announce plan increase 52 per month 2018 also quarter first genxpowered 7879 dreamliner deliver commercial airplanes book 501 net order quarter backlog remain strong 5500 airplanes value record defense space security thirdquarter revenue operate margin 108 percent table 5 boeing military aircraft bma thirdquarter revenue reflect higher p8 deliveries operate margin increase 124 percent reflect improve performance quarter bma deliver first yous army multiyear ii configure chinook network space systems n ss thirdquarter revenue reflect time unite launch alliance ula launch lower government satellite volume operate margin increase 93 percent reflect strong performance quarter n ss award contract sa commercial crew program global service support gs thirdquarter revenue lower volume operate margin 97 percent reflect delivery mix quarter gs deliver first upgrade french airborne warn control system awacs aircraft backlog defense space security 37 percent represent order international customers quarterend boeing capital net portfolio balance unallocated items eliminations thirdquarter revenue decrease period prior year due elimination intersegment revenue two aircraft deliver operate lease table 6 total pension e third quarter period prior year company 2014 financial guidance table 7 reflect continue strong performance businesses supplement report financial information determine yous generally accept account principles gaap certain nongaap financial information nongaap financial information present e certain significant items may indicative unrelated result ongoing business operations believe nongaap measure provide investors additional insight company ongoing business performance nongaap measure consider isolation substitute relate gaap measure company may define measure differently encourage investors review financial statements publiclyfiled report entirety rely single financial measure follow definitions provide core operate earn define gaap e core operate margin define core operate earn e percentage revenue core earn per share define gaap e net earn per share impact represent portion pension postretirement cost recognize business segment segment report purpose management use core operate earn core operate margin core earn per share purpose evaluate forecast underlie business performance management believe core earn measure provide investors additional insights operational performance e unallocated pension postretirement cost primarily represent cost drive market factor cost allocable government contract reconciliation gaap nongaap measure provide page 13 operate cash flow pension contributions define gaap without management believe operate cash flow pension contributions provide additional insights underlie business performance management use operate cash flow pension contributions measure assess business performance overall liquidity table 2 provide reconciliation gaap operate cash flow operate cash flow pension contributions free cash flow define gaap without capital e management believe free cash flow provide investors important perspective cash available shareholders debt repayment acquisitions make capital investments require support ongoing business operations long term value creation free cash flow represent residual cash flow available discretionary e e certain mandatory e repayment mature debt management use free cash flow measure assess business performance overall liquidity table 2 provide reconciliation gaap operate cash flow free cash flow press release contain forwardlooking statements within mean private securities litigation reform act 1995 word may e intend project plan believe estimate target anticipate similar e use identify forwardlooking statements e forwardlooking statements include statements relate future financial condition operate result well statement directly relate historical current fact forwardlooking statements base current e assumptions may prove accurate statements guarantee subject risk uncertainties change circumstances difficult predict many factor could actual result differ materially adversely forwardlooking statements among factor risk relate 1 general condition economy industry include due regulatory change 2 reliance commercial airline customers 3 overall health aircraft production system plan production rate increase across multiple commercial airline program commercial development derivative aircraft program aircraft subject stringent performance reliability standards 4 change budget appropriation level acquisition priorities yous government 5 dependence yous government contract 6 reliance fiprice contract 7 reliance costtype contract 8 uncertainties concern contract include inorbit incentive payments 9 dependence subcontractors suppliers well availability raw materials 10 change account estimate 11 change competitive landscape market 12 nonyous operations include sales nonyous customers 13 potential adverse developments new pending litigation andor government investigations 14 customer aircraft concentration boeing capital customer finance portfolio 15 change ability obtain debt commercially reasonable term competitive rat order fund operations contractual commitments 16 realize anticipate benefit mergers acquisitions joint venturesstrategic alliances divestitures 17 adequacy insurance coverage cover significant risk e 18 potential business disruptions include relate physical security threats information technology cyberattacks natural disasters 19 work stoppages labor disruptions 20 significant change discount rat actual investment return pension assets 21 potential environmental liabilities 22 threats security customers information additional information concern factor find file securities e commission include recent annual report form 10k quarterly report form 10q current report form 8k forwardlooking statement speak date make assume obligation update revise forwardlooking statement whether result new information future events otherwise e require law contact view original version pr newswire visit nyse', 'detail governance structure read board structure information detail guidelines governance structure read committee structure membership information corporate governance document find investor contact mike mcguire vice president investor relations durant investor relations 8002010938 cvshealthcom follow us sign email alert millions time day help people path better health prescriptions help manage chronic specialty condition present many moments big small active supportive role shape future health care copyright 1999 2017 x health', 'latest stock data x health understand value stock hold x health view dividends pay last ten years access detail analyst coverage access netbasis cost basis system investor contact mike mcguire vice president investor relations durant investor relations 8002010938 cvshealthcom follow us sign email alert millions time day help people path better health prescriptions help manage chronic specialty condition present many moments big small active supportive role shape future health care copyright 1999 2017 x health', 'indiapolis deerfield aug 1 prnewswirefirstcall inc nyse wlp nation lead health benefit provider announce completion acquisition american image aim lead radiology benefit management technology aim remain headquarter deerfield illinois wholly operate division x continue lead dave harrington primary strategic goal acquisition achieve appropriate diagnostic image service members say f braly president chief e officer x aim position radiology management technology help enable advance initiatives drive value health better manage rise health care cost increase transparency improve quality patient outcomes aim pioneer integration technology clinical content management introduction webbased prior authorization 2002 platform allow order physicians directly submit receive realtime evaluation widely accept clinical easytouse interface aim web capabilities also help improve quality efficiency information transfer order physicians render deliver complete correct understand clinical help reduce potential waste administrative burden cause communication aim also introduce first set webenabled tool cost quality transparency selection best value image facilities aim currently serve health plan clients represent 20 million acquisition aim accretive earn begin x inc x mission improve live people serve health communities x inc largest health benefit term commercial membership unite state network company deliver number lead health benefit broad portfolio integrate health care plan service along wide range specialty products life disability insurance benefit pharmacy benefit management dental behavioral health benefit service well long term care fle spend account headquarter indianapolis x independent licensee blue cross blue association serve members blue cross licensee blue cross blue shield licensee colorado connecticut indiana kentucky maine missouri e 30 counties city area nevada new hampshire new york empire blue cross blue 10 new york city metropolitan surround counties empire cross empire blue cross blue shield select upstate counties ohio virginia e northern virginia suburbs washington c wisconsin unicare additional information x available www xcom safe harbor statement private securities litigation reform act 1995 document contain certain forwardlooking information inc x intend cover safe forwardlooking statements provide private securities reform act 1995 forwardlooking statements statements generally historical facts word e feel believe may anticipate intend estimate project similar e intend identify forwardlooking statements statements include limit financial projections underlie assumptions statements regard plan e respect future operations products statements regard future performance statements certain risk uncertainties many difficult generally beyond control x could actual differ materially e imply project forwardlooking information statements risk include discuss identify public file yous securities e commission sec make x government regulation health benefit manage care pharmacy management operations trend health care cost utilization ability secure sufficient premium rate increase ability providers consistent past practice competitor price market trend increase cost reduce enrollment well change health care product mix risk uncertainties medicare part prescription drug benefit program include uncollectability receivables result process andor enrollment include facilitate enrollment inadequacy assumptions inability receive process information premium members increase pharmaceutical cost underlie seasonality business downgrade financial rat litigation investigations target health benefit ability resolve litigation investigations within ability achieve e synergies operate wellchoice inc acquisition within e time successfully integrate operations ability e regard repurchase share common stock risk respect revenue receive participation medicare medicaid program complex regulations impose medicare fiscal events result negative publicity health industry failure effectively maintain modernize systems ebusiness organization maintain good third party vendors information system resources may negatively affect license blue cross blue association possible impairment value intangible assets future result adequately support goodwill intangible intense competition attract retain employees unauthorized member sensitive confidential information change market condition well regulations applicable portfolios possible restrictions payment dividends subsidiaries increase require minimum level capital negative affect substantial amount outstanding general risk associate mergers acquisitions various govern document may prevent discourage takeovers combinations potential hedge activities common stock bioterrorist activity potential public health epidemics economic downturns readers caution place undue reliance forwardlooking statements speak date hereof e otherwise require federal securities law x undertake obligation republish revise forwardlooking reflect events circumstances date hereof occurrence unanticipated events readers also urge review consider various disclosures x sec', 'indiapolis march 14 2011 prnewswire via comtex x announce today name vice president underwrite national account business schell replace recently name vice president commercial underwrite new role schell lead national account underwrite team provide strategic consultation new sales account renewals drive product price strategy schell industry veteran 24 years underwrite e recently serve regional vice president underwrite x local market hold underwrite leadership roles almost 13 years receive mba bachelor business administration sowatzke new role lead overall commercial business underwrite efforts commercial business segment include policy compliance report analytics underwrite performance effectiveness andrea bring wealth e knowledge new role vital ensure continue success national account say president ceo x national account business also want thank norm success national account wish well e role within company x inc', 'december 6 2012 x inc nyse wlp announce today annmarie hagan name president company specialty businesses effective immediately x specialty businesses include dental disability life vision workers compensation addition dani fjelstad name president x dental business mike walsh announce retirement x serve president company specialty business previously president decare dental since 1987 walsh continue support x business consult role retirement focus innovation drive specialty business growth hagan e operational financial leader prove track record drive profitable growth set strategic direction recently serve chief operate officer x specialty businesses since join x role responsibilities include strategy development position x disabilitylife workers compensation vision businesses strong growth future e role hagan also responsible drive overall revenue profit growth across specialty businesses include dental commit meet need customers diversify x specialty earn stream prior join x hagan serve e vice president chief financial officer cigna hagan receive bachelor science finance account dre university philadelphia knowledge industry history drive success deep operational financial background help drive success specialty businesses x say lori beer e vice president x specialty businesses information technology confident leadership specialty businesses continue grow profitably provide products service benefit consumers fjelstad helm x dental business responsible overall position growth performance x dental business new products service e network development would like congratulate annmarie dani new roles thank mike years service x mike true pioneer dental benefit drive significant increase membership revenue x decare dental say beer wish best luck welldeserved retirement look forward work mike consultant role x believe important connection members health wellbeing value bring customers shareholders day work improve health members communities make real difference since 33 million people brand health plan appro 64 million people serve subsidiaries independent licensee blue cross blue shield association x serve members blue cross licensee california blue cross blue shield licensee colorado connecticut georgia indiana kentucky maine missouri e 30 counties kansas city area nevada new hampshire new york blue cross blue shield licensee 10 new york city metropolitan surround counties blue cross blue cross blue shield licensee select upstate counties ohio virginia e northern virginia suburbs washington dc wisconsin majority service areas x plan business anthem blue cross anthem blue cross blue shield blue cross blue shield georgia empire blue cross blue shield empire blue cross new york service areas x also serve customers throughout country unicare certain california arizona nevada market caremore subsidiary 1800 contact inc subsidiary offer customers online sales contact lenses eyeglasses ocular products', 'dec 11 2012 nyse wlp announce name 2013 premier 100 leader 2013 premier 100 leaders award spotlight 100 leaders technology business side company e technology leadership innovative approach business challenge effectively manage strategies fourth year row x leader name list ghanayem x information technology vice president information officer currently lead large diverse information technology department include x claim membership financial disbursement price product systems electronic data interchange edi systems collectively process 379 million medical claim 26 billion edi transactions disburse annually support x affiliate company diverse member provider customers throughout country team rise challenge consolidate multiple complex methodologies systems obtain mergers acquisitions successfully create implement efficient enterprisewide solutions make difference within x throughout health care industry say ghanayem honor recognize premier 100 leader team work daily provide quality value customers x leaders previously honor premier 100 leaders award include e vice president specialty business information technology senior vice president chief information officer premier 100 award program showcases e work dedicate group technologysavvy business leaders drive huge change organizations say editor chief day e business leaders make strategic technology decisions track organizations top priorities 100 men women keep keen eye change landscape political economic regulatory technology trend drive significant shift please recognize leadership honor achievements 2013 premier 100 honorees x believe important connection members health wellbeing value bring customers shareholders day work improve health members communities make real difference since 33 million people brand health plan appro 64 million people serve subsidiaries independent licensee x serve members licensee licensee e 30 counties area licensee 10 new york city metropolitan surround counties licensee select upstate counties e northern suburbs majority service areas x plan business service areas x also serve customers throughout country unicare certain market caremore subsidiary 1800 subsidiary offer customers online sales contact lenses eyeglasses ocular products', 'jun 23 2013 pilot program california public employees retirement system lower price members hip knee replacement surgeries 19 percent one year also demonstrate similar better outcomes lowercost hospitals analysis conduct healthcore x outcomes research company present academyhealth annual research meet today study base find referencedbased purchase design program calpers members develop calpers x affiliate health plan may release database 2011 hospital charge service show wide disparity charge service hospitals areas hospital charge total knee replacement total hip replacement surgeries range without evidence difference outcome quality accord x affiliate health plan analysis conduct 2009 please see program result substantial save calpers several measure higher quality outcomes members say dr x chief medical officer program demonstrate power innovative product design align financial incentives better inform decisionmaking part calpers intervention program members public employees retirement system give list designate facilities charge less inpatient cost associate knee hip replacement surgery qualify list hospitals already contract network x affiliate health plan manage robust credentialing process participation include require participate hospitals maintain accreditation least one several nationally renowned accreditation organizations addition hospitals perform enough procedures ensure result could represent credible measurement positively demonstrate hospital skill surgeries members able either choose 46 facilities list would result pay little outofpocket cost beyond deductible coinsurance pay difference use another facility charge result calpers health plan cost drop significantly 19 percent per surgicalrelated admission program effective tool manage cost know current spend level sustainable go provide benefit affordable future say deputy e officer benefit program policy plan california public employees retirement system 356543 ppo members serve x affiliate health plan believe innovative benefit design important component control health care cost increase access quality care say x e vice president commercial specialty business continue develop benefit positive impact cost quality employers consumers healthcore research find offer validation make progress actually move needle analysis also find study compare utilization calpers ppo members x affiliate health plan analysis use administrative medical claim patients elective nonemergency total knee replacement total hip replacement surgeries nyse wlp believe important connection members health wellbeing value bring customers shareholders day work improve health members communities make real difference since nearly 36 million people affiliate health plan nearly 68 million people serve subsidiaries independent licensee x serve members licensee licensee e 30 counties area licensee 10 new york city metropolitan surround counties licensee select upstate counties e suburbs majority service areas x plan business service areas also serve customers several additional state amerigroup subsidiary certain market caremore subsidiary 1800 subsidiary offer customers online sales contact lenses eyeglasses ocular products', 'sep 2 2014 lot write selfishness americans new survey indicate quite opposite recent x survey americans would make large small sacrifice love ones hand last piece dessert 88 percent forgo watch favorite tv show love ones enjoy favorite program 90 percent care illness 96 percent americans commit bunch come love ones honor life insurance awareness month x conduct survey find many americans believe commitment e safeguard family future wellbeing surprise give financial concern 39 percent physical 36 percent mental 21 percent concern worry think future security family furthermore majority americans 83 percent believe family financial wellbeing important emotional wellbeing americans protect family financial future life insurance retirement plan live will list x survey find majority americans consider invest retirement plan 68 percent select life insurance plan 57 percent create live 64 percent important components safeguard family future wellbeing stress associate financial worry life insurance products design say president x life disability business products service help families deal loss love one provide resources address financial emotional wellbeing research show spend money others rather boost happiness wellbeing even amount spend relatively small one way people increase family level happiness sense wellbeing make sure protect financially emotionally une events happen achieve make sure appropriate life disability coverage consumers motivate protect future wellbeing love ones offer toptier design plan competitive price plenty fle say wozny e member assistance program include life disability plan offer counsel legal financial consultations beneficiary companion service help family members close account finalize love one estate x survey also illustrate importance consumers place life insurance twothirds 67 percent survey respondents indicate life insurance group onethird 36 percent indicate fully pay slightly less onethird 30 percent report life insurance clear americans value life insurance good news say wozny life insurance awareness month perfect time americans take ne step safeguard love one financial wellbeing enrol life insurance information x life insurance benefit find report present find telephone survey conduct among 1005 adults 502 men 503 women 18 years age older live continental interview caravan survey complete 605 interview landline sample 400 interview cell phone sample margin error total sample 0 percent 95 confidence level mean replicate study would e get result within 30 percentage point 95 time 100 x work transform health care trust care solutions health plan company deliver quality products service give members access care need nearly 69 million people serve affiliate company include 37 million enrol family health plan x one nation lead health benefit company x company serve members licensee license e 30 counties area licensee 10 new york city metropolitan surround counties licensee select upstate counties e suburbs service areas x business service areas also serve customers state amerigroup caremore unicare subsidiaries', 'may 25 2016 insurers play role help reduce rate drug overdose improve quality care anthem inc affiliate health plan launch program help reduce addiction opioids prescription drug improve drug safety enrol highrisk members individual employersponsored plan pharmacy home program limit drug coverage one memberchosen home pharmacy people die drug overdose 2014 previous year record accord nearly half million people die drug overdose 20102014 si percent drug overdose result death involve narcotics least half opioid overdose deaths involve prescription opioid overuse abuse prescription drug evolve national epidemic public health emergency say anthem vice president clinical specialty pharmacy insurers anthem uniquely position help improve prescription drug safety health care quality outcomes realtime access information medication use determine members use multiple prescribers several pharmacies obtain medications often correlate addictive behavior pharmacy home program begin distribution letter eligible members focus small e highrisk segment members anthem health plan 14 state diagnosis prescription history hiv sickle cell anemia multiple sclerosis cancer hospice palliative care e program even overdose opioids class painkillers nine 10 people continue get prescriptions accord 2015 study publish annals internal medicine patients go suffer another overdose seventy percent patients overdose later receive prescriptions health care professional prescribe opioids first overdose prescribers key haines say many medical information systems integrate prescribers may aware patient overdose patient get several prescriptions drug many many drug multiple doctor pharmacy home program notify prescribers write decision include member program prescriber also receive threemonth member prescription history education piece advantage one pharmacy review member members increase safety risk candidates pharmacy home program meet criteria within 90day period member change behavior view claim activity within 60 days first letter member mail enrollment letter request selection single pharmacy location fill medications e period one year know program efforts like result large drop opioid prescriptions lead appropriate treatment substance abuse pain management say dr anthem vice president behavioral health clinical program like one part overall strategy help prevent addiction redirect consumers appropriate care hopefully prevent deaths major medical problems overdose drug interactions anthem work transform health care trust care solutions health plan company deliver quality products service give members access care need 72 million people serve affiliate company include 39 million enrol family health plan anthem one nation lead health benefit company', 'jul 26 2017 nyse antm today announce second quarter 2017 net income per share result include net negative adjustment items per share net income second quarter 2016 per share include net negative adjustment items per share e items note period adjust net income per share second quarter 2017 compare adjust net income per share prior year quarter refer gaap reconciliation table directly comparable measure calculate accordance yous generally accept account principles please second quarter 2017 result carry forward operate momentum commitment improve quality affordability health care customers resonate marketplace benefit shareholders say joseph swedish president chief e officer solid second quarter financial result reflect solid performance across various business segment reflect update 2017 outlook say e vice president chief financial officer medical enrollment total appro 404 million members june 2017 increase 06 million members 16 percent 398 million june 2016 commercial specialty business enrollment increase 389 thousand medical members company e growth fully insure selffunded local group businesses partially offset decline membership national account individual businesses enrollment also grow 193 thousand business 58 thousand business medical enrollment increase 468 thousand first six months 2017 enrollment gain primarily local group individual businesses operate revenue second quarter 2017 increase 43 percent versus prior year quarter growth revenue reflect premium rate increase cover overall cost trend across business additionally increase drive higher enrollment local group insure selffunded businesses well increase partially offset impact one year waiver health insurance tax 2017 less favorable adjustments prior year risk adjustment estimate benefit e ratio 861 percent second quarter 2017 increase 190 basis point 842 percent prior year quarter increase e largely drive impact one year waiver health insurance tax 2017 less favorable adjustments prior year risk adjustment estimate increase partially offset improve medical cost performance local group individual businesses medical claim reserve establish develop moderately better company e first six months 2017 full year 2017 company continue e underlie local group medical cost trend range 65 70 days claim payable 405 days june 2017 decrease 01 days 406 days sg e ratio 138 percent second quarter 2017 decrease 20 basis point 140 percent second quarter 2016 decrease e primarily drive impact one year waiver health insurance tax 2017 impact operate e efficiency initiatives take company fi cost leverage operate revenue growth decrease partially offset higher performancebased incentive compensation accruals 2015 cyber attack litigation settlement record quarter operate cash flow 05 time net income second quarter 2017 appro 17 time net income first six months 2017 company continue e full year 2017 operate cash flow greater second quarter 2017 company repurchase 25 million share common stock weightedaverage price first six months 2017 company repurchase 28 million share common stock weight average price company appro boardapproved share repurchase authorization remain second quarter 2017 company pay quarterly dividend per share represent distribution cash total audit committee declare third quarter 2017 dividend shareholders per share increase per share second quarter dividend annualized basis equate dividend per share third quarter dividend payable shareholders record close business second quarter 2017 company record net realize gain financial instrument total otherthantemporary impairment losses total second quarter 2016 company record net realize gain otherthantemporary impairment losses total june 2017 company net unrealized gain position investment portfolio consist net unrealized gain equity fi maturity securities total respectively june 2017 cash investments parent company total appro three reportable segment commercial specialty business comprise local group national account individual specialty businesses government business comprise businesses national government service federal employee program comprise unallocated corporate e certain businesses meet quantitative thresholds separate reportable segment disclosure nm nm 150 bp 120 bp 150 bp 90 bp 160 bp 110 bp 1 see presentation 2 nm calculation meaningful operate gain commercial specialty business segment total second quarter 2017 decrease 100 percent second quarter 2016 decrease drive less favorable adjustments prior year risk adjustment estimate one year waiver health insurance tax 2017 higher performancebased incentive compensation accruals decrease partially offset improve medical cost performance local group individual businesses operate gain government business segment second quarter 2017 decrease 349 percent second quarter 2016 decrease reflect higher performancebased incentive compensation accruals impact one year waiver health insurance tax 2017 company report operate loss segment second quarter 2017 compare operate loss prior year quarter management host conference call webcast today discuss company second quarter result outlook conference call access least 15 minutes prior start call follow number access code require today conference call access code replay 403156 replay available today end day call also available live webcast link webcast replay available follow call anthem work transform health care trust care solutions health plan company deliver quality products service give members access care need 74 million people serve affiliate company include 40 million enrol family health plan anthem one nation lead health benefit company', 'indiapolis feb 20 2003 prnewswirefirstcall via comtex x nyse ath announce today third consecutive year fortune magazine one 10 admire health care company fortune march 3 2003 issue list anthem third admire care company anthem hold position last year determine admire company list fortune use eight criteria financial soundness employee talent use corporate assets term investment value social responsibility quality management productsservices please include fortune admire health care company year say larry c glasscock president ceo anthem fortune criteria match anthem strategic business objectives quality service continue growth continue strong recognize increase strength anthem blue cross blue plan dedication meet need customers publish list america admire company annually look 10 largest yous company 66 industry group include subsidiaries foreignowned company ask 10000 e securities analysts rate company industry criteria inc indianadomiciled publicly trade company company provide health care benefit 11 million anthem fifth largest publicly trade health benefit company unite state independent licensee blue cross blue shield anthem blue cross blue shield licensee indiana ohio connecticut new hampshire colorado nevada maine e immediate suburbs washington dc december 31 anthem assets 12 billion operate revenue 13 billion information anthem available atanthemcom contact news media lauren greencaldwell 13174886321 investor relations tami durle 13174886390 x', 'thousand oaks califjan 29 2003 x network inc nyse wlp today announce members management currently schedule appear ubs warburg health service conference monday february 3 2003 x presentation e begin appro00 eastern time investors analysts general public invite listen presentation free internet http www xcom click investor info listen presentation live internet visit www xcom least 20 minutes prior presentation download install necessary audio software anyone x management presentations presume read x annual report form 10k year end 31 2001 quarterly report form 10q quarter march 31 2002 june 30 2002 september 30 2002 include discussion caption factor may affect future operations conference date time subject change base upon e x health network inc serve health care need 13 million medical members appro 46 million members nationwide blue cross california blue blue shield georgia blue cross blue shield healthlink unicare x offer broad spectrum networkbased health products include open access ppo pos hybrid products hmo specialty products specialty products pharmacy benefit management dental utilization management mental health life disability insurance long term care fle spend account cobra administration supplement x may find web xcom blue cross california blue cross blue georgia blue cross blue shield missouri license blue cross blue shield association 30rjla', 'thousand oaks califjan 21 2003 x network inc nyse wlp carefirst inc agree respective board directors approval friday january 24 2003 amend restate agreement merger two organizations propose form merger agreement file insurance regulators amendment pending form applications relate principal change original agreement sign 2001 include follow consideration transaction would pay fully 850 million could raise finance transaction unless stock othercash consideration allow applicable law law provide consideration must cash close transaction would condition certain compensation plan agreements carefirst revise provide amend merger revisions provide close carefirst merger incentive plan employment agreements carefirst eight senior e terminate participation carefirst longterm incentive supplemental e retirement plan would also terminate e would enter twoyear agreements x close e payments would make insurance entity maryland district delaware would instead bear x specifics revisions include part amend merger agreement 60day period follow sign date amend agreement x would waive termination fee payable carefirst e reimbursement e carefirst accept superior proposal another party x would retain right match proposal result change consideration payable would increase 70 million 1370000000 x carefirst believe change eliminate raise consultants maryland insurance regard appropriateness legality compensation program form consideration merger agreement result focus benefit transaction maryland delaware district columbia include opportunities improve health care service financial return jurisdictions use health care purpose assurances make give amend merger approve respective board directors carefirst approve without change carefirst inc independent licensee blue cross shield association notforprofit health care company along affiliate subsidiaries offer portfolio health insurance products direct health administrative service nearly 32 million individuals northern virginia district columbia maryland 17000 associate x health network inc health care need 13 million medical members appro 46 million specialty members nationwide blue california blue cross blue shield georgia blue cross blue shield missouri healthlink unicare x offer broad spectrum quality networkbased health products include access ppo pos hybrid products hmo specialty products products include pharmacy benefit management dental management vision mental health life disability long term care insurance fle spend account cobra medicare supplement x may find web www xcom blue cross california blue cross shield georgia blue cross blue shield missouri license blue cross blue shield association cautionary statement certain statements contain press forwardlooking statements actual result events could materially due among things failure board either x carefirst approve amend agreement operational difficulties associate acquire businesses business condition competition manage care company rise health care cost trend loss ratios health care reform regulatory issue time receipt regulatory shareholder additional risk factor list time time various sec report include limit annual report form 10k year end december 31 30japla', 'indiapolis aug 16 prnewswire x inc nyse wlp lead health benefit company today announce alan spiro name vice president chief medical officer national business unit lead development delivery care management program employers 5000 employees program central x mission health people communities serve e dr spiro join team say john watts ceo x national account business unit 30 years clinical medical management e include data management electronic health solutions public health dr spiro bring truly unique perspective organization spiro recently principal national clinical practice leader tower perrin work fortune 500 company develop health care benefit program employees develop perrin first ehealth strategy work health care insurers develop new program products improve operational performance prior join tower spiro chief medical officer utilimed senior vice president medical director connecticare vice medical director celtic life insurance company also run private practice work several hospitals throughout state look forward work dr spiro develop innovative health program members customers alan integral member health care management team say samuel nussbaum md e president chief medical officer x accomplishments physician health care leader instrumental development industryleading solutions help ensure largest clients receive access quality affordable care spiro receive md columbia university mm university kellogg school management complete internal medicine michael reese hospital medical center fellowships boston beth israel hospital gastroenterology new england deaconness hospital nutrition author 25 article manage care clinical best practice medicare disease gastroenterology member several medical care associations serve visit professor michigan university sloan school business x inc x inc largest publicly trade commercial health benefit term membership unite state x inc licensee blue cross blue shield association serve members blue cross licensee california blue cross blue licensee colorado connecticut georgia indiana kentucky maine e 30 counties kansas city area nevada new ohio virginia e northern virginia suburbs dc wisconsin healthlink unicare', 'follow document hereby incorporate reference 1 annual report form 10k unite technologies corporation corporation file securities e commission commission year end december 31 1994 2 quarterly report form 10q corporation file quarter end march 31 1995 3 report file corporation commission pursuant section 13 section 15 securities e act since end period cover annual report form 10k refer 1 4 description corporation common stock contain statements report file securities e act document subsequently file corporation pursuant section 13 c 14 15 securities e act 1934 prior posteffective amendment indicate securities offer sell deregisters securities remain unsold shall deem incorporate reference registration statement part hereof date file document securities register hereby constitute share common stock 500 value unite technologies corporation issue certain participate unite technologies corporation define retirement plan _plan_ direct certain plan invest corporation common stock share common stock acquire hold sell distribute trustee accordance term plan financial statements incorporate reference annual report 10k corporation year end december 31 1994 reliance report price waterhouse llp independent give authority say firm e audit legality securities offer pursuant registration pass richard kaplan esq mr kaplan associate counsel corporation shareowner common stock undersign registrant hereby undertake 1 file period offer sales make aeffective amendment registration statement include material respect plan distribution previously disclose registration statement material change information statement 2 purpose determine liability securities 1933 posteffective amendment shall deem new statement relate securities offer therein securities time shall deem initial bona offer thereof 3 remove registration mean posteffective amendment securities register remain unsold termination undersign registrant hereby undertake purpose liability securities act 1933 file annual report pursuant section 13 section 15 e act 1934 incorporate reference statement shall deem new registration statement securities offer therein offer securities time shall deem initial bona fide offer thereof insofar indemnification liabilities arise securities act 1933 may permit directors officer control persons registrant advise opinion e commission indemnification public policy e act therefore unenforceable event indemnification liabilities payment registrant e incur pay director officer person registrant successful defense action proceed assert director officer control person connection securities register registrant unless opinion counsel matter settle control submit court appropriate jurisdiction question whether indemnification public policy e act govern final adjudication issue pursuant requirements securities act 1933 registrant reasonable ground believe meet file form s8 duly cause registration sign behalf undersign thereunto duly city hartford state connecticut 28 day 1995 pursuant requirements securities act 1933 statement sign follow persons indicate 28 day april 1995 h trachsel board directors technologies corporation technologies build financial plaza ct 06101 s8 registration statement define contribution retirement plan gentlemen opinion furnish connection propose file e commission april 28 1995 registration form s8 securities act 1933 amend offer 25000 share common stock par value 5 per _shares_ issue corporation define contribution plan _plan_ act counsel corporation connection certain matter plan familiar corporate proceed relate e document consider matter law deem necessary give opinion opinion share offer sell pursuant plan purchase plan trustee open market original issue share plan timely file revenue service determination letter plan constitute a_tax qualified_ plan internal revenue code erisa hereby file opinion e aforementioned statement truly richard kaplan associate general counsel mmrh secdoc hereby consent incorporation reference registration form s8 report date january 26 1995 appear incorporate reference unite technologies annual report form 10k year end december 31 1994 report date april 25 1995 appear unite technologies november 30 1993 also consent incorporation reference report financial statement schedule appear page s1 annual report form 10k also consent reference us head _interests name e counsel_ form s8 waterhouse llp connecticut 28 1995 undersign howard h baker constitute appoint stephen true lawful attorneysinfact agents power substitution resubstitution sign registration statements notice consent service document instrument include amendments file document connection securities e commission authority state responsible regulation offer sale securities connection offer sale pursuant term unite technologies corporation contribution retirement plan effect date hereof may amend time time plan grant unto say infact agents full power perform every act thing requisite necessary do premise fully intents purpose undersign might could person hereby ratify confirm attorneysinfact agents substitute substitute may do virtue hereof h baker howard h baker date february 6 1995 undersign antonia handler chayes constitute appoint true lawful attorneysinfact power substitution resubstitution capacities sign registration statements consent service document instrument include amendments thereto file document therewith securities e commission regulatory authority state responsible regulation offer sale securities connection offer sale securities pursuant term unite technologies corporation contribution retirement plan effect date hereof may amend time time plan grant unto say infact agents full power perform every act thing requisite necessary do premise fully intents purpose undersign might could person hereby ratify confirm attorneysinfact agents substitute substitute may do virtue hereof handler chayes antonia handler chayes date february 6 1995 undersign robert f dee constitute appoint stephen f true lawful attorneysinfact agents power substitution resubstitution sign registration statements notice consent service document instrument include amendments file document connection securities e commission authority state responsible regulation offer sale securities connection offer sale pursuant term unite technologies corporation contribution retirement plan effect date hereof may amend time time plan grant unto say infact agents full power perform every act thing requisite necessary do premise fully intents purpose undersign might could person hereby ratify confirm attorneysinfact agents substitute substitute may do virtue hereof f dee robert f dee date february 6 1995 undersign charles w duncan jr constitute appoint true lawful attorneysinfact power substitution resubstitution capacities sign registration statements consent service document instrument include amendments thereto file document therewith securities e commission regulatory authority state responsible regulation offer sale securities connection offer sale securities pursuant term unite technologies corporation contribution retirement plan effect date hereof may amend time time plan grant unto say infact agents full power perform every act thing requisite necessary do premise fully intents purpose undersign might could person hereby ratify confirm attorneysinfact agents substitute substitute may do virtue hereof w duncan jr charles w duncan jr date february 6 1995 undersign pehr g gyllenhammar constitute appoint true lawful attorneysinfact power substitution resubstitution capacities sign registration statements consent service document instrument include amendments thereto file document therewith securities e commission regulatory authority state responsible regulation offer sale securities connection offer sale securities pursuant term unite technologies corporation contribution retirement plan effect date hereof may amend time time plan grant unto say infact agents full power perform every act thing requisite necessary do premise fully intents purpose undersign might could person hereby ratify confirm attorneysinfact agents substitute substitute may do virtue hereof g gyllenhammar pehr g gyllenhammar date february 6 1995 undersign gerald hines constitute appoint stephen true lawful attorneysinfact agents power substitution resubstitution sign registration statements notice consent service document instrument include amendments file document connection securities e commission authority state responsible regulation offer sale securities connection offer sale pursuant term unite technologies corporation contribution retirement plan effect date hereof may amend time time plan grant unto say infact agents full power perform every act thing requisite necessary do premise fully intents purpose undersign might could person hereby ratify confirm attorneysinfact agents substitute substitute may do virtue hereof hines gerald hines date february 6 1995 undersign robert h malott constitute appoint stephen true lawful attorneysinfact agents power substitution resubstitution sign registration statements notice consent service document instrument include amendments file document connection securities e commission authority state responsible regulation offer sale securities connection offer sale pursuant term unite technologies corporation contribution retirement plan effect date hereof may amend time time plan grant unto say infact agents full power perform every act thing requisite necessary do premise fully intents purpose undersign might could person hereby ratify confirm attorneysinfact agents substitute substitute may do virtue hereof h malott robert h malott date february 6 1995 undersign jacqueline g wexler constitute appoint true lawful attorneysinfact power substitution resubstitution capacities sign registration statements consent service document instrument include amendments thereto file document therewith securities e commission regulatory authority state responsible regulation offer sale securities connection offer sale securities pursuant term unite technologies corporation contribution retirement plan effect date hereof may amend time time plan grant unto say infact agents full power perform every act thing requisite necessary do nd premise fully intents purpose undersign might could person hereby ratify confirm attorneysinfact agents substitute substitute may do virtue hereof g jacqueline g date february 6 1995 undersign robert f daniellconstitutes appoint stephen true lawful attorneysinfact agents power substitution resubstitution sign registration statements notice consent service document instrument include amendments file document connection securities e commission authority state responsible regulation offer sale securities connection offer sale pursuant term unite technologies corporation contribution retirement plan effect date hereof may amend time time plan grant unto say infact agents full power perform every act thing requisite necessary do premise fully intents purpose undersign might could person hereby ratify confirm attorneysinfact agents substitute substitute may do virtue hereof f daniell robert f daniell date february 6 1995 undersign george david constitute appoint stephen f true lawful attorneysinfact agents power substitution resubstitution sign registration statements notice consent service document instrument include amendments file document connection securities e commission authority state responsible regulation offer sale securities connection offer sale pursuant term unite technologies corporation contribution retirement plan effect date hereof may amend time time plan grant unto say infact agents full power perform every act thing requisite necessary do premise fully intents purpose undersign might could person hereby ratify confirm attorneysinfact agents substitute substitute may do virtue hereof david george david date february 6 1995 undersign charles r lee constitute appoint stephen true lawful attorneysinfact agents power substitution resubstitution sign registration statements notice consent service document instrument include amendments file document connection securities e commission authority state responsible regulation offer sale securities connection offer sale pursuant term unite technologies corporation contribution retirement plan effect date hereof may amend time time plan grant unto say infact agents full power perform every act thing requisite necessary do premise fully intents purpose undersign might could person hereby ratify confirm attorneysinfact agents substitute substitute may do virtue hereof r lee charles r lee date february 6 1995 undersign h wagner constitute appoint stephen f true lawful attorneysinfact agents power substitution resubstitution sign registration statements notice consent service document instrument include amendments file document connection securities e commission authority state responsible regulation offer sale securities connection offer sale pursuant term unite technologies corporation contribution retirement plan effect date hereof may amend time time plan grant unto say infact agents full power perform every act thing requisite necessary do premise fully intents purpose undersign might could person hereby ratify confirm attorneysinfact agents substitute substitute may do virtue hereof wagner h wagner date february 6 1995 hereby consent incorporation reference statement form s8 report date 26 1995 appear page 26 1994 report shareowners unite technologies incorporate reference unite corporation annual report form 10k year end december 31 1994 report date april 1995 appear unite technologies corporation contribution retirement plan annual report end november 30 1993 also consent reference report financial schedule appear page s1 annual form 10k also consent reference head interest name e form s8 waterhouse llp connecticut 28 1995 pension administration investment committee unite technologies corporation members unite technologies corporation define contribution retirement plan opinion accompany statements financial relate statement income change equity present fairly material respect position unite technologies corporation contribution retirement plan november 30 1993 1992 result operations change plan equity year end november 30 1993 generally accept account principles financial statements responsibility administrator responsibility e financial statements base audit conduct audit statements accordance generally accept audit standards require plan perform audit obtain reasonable whether financial statements free misstatement audit include e basis evidence support amount disclosures financial statements assess account use significant estimate make evaluate overall financial statement believe audit provide basis opinion e connecticut 25 1995 unite technologies corporation define contribution retirement plan define contribution save plan sponsor unite technologies unite plan become effective december 1 1984 membership plan offer eligible employees certain subsidiaries unite employer make contributions respect member amount 5 percent member compensation addition members may elect payroll deductions 1 9 percent total first 4 percent member contribution 50 percent employer member contributions fully vest time plan generally employer contributions become fully vest years first join plan contributions credit member account maintain plan contributions invest pursuant member direction one follow fund income fund equity fund may elect 100 percent contributions invest one fund may allocate contributions multiples 25 percent two fund members permit transfer account fund per quarter multiples 10 percent income fund invest contract issue five insurance company pension investment committee contract company guarantee repayment full principal amount invest interest credit fi rate specify period interest contract base annual interest rate set year insurance carriers rate differ among contract take account difference prior year credit interest actual investment earn allocable contract accordance allocation procedures insurance carrier weight rate set 1993 calendar year 80 percent equity fund may invest common capital stock corporations securities convertible stock share federally mutual fund similar type investment fund include investment commingle trust fund manage trustee bankers trust company invest primarily similar type equity securities 1993 1992 equity fund invest principally trustee bt pyramid index fund portfolio common stock replicate poor composite index 500 stock interest dividends earn investment reinvested increase market value employer contributions use reduce employer contributions unapplied forfeitures apply future employer show separately statement income change equity participate plan year end follow', 'prospectus date april 29 2016 prospectus supplement date may 1 2017 statement file 333211035 technologies corporation term sheet date may 2017 1000000000 1900 note due 2020 500000000 2300 note due 2022 800000000 2800 note due 2024 1100000000 3125 note due 2027 600000000 4050 note due 2047 900 note due 2020 note 300 note due 2022 note 800 note 2024 note 125 note due 2027 note 050 note due 2047 note amount 1000000000 2020 note 500000000 2022 note 800000000 2024 note 1100000000 2027 600000000 2047 note date 4 2020 2020 note 4 2022 2022 4 2024 2024 note 4 2027 2027 note 4 2047 2047 note 900 2020 note 300 2022 note 800 2024 note 125 2027 note 050 2047 note public 951 face amount 2020 note 779 face amount 2022 note 792 face amount 2024 note 000 face amount 2027 note 724 face amount 2047 discount 300 2020 note 350 2022 note 400 2024 note 450 2027 note 875 2047 note maturity 917 2020 note 347 2022 note 833 2024 note 125 2027 note 066 2047 note benchmark treasury 45 basis point 2020 note 50 basis 2022 note 70 basis point 2024 note 80 basis 2027 note 105 basis point 2047 note treasury 500 due april 15 2020 2020 note 875 due april 30 2022 2022 note 000 due april 30 2024 2024 note 250 due february 15 2027 2027 note 875 november 15 2046 2047 note treasury spot yield 03 1467 2020 note 04 1847 2022 note 04 2133 2024 note 11 2325 2027 note 08 3016 2047 payment date count convention whole call 75 basis point 2020 note 10 basis prior april 4 2022 2022 note 125 basis point prior march 4 2024 2024 note 15 basis point prior february 4 2027 2027 note 20 point prior november 4 2046 2047 note call april 4 2022 2022 note march 4 2024 2024 note february 4 2027 2027 note november 4 2046 2047 note e 996510000 2020 note 497145000 2022 795136000 2024 note 1095050000 2027 593094000 2047 note date date cm9 2020 note cq0 2022 cn7 2024 note cr8 2027 note cp2 2047 note 2020 note 2022 2024 note 2027 2047 note 2 bookrunning managers lynch pierce fenner smith lead managers comanagers managers 3', 'houston houstonbased former yous astronaut give almost 10000 houstonarea students firsthand e wonder science technology engineer math hightech highenergy performance toyota center monday dec 14 event final stop 2009 present feature appearances local athletes e engineer upbeat performances local artists focus encourage students pursue career math science students alief aldine fort bend houston north forest school district join dr harris twohour program tour visit nine yous cities 2009 design encourage middle school students realize potential strive acquire strong math science skills grow dream travel space education enable dream would like encourage students follow dream pursue career math science dr harris say students incredible opportunities dream tour one way open eye limitless possibilities long math science education part equation stop tour culmination years hard work tremendous way give back houston area invest future humble beginnings houston make history first african american walk space february 1995 dr harris live e achieve high aspirations story provide powerful backdrop bring message students cities across america 2008 inaugural year dream tour dr harris encourage 8500 middle school students boston dallas los angeles new orleans new york city oklahoma city san antonio st louis washington dc second year dream tour atlanta chicago detroit houston indianapolis minneapolisst paul miami mobile oakland seattle dr harris continue motivate inspire students pursue math science focus need attract america students pursue career math science say gerald mcelvy president e foundation start take higher level math science course middle school high school class choose today make break options future dream tour present e one way highlight career possibilities', 'irving te e mobil corporation nyse xom see upstream earn 5336 1524 million second quarter 2009 higher crude oil natural gas realizations drive improvement increase earn 16 billion oilequivalent basis production increase 8 second quarter 2009 e impact entitlement volumes opec quota effect divestments production 10 liquids production total 2325 thousands barrel per day 21 kbd second quarter 2009 e impact entitlement volumes opec quota effect divestments liquids production 1 increase production project qatar kazakhstan offset net field decline second quarter natural gas production 10025 millions cubic feet per day 1984 mcfd 2009 drive project rampups qatar higher demand europe partly offset net field decline earn yous upstream operations 865 52 higher second quarter 2009 nonyous upstream earn 4471 million 1472 last year downstream earn 1220 708 second quarter 2009 higher industry refine market margins increase earn 780 volumes product mix effect increase earn 170 million factor mainly unfavorable foreign e impact decrease earn 240 million petroleum product sales 6241 246 lower last year second quarter mainly reflect lower demand earn yous downstream 440 455 second quarter 2009 nonyous downstream earn 780 253 higher last year chemical earn 1368 1001 higher second quarter 2009 stronger margins improve earn 840 million higher sales volumes increase earn 120 million second quarter prime product sales 6496 thousands metric tons 229 higher prior year primarily due improve global demand corporate finance e e special items 364 237 due mainly favorable tax items second quarter 2010 e mobil corporation purchase 24 million share common stock treasury gross cost 16 billion purchase include 1 reduce number share outstanding balance use offset share issue conjunction company benefit plan program result regulatory requirements open market purchase share make pro solicitation period xto transaction include 416 million share issue connection xto merger share outstanding increase 4698 million end first quarter 5092 million end second quarter share purchase reduce share outstanding currently anticipate equal 3 billion third quarter 2010 purchase may make open market negotiate transactions may increase decrease discontinue time without prior notice earn 13860 293 per share increase 5360 million 2009 e special items earn first half 2010 increase 5220 million 2009 upstream earn 11150 3835 million 2009 higher net realizations increase earn appro 4 favorable impact higher volumes 04 billion partially offset higher operate cost 03 billion oilequivalent basis production 6 compare period 2009 e impact entitlement volumes opec quota effect divestments production 8 liquids production 2370 decrease 41 kbd compare 2009 e impact entitlement volumes opec quota effect divestments liquids production flat 2009 new volumes project rampups qatar kazakhstan offset net field decline natural gas production 10852 increase 1744 2009 drive higher volumes qatar project higher demand europe earn yous upstream operations 2010 1956 increase 783 earn outside yous 9194 3052 downstream earn 1257 388 lower 2009 lower refine margins decrease earn 05 billion unfavorable forex impact 04 billion offset improve market margins favorable sales volume mix refine operations effect petroleum product sales 6193 decrease 268 mainly reflect lower demand yous downstream earn 380 43 2009 nonyous downstream earn 877 431 lower last year chemical earn 2617 increase 1900 2009 stronger margins increase earn appro 14 billion higher volumes increase earn 03 billion prime product sales 12984 1190 2009 corporate finance e e special items 1164 127 million 2009 mainly due tax charge relate yous health care legislation first half 2010 gross share purchase first half 2010 41 billion reduce share outstanding 61 million share e impact xto transaction estimate key financial operate data follow 19280 compute use average number share outstanding period sum four quarter may add full year periods prior 2009 earn per share eps number adjust retrospectively consistent basis 2009 report new authoritative guidance eps adopt e media relations 9724441107', 'corporation continue deliver investment operate commitments downstream chemical result underscore resilience integrate business model upstream volumes increase 36 percent liquids production 119 percent irving te nyse xom e today announce estimate second quarter 2015 earn 42 1 share compare 88 year earlier higher downstream chemical earn offset impact weaker upstream realizations lower asset management gain deliver investment operate commitments across e integrate portfolio say rex w tillerson chairman chief e officer quarterly result reflect disparate impact current commodity price environment also demonstrate strength sound operations superior project e capabilities well continue discipline capital e management downstream chemical segment earn increase significantly second quarter 2014 drive higher margins continue strong demand quality company product asset mix e produce 4 oilequivalent barrel per day increase 139000 per day 36 liquids volumes 23 barrel per day increase 119 benefit new developments angola canada indonesia unite state quarter corporation distribute 41 shareholders form dividends share purchase reduce share outstanding upstream earn 2 second quarter 2015 59 second quarter 2014 lower liquids gas realizations decrease earn 45 volume effect increase earn 330 drive new developments items decrease earn 17 include onetime 260 defer income tax impact relate tax rate increase alberta canada absence prior year asset management gain oilequivalent basis production increase 36 second quarter 2014 liquids production total 23 barrel per day 243000 per day project rampup entitlement effect partly offset field decline natural gas production 101 cubic feet per day 622 cubic feet per day 2014 due regulatory restrictions netherlands project volumes entitlement effect offset field decline yous upstream operations record loss 47 12 second quarter 2014 nonyous upstream earn 21 46 prior year downstream earn 15 795 second quarter 2014 stronger margins increase earn 11 volume mix effect decrease earn 80 items include higher maintenance e decrease earn 230 petroleum product sales 57 barrel per day 104000 per day lower prior year second quarter earn yous downstream 412 124 second quarter 2014 nonyous downstream earn 11 919 higher last year chemical earn 12 405 higher second quarter 2014 margins increase earn 340 benefit lower feedstock cost volume mix effect increase earn 20 items primarily asset management gain yous partly offset unfavorable foreign e effect increase earn net 50 second quarter prime product sales 61 metric tons 61000 tons lower prior year second quarter corporate finance e 593 second quarter 2015 60 second quarter 2014 second quarter 2015 e purchase 12 share common stock treasury reduce number share outstanding cost 1 share purchase reduce share outstanding currently anticipate equal 500 third quarter 2015 purchase may make open market negotiate transactions may increase decrease discontinue time without prior notice upstream earn 49 108 first half 2014 lower realizations decrease earn 10 favorable volume mix effect increase earn 570 items primarily absence prior year asset management gain decrease earn 14 oilequivalent basis production 41 barrel per day 3 compare period 2014 liquids production 23 barrel per day increase 186000 per day project rampup entitlement effect partly offset field decline natural gas production 11 cubic feet per day decrease 407 cubic feet per day 2014 due regulatory restrictions netherlands project rampup entitlement effect e field decline yous upstream operations record loss 99 25 2014 earn outside yous 5 82 prior year downstream earn 32 increase 16 2014 stronger margins increase earn 21 volume mix effect essentially flat periodtoperiod items include higher plan maintenance e decrease earn 480 petroleum product sales 58 barrel per day 54000 per day lower 2014 yous downstream earn 1 decrease 180 2014 nonyous downstream earn 22 18 billion prior year chemical earn 22 increase 340 2014 higher margins increase earn 590 favorable volume mix effect increase earn 70 items include unfavorable foreign e effect partly offset asset management gain yous decrease earn 320 prime product sales 121 metric tons 120000 tons 2014 corporate finance e 12 first half 2015 essentially flat 2014 first half 2015 e 32 share common stock treasury gross cost 28 purchase include 2 reduce number share outstanding balance use acquire share conjunction company benefit plan program e media relations 9724441107', 'chicago three local hispanic high school seniors honor achievements engineer mathematics award recipients rocio garay anderson high school arturo lopez attend west leyden high school christian pereda elgin high school recognize 2009 gold silver bronze medallion winners hispanic heritage youth award regional award ceremony hold university chicago june 2 garay receive 3000 scholarship gold medallion winner lopez receive 2000 silver medallion winner pereda receive 1000 educational grant bronze medallion winner award winners three 18 hispanic high school seniors chicago recognize individual achievements strong commitments community heritage congratulate winners outstanding accomplishments academically role model peer say rex w tillerson chairman chief e officer e mobil corporation proud sponsor hispanic heritage youth award efforts honor promote ne generation math science leaders hispanic community e ninth year sponsor national award 12 regional award provide 14 million support since partner hispanic heritage youth award e present 2009 national winner engineer mathematics additional 15000 educational grant hispanic heritage youth award program offer educational grant hispanic high school seniors 12 cities chicago dallas houston los angeles miami new york city philadelphia phoenix san antonio san diego san jose washington dc award recipients choose regional selection committees base academic achievement community service category focus essay important role heritage play success study show unite state face critical shortage engineer scientists technically train workers near future help address nation math science crisis e support organizations national math science initiative nmsi focus improvements areas preschool higher education e foundation primary philanthropic arm e mobil corporation unite state foundation corporation engage range philanthropic activities advance education health science communities e significant operations unite state e support initiatives improve math science education k12 higher education level globally e provide fund improve basic education combat malaria infectious diseases develop countries 2008 together employees retire e mobil corporation divisions affiliate e foundation provide 225 million contributions worldwide 89 million dedicate education additional information e community partnerships contributions program available hispanic heritage youth award create 1998 hispanic heritage award foundation effort recognize celebrate achievements hispanic high school seniors across nation promote role model peer throughout unite state total 216 regional youth award winners students six categories 12 cities honor receive educational grant special ceremonies subsequently one national youth award winner choose pool regional winners category receive additional educational grant laptop computer free trip national youth award presentation national hispanic heritage award ceremony washington dc present award stage information visit e foundation kim quirk 2143731601', 'new york nyse xom partnership today introduce initiative help women develop countries fulfill economic potential technology innovation program call help identify deploy technologies innovations improve quality life enable women participate fully incomegenerating activities program part e women economic opportunity initiative previously launch 2005 invest 20 million program involve women 64 develop countries global technology company e make last contribution help identify deploy new technologies improve strengthen economic livelihoods women say rex w tillerson chairman chief e officer focus area consistent belief e technology innovation critical address many world major challenge e new initiative announce former president bill clinton clinton global initiative annual meet new york e cosponsor firstever cgi special program focus invest girls women tillerson participate panelist plenary session girls women investments area aim increase opportunities women develop countries improve economic prospect become remain successful business leaders entrepreneurs say tillerson please support clinton global initiative new focus invest women reflect world grow recognition critical role women deliver high return economic social development 15 million firstyear commitment technologies improve women economic livelihoods program involve research publication dissemination white paper international center research women areas technological innovation advance women economic productivity complementary groundbreaking research global program partnership ashoka changemakers identify promise innovations greatest impact women determine best bring market innovations could range technologies equipment reduce burden household task cook water collection crop harvest technologies assist women become efficient incomegenerating activities bill drayton founder chief e officer ashoka say organization look forward work e find help deploy promise innovations greatest impact women see individuals engineer change communities say drayton collaborative search help us see technology innovations women part solution global poverty e involve cuttingedge effort spur women access technologies could provide opportunities economically productive say geeta rao gupta icrw president effort address critical barrier women economic participation significant impact boost women economic activity productivity e largest publicly trade international oil gas company use technology innovation help meet world grow energy need e hold industryleading inventory resources largest refiner marketer petroleum products chemical company one largest world globally e provide fund improve basic education promote women catalysts development combat malaria infectious diseases develop countries 2008 together employees retire e corporation divisions affiliate e foundation provide 225 million contributions worldwide 89 million dedicate education additional information e community partnerships contributions program available ashoka global association world lead social entrepreneurs men women systemchanging solutions world urgent social problems ashoka changemakers create opportunities organizations individuals drive meaningful measurable social change collaborative competitions changemakers connect ashoka elite fellowship online community social innovators pioneer investors inspire drive innovative solutions world press challenge focus lead social entrepreneurs government agencies corporations citizens solve vital problems build communities changemakers partner spark promise ideas development investment', 'irving te commemoration world malaria day april 25 e announce today new fund additional efforts combat disease raise awareness include renew partnership idol e sponsor concert venue tonight broadcast give back fox station across unite state beyond sponsorship enable proceed ticket sales twohour concert benefit five yous international charities e announce donation 11 million antimalaria efforts host idol celebrities trip africa see effect malaria benefit previous idol give back efforts new fund bring e 10year commitment africa community outreach program 193 million include 69 million program fight malaria e donate 14 million enable distribution hundreds thousands bed net throughout communities africa addition education train health care workers local leaders lead killer young children africa 90 percent malaria case find say rex w tillerson chairman chief e officer e great tragedy disease preventable e commit fight disease provide distribute lifesaving bed net raise awareness communities operate fund research development new medications train education malaria day opportunity call attention devastate impact malaria millions people around world many afford insecticidetreated net medication would protect families year e participate number activities world malaria day highlight progress partner make fight disease recruit champion efforts e believe multifaceted approach necessary tackle malaria include work governments nongovernmental organizations foundations private sector media outlets discipline resultsbased business practice e employ global operations charities receive fund idol give back program children health fund feed america malaria save children unite nations foundation nyse xom engage range philanthropic activities advance education health science communities e significant operations globally e provide fund improve basic education combat malaria infectious diseases develop countries e largest nonpharmaceutical corporate donor malaria research development efforts since 2000 commit 193 million africa community outreach program include 69 million program fight malaria company establish malaria initiative 2000 support abuja declaration roll back malaria africa national malaria plan countries operate since e develop ontheground publicprivate partnerships fight malaria community level progress treatment vaccine research raise awareness international support contribute antimalaria efforts 20 african countries e karen matusic 9724441108', 'prudential 9738023996 joint industry board jib new yorkbased labormanagement organization serve international brotherhood electrical workers ibew local union 3 members employers since 1943 select x retirement recordkeeper defer salary plan 401 k plan x retirement among industry largest recordkeepers lead provider tafthartley retirement plan solutions business unit x financial inc smart news release feature multimedia view full release x oversee 57 billion assets cover 33000 participants begin july 3 play critical role give members voice workplace issue range compensation safety access employee benefit offer like retirement plan say harry dalessio head sales strategic relationships x retirement latest client retain us testament deep e commitment partner unions help improve members longterm financial security accord x economist intelligence unit half union members 51 percent say unions focus protect security pension employee benefit lead provider retirement solutions manage 235 billion assets behalf 460000 union members participate 204 plan x retirement deliver retirement plan solutions public private nonprofit organizations service include define contribution define benefit nonqualified defer compensation recordkeeping administrative service investment management comprehensive employee education communications trustee service well variety products strategies include institutional investment income products pension risk transfer solutions structure settlement service 85 years retirement e x retirement help meet need 42 million participants annuitants x retirement 3955 billion retirement account value march 31 2017 retirement products service provide x retirement insurance annuity company priac hartford conn affiliate 0000100', 'x financial inc nyse pru participate cecp strategic investor initiative ceo investor forum new york tuesday sept 2017 day appro 925 et mark grier vice chairman x financial discuss company longterm business strategies purpose interest party may listen presentation live audio webcast view presentation materials x financial investor relations website please log least fifteen minutes early register well download install necessary software replay available x investor relations website october 3 2017 x financial inc financial service leader 1 trillion assets management june 30 2017 operations unite state asia europe latin america x diverse talented employees commit help individual institutional customers grow protect wealth variety products service include life insurance annuities retirementrelated service mutual fund investment management yous x iconic rock symbol stand strength stability e innovation century information please visit', 'x today national community advisory council ncac diverse group nonprofit privatesector leaders convene x recognize 10 anniversary addition five new members represent environment sustainability e meet week washington dc group senior consumer community academic leaders gather twice year advise bank critical issue impact society x announce today latest round project ongoing global art conservation project help restore preserve culturally significant work art around world 2015 fund provide 13 project seven countries full list 2015 grant recipients include saturday 7 november awardwinning social enterprise inspire ne generation females enter stem science technology engineer maths sector run stemettes panel event monday october 12 vital voice global partnership x launch weeklong mentorship initiative tokyo convene women leaders japan engage business social enterprise nongovernmental organizations ngos well senior women e world lead private sector civil society organizations recognition unite nations world habitat day x partnership habitat humanity international launch second take place eight countries around world one week across 11 time zone global build feature firstever home build new york city bryant park volunteer build partnership local habitat family x announce today launch online community development financial institution cdfi directory connect small businesses capital nationwide directory enable entrepreneurs small business owners find cdfi community create opportunity access fund help grow businesses registration 2016 x shamrock shuffle 8k open today 1 pm central time classic road race annual tradition runners look continue essence st patrick day celebration fun run heart chicago 2016 race hold sunday april 3 welcome thousands runners oneofakind course weave way chicago loop start finish today x chicago marathon announce 2012 champion tsegaye kebede ethiopia current half marathon world recordholder florence kiplagat kenya return compete crown 38 annual event today x chicago marathon announce host 2016 yous paralympic team trials marathon streets chicago sunday october 11 america top athletes race event professional elite wheelchair field secure one four spot 2016 yous paralympic team x chicago marathon continue provide yearoveryear growth chicago economy 2014 race deliver estimate 254 million total business impact city find come latest economic impact study report today x event remain key economic driver city provide quarter billion dollars chicago second year row world top professional wheelchair athletes go headtohead first chicagonew york challenge announce today carey pinkowski e race director x chicago marathon peter ciaccia president events new york road runners race director tcs new york city marathon x today announce jackie yoon name market president serve company enterprise leader st louis x chicago marathon announce today legendary american runners joan benoit samuelson deena kastor compete 38 run x chicago marathon sunday october 11 athletes return chicago commemorate anniversaries victories also set sight new challenge fast time annual corporate social responsibility csr report release today x share successes challenge fulfil purpose make financial live better customers clients communities power every connection report include detail csr integrate x business policies practice service products employee benefit x today announce start fourth consecutive thank campaign work help service members veterans families successfully transition civilian life campaign build upon 24 million raise since first e thank campaign 2012 x chicago marathon recognize hillary gelfman fifth recipient richard daley maggie daley award award establish 2010 honor x chicago marathon participant raise fund charity annual worldclass event member team train fundraise program leukemia lymphoma society lls gelfman raise 88000 susan g komen x today announce renewal longstanding partnership 2020 x pledge 3 million bank also continue sponsorship fundraise events national present sponsor prestigious yous runners enter 2015 x chicago marathon lottery notify today selection status year field comprise runners select lottery well participants qualify one five guarantee entry opportunities lottery entrants inform status throughout day via email worldclass event take place sunday october 11 2015 mayor mike duggan join city community nonprofit partner unveil detroit 0 interest home repair loan program provide 8 million finance eligible homeowners look patch roof replace windows upgrade plumb address structural safety issue x merrill lynch community development bank provide 32 billion loan tax credit equity investments real estate development solutions 550 clients 2014 create 13000 house units individuals families seniors students veterans atrisk group across country effort include', 'x small business owners get little help friends family community 83 percent report receive financial operational andor emotional assistance family accord women small business owners feel optimistic annual revenue growth e male counterparts accord inaugural study base survey 1000 small business owners across country focus aspirations pain point women business owners boston small business owners confidence national economy business decline year accord find 33 percent feel confident national economy improve ne year 18 percentagepoint drop year ago chicago small business owners confidence national local economies significantly last year accord 33 percent small business owners chicago say confident national economy improve ne year 25 percentagepoint decrease last year 41 percent confident local economy improve 56 percent last year seventy percent san francisco small business owners believe minimum wage increase positive impact economy accord semiannual study e concern aspirations perspectives small business owners san francisco around country much higher national average 47 percent well metropolitan areas include chicago 54 percent los angeles 48 greater washington small business owners much brighter business outlook national counterparts accord seventyone percent plan grow business ne five years compare 55 percent small business owners nationally additionally 66 percent e revenue increase ne year compare national average 51 percent accord metro new york small business owners e greater caution hire business growth year cite upcoming yous presidential election top factor impact business outlook los angeles small business owners much confident ability grow business increase revenue compare entrepreneurs rest country accord report semiannual study e concern aspirations perspectives small business owners los angeles around country find sifour percent plan grow business ne five years versus miami small business owners confidence remain high spring accord find 71 percent believe revenue increase ne year higher market survey 20 percentage point higher national average atlanta small business owners show greater confidence economy national counterparts accord thirtyseven percent local entrepreneurs believe national economy improve ne 12 months compare 29 percent nationally 48 percent e local economy improve 10 percentage point higher national average dallasfort worth small business owners show greater confidence revenue projections local economy peer across country even though confidence national economy overall accord sitwo percent dallasfort worth entrepreneurs e revenue increase year higher national average 51 percent addition 56 percent anticipate local economy small business owners confidence national economy accord find 29 percent small business owners feel confident national economy improve ne year sharp drop year ago x today announce double investment tory burch foundation capital program formerly elizabeth street capital connect women small business owners affordable capital community development financial institutions cdfis since tory burch foundation capital program announce january 2014 10 million loan women entrepreneurs twoyear timeframe bank los angeles small business owners concern minimum wage hike optimistic revenue growth many plan hire 2016 accord semiannual study e concern aspirations perspectives small business owners los angeles around country small business owners bay area overwhelmingly optimistic accord semiannual study e concern aspirations perspectives small business owners san francisco around country small business owners metro new york bullish year ahead accord semiannual study e concern aspirations perspectives small business owners metro new york around country small business owners boston area overwhelmingly optimistic accord semiannual study e concern aspirations perspectives small business owners boston around country small business owners dallasfort worth area overwhelmingly optimistic businesses ne 12 months accord semiannual study e concern aspirations perspectives small business owners dallasfort worth area around country small business owners chicago area feel increasingly optimistic accord semiannual study e concern aspirations perspectives small business owners chicago area around country small business owners miami area remain e optimistic accord semiannual study e concern aspirations perspectives small business owners miami around country small business owners atlanta overwhelmingly optimistic plan growth accord semiannual study e concern aspirations perspectives small business owners atlanta around country small business owners greater washington area overwhelmingly optimistic accord semiannual study e concern aspirations perspectives small business owners washington dc around country america small businesses gear growth accord small business optimism highest since survey inception 2012 e revenue growth plan hire hit threeyear high x announce today launch online community development financial institution cdfi directory connect small businesses capital nationwide directory enable entrepreneurs small business owners find cdfi community create opportunity access fund help grow businesses dean athanasia president prefer small business bank cohead consumer bank x participate deutsche bank global financial service investor conference wednesday june 3 215 pm eastern time live audio webcast accessible x investor relations website replay also available', 'x x today announce series update awardwinning mobile app customize user e continue investment innovation improve financial live customers 23 million mobile customers grow improve customer e always top priority say michelle moore head digital bank x take customerfirst approach innovation continuously raise bar deliver new digital natives obsession technology set change world know new survey release today find concern digital footprint majority 54 percent millennials generation z age 1317 google regularly 10 percent selfsearching daily basis x paypal today announce strategic partnership soon enable x customers transact paypal store seamlessly link x card paypal agreement take effect immediately new e available x customers first half 2018 make even easier shop wish know choose career question heart collaboration x khan academy help young adults gain knowledge career personal finance look job start workforce class 2017 set worth note roughly eight ten recent college students graduate without job line accord accenture study x launch new capabilities mobile clients complete auto finance process company clients search car participate dealerships mobile device computer ever visit dealership program begin pilot period carolinas e across country phase rollout continue throughout year appear americans run e pay friends back timely manner whether 5 latte 2500 vacation new survey release today find 36 percent adults currently use persontoperson payments service p2p millennials lead charge nearly double rate 62 percent 45 percent nonusers say plan start use service within ne year foreshadow boston homeowners increasingly invest home 78 percent look ways make valuable 59 percent spend lot free time work home still fewer one four e buyers boston area say home true value determine much cost purchase accord second annual fewer homeowners nationally 33 percent 10 market survey e buyers charlotte metro area current home may forever home accord second annual seventynine percent local homeowners say could stay current home rest live higher 10 market survey e buyers show clear sentimental tie property nearly proud own home 94 percent treasure memories e buyers chicago metro area homeownership clear sentimental value accord second annual nearly 97 percent chicago homeowners say proud own home higher 10 local market survey additionally 92 percent say treasure memories make home 79 percent say home e personality think homeownership e buyers dallasfort worth metro area overwhelmingly see positive longterm impact accord second annual compare national average 84 percent 10 market survey dallas homeowners 90 percent likely say homeownership positive impact longterm financial picture denverarea homeowners see value buy early even mean put dream home hold accord second annual fortysix percent e local buyers say current home step stone forever home national average 36 percent 10 local market survey share advice homebuying e nearly one three denver owners say buy home sooner many aspire buyers houston metro area look become solo homeowners accord second annual forty percent plan buy first home instead family spouse nationally 27 percent 10 local market survey firsttime buyers miami metro area place significant emphasis save see homeownership horizon accord second annual nearly threequarters aspire buyers area cite save home major priority ahead improve credit score 71 percent save retirement 66 percent national average 45 percent higher 10 local market survey prepare first home purchase many prospective buyers new york metro area live mom dad accord second annual onethird aspire buyers currently live parent 10 market survey despite think ahead first home financial mean 53 percent outweigh want place call 38 percent top influence purchase e buyers phoenix metro area likely view home financial asset rather element personality accord second annual ask best describe current home local homeowners 49 percent nationally 36 percent 10 market survey say financial investment fewer three 10 say reflection personality st louisarea homeowners family play major role homebuying decision accord second annual compare national average 35 percent market survey st louis homeowners 51 percent purchase first home familial reason include marriage children additionally 59 percent e buyers st louis associate homeownership family higher 10 local market survey forwardthinking millennials buy home happy report last year want skip starter home reveal millennials take plunge homeownership buy house afford look ahead ideal home future fact large majority 68 percent millennial homeowners x today announce plan open first financial center indianapolis offer retail bank service e clients area company sign lease space cummins office tower 301 e market street downtown indianapolis financial center open late 2017 multiple financial center standalone atms schedule open ne several years x today introduce industryleading persontoperson technology awardwinning mobile platform part broader strategy propel industry ne generation digital bank service one first bank offer mobile bank decade ago e usher new era hightech hightouch bank say michelle moore head digital bank x 2017 see strong focus payments intelligent solutions x today announce merrill edge designate top online stock broker 2017 nerdwallet part personal finance site online brokerage laud stock trade service rank one two investment firm best category x today announce merrill edge online brokerage receive two monitor award three monitor award corporate insight 2016 emonitor award report recognitions highlight merrill edge digital offer well value service provide customers x today celebrate grand open new hayward financial center locate 1253 street much bank branch new financial center destination clients connect x financial service personalize solutions e need help financial decisions x today unveil series update awardwinning mobile platform include financial wellness tool personalize customer e majority 74 percent today atlanta labor force e continue work retirement whether income keep busy pursue passion stark contrast 90 percent area retire currently work never golden years majority 80 percent today chicago labor force e continue work retirement whether income keep busy pursue passion stark contrast 77 percent area retire currently work never golden years', 'x part longstanding commitment customers visual impairments america announce today enhance accessibility awardwinning online mobile bank security feature x security feature allow customers safely access account home computers mobile devices accessibility enhancements announce today apply online mobile bank apple products ios operate systems x continue use web content accessibility guidelines wcag 20 level aa standard ensure online mobile bank application content feature service accessible people blind visually impair goal priority provide customers convenient secure accessible bank platforms continuously develop enhance products service ensure meet need customers say david godsman online mobile solutions e x x work bay state council blind customers visual impairments newest accessibility initiative marcia dresser president bay state council blind massachusetts affiliate american council blind praise bank efforts many years x strong partner blind community improve access wide variety bank service accessibility enhancements mobile online bank security feature welcome addition bank commitment customers disabilities 10 years x industry leader provide accessible service people disabilities one first work blind community website accessibility initiative agree national talk atm installation plan 2010 x announce every atm fleet upgrade deliver private speak instructions headset plug audio jack order provide independent accessibility persons see atm screen customers also opt receive check save credit card account statements braille largeprint format information please visit bay state council blind bay state council blind bscb massachusetts affiliate american council blind national consumerbased advocacy organization work behalf blind visually impair americans throughout country bscb dedicate improve quality life equality opportunity independence people visual impairments members long history commitment advancement policies program enhance independence people blind visually impair many members bscb community serve x customers x x one world largest financial institutions serve individual consumers small middlemarket businesses institutional investors large corporations governments full range bank invest asset management financial risk management products service serve appro 53 million consumer small business relationships appro 5500 retail bank offices appro 16300 atms awardwinning online bank 30 million active users x among world lead wealth management company global leader corporate investment bank trade across broad range asset class serve corporations governments institutions individuals around world x offer industryleading support appro 3 million small business owners suite innovative easytouse online products service company serve clients operations 40 countries x corporation stock nyse bac component dow jones industrial average list new york stock e', 'x mobile access 401 k auto feature personalize advice make financial benefit plan valuable easy use help drive positive behaviors new study offer insights give motivations priorities strategies wealthy americans new service apple provide simple secure payment method result include doj settlement cost 53 billion pretax 043 per share tax continue business momentum capital liquidity measure remain strong', 'x new functionality available clients emea americas asiapacific recognition include award best card solution hit every state 46 days thousands carry flame hope light way future inclusion respect people intellectual disabilities espn abc showcase story historic relay lead 2015 special olympics world game', 'x x usa today better money habit report find young ohio residents optimistic financial futures worry job economy x usa today better money habit report also show economic issue top social issue young voters area x usa today better money habit report show economic issue top social issue young voters election x usa today better money habit report show job growth top list election concern x usa today better money habit report show student debtcollege affordability top issue among young voters bay area', 'x company name top financial service company cdp p 500 report djsi north america banker bloomberg world greenest bank rank ceo brian moynihan speak unite nations climate summit partnership pacific institute drought research response effort new pilot transform landscape bank center', 'x x today announce series improvements mobile online bank better meet customers change need make easier users manage finance digitally new update include introduction fingerprint touch id signin addition launch apple watch mobile bank app streamline overview page new security center 31 million active digital bank customers continue deliver enhancements provide customers seamless secure bank e say michelle moore head digital bank x another e help mobile online bank users simplify financial live new fingerprint touch id signin capabilities provide eligible android iphone ipad customers secure convenient way log mobile bank app use fingerprint feature allow access common functionality app without additional need passcode part bank ongoing commitment stay ahead advancements mobile device authentication technology support fingerprint signin build accord fido fast identity online standards mobile bank app compatible apple watch allow users view account balance recent transactions link check save credit card account well receive realtime alert notifications wrist functionality require enrollment x mobile bank app compatible iphone 5 devices later operate ios 82 mobile bank app home page online bank overview page redesign give users personalize seamless e mobile bank app users benefit new quick link tile provide faster access popular feature include mobile check deposit appointment schedule new account open update also include addition new section educate customers functionalities available online bank customers home page redesign make easier review account information glance include personalize greet new quick view function display last five transactions link recent statement newly create activity center provide users easy access popular feature include ability view pay ebills transfer money account review special offer deal without leave page launch new security center offer mobile online bank customers tool securely manage finance include additional options sign monitor activity account customers manage digital bank security settings one place opt e security feature signin help verify customer identity onetime authorization code send via te email time sign bank appointment feature update allow mobile online bank customers schedule sameday financial center appointments specialists everyday bank investment retirement home loan small business need mobile users enhancement also include streamline customer e add calendar option populate appointment personal calendar device x customers currently schedule 15000 appointments per week via feature mobile bank customers e speak specialist feature enhance present customers list topics choose include bill pay inquiries feerelated question report suspicious activity new functionality provide users streamline quicker access proper associate address need access several mobile bank page feature currently enable prefer customers roll broadly ne month learn new offer x digital bank solutions visit x focus mobile bank x continuously focus provide customers ease convenience mobile bank x mobile bank platform remain key source increase customer engagement satisfaction 18 million active users grow rate appro 5000 users per day second quarter 2015 mobile bank customers log account 620 million time almost 35 time per user period customers make nearly 900000 mobile bill payments money transfer day customers also use mobile devices deposit 215000 check via mobile check deposit every day log 32000 time schedule appointments personal banker financial center specialist x x one world largest financial institutions serve individual consumers small middlemarket businesses large corporations full range bank invest asset management financial risk management products service company provide unmatched convenience unite state serve appro 48 million consumer small business relationships appro 4800 retail financial center appro 16000 atms awardwinning online bank 31 million active users 18 million mobile users x among world lead wealth management company global leader corporate investment bank trade across broad range asset class serve corporations governments institutions individuals around world x offer industryleading support appro 3 million small business owners suite innovative easytouse online products service company serve clients operations 50 state district columbia yous virgin islands puerto rico 35 countries x corporation stock nyse bac list new york stock e', 'x x corporation today announce hold special meet shareholders september 22 vote proposal ratify board directors october 2014 amendments company bylaws amendments authorize board determine leadership structure include appoint independent chairman appoint lead independent director chairman independent director board previously inform stockholders vote would hold later company 2016 annual meet stockholders shareholders record close business august 10 2015 entitle vote special meet hold 1 x center auditorium charlotte nc begin 10 et addition vote meet stockholders may submit pro internet telephone mail detail include materials file today yous securities e commission available x website provide directly eligible shareholders board call special meet follow promptly commitment stockholders regard vote encourage participation say lead independent director jack bovender x x one world lead financial institutions serve individual consumers small middlemarket businesses large corporations full range bank invest asset management financial risk management products service company provide unmatched convenience unite state serve appro 48 million consumer small business relationships appro 4800 retail financial center appro 16000 atms awardwinning online bank 31 million active users appro 18 million mobile users x among world lead wealth management company global leader corporate investment bank trade across broad range asset class serve corporations governments institutions individuals around world x offer industryleading support appro 3 million small business owners suite innovative easytouse online products service company serve clients operations 50 state district columbia yous virgin islands puerto rico 35 countries x corporation stock nyse bac list new york stock e', 'x today x merrill lynch open applications seventh uk return talent programme individuals work 12 months longer former stayathome parent carers someone choose take career break e invite apply via application close date 6 december x merrill lynch partnership look attract individuals financial service background include limit business project relationship management bank operations technology compliance specifically company look source suitable candidates programme fill three position business analyst project manager programmer e bromleybased control middle office technology team follow success earlier offer ne year programme commence conference 30 january 2017 give 60 participants opportunity e change workplace role returner new office environment number speaker sessions workshops participants also gain insight x merrill lynch potential employer thirty attendees select attend two fullday workshops 6 10 february 2017 design support transition back work offer practical guidance focus manage career search provide interview skills sessions insights balance work home live access e coach also opportunities participants start build professional connections series network opportunities bank employees neeha khurana international talent e x merrill lynch say launch seventh uk return talent programme testament success also demonstrate value importance place identify strong diverse talent across business initiatives able give people stag live career support confidence skills prosper inspiration succeed financial service marketplace jo vale business analyst global market operations technology 2016 return talent participant say e break raise children return talent give opportunity return career think might never reenter help focus sell strengths great opportunity meet others boat thoroughly enjoy back work feel sense achievement sustainable worklife balance would definitely recommend programme others consider return work career break five years ago x merrill lynch pioneer one first returner program e professionals 200 people take part initiative many go secure roles x merrill lynch firm company progress area well ongoing commitment develop female talent 2015 top employer award career progression company establish alumni network past return talent participants allow keep touch network share e knowledge note editors applications open 31 october 2016 applications close 6 december 2016 return talent date application detail click complete application form attach cv 6 december 2016 oneday conference 30 january 2017 9 pm twoday workshop 6 10 february 2017 9 pm sessions host x merrill lynch city offices e coach consultancy e coach consultancy launch 1994 one first dedicate e coach providers work alongside marketleading organisations different point career journey improve talent acquisition retention diversity strategies deep e support parent career coach 7000 individuals managers key life stage work nationally internationally tailor content understand local market highly e accredit coach team bring professionalism passion develop talent x x one world lead financial institutions serve individual consumers small middlemarket businesses large corporations full range bank invest asset management financial risk management products service company provide unmatched convenience unite state serve appro 47 million consumer small business relationships appro 4600 retail financial center appro 16000 atms awardwinning online bank appro 34 million active account 21 million mobile active users x global leader wealth management corporate investment bank trade across broad range asset class serve corporations governments institutions individuals around world x offer industryleading support appro 3 million small business owners suite innovative easytouse online products service company serve clients operations 50 state district columbia yous virgin islands puerto rico 35 countries x corporation stock nyse bac list new york stock e x merrill lynch market name global bank global market businesses x corporation derivatives commercial bank activities perform globally bank affiliate x corporation include x na member fdic securities strategic advisory investment bank activities perform globally investment bank affiliate x corporation bank affiliate include unite state merrill lynch pierce fenner smith incorporate merrill professional clear corp register brokerdealers members', 'x conjunction neugroup assistant treasurers group thirty at30 meet take place september 2930 x merrill lynch share e best practice work change treasury leadership several bay area corporations large corporates world work key bank partner secure continuity key treasury service market participants adapt new regulations compound challenge doddfrank basel iii host regulatory initiatives implement time unprecedented central bank policy change result volatile global financial condition put additional pressure global company industries ensure adequately prepare e scenarios change global finance climate unprecedented period company work bank providers request necessary service e help navigate change regulatory landscape note liz minick head global corporate sales global transaction service gts x merrill lynch x merrill lynch thus work company educate importance investment policies help prepare change manage liquidity reserve minick add events at30 critical forum deepen conversation e detail concern clients regard global cash management good job educate customers know potential impact today regulatory monetary policy environment make necessary transition less painful win long run note joseph neu founder ceo neugroup members at30 lead company need treasury operations change well tactical position fund capital structure help mitigate impact change global financial landscape give uncertainty create change monetary policies financial market condition capital raise also vital topic discuss at30 meet best practice bond issuance cp well bank finance something company monitor proactively note jeff rothman head technology media telecom corporate bank x merrill lynch x merrill lynch neugroup appreciate opportunity discuss topics at30 company responses recent financial market volatility september event neugroup neugroup leader peer knowledge e intelligence treasurers flagship publication itreasurer neugroup research neugroup network 18 invitationonly membership peer group serve 350 treasury finance professionals world top company benchmarking survey member peer neugroup research unprecedented access data trend thoughts world lead treasury professionals x x one world largest financial institutions serve individual consumers small middlemarket businesses large corporations full range bank invest asset management financial risk management products service company provide unmatched convenience unite state serve appro 48 million consumer small business relationships appro 4800 retail bank offices appro 16000 atms awardwinning online bank 31 million active users appro 18 million mobile users x among world lead wealth management company global leader corporate investment bank trade across broad range asset class serve corporations governments institutions individuals around world x offer industryleading support appro 3 million small business owners suite innovative easytouse online products service company serve clients operations 50 state district columbia yous virgin islands puerto rico 35 countries x corporation stock nyse bac list new york stock e x merrill lynch market name global bank global market businesses x corporation lend derivatives commercial bank activities perform globally bank affiliate x corporation include x na member fdic securities strategic advisory investment bank activities perform globally investment bank affiliate x corporation bank affiliate include unite state merrill lynch pierce fenner smith incorporate merrill lynch professional clear corp register brokerdealers members jurisdictions locally register entities merrill lynch pierce fenner smith incorporate merrill lynch professional clear corp register futures commission merchants cftc members nfa investment products offer investment bank affiliate fdic insure may lose value bank guarantee copyright 2015 x corporation', 'x institute economic empowerment women ieew x renew partnership peace business program peacethroughbusiness support women entrepreneurs rwanda afghanistan 600 women entrepreneurs rwanda afghanistan graduate ieew peace business program since inception 11 years ago initiative provide train strategic plan support mentorship equip women grow businesses strengthen communities since program launch 80 percent women still business today create 13000 job preserve bring sustainable profitable businesses communities advance economic growth stability regions partnership ieew part larger effort x empower women yous around world drive economic mobility say andrea smith chief administrative officer x women overcome incredible challenge help businesses grow communities thrive important support women like addition receive oneonone mentor new trainees attend peace business train boot camp dallas july 10 receive instruction topics include apply loan human resources best practice important business skills train x provide financial management e help coach women entrepreneurs specific business goals challenge x 11 year global impact provide us financial engine assist women entrepreneurs afghanistan rwanda say dr terry neese founder ceo ieew global financial focus critical peace business mission empower women economically socially politically e e raise status women similar partnerships offer new opportunities women around world organizations serve proud continue partnership x together build road peace many women entrepreneurs hold back lack access business skills technology capital need partner organizations like ieew x empower women solutions ignite accelerate potential make significant contributions create healthy vibrant communities advance economic growth ieew institute economic empowerment women start 2006 oklahoma citybased 501 c 3 nonprofit mission empower women grow businesses pursue greater entrepreneurial venture become active public policy advocate institute accomplish mission focus education mentorship coach women unite state abroad seek acquire entrepreneurial skills help start grow business ieew work network mentor corporate sponsor private donors across unite state accomplish work learn visit x environmental social governance x guide common purpose help make financial live better power every connection deliver responsible growth focus environmental social governance esg leadership esg embed across eight line business reflect help fuel global economy build trust credibility represent company people want work invest business demonstrate inclusive supportive workplace create employees responsible products service offer clients impact make around world help local economies thrive important part work form strong partnerships nonprofits advocacy group community consumer environmental organizations bring together collective network e achieve greater impact', 'x investors regain confidence global economic outlook follow resolution yous debt crisis accord bofa merrill lynch fund manager survey november political paralysis washington overcome net 67 percent respondents e world economy strengthen ne 12 months notable 13 percentage point october important new question survey investors ask yous federal reserve begin bond purchase signal central bank view economic condition robust enough lessen support fortyeight percent see happen ne march eighteen percent e second quarter 2014 second new question ask investors likeliest catalyst global economy reach velocity virtuous cycle growth 2014 common answer growth bank lend g7 economies 31 percent follow acceleration chinese asian economies 26 percent investors increase equity allocations slightly month net 52 percent overweight also up underweight bond biggest shift global emerge market equities return net overweight strong overweights eurozone japanese stock moderate slightly strikingly small net majority asset allocators view equities overvalue mark first read measure since march 2004 regionally europe still considerably undervalue compare yous accompany cash hold rise 46 percent remain reluctant bull would think alltime highs yous stock price would coincide high cash level say michael hartnett chief investment strategist bofa merrill lynch global research still low europe portfolio managers e eps grow fewer see reach doubledigit level add john bilton european investment strategist net 59 percent european fund managers e region company increase earn ne year net 49 percent october however last month e hike could reach doubledigit level evaporate net 9 percent doubt 10 percent better rise achieve nonetheless october e towards eurozone equities normalize somewhat fund managers still discern value market survey show net 18 percent view region stock undervalue even recent strong performance global emerge market fund managers show significant rise confidence corporate earn month net 44 percent e emerge market company improve profit ne year compare net 11 percent october september net 8 percent e earn decline month fund managers also shift preferences strongly global emerge market reflect restoration potential hard land china greatest tail risk globally emerge market specialists scale back overweight country substantially net 11 percent 45 percentage point china replace russia top pick among bric market 12month basis however much shift chinese equities appear direct korea global emerge market fund managers ramp overweight country net 56 percent 34 percentage point investors signal new appetite smallcap stock month net percentage fund managers e largecaps outperform smaller peer fell 7 represent monthonmonth fall 10 percentage point take read lowest since survey begin ask question openness higher risk lessestablished company consistent investors strong conviction outlook global economy e corporate earn rise regions survey fund managers overall total 222 panelists us 599 billion assets management participate survey 1 november 7 november 2013 total 174 managers manage us 444 billion participate global survey total 111 managers manage us 280 billion participate regional survey survey conduct bofa merrill lynch research help market research company tns international network 50 countries tns provide market information service 80 countries national multinational organizations rank fourthlargest market information group world bofa merrill lynch global research bofa merrill lynch global research franchise cover nearly 3500 stock 1100 credit globally rank top tier many e survey recently group name top global research firm 2012 institutional investor magazine 1 2013 institutional investor allasia survey third consecutive year 1 institutional investor 2013 emerge market fi income survey 2 2013 institutional investor allamerica survey 2 alljapan survey second consecutive year 2 2013 alllatin america survey 2 2012 allchina survey 3 2013 institutional investor alleurope survey group also name 2 2013 institutional investor allamerica fi income survey second consecutive year 3 2013 alleurope fi income research survey x x one world largest financial institutions serve individual consumers small middlemarket businesses large corporations full range bank invest asset management financial risk management products service serve appro 51 million consumer small business relationships appro 5200 retail bank offices appro 16200 atms award win online bank 30 million active users 14 million mobile users x among world lead wealth management company global leader corporate investment bank trade across broad range asset class serve corporations governments institutions individuals around world x offer industryleading support appro 3 million small business owners suite innovative easytouse online products service company serve clients operations 40 countries x corporation stock nyse bac list new york stock e x merrill lynch market name global bank global market businesses x corporation lend derivatives commercial bank activities perform globally bank affiliate x corporation include x na member fdic securities strategic advisory investment bank activities perform globally investment bank affiliate x corporation bank affiliate include unite state merrill lynch pierce fenner smith incorporate register brokerdealer member finra sipc jurisdictions locally register entities investment products offer investment bank affiliate fdic insure may lose value bank guarantee', 'x investor optimism global economic recovery corporate profit dent tail risk associate yous economy escalate though sentiment towards europe improve accord survey take october 4 october 10 show number investors believe global economy strengthen fall net 54 percent net 69 percent september albeit still historically strong level net 71 percent e economic growth remain trend come 12 months net 61 percent month ago concern yous fiscal tighten number one tail risk 24 percent panel 6 percent september e recovery corporate profit also fall last month net 41 percent say e corporate profit worldwide would improve follow 12 months figure tumble net 28 percent october net 18 percent believe corporate profit margins decrease come year net 11 percent month ago asset allocators scale back equity hold net 49 percent global asset allocators overweight equities net 60 percent september past month investors reduce position eight 11 sectors monitor survey last month net 9 percent panel remain overweight yous equities month measure drop zero percent time investors shift back towards fi income scale back underweight position bond portfolio cash level rise washington clearly cause investors shift back towards benchmarks asset price gain still drive high cash level say michael hartnett chief investment strategist bofa merrill lynch global research flow europe would call touch nearterm caution solid macro momentum region suggest dip eu equity market would enthusiastically buy say john bilton european investment strategist europe able avoid downward shift global sentiment equity allocations reach sixyear high net 46 percent asset allocators overweight european equities net 36 percent september represent highest read since 2007 global investors outlook european corporate profit continue rise uninterrupted events washington positive level since september 2007 net 10 percent panel say eurozone region favorable outlook two months ago net 5 percent forecast fall profit positivity towards corporate europe also evident within region august net 55 percent european respondents regional survey say doubledigit growth unlikely follow year month net 6 percent say doubledigit earn growth likely twomonth swing 61 net percentage point japanese equities also resist global trend october record second successive month improvement net 30 percent global asset allocators overweight region net 22 percent september investors asset allocators increase allocations towards global emerge market equities indicate october survey see value region signal towards global emerge market universally positive however asset allocators scale back underweight position net 10 percent panel underweight emerge market equities october improve net 18 percent underweight month ago average net 26 percent investors overweight region net 38 percent global respondents say emerge market equities undervalue regions contrast net 63 percent say yous overvalue region amount investors name emerge market region want underweight continue fall time however outlook china economy worsen net 5 percent regional fund managers e chinese economy strengthen come year net 28 percent september asset allocators reduce e commodities important pro emerge market sentiment net 28 percent asset allocators underweight commodities compare net 16 percent september survey fund managers overall total 183 panelists us 643 billion assets management participate survey october 4 october 10 2013 total 183 managers manage us 500 billion participate global survey total 118 managers manage us 291 billion participate regional survey survey conduct bofa merrill lynch research help market research company tns international network 50 countries tns provide market information service 80 countries national multinational organizations rank fourthlargest market information group world bofa merrill lynch global research bofa merrill lynch global research franchise cover nearly 3500 stock 1100 credit globally rank top tier many e survey recently group name top global research firm 2012 institutional investor magazine 1 2013 institutional investor allasia survey third consecutive year 1 institutional investor 2013 emerge market fi income survey 2 2013 institutional investor allamerica survey 2 alljapan survey second consecutive year 2 2013 alllatin america survey 2 2012 allchina survey 3 2013 institutional investor alleurope survey group also name 2 2013 institutional investor allamerica fi income survey second consecutive year 3 2013 alleurope fi income research survey additionally bofa merrill lynch global research name 1 global broker financial timesstarmine well rank 1 yous europe 2 asia group also name 1 asia 2 yous wall street journal best street 2012 analysts survey x x one world largest financial institutions serve individual consumers small middlemarket businesses large corporations full range bank invest asset management financial risk management products service serve appro 51 million consumer small business relationships appro 5200 retail bank offices appro 16200 atms award win online bank 30 million active users 14 million mobile users x among world lead wealth management company global leader corporate investment bank trade across broad range asset class serve corporations governments institutions individuals around world x offer industryleading support appro 3 million small business owners suite innovative easytouse online products service company serve clients operations 40 countries x corporation stock nyse bac list new york stock e x merrill lynch market name global bank global market businesses x corporation derivatives commercial bank activities perform globally bank affiliate x corporation include x na member fdic strategic advisory investment bank activities perform globally investment bank affiliate x corporation bank affiliate include unite state merrill lynch pierce fenner smith incorporate merrill professional clear corp register brokerdealers members finra sipc jurisdictions locally register entities merrill lynch pierce fenner smith incorporate merrill lynch professional clear corp register futures commission merchants cftc members nfa products offer investment bank affiliate fdic insure may lose value bank guarantee x news visit', 'x small business owners metro new york 68 percent still recover recession market accord semiannual study e concern aspirations perspectives small business owners metro new york around country national average 64 percent market include miami 61 percent los angeles 60 percent chicago 59 percent report reveal metro new york entrepreneurs work hard combat impact recession almost nine 10 metro local small business owners 86 percent work 40 hours week also make lot financial sacrifice businesses business owners metro new york area resilient individuals make lot personal sacrifice sake businesses customers employees say michael angelone metro new york small business banker manager x small business bankers commit work hardworking entrepreneurs support help succeed spite linger concern metro new york small business owners still optimistic business years ahead nearly twothirds 64 percent plan grow business ne five years addition 59 percent anticipate revenue growth come year nearly half metro new york entrepreneurs 44 percent say e hire employees year many 48 percent say difficult find qualify staff metro new york entrepreneurs say top challenge find qualify staff attribute skills gap 61 percent high salary demand 48 percent majority metro new york small business owners 60 percent say establish relationships customers clients primary driver repeat business find many ways show appreciation include report also find 70 percent metro new york small business owners become technologically advance meet customer demand forty percent say social media online review sit provide informative feedback prompt change businesses 36 percent e uptick customers spring 2015 small business owner report find metro new york small business owners increasingly concern impact health care cost compare find fall 2014 small business owner report 73 percent versus 65 percent six months ago however significantly less worry many issue six months ago include effectiveness yous government leaders 63 percent versus 81 percent strength yous dollar 50 percent versus 69 percent interest rat 50 percent versus 62 percent global stock market 42 percent versus 52 percent come government policies metro new york small business owners say greatest potential positive impact business could come e tax break automatically enrol employees retirement save account 33 percent incentives keep job yous soil 29 percent conversely policies would negative impact business would require health care plan employees 36 percent mandate sick leave employees 32 percent metro new york small business owners overwhelmingly support small businesses community shop small sinine percent metro new york small business owners give grade shop local small businesses also rate local community high shop small 63 percent hand grade assess well metro new york residents frequent small businesses many small business owners feel support local community 28 percent metro new york entrepreneurs believe policymakers appreciate small business owners indepth look attribute nation small business owners read full additional metro new yorkbased insights download small business owner report metro new york infographic x small business owner report braun research conduct x small business owner report survey phone march 4 2015 march 27 2015 behalf x braun contact nationallyrepresentative sample 1000 small business owners unite state annual revenue 100000 4999999 employ 2 99 employees addition 300 small business owners also survey nine target market los angeles dallas washington dc new york boston chicago san francisco atlanta miami margin error national sample 31 percent margin error oversampled market 57 percent report 95 percent confidence level braun research survey result conduct behalf x interpretations release intend imply substitute professional advice receive qualify accountant attorney financial advisor always seek advice accountant attorney financial advisor question may regard decisions undertake result review information contain herein nothing report construe either advice legal opinion x x one world largest financial institutions serve individual consumers small middlemarket businesses large corporations full range bank invest asset management financial risk management products service company provide unmatched convenience unite state serve appro 48 million consumer small business relationships appro 4800 retail financial center appro 15900 atms awardwinning online bank 31 million active users appro 17 million mobile users x among world lead wealth management company global leader corporate investment bank trade across broad range asset class serve corporations governments institutions individuals around world x offer industryleading support appro 3 million small business owners suite innovative easytouse online products service company serve clients operations 50 state district columbia yous virgin islands puerto rico 35 countries x corporation stock nyse bac list new york stock e', 'x boom yous energy market robust house recovery strengthen economy create growth opportunities investors nonfinancial specialty assets include farmland timberland real estate private businesses oil gas accord yous trust report publish today 2014 outlook nonfinancial assets yous trust specialty asset management group say e strong performance asset class market poise longterm growth factor longterm market trend population growth economic development emerge market correlate demand energy food house see strong growth opportunity emerge nonfinancial assets say dennis moon national e yous trust specialty asset management group manage separate account high net worth investors real assets factor drive value assets unique independent volatile force often play broader market make investments highly attractive important consideration construction balance portfolio yous trust take indepth look opportunities five key nonfinancial asset categories financial assets effective diversifier portfolio financial assets see asset class become increase focus many clients individual institutional investors access amount capital need direct investments add moon nature unique investments assets need manage value deal investment incomeproducing potential specialty asset management team yous trust offer strategic insight specialize e require manage potential investments lead dennis moon e team include copy yous trust 2014 outlook nonfinancial assets available along additional whitepapers specialty asset management group yous trust note oil gas mineral interest available direct investment yous trust yous trust yous trust x private wealth management lead private wealth management organization provide vast resources customize solutions help meet clients wealth structure investment management bank credit need clients serve team e advisors offer range financial service include investment management financial succession plan philanthropic specialty asset management family office service custom credit solutions financial administration family trust stewardship yous trust part global wealth investment management unit x na global leader wealth management private bank retail brokerage yous trust employ 4000 professionals maintain 140 offices 32 state part x yous trust provide access broad range bank solutions individuals businesses e retail bank platform x x one world largest financial institutions serve individual consumers small middlemarket businesses large corporations full range bank invest asset management financial risk management products service company provide unmatched convenience unite state serve appro 50 million consumer small business relationships appro 5100 retail bank offices appro 16300 atms awardwinning online bank 30 million active users 14 million mobile users x among world lead wealth management company global leader corporate investment bank trade across broad range asset class serve corporations governments institutions individuals around world x offer industryleading support appro 3 million small business owners suite innovative easytouse online products service company serve clients operations 40 countries x corporation stock nyse bac list new york stock e nonfinancial assets closelyheld businesses real estate oil gas mineral properties timber farm ranch land complex nature involve risk include total loss value special risk considerations include natural events e earthquakes fire complex tax considerations lack liquidity nonfinancial assets suitable investors always consult independent attorney tax advisor investment manager insurance agent final recommendations change implement financial tax estate plan strategy energy natural resources stock volatile may affect rise interest rat inflation also affect factor natural events e earthquakes fire international politics diversification ensure profit protect loss decline market yous trust operate x na subsidiaries x corporation x na member fdic investment products 2014 x corporation', 'get latest information race road versions ford supercar watch focus rs rx race facebook live youtube find ford performance race weekend 6 race chuck watson sr hoist wally win school automotive machinists factory stock showdown hold nhra summit race nationals summit motorsports park sam tech factory stock showdown ultimate battleground chevy copo camaros dodge drag pak challengers ford performance cobra jet mustang watson best field run 819 165 mph win allford final standout kevin skinner like someone take sack concrete shoulder say watson winner circle engine car tuner kim map job whole team come together crowd enthuse wellreceived whole e awesome add watson run three nhra factory stock showdown events 2016 compete three events far season 70yearold driver make final gainesville lose semifinals charlotte qualify pole time david barton watson face stephen bell open frame handle easily bell camaro spin line set semifinal match barton quick copo concentrate anything different say watson barton spin badly first round opponent redlighted watson run 829 team tweak car clash barton cut better light 038 063 come pass second gear e watson us make great run mine little better watson improve 822 16483 barton trail 82716435 david barton gratify win event say waston tough competitor tough come mindset go final confidence like 100 percent cut light run race kevin little much car spin drama car go watson say wrong converter gainesville car violent really respond change tune smaller window race 1964 gala mustang watson take break focus business return 1990s one first modularpowered drag cars run mostly local fordbased events watson take another hiatus drag race return three years ago son chuck jr team watson race secretly build 2014 cobra jet honest birthday september son employees build black 2014 cj get collection 70 cars mostly cars park cj collection ne spring get license start get active last season watson move 2016 blue car car 001 2016 model tough guy good state keep test get better better need keep improve car improve drive skills become obvious month ago hunt need improve drive engine builder kim map help get rid distractions plus work portatree practice tree start early thursday prepare track much tune make small improvements minute change right place never spin tire ford performance cobra jet perform flawlessly go continue work car ne factory stock showdown hold indy big stage yous nationals prepare say watson ready make adjustments condition e drive skills even better', 'power connectivity transform industries forwardthinking cities drive ne generation wireless access commercial availability around 2020 4glte technology enable e smartphones mobile applications mobile commerce evolution 5g enable rapidly grow human machine communications since 5g build license 4glte benefit lowpower iot devices begin early ne five years traffic volumes cellular network 1000 time 100 time devices require connectivity applications demand data rat 100 time speed average network currently deliver require nearzero latency network delay entire system work enable battery life 10 years lowpower iot devices spur innovation make cities livable secure efficient responsive citizens need glenn la cto head strategy ericsson north american region responsible define drive ericsson technology direction company strategy disruptive technology areas mobile cloud catch latest news events series come x citizenship sustainability team visit blog want hear', 'jul 18 2017 x provide e coverage 146th open championship directv channel 701 jul 13 2017 directv streamers first fall e new platform deliver feature innovation entertainment options begin fall jun 30 2017 directv users market watch best abc nbc fox begin july jun 29 2017 directv provide e live coverage first eight days wimbledon directv wimbledon e jun 29 2017 x give directv customers e look last face watch directv cinema arrive theaters july 28', 'mar 30 2017 x select first responder network authority firstnet build manage first broadband network dedicate america police firefighters emergency medical service learn', 'oct 10 2013 digital life cover jul 25 2013 two iconic american brand join together create x stadium home dallas cowboys organizations work together x continue invest advance mobile technology around x stadium benefit visitors jul 18 2013 x bring cell sit downtown san diego preparation increase wireless network usage year comic book convention jun 21 2013 get summerbreak cast party teens kick social media summer dj food truck photo booths lot action see celebration santa monica jun 17 2013 dad still try figure te give dad gift tech ideas match favorite hobbies personality', 'share x e fi wireless 5g trials business residential customers waco te kalamazoo michigan south bend indiana end year june second fi wireless 5g trial austin local businesses include car wash church small businesses also launch test site apartment unit since gain new insights millimeter wave mmwave performance propagation also learn things like foliage build materials device placement surround environment weather impact signal system realworld environment see speed 1 gigabit per second latency rat well 10 milliseconds radio link customer trial locations austin also continue conduct outdoor prestandards mobile 5g test one top north american wireless carrier contributors 3rd generation partnership project 3gpp wireless standards body work 5g standards contribute key trial find austin standards process austin see type weather substantial foliage say marachel knight senior vice president wireless network architecture design x fi wireless 5g trials lab real world help us learn important factor mmwave 5g learn better design network future time trial participants austin e glimpse future see reallife benefit tomorrow 5g offer give austinites best car wash service e 20 years trial sound like way make e even better think everyone phone wait room customers pass time entertainment latest internet connection say dave swenson owner arbor car wash lube center one else claim trialed first 5genabled car wash apartment unit set fi wireless 5g home multiple applications run simultaneously fi wireless 5g connection stream directv 360 video international videoconferencing demonstrate people live work play connect home future apply key learn austin come trials waco kalamazoo south bend e learn even market plan increase number participants e physical footprint continue test fi mobile wireless solutions operate mmwave spectrum field testbeds learn new fi wireless 5g trials help speed standards base deployment early late 2018 trial participants new market may include universities hospitals church restaurants small businesses participants able stream premium live tv via directv e faster broadband service 5g internet connection test demonstrate 5g technologies x year e scope trial x customers waco say joakim sorelius head product area network systems ericsson provide end end solution include new 28ghz radio virtualized run full 5g virtualized core test technologies live commerciallike environment trialing new 5g use case together able gain valuable e preparation commercial deployments base 3gpp new radio nr technology e trials additional cities build longterm collaboration x industry partner say sandra rivera senior vice president general manager xcorporation network platforms group 5g e sponsor take learn x5g mobile trial platform austin new market able test realworld applications 5g technology infrastructure partner ecosystem network cloud device make 5g reality endtoend 5g solution let us x customers e ne generation wireless service say wilf norrlinger vice president general manager sales network samsung electronics america deliver 5g network solution south bend indiana trial include 5g router businesses home foundation build samsung 5g rfic chipset virtualized core vran deploy operate faster easier e work x advance 5g take learn lab real world x enterprise residential consumers say ricky corker e vice president head north america nokia deployment offer good environment test multitude new use case deployment challenge within fi trial also e include mobility 5g trials standards release let us us learn 5g mmwave characteristics prepare network plan deployment contribute learn real time standards develop aggressively deploy equipment invest right mix spectrum technology lay foundation evolution 5g 5g standards finalize major step journey deliver stateoftheart 5g speed soon late 2018 addition austin indianapolis second metro thank within 3gpp lessons learn trials e commercial equipment available within 6 months completion 5g release 15 standard contrast lte equipment available year 18 months lte standard complete x inc help millions around globe connect lead entertainment business mobile high speed internet service offer nation best data network best global coverage yous wireless provider one world largest providers pay tv tv customers yous 11 latin american countries nearly 35 million company small large businesses around globe turn x highly secure smart solutions x products service provide offer subsidiaries affiliate x inc x brand x inc', 'despite initial skepticism walt disney believe vision children amusement park would bring life magic imagination cartoon film x finance construction disneyland anaheim california early 1950s walt disney x chairman board louis lundborg construction small world disneyland california x promotional brochure give customers feature map newly open disneyland x check client walt disney photo x financial center locate wthin disneyland main street feb 4 1938 world first featurelength animate movie hit theaters finance x break record ticket sales thrill film critics never see like artistry begin relationship disney x evolve finance animate film include decades follow x also finance construction disneyland later disney world walt disney vision amusement park children would embody magic imagination cartoon film initially meet discouragement among skeptics company brother roy think fanciful e amusement park would lead financial ruin walt confident vision x construction disneyland begin anaheim california early 1950s construction disneyland begin july 16 1954 crew work around clock meet demand deadline completion park walt visit site several time week check progress weeks months pass materialization tropical jungles rustic frontier fort tomorrowland main street usa charm ornate castle take shape among 160 acres orange groves one full year construction total investment 17 million gate disneyland open guests sunday july 17 1955 inside park locate main street stand fully function x branch bank associate dress turnofthecentury clothe even offer money order print disneyland branch park iconic ride small world rebuild 1966 x sponsor ride huge success new york world fair bank sponsorship promote america first modern credit card bankamericard first credit card accept magic kingdom decades follow x also finance construction walt disney world florida open 1971 1963 disney set find site new disney amusement park would give room need create multiple theme park hotels restaurants fly across florida one day walt look undeveloped swamp land cattle pasture around orlando saw location new park disney start acquire much land possible discreetly time disney announce project november 15 1965 company own 43 square miles land within days announcement land value property surround disney site shoot 180 per acre much 80000 per acre 1986 disney grow internationally x capital market group play lead role arrange 10 billion yen transaction walt disney company e operations japan three years open 1983 visit one heritage center close look stories bank history strive provide information products service might find interest useful relationshipbased ads online behavioral advertise help us work gather information online activities search conduct sit page visit information may use deliver advertise sit offline e phone email direct mail customize meet specific interest may prefer use information opt though may still receive generic advertise also opt online behavioral advertise may still see ads sign account e online bank mymerrill ads base specific account relationships us learn relationshipbased ads online behavioral advertise privacy practice please review site contain pdf document require latest version adobe reader order read america na member fdic', 'mission bridge economic racial social divisions provide youth projectbased steam science technology engineer arts mathematics education 21st century skills advancement workforce train job e pay participation youth arts enterprise program combine approach address trouble statistics boston teens include crisis high youth unemployment public high school graduation rate hover 66 research document economically disadvantage teens without pay employment high school years susceptible drop afh youth arts enterprise program connect youth professional artists designers mentor collaborate innovative project promote active learn advance skills development creativity media technology criticalthinking problemsolving critical outofschool hours nationally recognize program widely hail best practice model effective mentorship youth empowerment social entrepreneurship fact afh award x prestigious 2010 recognition impact program transform live provide pathway financial selfsufficiency boston atrisk youth regular hostorganization x several local high school students benefit unique summer job afh encompass leadership skills development develop ne generation leadership nonprofit sector humanity impact change live teens throughout greater boston utilize power art creativity steward toward selfsufficiency success unparalleled say miceal chamberlain massachusetts state president x america commit make financial live better key way support program like artists humanity provide young adults path toward economic selfsufficiency mobility say miceal chamberlain massachusetts state president x addition program operational support x connect afh innovative project commission largescale sculpture encourage recycle instal lobby x boston offices 2015', 'partner locally build stronger latin american economies 1574042 philanthropic support x merrill lynch proudly serve corporate institutional clients latin america since 1951 open first office city today corporate offices six latin american countries argentina brazil chile colombia peru combine best local knowledge e reach global bank history span 60 years region x merrill lynch offer complete portfolio corporate institutional bank solutions across equities ficc fi income commodities currencies research investment bank corporate bank global transaction service latin america dedicate build strong economies invest give communities operate community investments focus create opportunities build better economic future 24 2014 news huffington post imagine bill gate mark zuckerberg steve job bear africa asia latin america think would realize potential imagine men sister also innovator think would access resources brother enjoy realize dream 06 2014 march x vital voice bring global ambassadors program city first meet 2014 mentor program connect women business leaders latin america caribbean senior women e help participants access network gain e around strategic plan create impact countries economies march 2014 global ambassador program city bring together global ambassadors women business leaders around latin america caribbean program focus empower women entrepreneurs active contributors countries economies 09 2014 force sweep across globe reshape live past year e theme share insights seismic demographic economic environmental change mean us participate collaborate switzerland influencers around world 10 2013 cherie blair foundation program connect women business owners x employees technologyenabled global network us dollars select country select state strive provide information products service might find interest useful relationshipbased ads online behavioral advertise help us work gather information online activities search conduct sit page visit information may use deliver advertise sit offline e phone email direct mail customize meet specific interest may prefer use information opt though may still receive generic advertise also opt online behavioral advertise may still see ads sign account e online bank mymerrill ads base specific account relationships us learn relationshipbased ads online behavioral advertise privacy practice please review site contain pdf document require latest version adobe reader order read america na member fdic', 'transcript clarissa black video merrill lynch wealth management please see important information end program graphic title white type black background sometimes one person vision help live many lower third blade anthony corpsman usmc iraq war veteran graphic subtitle appear lower portion frame accord 2013 department veterans affairs report blade anthony 22 people go die today twentytwo brothers sisters go take life deal stuff almost one clarissa organization dog dede clarissa black every year appro four million animals euthanized shelter across country 2nd graphic subtitle accord spca statistics lower third clarissa black founder pet vet merrill lynch client clarissa black inspire think find right shelter dog help veterans go matt dupuis watch clarissa black start organization scratch see immediate impact individual live contagious doubt mind go look back short amount time pet vet household name clarissa black pet vet nonprofit organization match shelter dog return veterans help posttraumatic stress disorder traumatic brain injury depression clarissa black actually really get know veterans look need go find dog go fit seamlessly life top actually provide dog train help fit particular veterans ptsd blade anthony use get really mad de de would come would make less mad would calm would cry afraid would make cry feel better clarissa black work blade discover really good night sleep since return home train dede actually recognize wrestle moan nightmare order wake blade night actually start reduce number nightmares able get good night sleep blade anthony really mean say stand away adam renteria get rakkasan want much bigger dog come type warrior mentality want warriortype dog clarissa black feel large dog think go help tell us look adam renteria look void fill rather process heal clarissa assessment evaluation understand broll adam clarissa fountain sync much sync adam clarissa rakkasan walk together clarissa black match veterans actually become part pet vet family think really important also heal ptsd feel part community clarissa black incredible community build pet vet family volunteer give time believe pet vet also want help veterans help rescue animals fa matt dupuis clarissa pet vet chapters 19 state think go stop 50 state surely hope people opportunity something like life look back say something bigger make difference blade anthony pet vet rescue de de pretty bad scar face like probably ptsd like blade anthony together heal together important information case study intend illustrate brokerage bank products service available merrill lynch consider endorsement merrill lynch investment adviser testimonial client e us investment adviser case study necessarily represent e clients indicate future performance investment result may vary investment strategies discuss appropriate every investor consider give person investment objectives financial situation particular need clients review merrill lynch financial advisor term condition risk involve specific products service merrill lynch wealth management make available products service offer merrill lynch pierce fenner smith incorporate mlpf subsidiaries x corporation bofacorp bank products provide x na affiliate bank members fdic wholly own subsidiaries bofacorp investment products fdic insure bank guarantee may lose value mlpf register brokerdealer member sipc wholly own subsidiary x corporation x corporation', 'select country select state partner locally proud help fuel local economy address critical need revitalize neighborhoods right san francisco e stories videos galleries see everywhere look see people work hard every day hard families communities job face challenge yet fight moment along way conviction courage courage change circumstance courage rally community courage create moment time lead better see successes big small responsibilities tackle together drive determination drive us invest partner communities create partnerships connect people communities opportunity build clear path economic progress age race lifestyles look second job provide second chance believe offer chance build sometimes rebuild career live communities x clear purpose make financial live better work hard invest future partner along way drive hard work partnerships share success drive super x ask giants players share favorite baseball memory brandon belt san francisco first baseman first game ever play organize baseball uh pitch machine eight years old uh remember uh know hit ball pretty well uh think hit top fence angel pagan san francisco leave fielder mom know take ballpark baseball player house uh first manager joe panik san francisco giants second baseman fondest memory parent honestly uh day world series clubhouse kinda share moment super mlbmemorybank x logo super x x logo san francisco giants logo official bank san francisco giants share favorite memory bankofamericacommlbmemorybank major league baseball trademark copyright use permission mlb advance media lp', '21 2015 nearly 50 years special olympics promote better world people intellectual disabilities power sport school day game come directly students school across massachusetts school day game students participate traditional open ceremony compete participate three sport activities receive award accomplishments presentation end event spring 30 school district participate game thank part grant x charitable foundation special olympics massachusetts school partner organize 31 school day game 400 school 4500 athletes across state participate game design introduce students special olympics combat bully negative behaviors promote acceptance inclusion people intellectual disabilities incredible grateful partnership x schooldaygames important initiative spread mission respect inclusion opportunity school throughout massachusetts say mary beth mcmahon president ceo special olympics massachusetts america longtime support tremendous impact help mission reach tens thousands students massachusetts employees x locations across state regularly volunteer individually team many school day game assist organizers athletes ensure wellrun enjoyable day involve x special olympics partner 30 years addition local efforts like school day game x charitable foundation provide 5 million support 2015 special olympics world game los angeles select country select state strive provide information products service might find interest useful relationshipbased ads online behavioral advertise help us work gather information online activities search conduct sit page visit information may use deliver advertise sit offline e phone email direct mail customize meet specific interest may prefer use information opt though may still receive generic advertise also opt online behavioral advertise may still see ads sign account e online bank mymerrill ads base specific account relationships us learn relationshipbased ads online behavioral advertise privacy practice please review site contain pdf document require latest version adobe reader order read america na member fdic', 'x corporation variety different twitter handle several purpose include share local communities provide customer service assistance share information career opportunities x please see company twitter page public mean anyone see tweet unless protect tweet something twitter account settings anyone see tweet tweet may even show searchengine result like google yahoo tweet x corporation encourage everyone common courtesy respectful others original content avoid content know fraudulent tweet someone else copyright work unless permission tweet personal identify confidential information x customer specific question account please tweet us handle x employee assist also get help us bankofamericacom online bank us 18004321000 one bank center speak professional person service specialist get help section x app facebook access x merrill lynch client specific question account get help us merrill lynch client specific question account get help us us 1800merrill 6377455 yous trust client specific question account get help us 1800ustrust 8787878 merrill edge client specific question account get help call us 1888meredge 6373343 twitter handle manage monitor x corporation basics full policies twitter handle public anyone twitter account engage us responsible view e please note may unfollow user dramatically change mission objectives feel violate community policy x corporation presence various social mediasocial network outlets may occasionally identify respond customers seek assistance bankingrelated issue event customer receive communication bank regard service request need customer may offer x channel help address concern smoothly effectively possible twitter handle manage monitor x corporation actively watch people say x twitter ensure receive andor offer feedback however public nature platform simply respond engage issue never disclose financial information twitter x corporation affiliate ever ask social security number account information passwords pin via twitter responsible privacy security practice twitter addition discourage click link post twitter users link may pose risk computer take inappropriate sit also accept consider unsolicited ideas however send us ideas solicit submit govern idea submission policy term please dont use twitter report phishing criminal activity suspicious email forward would like make report please call 18004321000 representative assist tweet direct communications employees please note see tweet regard question x bank products service career opportunities try reach see help want make bank e better make every effort respond tweet timely manner cant guarantee reply every tweet learn career opportunities latest community information customer service latest news information tip helpful information global perspective wealth management insights latest news information invest insights tip member media please visit page information press contact may occasionally tweet retweet link thirdparty sit think find information helpful however please note way constitute official endorsement individual website company participation followfridays also doesnt constitute official endorsement x large corporation many advertise relationships link thirdparty sit may contain content sponsor sponsorships pay x pay sponsor may disclose relationship sit additionally pay sponsor tweet may contain term sponsor indicate pay nature relationship also note twittercom host twitter govern twitter separate website policies include policies apply use twitter addition please note visit official x company twitter page also subject term condition x privacy policy general term use protect privacy privacy others please include personally identifiable information social security number financial account number phone number email address comment post include personally identifiable information comment comment post may delete stay uptodate feature job opportunities x x merrill lynch merrill lynch yous trust follow twitter please note accept applications via twitter apply position please visit x corporation affiliate consider employment hire qualify candidates without regard race religious creed religion color sex se orientation genetic information gender gender identity gender e age national origin ancestry citizenship protect veteran disability status factor prohibit law affirm policy practice support promote concept equal employment opportunity affirmative action accordance applicable federal state provincial municipal laws wish receive tweet please follow follow receive uptodate information x empower consumers support communities fuel economic growth local communities serve wish receive tweet please follow tweet direct communications employees assistance available operate hours 8am mon 11am sit time eastern best respond may also proactively reach people tweet x products service happy able serve customers way however limit discuss public forum like twitter question personal account confidential matter may request send us direct message twitter name phone number point x employee follow personally discuss issue question detail handle intend serve x merrill lynch merrill lynch yous trust customers wish receive tweet please follow follow let us stay uptodate news information resources x wish receive tweet please follow use twitter help get money throughout daily routine follow wish receive tweet please follow follow great way receive relevant uptodate information company global perspective comprehensive solutions strategic guidance wish receive tweet please follow opinions view statements estimate projections post post company social media sit page solely individual author post employee agent x merrill lynch affiliate bofaml solely employee agent necessarily reflect view bofaml post bofaml employee agent intend use solely informational purpose mean official statement confirmation offer agreement kind solicitation recommendation buy sell hold securities similarly bofaml accept timesensitive actionoriented message transaction order include order purchase sell securities via online post market price market data contain attach post indicative subject change without notice bofaml obligation update modify amend post web page otherwise notify recipient thereof event matter state herein opinion projection forecast estimate set forth herein change subsequently become inaccurate thirdparty post andor link reflect view bofaml bofaml adopt endorse shall responsible thirdparty post bofaml reserve right intercept monitor review retain post post web site thirdparty permit applicable law post whether thirdparties bofaml employees agents may subject archive monitor produce regulators litigation accordance bofaml policies applicable laws rule regulations unless e prohibit applicable law post may archive countries country party make post locate may treat accordance laws regulations country individual include entire communication bofaml reserve right remove modify post whether post employee agent thirdparty site sole discretion post consistent policies business purpose post content information materials provide company social media sit page basis bofaml make warranty e imply accuracy completeness timeliness result obtain recipients shall way liable recipient inaccuracies errors omissions herein bofaml waive intellectual property right post information post company social media sit page intend replace recipient internal business process evaluate propose transactions recipients seek financial advice regard appropriateness invest securities refer post understand statements regard future prospect instrument securities include may realize assurance securities mention post could sell buy price bofaml another party market participants past performance necessarily guide future performance foreign currency rat e may adversely affect value price income security relate investment bofaml provide tax account regulatory advice tax statements contain post intend write use use purpose avoid yous federal state local tax penalties ii promote market recommend another party transaction partnership entity investment plan arrangement please consult advisor tax account legal statements make herein without limit forego bofaml shall liability whatsoever recipient message content whether contract tort include negligence warranty statute otherwise respect loss damage suffer recipient result connection action opinions recommendations forecast judgments conclusions course action determine third party whether base content information materials contain herein bofaml employees make defamatory statements andor statements infringe authorize infringement copyright legal right online communications may violate company policy statements make outside scope employment employee make statement may subject discipline include termination company accept liability respect communication employee responsible personally liable damage liability arise statements inclusion link e web site bofaml understand endorsement website site owners productsservices bofaml responsible either content output e websites x merrill lynch market name global bank global market institutional retirement businesses x corporation lend derivatives commercial bank activities perform globally bank affiliate x corporation include x na member fdic securities strategic advisory investment bank activities perform globally investment bank affiliate x corporation investment bank affiliate include unite state merrill lynch pierce fenner smith incorporate merrill lynch professional clear corp register brokerdealers members sipc jurisdictions locally register entities merrill lynch pierce fenner smith incorporate merrill lynch professional clear corp register futures commission merchants cftc members nfa investment products offer investment bank affiliate fdic insure may lose value bank guarantee follow great way receive relevant uptodate information investment update strategies wish receive tweet please follow merrill lynch never ask disclose social security number financial account information passwords pin via twitter twitter thirdparty site unaffiliated merrill lynch merrill lynch responsible privacy security policies practice twitter thirdparty websites may link review privacy security practice twitter thirdparty websites review merrill lynch privacy security practice click link thirdparty sit may contain content provide pay sponsor merrill lynch andor affiliate sponsor disclose relationship site additionally pay sponsor tweet may contain term sponsor indicate pay nature relationship link thirdparty site content merrill lynch review entirety sit therefore endorse content post sit follower merrilllynch consent receive news company information tweet merrilllynch think followers find useful solicit ideas send us ideas receive compensation us use invest securities involve risk always potential lose money invest securities opinions e subject change past performance guarantee future result information present general nature intend provide personal investment advice investments strategies present take account investment objectives financial need particular investors important consider information conte personal risk tolerance investment goals asset allocation diversification rebalancing assure profit protect loss decline market information present tax considerations affect client financial transactions arrangements intend tax advice rely upon purpose avoid tax penalties x subsidiaries representatives provide tax account legal advice clients review plan financial transactions arrangements may tax account legal implications personal professional advisors merrill lynch wealth management make available products service offer merrill lynch pierce fenner smith incorporate mlpf subsidiaries bac private bank investment group division mlpf offer broad array personalize wealth management products service bank mortgage products provide x na affiliate bank members fdic wholly own subsidiaries bac investment insurance annuity products follow great way receive relevant uptodate information high net worth strategies use send information dont ability respond follow wish receive tweet please follow yous trust never ask disclose social security number financial account information passwords pin via twitter twitter thirdparty site unaffiliated yous trust yous trust responsible privacy security policies practice twitter thirdparty websites may link review privacy security practice twitter thirdparty websites review yous trust privacy security practice click link thirdparty site content yous trust review entirety sit therefore endorse content post sit follower consent receive news company information tweet think followers find useful wish receive tweet unfollow us twitter solicit ideas send us ideas receive compensation us use invest involve risk include loss principal bond investments subject interestrate credit risk refer ability issuer make timely payments principal interest invest derivatives entail special risk relate liquidity leverage credit may reduce return andor increase volatility invest foreign securities particularly emerge market present certain risk currency fluctuations political economic change market risk additional risk associate invest commodities highyield bond aggressive growth stock nondiversifiedconcentrated fund small midcap stock fully e financial advisor please check advisor additional guidance make investment decisions credit collateral subject approval term condition apply program rat term condition subject change without notice investment products yous trust x private wealth management operate x na subsidiaries x corporation x na member fdic follow great way receive relevant educational information investment ideas retirement plan wish receive tweet please follow merrill edge never ask disclose social security number financial account information passwords pin via twitter twitter thirdparty site unaffiliated merrill edge merrill edge responsible privacy security policies practice twitter thirdparty websites may link review privacy security practice twitter thirdparty websites review merrill edge privacy security practice click link thirdparty sit may contain content provide pay sponsor merrill edge andor affiliate sponsor disclose relationship site additionally pay sponsor tweet may contain term sponsor indicate pay nature relationship link thirdparty site content merrill edge review entirety sit therefore endorse content post sit follower consent receive news company information tweet think followers find useful solicit ideas send us ideas receive compensation us use opinions e subject change past performance guarantee future result information present general nature intend provide personal investment advice investments strategies present take account investment objectives financial need particular investors important consider information conte personal risk tolerance investment goals invest securities involve risk always potential lose money invest securities neither merrill lynch affiliate financial advisors provide legal tax account advice consult legal andor tax advisors make financial decisions merrill edge available merrill lynch pierce fenner smith incorporate mlpf consist merrill edge advisory center investment guidance selfdirected online invest bank products provide x na affiliate bank members fdic wholly own subsidiaries x corporation merrill lynch life agency inc mlpf register brokerdealer member whollyowned subsidiaries x corporation investment products offer mlpf insurance annuity products offer merrill lynch life agency inc select country select state strive provide information products service might find interest useful relationshipbased ads online behavioral advertise help us work gather information online activities search conduct sit page visit information may use deliver advertise sit offline e phone email direct mail customize meet specific interest may prefer use information opt though may still receive generic advertise also opt online behavioral advertise may still see ads sign account e online bank mymerrill ads base specific account relationships us learn relationshipbased ads online behavioral advertise privacy practice please review site contain pdf document require latest version adobe reader order read america na member fdic', 'leadership strategy responsible growth deliver 2016 earn nearly 18 billion 13 percent year ago put perspective secondmost profitable year company history e 21 billion earn 2006 prior economic financial crisis strong performance allow us return 66 billion capital shareholders higher dividend repurchase common share latter help offset significant shareholder dilution occur financial crisis discuss detail result reflect years work simplify company rebuild strengthen balance sheet focus serve core customers dynamic operate environment characterize une events around world saw benefit remain nimble adapt change near term adhere longterm strategy support customers clients deliver shareholders responsible growth strategy grow revenue reduce e manage risk continue invest workforce capabilities also make steady progress relative longterm financial goals return tangible common equity 12 percent return assets 1 percent return tangible common equity increase 95 percent return assets improve 082 percent efficiency ratio improve 70 percent 66 percent tangible book value per share measure value create increase 9 percent 2016 1695 2017 continue drive company toward goals drive result part operational e work hard manage e reinvest capabilities reduce e 3 billion last year work e 22 billion nearly 30 percent peak 77 billion 2011 important note grow business create operate leverage need invest future also accomplish slowgrowth yous global economy however yous interest rat begin rise encourage signify improve yous economy mark low unemployment increase consumer business confidence job nurture growth help drive real economy yous around world want focus result mean longterm shareholder value little background necessary 2006 earn history 21 billion 46 billion share outstanding mean dilute earn per share 458 also pay common stock dividend 212 per share 46 percent earn compare 2016 result earn 18 billion twice many share outstanding eps 150 per dilute share common stock dividend 025 per share 17 percent earn biggest difference two periods increase common share reduction dividend necessary stabilize company worst economic crisis since great depression company stronger focus reduce dilution increase dividend share outstanding fully dilute basis peak 116 billion issue 7 billion common share crisis fund acquisitions strengthen balance sheet meet higher capital requirements repay government tarp investment within 13 months work share count year end 11 billion share market value company remain strong write letter market capitalization fully dilute basis alltime high 280 billion also focus increase dividend last june increase quarterly common stock dividend 50 percent make possible work do simplify company strengthen balance sheet rebuild capital lessons learn first must grow organically acquisitions part strategy issue share second businesses generate sufficient capital fund growth would noncore businesses everything need serve clients focus build stronger relationships optimize return third need continue reduce number share outstanding essential want stock price e record highs achieve market capitalization tangible book value per share stock trade price close book value repurchase share create longterm value remain shareholders buy sell shareholders level finally stay focus things e strategy responsible growth deliver return e us continue return e capital dividends common stock repurchase remain path lead us nearrecord earn 2016 responsible growth mean remain steadfast deliver purpose help customers clients live financial live connect capabilities strategy four tenets put simply every dollar good dollar unless come activities satisfy customer need fit risk parameters serve customers clients nurture relationships drive growth lead capabilities across company relationship business report read relationships build several client company help achieve financial goals begin people serve serve 46 million households every week interact customers 130 million time time take read letter 100000 contact customers last year consumer wealth management segment grow deposit 57 billion 7 percent increase loan 29 billion 8 percent originate 79 billion residential mortgage 13 percent help 260000 families buy refinance home continue see strong enrollment prefer reward program 40 percent 2015 see 99 percent retention rate program 33 million online customers nearly 22 million mobile bank users learn redefine retail financial service e comment dean athanasia thong nguyen coheads consumer bank business page 10 merrill lynch yous trust two best brand wealth management business well 1 market position across assets deposit loan merrill lynch private wealth advisor raj sharma e page 10 businesses continue integrate broad capabilities company meet client need turn company serve global bank business work virtually every one p 500 firm addition range lend solutions one world toptier investment bank rank 3 globally investment bank fee last year also one largest lenders midsized company small businesses see stories great clients cisco wework yoobi report bring broadest array capabilities clients cash management trade finance lend local currencies support businesses drive real economy yous around world finally global market business serve many world largest institutional investors manage save investments pension retirement fund balance business narrower scope activities financial crisis focus clients need raise capital investors seek best opportunities put capital work balance approach global market weather market volatility make money wide range economic scenarios sales trade business profitable three days last year despite volatility cause macroeconomic events include unite kingdom vote leave european union yous elections differentiator us global research team si year row team rank 1 world institutional investor magazine research capabilities help drive entire company provide valuable insights market business corporate bank wealth management clients addition keep clear focus customers clients responsible growth strategy include grow within clear risk framework maintain balance stable financially strong platform mean understand risk reward everything empower teammates share opinions ideas make better decisions last quarter 2016 lowest chargeoff ratio company history 2016 grow core loan balance 6 percent yet chargeoffs decline 12 percent demonstrate focus grow right way report chief risk officer geoff greener discuss continue strengthen risk management every employee understand role final tenet responsible growth must grow sustainable manner mean must adhere rigorous standards corporate governance must invest communities must strive best place work help 200000 teammates achieve goals aspirations environmental social governance esg practice central grow sustainable manner special esg supplement enclose annual report mail year provide additional detail also e discussion esg practice pro statement let highlight key elements commit best practice corporate governance include strong independent board directors measure board oversee responsible growth strategy deliver longterm value shareholders also board empower lead independent director whose duties responsibilities meet e corporate best practice learn board discharge responsibilities q lead independent director jack bovender report 2017 pro statement also view nearly 200 million philanthropic investments make communities around world nearly 2 million volunteer hours teammates commit cause care critical create condition longterm sustainable growth also critical foster sustainable growth way invest workforce create environment thrive early 2017 increase minimum wage employees earn 15 hour continue adjust regularly several years 2016 also increase fully pay parental leave 12 16 weeks new parent create sustainable result simplify improve sim program well drive thousands ideas generate teammates sim ongoing process simplify company eliminate streamline internal e process reduce cost reinvest future growth hard work team make everything share page possible duty create environment reflect honor diversity represent promote inclusiveness share different viewpoints provide benefit career development opportunities continue grow thrive continue strong performance saw 2016 remain focus e responsible growth strategy e impact change market drive political economic factor predict may see change bank laws regulations implement unite state jurisdictions operate reasonable regulation important safety soundness financial system support review policymakers elect officials ensure strike right balance drive responsible economic growth always must agile adaptive change principles upon run company near term long term give current regulatory environment way rebuild balance sheet e responsible growth strategy e capital put work drive economy lend continue return capital shareholders dividends stock repurchase discussion quarter perceive tradeoffs important objectives grow company continue invest business people communities understand customers communities employees succeed succeed thank invest x brian moynihan march 3 2017 select country select state strive provide information products service might find interest useful relationshipbased ads online behavioral advertise help us work gather information online activities search conduct sit page visit information may use deliver advertise sit offline e phone email direct mail customize meet specific interest may prefer use information opt though may still receive generic advertise also opt online behavioral advertise may still see ads sign account e online bank mymerrill ads base specific account relationships us learn relationshipbased ads online behavioral advertise privacy practice please review site contain pdf document require latest version adobe reader order read america na member fdic', 'x iot suite capture analyse untapped data improve business result get credit enable send 200 million message much get credit enable store 500000 object active directory multifactor auth 100 users much free account include five free users unlimited private code repos operations management suite manage protect cloud onpremises infrastructure sign free get spend x service sign free get spend x service sign free get spend x service iot hub message rout do message body thank inundation feedback customers request ability route message base message body team prioritize work available everyone use get lot ask new rout endpoints x iot hub one common ask able route directly x function power serverless compute fingertips powerful allow sort amaze things iot data prosoft leverage x iot gateway sdk easily securely connect millions e industrial devices iot solutions happy announce x stream analytics support iot hub operations monitor give easy way analyze operations iot devices x iot hub device management recently announce build e follow detail x iot hub device management available preview standards one question field often folks iot hub throttle certain operations iot hub service build support millions connections single region announce two new offer streamline internet things iot management businesses tens thousands even millions geographically distribute assets devices device management iot hub x iot gateway sdk connect device x iot hub second new visual studio connect service x iot hub february 4 announce general availability x iot hub service provide capabilities securely connect provision update send command devices x x event hubs x iot hub provide perfect endpoints collect massive quantities data come devices tiny sensors line business systems x dynamics', 'process build revise business continuity plan worth take look x site recovery asr asr disaster recovery service allow failover onpremises applications run linux windows use vmware hyperv x event outage today episode x mechanics walk x site recovery help keep applications available include set replication onpremises applications x test solution meet compliance need discuss today demobench reduce comple traditionally involve set disaster recovery asr build x long x subscription get start today free use first 31 days also x hybrid use benefit apply e windows server license toward effort learn chris van wesep recent demo bench three pivotal step get run first prepare local infrastructure depend platform use point x site recovery onpremises components need replicate applications e today see e replicate applications vmware esx use vcenter directly connect x vcenter instance onpremises step replicate applications facilitate guide e within x portal include things like select target applications land x virtual machine configuration properties replication settings last step create store recovery plan also customize recovery test failover without impact production workloads end users customize mean sequence failover multitier applications run multiple vms use x automation automate common postfailover step course set test failover demonstrate today move forward business continuity plan want use x backup protect data mitigate corruption accidental deletion ransomware x backup also fully integrate x protect data run linux windows virtualized vmware hyperv hope find today helpful please let us know thoughts feel free post question', 'post series provide latest update news visual studio team service great way x users keep uptodate new feature release every three weeks visual studio team service offer best devops tool create efficient continuous integration release pipeline x post series provide latest update news visual studio team service great way x users keep uptodate new feature release every three weeks visual studio team service offer best devops tool create efficient continuous integration release pipeline x latest devops visual studio team service post series provide latest update news visual studio team service great way x users keep uptodate new feature release every three weeks post series provide latest update news visual studio team service great way x users keep uptodate new feature release every three weeks visual post series provide latest update news visual studio team service great way x users keep uptodate new feature release every three weeks post series provide latest update news visual studio team service great way x users keep uptodate new feature release every three weeks post series provide latest update news visual studio team service feature release every three weeks post series provide latest update news visual studio team service great way x users keep uptodate new feature release every three weeks learn visual studio team service update make july 2016', 'use x backup backup windows server system state directly x protect active directory fileserver web server roles comprehensive disaster recovery use x backup backup prechecks identify resolve x vm config issue ensure successful backups article cover nuances longterm backup pst file provide ways check back right way', 'x documentdb release general availability april 8 2015 since release several version update refine protocol add new feature latest sdks offer best performance comprehensive set capabilities documentdb developers prior release april run limit support public preview service service version associate client sdks today announce upcoming retirement preview versions rest api client sdks post outline need know ensure application continue run well versions remove x documentdb access use service api first release august 2014 service release preview improve service numerous additions change use versioning maintain compatibility e applications time make change could break e application introduce new version applications must e optin use e applications unaffected new version e call documentdb e specify version use set http header rest request header set recent version use serve request majority users consume documentdb use publish client libraries provide x client libraries wrap call rest api bind specific version api approach versioning unchanged continue introduce new versions rest api whenever make change incompatible e version however retire previous versions rest api associate preview client sdks versions prior version 20150408 retire february 29 2016 include follow versions follow versions unaffected continue fully support information rest api versions currently support please refer msdn affect versions remove request e versioned use request header set one remove versions fail receive http 400 bad request status code users upgrade latest version client sdk whenever possible client sdk release prior general availability april 8 2015 version number less 100 09xpreview retire support beyond february 29 2016 table provide allow users quickly see use components target versions retire recommend users begin application upgrade least earliest support version appropriate platform early possible avoid impact preview service versions remove march 1 2016 review version differences sdks identify apis change see release note whatever reason unable upgrade applications months lead march 1 2016 please contact prior cutoff date assistance new documentdb try today sign create need help question please reach us developer forums stay uptodate latest documentdb news feature follow us twitter', 'e announce production support x customers deploy via new offer x cloudera e support follow key areas cloudera enterprise ds13 ds14 instance deploy single click instance type also deploy additional level control customization note premium storage currently support master nod provide enterpriseready open source distribution include apache hadoop relate project cloudera enterprise include world popular open source hadoopbased platform well advance system management data management massively scalable platform unite storage array powerful process analytics frameworks add enterpriseclass management data security governance cloudera enterprise include core elements hadoop hdfs mapreduce yarn well hbase impala solr spark cloudera cluster consist virtual machine instance worker nod master nod nod deploy x virtual network communicate one another access nod protect network security group nsg subnet level vm level edge nod deploy separately directly access cluster internal network nod provision centos 67 base cloudera vm image image configure optimize performance cloudera workload gs instance support premium storage worker node either premium storage standard storage disk attach master node three 512gb premium storage disk addition 512gb disk attach log per node node x storage account throughput cluster minimum four nod include three worker nod one master node deploy evaluation purpose production deployment consist three master nod three 90 worker nod high availability ha support provision standby master node refer detail cloudera architecture x deploy cloudera cluster x use marketplace template need sufficient number cpu core x subscription cluster deploy minimum four ds13 vms 8 core minimum 32 core need request increase quota core open support ticket state number core need region need specify core x resource manager find cloudera enterprise offer x marketplace navigate marketplace x portal search cloudera follow wizard enter configuration cluster deployment cluster name vm credentials resource group show specify network storage virtual machine configurations cluster enter cloudera manager credentials cluster size enter user information please reference detail user information use review summary purchase deploy cluster cluster provision successfully create ssh tunnel access hadoop endpoints x vnet e follow instructions set ssh tunnel master node mn0 access cloudera manager http localhost7180 use cloudera manager user name password specify deployment run error deployment please navigate resource group contain cloudera cluster x portal click fail deployment scroll find oldest fail event click see detail error error appear transient may remove resource group contain resources create outside cloudera cluster deployment try need greater level customization deploy cloudera cluster find publish github click x button deploy cluster similar e deploy marketplace e parameters e e address space virtual network subnet also use deploy template need customize sub templates master nod data nod e change number disk attach node download template file script github modify need upload github repo finally change variable xdeployjson point github repo also use cloudera director customize deployment detail deploy cluster use please refer', 'use intelligence apis enable vision speech language knowledge capabilities e us government entities eligible purchase x government service license solution provider upfront financial commitment directly payasyougo online subscription important price r merely reference international transaction final price subject e rat inclusion iof ta enf issue x germany available customers partner business european union eu european free trade association efta unite kingdom uk provide data residency germany additional level control data protection also sign computer vision api available east asia region please select another region computer vision api available australia east region please select another region computer vision api available australia southeast region please select another region computer vision api available brazil south region please select another region computer vision api available canada central region please select another region computer vision api available canada east region please select another region computer vision api available central india region please select another region computer vision api available north europe region please select another region computer vision api available germany central region please select another region computer vision api available germany northeast region please select another region computer vision api available japan east region please select another region computer vision api available japan west region please select another region computer vision api available korea central region please select another region computer vision api available korea south region please select another region computer vision api available south india region please select another region computer vision api available uk south region please select another region computer vision api available uk west region please select another region computer vision api available central us region please select another region computer vision api available east us region please select another region computer vision api available north central us region please select another region computer vision api available south central us region please select another region computer vision api available west us 2 region please select another region computer vision api available west india region please select another region stateoftheart cloudbased api provide developers access advance algorithms e rich information image categorise process visual data capabilities include image analytics tag recognition celebrities te e smart thumbnail generation please refer detail description operations emotion api face api language understand intelligent service api bing speechtote api bing tetospeech api bill per 1000 api transaction call production api call actively e bill prorate production api transaction call quantities bing long form speech api service bill per hour speech analyse bill prorate perminute basis recommendations api te analytics api purchase units standard tiers fi price unit tier come include quantities api transactions user e include quantities overages charge rate specify price table overages prorate service bill monthly basis include quantities tier reset month usage throttle transaction limit reach free tier customers accrue overages free tier usage standard tier e account start accrue overages overages bill monthly basis calculate rate specify tier api call e batch score call count transaction batch score call count base number items need score transaction usage throttle transaction limit reach free tier customers accrue overages free tier batch score support free tier recommendations api purchase units standard tiers fi price unit tier come include quantities api transactions user e include quantities overages charge rate specify price table overages prorate service bill monthly basis include quantities tier reset month bing search apis bing autosuggest api bing speller api bill monthly basis depend tier purchase include quantities transactions define api call include quantities always tie calendar month regardless start usage user e include quantities overages charge rate specify price table overages prorate service bill monthly basis include quantities tier reset month please visit request free trials may upgrade higher tier time bill rate include quantities correspond higher tier begin immediately estimate monthly cost x service review x price frequently ask question learn cognitive service review technical tutorials videos resources', 'get hard keep say blockchain everything space start refer distribute ledger ecosystem x blockchain service become diverse ecosystem host wide variety technologies open perhaps best describe current environment place partner put new platforms frameworks tool service curious customers discover e best way find well consensus protocol perform geographically distribute network x course right platform test wild idea distribute ledger technology without break bank pun intend x course go test particular platform functional nonfunctional requirements x course well enough update welcome several new partner decentralize prediction market platform build ethereum blockchain learn revolutionary decentralize platform like augur actually work watch narrate country singer shooter jennings simplify complex project global platform enable precise forecast topic politics commerce technology entertainment augur x businesses use prediction market forecast product launch date whether project fund sales number key metrics anything else like accurate information x augur offer turnkey solution enterprises interest run internal version platform company may want market public may want deal compliance cost run public market employees could even incentivized predict reward accurate forecasters internal e perk proud make announcement augur beta lisk aim revolutionize decentralize application blockchain technology power cryptocurrency lisk platform allow developers worldwide easily deploy custom blockchains program decentralize applications top use highly accessible program language javascript provide guide arm templates use lisk internet things custom blockchain deployment development decentralize applications want make e easy possible javascript developers use x x cloud platform blockchain financial service platform couple everything github available smartcoin pricestable digital asset peg value various currencies commodities stock financial instrument within derivatives market accomplish source price information world financial market publish blockchain inform decentralize asset e market make asset pair therein serialize order book mitigate frontloading transaction throughput currently operate threesecond block interval peak thousands transaction per second bitshares accomplish speed maintain transaction identity security unique give syscoin suite blockchainenabled service provide merchants ability buy sell goods service encrypt message escrow digital asset storage resell syscoin also provide replacement typical blockchain address know aliases provide easeofuse goal syscoin integrate major centralize marketplace ecommerce platforms help ease merchants transition centralize marketplace solutions decentralize blockchainbased marketplaces lower cost better reliability much higher level redundancy slockit aim address security identity coordination privacy billions devices part collaborative economy allow object rent sell share securely without middlemen integration x x make easy developers build apps slockit first product ethereum computer apps build x compute cloud deploy without modifications ethereum computer make x cloud perfect environment e slockit deploy slockit x also mean simplify valuable integration business analytics data management identity message physical access control automate decentralize slockit app x integration do part incremental transition toward decentralization waive need call e integrator spend months e costly pocs look forward e couple weeks x conferences right around corner', 'thrill toronto week wpc 16000 attendees events one favorite part job get talk many people incredible opportunity customers partner industry digitally transform respective business conversations hear consistently partner cloud provide opportunity customers agile derive intelligence improve business deliver apps businesses need e share today new program innovations across enterprise cloud portfolio help partner achieve even customers importantly e share customers already change world x cloud intelligence deliver power untapped data combine scalability speed cloud mindblowing incredible e company transform live millions people nigeria partner x lagos state electricity board provide reliable solar power 170 school clinics use x iot suite cortana intelligence monitor diagnose power usage predict better prevent outages e valuable energy past sundown school clinics operate around clock provide valuable medical care learn opportunities understand e weather important us personally business consider profound impact market demand different products operations mobile phone increase demand uptotheminute weather forecast two million four billion request day online weather service partner x build solutions turn data three billion locations around world actionable intelligence customers need weather forecast realtime x cloud speed fle respond effectively 15 billion service request day accuweather continue digital transformation company e partnership us streamline broader scope business operations make customer e even better see stories cloud deliver amaze change know journey get happen overnight customers need fle move cloud term partner need solutions e help get today make cloud benefit even accessible first way enhance data service portfolio today generally available bring true cloud elasticity data warehouse save time money e customers already see benefit service learn data service like sql data warehouse integral analytics switch aws redshift migrate 7tb uncompress data week ne thrill share new operate system provide customers clear path cloud launch ignite new version industryleading os know trust feature new innovations like windows server hyperv containers nano server new security feature give platform build run cloudnative apps mission critical apps know want learn x stack work bring new hybrid cloud platform want share update able get share today work us deliver preconfigured x stack integrate systems deliver x service datacenter customers cloud speed hard work things work prioritize deliver x stack customers via systems launch e mid2017 apps business differentiators days culture shift require across people process technology create get use apps drive value empower partner help customers shift application culture announce transformation application lifecycle management alm partner program design help company deliver quality apps x enterprise scale e readiness program sales coverage partner everything need enable app transformation also launch help partner customers easily find use cloud solutions need get cloud applications run faster partner customers canada new datacenter regions toronto quebec city alongside alreadyavailable x office 365 x announce 34 x regions globally 26 generally available major cloud provider update come top new innovations deliver intelligent enterprise apps business users new destination businesses get lineofbusiness saas apps x partner introduce simplify intuitive approach business apps rich data visualization natively deliver power bi embed generally available also share x powerapps x flow help customers compose new business process easily e modify e systems meet change need new preview enable customers drive accurate outcomes wide variety business problems wpc look forward talk hear help transform business take advantage many opportunities cloud home follow action', 'run one largest cloud world x gain lot insight build manage global high performance highly available secure network e teach us hundreds datacenters tens thousands switch need address requirements x pioneer software open network cloud sonic breakthrough network switch operations management x opensourced innovation community make available sonic uniquely e platform large grow ecosystem hardware software partner offer multiple switch platforms various software components sonic build define standardize api network hardware vendors use develop innovative hardware platforms achieve great speed keep program interface asic applicationspecific integrate circuit consistent x open source sai 2015 approach enable operators take advantage rapid innovation silicon cpu power port density optics speed preserve investment one unify software solution across multiple platforms sonic first solution break monolithic switch software multiple components sonic enable finegrained failure recovery inservice upgrade zero downtime conjunction service take advantage open source keyvalue pair store manage switch state requirements drive switch toward goal state instead replace entire switch image bug fix upgrade flaw container new code include protocols without data plane downtime capability key element serviceability scalability sonic platform containerization also enable sonic e e core sonic aim cloud network scenarios simplicity manage scale highest priority operators plug new components thirdparty proprietary open source software minimum effort tailor sonic specific scenarios monitor diagnostic capabilities also key largescale network management x continuously innovate areas early detection failure fault correlation automate recovery mechanisms without human intervention innovations available sonic represent culmination years operations e sonic sai gain wide industry support last year major network chip vendors support sai flagship asics community actively add new e advance capabilities sai release open compute project yous summit 2017 demonstrate 100gigabits switch multiple switch hardware company sonic enable latest fastest skus platforms support sonic sonic cloud community choices cherry pick bestofbreed solutions partner join ecosystem make richer work community partner ecosystem look revolutionize network today future available industrial collaborators researchers students innovators alike sonic containerize approach software simulation tool developers e switch software use x x one world largest cloud platforms contribute components benefit millions customers sonic benefit entire cloud community e increasingly strong partner momentum behind platform read post series please visit', 'celebration citigroup 200th anniversary share stories rich history blog 28th installation cover technological advance the1980s improve bank process customer service major advance compute database management telecommunications late 1980s early 1990s change bank forever big technological thing online interactive compute recall john reed batch compute common 1970s 1980s 1990s get online interactive compute internet different version technology become e important world today use online interactions financial institutions market change back office organizational term interaction customers technological change big database management allow manage databases differently give information didnt global telecommunications 1980s the1990s international telephone call become easy 1970s struggle late 1980s difficulties e savingsandloan institutions provide citicorp opportunity make acquisitions e domestic branch coverage outside new york use new network take lead position early form virtual bank point john reed move away idea physical distribution compel make strategic bet horizon virtual distribution would outpace physical distribution say steven freiberg later head global card business lot e innovation standpoint smart phone things nature try find ways distribute would unlock us high cost associate traditional physical presence one point citicorp team matsushita electric industrial co japanese company behind national panasonic brand e bank via smallscreen devices could attach telephone john push us path leverage technology 1970s freiberg recall may early huge penetration pcs internet everything dialup low band speed hard lot seed today yous overseas limit distribution sow back late 1970s 1980s tag must accept site usage rule post comment view comment discussion accept first comment register sign disqus comment moderate appear editor approve work back office nyc branch network time e time career advancements make every quarter john lead us innovate afraid try something e change customer time people say get cash sidewalk never ahead time credit card chip debit money account wow didnt work time years later debit card bear many innovations proud citibanker still proud association heady time one never forget reason skeptical future future despite customer account good stand nearly five years people see fit deny credit card actually temerity uselessly ding credit history sure move money bank credit union actually care members course since see comment moderate dont e comment site please accept site usage rule view recent comment discussion', 'tag must accept site usage rule post comment view comment discussion accept first comment register sign disqus comment moderate appear editor approve stop use city bank credit card difficult increase credit line without ssn yous many international students ssn issue college credit card credit line limit 1000 however x much fle international students will allow international students issue type credit card increase credit line depend spend several friends switch credit card main bank x boa know international students usually spend lot money study hope x bank come new strategical idea attract international students make satisfy thank get chip make sure compatible euro standard also denmark germany uk others like 1970 magnetic strip thank harry cancel x credit card erroneous charge place account x customer service team unwilling deal credit score perfect past 70 years association hilton hotels harmonious always log website try pay bill line site kick three service charge use x card outside us really punish fee would nice lower post comment concern treat new x e aadvantage world mastercard carry currently seven x card yet one take time contact past question citi good take care make sure prefer customers happy never contact misinform promotional bonus never close x card perfect pay full history one care help lower interest rate credit card 19 outrageous contact 8008426595 bill trouble set online account access point new account individual speak keep hold twice say would email username password immediately receive information last two days check recent spam please help x need make change credit card policies online purchase make travel x withhold payment online purchase make london london tour know locations date would travel speak customer service fraud protect say 1 x e users swipe card travel 2 travel users must call x make online purchase avoid denial payment freeze x card another customer rep research problem tell popup block turn online purchase allow x confirm purchaser authorize reaffirm x card would freeze well payment withhold base single online purchase x card user travel devastate traveler depend tool policies seem like small provincial bank x 21st century complete ta learn ta redeem thank point never disclose thank x please updatesimplify user interface design x card users right stand horrible clutter point hate even log 65 recently lose husband pull x card want use read lot high annual rate annual rate citibank mastercard 20 years typically pay every month recently citibank switch paperless bill without consent knowledge cause late payment supposedly resolve receive paper bill receive ne bill consequently late make payment customer 20 years credit limit 10000 think good payment history shut card 31 days balance payment due balance 5060 advance notice choose consciously business business e attitude toward longterm customers share opinion opportunity arise annual high intrest rate decrease credit without inform cardholder enable virtual card number hilton honor visa link post webpage log account click link message service available phone customer service confirm available available available x attmc close prematurely believe service hh visa valuable service use confidence regret close x attmc since x hilton honor visa offer service plan enable virtual card number future hilton honor visa kind regard bob pls drop 3 foreign transaction fee reason lengthy space stop use credit card shame x card since 1999 sit watch loyal customers leave quite glad annual fee quite high would like see strip go start use chip soon possible overseas charge 3 drop lower years credit card ten years free please remove foreigntransaction fee able use flyer miles least 4 years kinds point get reservations book months advance change card thank share comment question encourage hear feedback improvements know e satisfactory work ahead meet need question relate account member customer service team reach via phone email already also encourage contact us anytime 18009505114 let us know address concern member since 88 interest way high e credit rat choose use card disappoint point get since past november account seem get correct orientation service set get free point appreciate time take let us know meet e sincerely apologize business important us continue improve service someone contact shortly address concern directly would like use virtual account number could find x card interest rate high use card lowest interest rate available please get rid magnetic strip old technology help protect us identity theft annual fee two high use x card travel overseas 3 service charge would like x make app blackberry os10 blackberry z10 thank x guy please change add foreigntransaction fee x aadvantage platinum already reason use capital one instead guy travel abroad travel lot please consider know speak millions thank see advantage use driver x card advise could use reward service car inform longer true market purchase car reward use credit card give reward cash offer representative courteous helpful help understand account compromise would use card interest rate competitive 199 high compare card 724129 range add fact customer 14 years near e credit rat would hop view better customer give better rat citibank dividend mastercard rotate categories earn 5 complaint card categories would like see amount need accumulate get reward drop current 50 25 seem standard especially compare discover card chase freedom would use card often even base 1 purchase reward right take long earn reach 50 thank attention te blog anything pull account check see unusual activity happen pay bill many fancy things lot people really want keep simple somehow stay time pay bill happy also apps whatever yep older necessarily dumber keep simple send email request mobile app must someone else main reason prefer well fargo card reward system x get discount still pay partial amount wf get free kindle leather cover free delivery point would rather build point know x card please cancel wish reward would give 5 percent everything would use x card use card europe would much easier safer chip might e always impress x corp versus competition irritations competition little consideration customer go new card iwth chip anytime soon okay jud get citicard chip pin us card issuers technologically backward everyone europe use chip pin chip signature ever travel deal pain chip pin receive email say apply mobile app allow access account remotely place order virtual credit card number one best ways ever come along reduce fraudulent charge ruin couple months ago make necessary customer obtain authorization number time virtual card generate get number colossal hassle stop use x card virtual transactions intention succeed punish unwanted behavior e see enhance master card new chip swipe technology mastercard go way offer chip pin one day may unman fuel station new zealand mastercard work need pin kiosk paris get train 11 night reason usaa offer card mastercard thank michael burnett one events happen pin common europe loyal citibank customer since 2007 problem choose ignore loyal blackberry users years lot people still use security feature everyone fall iphoneandroid camp ask blackberry app since 2007 use normal citibank site look feel good accommodate us blackberry fan still wait resolution bonus point credit last paymenti write twice still credit get do thank carey thank make card secure would rather notify question charge account find card use unauthorized thank city bank customer many years happy city bank keep good work ceo jud like speak e customer service care listen contact travel e never use card chip pin use atm pay cash also usa need join 20th century sorry jean ever since start use new app take long time load account problem upgrade 10 minutes blog thing arrive speak citibank representative unable get ebills citicard business account send bank assume reason citibank want right go check account take whatever amount determine owe profitable allow get ebills send bank boa determine much want pay month furthermore sure give check info every bank vendor want dip money sooner later would serious problem hand hacker hit quite clear citibank far concern squeeze every penny profit customers customers fact earn miles aa use citicard would cut half wink eye go elsewhere card available chip like ones use europe happy citicards mastercard originally get great cashback bonus 5 gas purchses rotate 5 bonus categories purchase give back 5 limit almost useless make things worse allow cash cashback bonus 50 high level reason rarely use citicards mastercard prefer use cashback credit card offer much better broader cashback bonus categories rule make app windows phone like x post pending activity see hotel everyday charge go ahead post amount charge prefer mobile app available account opt never use phone mobile device account info want available desktop since open account never understand reward money 5000 send earn use x card see retrieve jud citicard user would like say thank become citicard memeber partly due research partly due necessity graduate college 2011 discover someone take fraudulent loan name since fight name take loan success spend many hours phone send numerous document loan company attempt prove knowledge fraudulent loan financial burden pay actual student loan fraudulent loan time overwhelm get research apply citicard felt best situation felt would protect identity theft important live budget citicard help tight spot whether une e buy groceries like many worry money citicard give relief say thank alex new app visually attractive clearly container web page native app performance app show fact two three versions ago x develop ios app native app significantly better screen responsive button look felt like rest system e fit better rest user e mobile please consider make ne version x mobile app truly native app series web page thank e service well organize card bank use x card years charge international transactions receive 2 credit back transactions bank love improvements mobile applications really need see travel perspective chip pin integration really want bonus point section back enjoy look list sit could earn one point per dollar purchase new program real disappointment e point gas din etc things charge reason choose card program go negative see website would like information post account happen least ne day like purchase credit card friday e post tuesday virtual number available nonwebsite purchase use account offer good deal balance transfer would balance transfer consolidate debt 18 month 0 interest rate available every time call offer available account thus use account need post ask feedback think would provide would like pay account full please nice good person call call nobody want work stay competitive need match e amex blue reward card charge yearly fee 75 offer 6 cash back groceries 3 cash back gasoline purchase year x card member many years one card truly love never time x card brush insensitive concern issue make feel like important customer admire professionalism interest rate platinum card e attempt number time request voluntary reduction rate avail longstanding customer goodstanding essentially subsidize less qualify customers show loyalty hi e service result x would recommend anyone thank jim appreciate change upates make would love keep old items atm also sure take option send receipt email away great option save lot print paper paper trail remove complain please reinstate thank develop competitive reward program american airlines citibank card use card e purchase like accumulate travel miles american last two years nightmare try use many miles acquire flight available additional fee etc realize fault citibank use card go give anything return use another card give us triple aaa benefit far less hassle try utilize accumulate point think would let know wish would offer cash refund credit instead point toward purchase never use point unless cash credit card offer suit many people would use credit card interest rate high mine suspend use citicard mastercard begin use another bank card two months succession payment mail take five business days post receive email alert january payment post monday jan 20 go account notice payment actually post friday jan 17 sloppy payment process accept payment process improve may return love ese use new app ability set te alert payments late able use x aadvantage mastercard travel europe format tell could get chip pin card replace current credit card apply andrews federal credit union chip pin visa card x aadvantage card upgrade chip pin ask use card lately answer credit line low apr high prefer use card high credit limit 0 apr like mobile app new atms accept deposit check simply really need improve take 1000 ceiling mobile check deposit ally bank limit change would save trip two nearest atm locate conveniently near thank please increase mobile deposit limit card do 5 cash back gas groceries restaurants drug store yearthat use card fix web site go balance transfer either say website available want sign thank recall ask fi terrible easy deal actually use point believe good idea mobile devices least safe relatively easy get hold private info appreciate effort facilitate access account respond people wish however necessarily safest would like see 0 fee balance transfer prefer spanish speak english hi pretty happy service citi one request use lumia 1020 see x app windows store bank account well fargo chase windows apps access account phone case x would happy could launch windows app soon thank vijay acct husband primary holder speak phone answer email reason think equal owners account thank apps definitely great quick access account information would nice least top three platforms supportedany progress bring app x customers windows phone mobile app access 1800 point find useless promotional advertise give point make customers point feel like get something money spend get point many point spend lifetime grocery store hack problem ask x change card number change wee start problems account card partially block still know right every portal information e one opportunity subvert consider good thing order help prevent deter incidents like recent target hack need x lead industry secure card one computer chip though perfect design greatly improve security technology robust use europe many years long something like come pass hopefully ne huge hack calamity use x card card lower interest rat use card lately due fact get much better reward another card give e cash back purchase always use ie gas groceries citibank give e cash back categories rarely use wonder use x card well basically rat card offer low purchase rat time period also low transfer rat x use card would help greatly process dispute charge e better middle try fix error fault least begin nightmare far love citi guy awesome good job think great citicard go eliminate foreign transaction fee message make senseinfo rebate bunch letter appriciate service lose love wish better others fraud monitor service call occasion find reasurring virtual number lose love start use mid 90s card use someone overseas use real card person every transaction virtual actually choose stay aa citicard vn one else offer carry one credit card virtual number change make difficult use ipad user friendly dowloadable pc version matter security concious card chip pic use signature front offer anymore wonder improve te notification feature send anytime transaction make account would nice get balance satisfy would like better user e look statement month think info x include statement include final date payment defer charge helpful budget chairman lenville would really helpful allow e cardholders good stand upgrade awardspoints type card similar amex chase ink card without undergo new credit report check travel lot internationally opt use citibank mastercard 3 foreign transaction fee use card website fine use citicard drastically reduce value reward program 1 point reward continue credit one percent card charge plus bonus category point award however 1 point formerly redeemable 1 cent cash award value reduce appro 38 significant difference one cause use credit card rather x please advise restore value x reward point solicitation quite number weeks ago switch card new one embed chip legit wait weeks get nothing arrive yet keep good lookout activities card away home mail hold touch via email maybe wait us return barb mr linville really read say read comment people complaints citibank offer reward 10 discount store joke get higher discount store senior citizen fact 3000 never use plan furthermore use credit card interest mobile apps young people things ones depend parent purchase need read really want view listen customers ought implement improvements occasion first communication hear long time complain number time perform e key stroke site efforts get something want eg want paperless statements time yet get ask website sign try pay bill spend time energy nav site bring screen want see bring screen associate button click pain neck waste time please button customer click want get paperless statements bring sign page click button thank consideration sure many others speak please listen thx stop use card reduce credit limit 17500 4500 dispute issuer another credit card dispute base change term card violation original contract consumer protection statutes case receive money however consider good faith dispute connection another credit card company reason reduce credit limit 500 even enough buy airline ticket want consider use citicard anything one starbucks year restore former credit limit app windows phone windows phone last 2 years fastest grow os business disappoint card holder 6 years first time go europe foreign transaction fee go capital one new cardthat fee bull yet totally change would like see go away stvev x card app would nice able see past future payments make change rather go online go x mobile app windows phone platform offer lower rate options balance transfer rate 99 plus 5 fee equal 66 equivalent rate high compare offer new apps appreciate however lower interest charge would bigger positive impact print last four digits account number email know use whole acct generate email absolutely reason publish part number high risk environment interest rate high reward program useless thousands point use e point time discount say gift card end spend money 90 gift card credit card end give back 10 think save let us spend point ever available without purchase interest rate high balance transfer fee high usually pay 1 2 3 5 transfer vacation every year puerto vallarta mx review card continue use 3 foreign transaction fee introduce scissor garbage account get close x since 1998 always treat well balance transfer last six month since become ceo thing change get good rat balance transfer bank well always go bank like x 0 2 fee x 0 5 never case x would rate always better bank sorry write many x always best thank need competitive card instance 1 12 purchase 2 groceries 3 gasoline would nice know different categories get 5 begin year customer years compare mode really think x card great reward come handy help family alot glad card x 20years great service keep good work comment cover x dividend master cardi would use card much dollar threshold redemption earn cash back lower minimumr edemption 50 cash use x card much lower redemption threshold give 2 back grocery store purchase give additional bonus redeem straight x deposit account folks go competitive b chase better card use use obviously listen well friday close branch near home closest branch minimum without traffic 42 minutes away pretty much make even think close account instead ask would make use x card honest concern close account bigger concern find new bank move money use credit card would like repayments 2000 per mo increase good imo thank things enhance e thank point already service fine competitive thank point bank data security everyone guide concern nowadays appreicate x efforts stay inform always research ways make data secure information private constant challenge issue citicard citicard since 1979 numerous time request interest rate reduce time refuse yet citicard will let new account holders transfer balance low interest rate month pay payments time yet min balance increase decrease curtail use citicard tranfer balance another bank would hesitate without give second think loyality citicard write find nothing wrong use card however differant card differant bank sour reward program take advantage thier offer ask certain gift card receive correct dollar amount differant type card bank question mean place correct error know eventually straighten great hassle lesson learn forget gift take cash reward sorry put citibank pot one competitors choice one great bank set correct errors may another great bank duh rat ridiculously high get better term loan shark clear enough first let note x customer years 2008 present start use x bank credit card issuer back 1970 people seem consider long relationship reason use x card currently lie two areas 1 reward card give add benefit higher rat rebate 2 service problem level response less make comfortable plan close relationship value longevity use x backup response follow dear robert hoffmann notice awhile since last use card would like hear gain better understand areas need focus improve many great suggestions cardmembers like let share recent improvement x card new x mobile app account information yo work windows phone 8 app interest lower interest rate oppose mobile 24hour accessibility reward program card worth effort appreciate everything live denton te zip code 76201 citibank around 7 eleven store atm drive 20 min hour away find citibank possible small bank denton te thank hi please also support windows phone thank pedro use card quite awhile outrageous interest rate currently use different card rate less half still benefit order x card christmas never receive get email say give correct address go keep 29 percent payment return rest idea return please service want thank reward would rather incentives use dividend card thing want dollars would nice would consider lower interest rate use card much get better reward elsewhere easily determine many point get purchase various categories want know would make simple find conclude proud reward like simple cash back work advertise denominate dollars ever changable point happy bank soon look account thank ask many time cash reward way get want bank give cash reward deduction get cash reward windows phone user would love guy could offer windows phone app loyal card key reason hold card double point flight miles purchase card tell change policy flight miles extremely dissappointing please something loyal customer rather switch hard justify card pay annual fee get benefit longer e vasu x bank thankyou world mastercard get chip signature credit card work perfectly usa europe reject many place specially train station require chip pin credit card know card still possible get us financial institutions lot americans travel europe let us decide payment apply want portion payment apply promotional balance able also show info ie e balance remain promo balance would helpful great wish get many point get gift card get something great still love citibank death would trade world 15 years loyalty guy great keep good work go put picture credit card use stop great way prevent unauthorized use card nothing confidential see nsa love fox news fox radio use card right interest rate way high would like gas card bring back options buy thank point value alternatively statement credit onetoone point chase offer chase freedom chase saffire credit card thank wish reward program simpler want earn point apply towards cash reward interest accumulate point merely give discount items interest would encourage put picture back credit card include thank card aadvantage credit card picture card serve id let us retailer know say always say thank verify identity dear mr linville please stop send email include email security zone box top list full name last 4 digits card date original membership understand idiocy hand security information insecure email format hackers believe company stupid especially many us cancel old card get new ones target debacle stop send email force cancel account altogether web would nice balance stand payments list manage account concern message state many great suggestions cardmembers like gain better understand areas need focus improve suggest anything bring discrepancy thank point account joann love resent make purchase 11300 would like use thank point like talk live person member since 1987 never problems always need help job well do say anything else use system damn complicate please give better reward pay use point would like able view purchase certain time period ability american e extremely helpful small business owner need see purchase begin month till end month base statement date hi jud thank update two things clear email web site offer 2x higher bonuses new categories drugstores utilities also redemption thank point statement credit 11 basis word every thank point earn give 1 credit back statement thank clarification provide none would nice could combine reward point x card please let know purchase items line like concert ticket goods may apply reward point time purchase sure conduct sophisticate market research design feature reward program however wife stop use x card one reason prefer simple program pay highest reward without think whether month quarter whatever bonus available gas station whatever live busy complicate want mess may atypical old spend quite lot money make credit card usage decisions base seem best us simple pay highest reward thank ask three credit account citicard two point reward program truly think program waste time bandwidth 9000 point card never use cost items within store ridiculously overprice also never win auction scam convert point cash gift card something use point time point never spend never use card however continue use platinum cash back card least cash 5000 much say say like e isef receive email ask use card temporarily live turkey employment provide new card international chip permanent address usa new card could send quite simple really lower interest rat look low rate balance transfer kind offer time account hack talk one people result try sign account try enter user name letter appear would appreciate could reintroduce gas card thank point categories please let know sincerely patel thank mr linville good news love x card use regularly good interest rat years use card never run problem representatives resolve love way company business keep use x card always take opportunity recommend family friends x card far opinion best business wish would reinstitute sunoco gas gift card really love use convenient x card almost pay back contact account name another x card tell identity theft get x card take 300 account months months tune 8000 almost 72 need retire pay bill make think unfair say protect recently receive email wonder use x reward card frankly would rather use credit card give back cash reward also x dividends card along card use card give cash back right bank america card hope answer question make easier get statement credit cash reward nonintuitive problematic require much search various web page frustrate problems x card ask thing ask leave alone 50 elligable glad hear x group best protect customers customer use credit debit card time x provide customer annual account summary help track e believe service helpful bring better relationship x customer time believe x increase royal customers interest rate card 30 use e credit card higher rate card limit number restaurants eat use card every time take uncle since options restaurants apparently qualify thank jud would like make additional recommendations please launch transfer partner x thankyou like hilton hhonors would love see american aadvantage airline transfer options would also love x launch card paypass builtin plastic card hate e mobile phone tag sticker finally please offer separate acct number authorize users andor distinguish charge base make statement want cardmembers add users additional spend make e painful separate charge thank jud look forward future x enhancements really care keep long term clients like email tell treat bank comment sound good wait implement change use cash reward available eliminate use reward reduce balance apply never appear security delay e hospital park garage 20 minutes 4 time time use another reliable credit card find fact email security issue appreciate first time use card hospital park lot use almost 3 months garage start block without notice garage office take put trust card another tem might mention courtesy agents use purpose reward reduce balance utmost courtesy deal phone treat like customer need 0 options transfer account x card use reward travelers give higher reward eat entertainment purchase airline ticket recently 1300 well two overseas tour plus everyday purchase use card give 1 12 x card give 1 problem card much hassle switch quarter quarter rather something permanent count get reductions point redemptions pain ass time waste unless cash loyal supporter mastercard 36 yrs e good bad reach final product e come long way baby transistion believe guy e loyal customers 20yrs appreciate verbal recognition service personnel fall short avenues need avail designate point customers 2025303540yrs folks thick thin growth years reward request pension surly better change great options get gas gift card point x card since 1999 call number time see could get interest rate lower always get oh interest people want never miss payment lowere use card din entertainment 2 back everyday purchase cecilia realize computer world hard understand 15 million yous house hold access type wire internet wi fi dial service best 288k satellite almost twice fast 46k put anything web site move talk freeze computer boot please bear mind one size fit thank use citicard year e cash point realize receive one half cent per point back bac card pay one percent addons plus bac card much higher limit ps like annual statement would like suggest improvement online travel thank point website air travel impossible instead pick flight view 4050 different round trip options ridiculous always call find flight scenario need go southwests website see mean site view available flight pick flight flight want x fix e frustrate fact charge things southwest card reason find objectionable x spend much time items improve user e time continually remove valuable benefit customers e flight miles longer count point recently x eliminate retailer portal customers could take advantage offer earn e point shop specific retailers x card many years every year get less appeal benefit take away replace hollow talk point toward benefit provide differentiation use card reward offer way e could get direct useless discover card service give credit score statement e charge x card consider benefit members free charge course would like know e warranties items purchase like discover card add ever original warranty time actually double warranty one reason use discover card switch card thank first sign thank card two years ago tell would annual fee great sell point probably sign card otherwise mention get promotional rate first year free would charge fee start second year surprise charge annual fee card renew months ago sure always case would charge fee two years policy change x part however think bite deceptive citibank charge fee inform annual fee either sort write notification notification appear monthly statement would problem inform ahead time annual charge would assess customer focus show much integrity ask lower competitive interest rate request fell deaf ears since card attractive term use instead x card put customers picture card know cashier look signature think least help little ways future security recently lose wallet reality hit please accept site usage rule view recent comment discussion', 'affordable plentiful energy cornerstone modern industry economic development yet across much africa remain desperately short supply people live subsaharan africa lack access electricity africa power problem cut right across society solve would benefit millions africans depend unhealthy often unsafe e alternatives electricity light cook heat improve electricity supply would also spur small business development create job help improve public service enable continent realize broader industrial economic potential prize huge finance build necessary energy infrastructure challenge power africa initiative come x play important role first ever yous africa leaders summit august 2014 washington dc x announce formal partnership usaid yous governmentled power plan increase access reliability sustainability electricity supply africa power africa initiative target investments energy infrastructure policy regulatory reform institutional capacity build subsaharan africa currently financial commitments private sector world bank public sector partner amount stakeholders power africa initiative include yous government also governments several african countries multinational company local public private sector enterprises initiative focus initial set six partner countries first phase ethiopia ghana kenya liberia nigeria tanzania power project already underway last week convene bring together delegation african stakeholders minister energy minister finance head utilities regulatory body meet yous investors discuss grow opportunities power sector across continent together colleagues glad attend summit reinforce citi commitment facilitate infrastructure development support public private sector clients africa believe increase awareness greater involvement private sector help drive important initiative forward look summit continuation recognition commitment many stakeholders make difference africa tag must accept site usage rule post comment view comment discussion accept first comment register sign disqus comment moderate appear editor approve', 'year mark third annual digital money symposium host x imperial college london london city hall together colleagues glad welcome 170 delegate e progress advance digital money agenda associate benefit indeed challenge digital money hold promise significant benefit businesses well public sector provide efficiency gain lower cost cash handle also provide significant gain play pivotal role evolve digital money ecosystem year symposium entitle far afield near field stories progress open jamie forese copresident x ceo institutional clients group speech jamie outline innovative technologies challenge traditional industries ways work symposium provide platform industry leaders discuss awareness readiness adoption digital money across multiple sectors understand opportunity reap benefit businesses must tailor strategies state readiness within market operate agenda feature presentations x business lead well e think leaders space full list speakers topics video highlight please visit another e development conference launch index provide 90market perspective digital money readiness benefit digital money adoption governments businesses consumers addition companion research report entitle release report e industries invest digital money journey worth take benefit digital money adoption undeniable important remember onesizefitsall approach increase adoption across market factor market maturity consumer demand corporate capabilities factor success individual market partnership essential opportunity magnitude see convergence commercial economic social policy goals rare truly deliver recognise offer set core attribute advantageous different stag digital money readiness single player alone tag must accept site usage rule post comment view comment discussion accept first comment register sign disqus comment moderate appear editor approve', 'saturday june 11 join tens thousands colleagues along friends families celebrate x 11th annual past decade mark annual day service around world donate time skills e make difference communities live work year together community partner stand progress help tackle range press challenge cities beautify park streets teach young people basics financial knowhow help communities bounce back natural disasters since inaugural global community day 2006 half million x volunteer contribute three million hours service global community day project hundreds cities truly become tradition citi statistics help tell big part story positive impact individuals communities participate community activities also see deeper level tangible result global community day 100 x volunteer red cross new york city make care package veterans military service members overseas also make card hand write note thank service least could give back others sacrifice much us many us stories service tell highlight ask x volunteer share global community day impact communities global volunteer effort demonstration commitment progress cities lie heart x volunteer citi short global community day yearround commitment volunteerism enable us succeed serve individuals communities institutions cities around world wait get june 11 tag must accept site usage rule post comment view comment discussion accept first comment register sign disqus comment moderate appear editor approve', 'enable thousands professionals positively impact high school students e imentor start receive x email call volunteer know something need always want make longterm mentor commitment conscious make sure could uphold end bargain imentor conducive someone like full schedule necessarily commit meet person weekly basis imentors task write one thoughtful email week mentees attend twohour session month even mentee high school find thus far continue engagements truly help mold young person life better enable achieve success mentee 9 grade boy name luis live bronx new york city attend high school manhattan first meet high school cafeteria play way eat pizza together talk respective live families goals program luis fairly shy quiet yet serious study interest technology though bank lawyer little knowledge technology know could help stay focus consider new possibilities go high school focus college application process 9 graders luis school must attend class teach imentor counselor deliver weekly prompt compose email mentor receive email like clockwork wednesday morning prompt ask answer several question luis would respond 2 3 sentence first start work together initial goal luis help improve write email risk sound like lecture stress make good impression scenario job application communicate business role must able write email well receive luis email respond even within days answer much longer email respond message answer mentor prompt go beyond order establish rapport luis program 7 months report luis consider friend mentor luis e like hear instead prompt use email update life ask report subject things life get start look forward mentor full four years high school see succeed college learn still lot give young people even 55yearold lawyer like never nyc high school open eye succeed kid take pride know whatever time give assist luis serve well find direction make full effort reach current long term goals grateful opportunity become available x foundation initiative thank x foundation introduce imentor program support tag must accept site usage rule post comment view comment discussion accept first comment register sign disqus comment moderate appear editor approve', 'x success lie ability deliver customers clients also serve trust partner invest longterm mutuallybeneficial relationships one e relationship unify government wyandotte county kansas city kansas span almost two decades relationship begin late 1990s successful development kansas speedway include development village west shop area professional soccer stadium recently professional soccer train development center director public finance banker x municipal securities division proud opportunity play role raise finance project make kansas city kansas western wyandotte county destinations today begin work together late 1990s unify government look ways spur economic development region decide partner international speedway corporation turn e land race track facilitate development unify government engage x structure underwrite sales tax revenue bond star bond finance construction 75000 seat kansas speedway innovative time bond structure rely sales tax revenues generate within project area make principal interest payments construction begin may 1999 2001 kansas speedway open inaugural race season kansas speedway bring fan area another economic development project aid star bond open shortly thereafter village west entertainment retail district currently showcases 100 businesses open shoppers 2002 village west provide area residents visitors easy access restaurants hotels shop success village west sales tax revenues generate businesses enable development finance additional project one opportunity present 2010 local professional soccer team look build socceroriented stadium greater kansas city area seek financial assistance local governments ultimately unify government partner capital project build 18000 seat soccer stadium village west serve home team give success businesses village west shop area unify government consider issue star bond raise fund necessary project give prior e unify government star bond knowledge community understand investor market unify government engage us structure underwrite new star bond soccer stadium unify government partnership team development finance soccer stadium succeed generate additional employment bring vibrancy community x team incredibly proud relationship unify government work accomplish together please able say past 17 years x underwrite 700 million bond community together unify government wyandotte county kansas city kansas contribute development attractive destination sport shop entertainment tag must accept site usage rule post comment view comment discussion accept first comment register sign disqus comment moderate appear editor approve', 'business opportunity risk way strike rational balance two elements decisionmaking create diversity perspective work force get closer goal build diverse team compose people different e genders nationalities religions ethnicities economic background se orientations effectively harness diversity perspectives help us truly e realize full potential x offer colleagues clients know research need least 30 cohort women room voice hear commitment model way others demonstrate diverse genderbalanced leadership team better business outcomes business x private bank north america leadership team 38 women grow business yearoveryear past three years record highs e x women network program design improve opportunities women contribute greatly drive diversity agenda still much work say meaningfully increase female representation firm especially senior roles number action take help us make progress increase female representation senior roles help us become company choice talented women interest build career financial service industry also important e team lead way set tone top especially x women affinity group man woman lead collaboratively powerful need men actively engage conversation help design strategy need x leaders accountable achieve goals business leaders need keep actively inspire young women aspire senior leadership roles energize young women see unlimited potential personal professional growth pipeline leadership position e grow one primary goals prepare women rise senior leadership opportunities arise career paths successful reach goals total engagement every level organization e majority senior managers men go take leadership genders help us advance diversity goals leadership team broad commitment drive diversity clarify degree diversity critical overall achievement financial target build culture make us respect company industry important bank clients corporate world since 1984 live many interest challenge e often woman room time learn use humor try always authentic self focus meet e business goals long term build credibility persevere x women hope take great foundational work do since 2006 create positive measurable impact support women create better balance leadership team x mission growth progress ask us become individually collectively model powerful global company maintain strong unwavering focus diversity inclusion mean achieve business goals', 'citi leaders employees partner enable growth economic progress clients communities around world result citifx pro forex trader survey 2010 reveal week show half traders survey employ combination fundamental technical strategies make decisions survey release october 2010 study fx traders work environments information source technology preferences find focus entirely fx asset class citi join bank manhattan coalition financial institutions nonprofits work together make easier lowincome people open traditional bank account help achieve goal citi eight participate bank offer basic check account waive monthly minimum balance requirements charge low maintenance fee feature minimize potential overdrafts bank manhattan initiative lead manhattan borough president scott stringer target estimate 95000 unbanked households borough rely alternative financial service providers checkcashing windows manage money research pew safe bank opportunities project pew charitable trust office manhattan borough president find families spend average 530 per year nonbank institutions pay bill cash payroll check buy money order reach three month mark citi already see whirlwind change since join citi see new leaders sign run card consumer bank business well change single chief market officer across global organization since new citi landscape many may know passion work variety customer service roles within financial firm brief stint cable television business e right overall shift see customer service field company place much larger emphasis overall customer e top priority citi everyone within company key driver join citi late october provide insight efforts improve customer e report positive momentum include uptick citi net promoter score bob annibale global director citi microfinance community development recently share observations trend microfinance keynote speaker columbia business school address outline citi foundation longstanding philanthropic support microfinance sector also discuss strategy underlie citi microfinance launch 2005 business serve microfinance institutions mfis clients partner annibale tell audience work across citi businesses product group geographies citi microfinance serve 100 mfis network investors clients 40 countries offer products service turn allow e access financial service underserved individual level include local currency finance hedge transaction service well development distribution save remittances insurance products refer economist develop concepts microcredit microfinance annibale say f muhammad yunus banker poor banker banker poor x name best global private bank organize two publications judge look 350 institutions around world fourmonth period global private bank award winners demonstrate ability adapt business model new regulatory post financial crisis environment also evaluate business growth strategies portfolio management innovation client communication technology fee structure among factor winners announce award ceremony last week geneva november issue include piece citi transformation wake financial crisis focus restructure progress make towards sustain profitability read entire article money flow small businesses lowwealth lowincome yous communities 200 million communities work fund launch may citi calvert foundation opportunity finance network ofn fund channel resources small startup businesses via local lenders community development finance institutions cdfis track disburse 60 million year end create vital job support economic recovery 39 state washington dc among recipients disbursements selfhelp venture fund nonprofit provide finance consumer financial service technical support advocacy leave economic mainstream president bob schall say communities work fund loan help unlock additional 11 million fund enable selfhelp deploy 31 million total towards charter school lowincome neighborhoods renovations vacant inner city property new miuse development areas operate', 'x leaders employees partner enable growth economic progress clients communities around world year ago begin quest find answer two press entrepreneurial question really take entrepreneur successful take business owner best best conversations take across country speak business owners different industries stag business growth also participate numerous discussions many members run businesses aspire entrepreneurs e ideas support one another advice succeed small business owner distil learn conversations three cardinal financial rule entrepreneurs think one every three yous microbusinesses small local businesses intricately weave fabric communities economy hire single worker unite state could achieve full employment time country need small businesses play important role increase financial inclusion create livelihoods employment opportunities however launch one involve overcome many challenge entrepreneurship powerful impact critical help microbusinesses access capital businesssupport service grow hire build communities main street usa strong america 600 commercial corridors 300 vibrant neighborhoods new york city city neighborhoods offer unique small town feel go washington heights manhattan enjoy dominican din culture visit calle de colombia commonly know 82nd street jackson heights queen soak rugged shoreline feel van brunt street pier 41 red hook brooklyn unique character come unique challenge new york city department small business service sbs responsible strengthen new york city commercial corridors support small businesses entrepreneurs well neighborhood leaders five boroughs primarily network 67 business improvement district nyc business solutions center cant alone publicprivate partner like x invaluable help us achieve goals contributions private funders recently announce program offer 5000 small businesses impact superstorm sandy grant give small businesses badly need lift replace fall awning repair freezer buy new mi help get back feet coach world former miss junior america may seem like get successful smart witty almost boot career coach media personality twicepublished author jump fair share hoop could build platform say good well mutually e week live chat host live proof three years guillaume cofounderceo transform company second largest yous private sale site moms kid 5 million members also raise 35m fund totsy wildly successful sale site also reflect guillaume personal commitment social responsibility hear carbonneutral socially responsible flashsale company country ask week live chat host second game howes rookie professional football season run catch pass wall would break six rib tear countless muscle different dog determination finish game skip recommend surgery decide tough season unfortunately backup plan hadnt even finish college degree yet full arm cast wasnt hireable guy around rock bottom money career passion anything football crash sister couch months realize could write playbook today lewis one internet greatest entrepreneurial success stories far x wall street journal team name award give innovative city base combination judge popular vote new york city one three finalists title city year cofounder chief e officer prior found outbrain yaron cofounder svp quigo inc provider performancebased market solutions advertisers premium publishers outbrain provide personalize recommendations across network premium publishers outbrain allinone content discovery solution publishers brand marketers able amplify audience engagement drive traffic content site around web found 2006 company headquarter new york 15 offices globally tel aviv specifically israel large rare combination ingredients need spur innovation risktaking entrepreneurial culture describe wonderfully book startup nation provide great community innovators cluster together provide critical support network need spur innovation say trigger community like big chicken egg problem happen place world tel aviv one rare e top culture community tel aviv offer great network service providers support entrepreneurs vc lawyers accountants providers bankers etc etc many cities might great law firm brand name bank actually tune able support specific need early stage risktaking innovators lastly tel aviv great city live work sunny great beach vibrant city diverse community', 'x leaders employees partner enable growth economic progress clients communities around world accelerate economic development remain one top priorities mayors around country increase focus intentionally target socioeconomic issue income inequality seventyfive percent mayors highlight economic development 2016 state city address accord national league cities 22 percent look specifically provide greater support small businesses 17 percent mention businesses own women people color period polarize national politics citizens increasingly look mayors solve challenge get things do financial service institution focus cities x care deeply urban areas proud efforts initiative along x foundation program help cities manage growth thrive also know challenge face cities complex take input best practice public private nonprofit sectors successfully identify implement innovative solutions 18 months cities louisville nashville philadelphia work address toughest challenge impact fire abandon build low enrollment ta benefit homelessness issue unique city cities common goal provide quality service accessible citizens city collaborate city accelerator construct tailor strategies approach specific challenge along way also opportunity share obstacles learn cities many others across country benefit process ahead final city accelerator convene philadelphia july nashville mayor megan barry louisville mayor greg fischer philadelphia mayor jim kenney reflect change underway cities initiative help cities lay groundwork ensure cuttingedge efforts sustain third cohort city accelerator formally kick april 15th denver include four cities need finance improvements vital often overlook infrastructure st paul need come overall framework strategy stormwater control three critical developments pittsburgh need identify strategy fund finance deliver improvements historic stairway system district columbia would like improve number infrastructure project include street light san francisco need shore seawall first glance project seem lot common yet project involve kind infrastructure stay background everything go right leap front center public mind something go drastically wrong us know care much stormwater control work neighborhood basement flood quickly become interest street light stairways things san francisco seawall perhaps dramatic e infrastructure really see appreciate something happen saw levees new orleans cost failure high worth huge investment prevent project third cohort involve single soar piece landmark infrastructure talk multibillion dollar new new york bridge replace tappan zee bridge even brand new drink water plant solid waste facility project challenge course many cities struggle fund infrastructure network like stormwater control structure street light sidewalks harder point get people care fail', 'x leaders employees partner enable growth economic progress clients communities around world part work engage progress makers year x partner program nbcuniversal news group mika brzezinski e female aspire leaders get worth work create live want samira cook gain chief civil right economic empowerment national community reinvestment coalition part x breakout session answer question', 'x leaders employees partner enable growth economic progress clients communities around world 8 graders disclaimer youth entrepreneurs anna doherty hope sacco send wave laughter around auditorium duo might 8 grade bright light front giant screen eager audience business pitch network teach entrepreneurship nfte national youth entrepreneurship challenge present x foundation make clear hundreds attendees business partner serious take success ne level baltimorebased cofounders color book feature illustrations inspire women wow guest judge include return judge david chubak x head productivity passion empower young girls compel team dynamic early business success bookstores help score point pair ultimately walk away 25000 grand prize package include college scholarship resources help business grow think many ways x make difference communities whether help volunteer neighborhoods help young people prepare job today economy always gratify recognitions organizations like point light largest organization dedicate volunteer service world year fourth year row honor include point light civic 50 initiative honor 50 communityminded company yous year civic 50 honorees select demonstrate consistent commitment help address wide range societal challenge volunteerism responsible business activities philanthropic support stories carry mean hold information world live inform us work still society effective efforts address change witness power stories firsthand x foundation work towards catalyze collective impact inspire young people believe future support diverse highperforming organizations meaningful work grind leverage e resources proud highlight stories impact result collaboration investment far beyond dollars select one young person three talented businesssavvy finalists network teach entrepreneurship nfte national youth entrepreneurship challenge present x foundation prove quite e october 6 part challenge 49 top young entrepreneurs age 1624 across yous arrive new york city opportunity pitch business ideas enthusiasm nfte judge deliberation room final round palpable passion e student participants stage know line chance make new business venture begin help prize package worth appro 25000 include college scholarship access business e citi e work colleagues drive result imagination determination innovation key scale company strategy across globe work take e ne level much like young entrepreneurs take ne step grow business skillset critical tap x strengths nfte x foundation well empower youth develop entrepreneurial mindset equip tool problemsolve instill confidence july 2015 x foundation fund remarkable customer service award successful 26th annual company year competition coyc junior achievement ja europe company lift trophy remarkable customer service student company orenda uk students impress x signature award jury strong attention customer e orenda create vibrant practical sip snack innovative water bottle multipurpose compartment enable clients take favourite drink snack wherever go 200 coyc students gather berlin germany july 28 31 celebrate top minicompanies europe 37 studentteams 36 countries compete part ja europe flagship company programme give opportunity set run real business support business mentor three days event student mini company impress innovation professionalism enthusiasm passion', 'recently chicago wonderful opportunity gather x ceo vikram pandit representatives local community organizations kitchen inspiration corporation new facility border garfield park facility leedcertified flood natural light offer great view park depend solar panel power heat water amid bright freshly paint wall table make recycle barn wood head manager anthony tell us story love cook lead inspiration kitchens 13week restaurant skills train program design help disadvantage individuals get job food service industry six years since series position increase amount responsibility within organization anthony gear open inspiration new facility public ne weeks inspiration corporation type organization support community development financial institutions know cdfis private nongovernmental organizations many years fund essential community service one else would cdfis build affordable house create retain job finance small local businesses make available social service shelter daycare meals accomplish things cdfis rely bank foundations investors well grant government fund last may calvert foundation thrill join x cdfi industry trade group opportunity finance network create fund make fle affordable finance available cdfis result manage calvert foundation wholly own subsidiary community investment partner since make investments group like iff regional organization base chicago provide finance inspiration corporation new facility chicago community loan fund cclf finance social enterprises grow home organic urban farm hire train homeless formerly incarcerate otherwise disadvantage individuals like inspiration kitchens since launch less one year ago communities work fund approve 100 million loan 20 cdfis across country serve lowincome populations nearly 50 state x foresight see could bring right players together could help create job opportunity scale larger calvert foundation could make possible calvert foundation also cdfi early investor cdfis well affordable house developers charter school microfinance institutions fair trade coffee coops past 15 years work hard popularize idea invest communities grow organization unique value provide connections make evidence success communities work fund new role president ceo calvert foundation also feel privilege work industry know every day work help transform communities give people like anthony opportunities wish every sociallymotivated investor could e e growth new sectors healthcare education green communities look forward continue important work turn disadvantage neighborhoods empower thrive communities', 'reach short longterm retirement goals save tool available teacher find creative ways save even 2016 x 200 park avenue new york ny 10166', 'doubt information become increasingly congest data capacity global challenge world wide mobile data traffic grow 63 percent 2016 reach 72 e per month put conte density mention word density relationship 5g almost always refer network mention conte asia word take whole new mean gsma predict asia highspeed mobile broadband continue enrich daily live increasingly useful entertain applications whether stream movie tablet realtime multiplayer game smartphone incredible improvements network speed device technology e see industry conversation around 5g grow crescendo good mean think future every often ask 5g xdual band wirelessac 8260 x3rd generation 80211ac dual band 2 wifi bluetooth 42 adapter engineer deliver lower power consumption1 improve rf coe complete microsoft windows 10 support m2 1216 form end 2014 marriott american hospitality lodge association make wave petition fcc right block personal wifi hotspots venues backlash immediate fierce everyone consumer advocate let face cord cute every time connect laptop 2in1 e display spend precious time fumble around clumsy cord rummage around bin full random adapters look wireless display capabilities grow leap bound recent months take new cordcutting technology ne level xpartnered lg release industry first wireless display support full 4k uhd video stream industryleading know wifi could cost buy new 2in1 new device include latest 80211ac wifi able take advantage incredible new speed stability new mobile devices laptops increasingly support fast 80211ac wireless demand institutions keep deliver better wireless speed capacities dramatically increase workforce push greater fle freedom', '5 2015 welcome another edition weekend read big week x news let dig mean less eight weeks windows customers get free upgrade start great things across devices help cortana windows hello x edge include windows 10 bring back familiar beloved start menu windows 10 start deliver vision personal compute define trust protect respect personal information mobility e across devices natural interactions windows devices include speech touch ink holograms terry myerson x e vice president operate systems group write able log face iris finger windows hello secure biometric authentication digital assistant cortana help get stuff do new browser x edge offer fresh ways search share read hold taipei event showcased innovative windows 10 devices available later year acer new aspire z allinone pc series hp 2in1 ultraportable tablet tablet fle thank cool magnetic hinge design windows 10 transition seamlessly tablet pc modes include versatile inspiron 5000 laptops inspiron 15 7000 2in1s inspiron 20 24 3000 desktops e fun introduce two affordable powerful include superslim ultralight asus transformer book t100ha launch windows 10 continue e partner ecosystem incredible variety pcs tablets phone iot devices run x apps service available help people productive digital work life corporate vice president x original equipment manufacturer division tell grow would things differently blind person sawhney prove wrong pursue passion technology study computer science stanford university recently land summer internship x team work technology accessibility eager focus difference difference people disabilities difference general say primary motivation go technical field sawhney story inspire life part mission productivity mobilefirst cloudfirst world write eran megiddo onenote general manager momentum well recent acquisitions demonstrate x commitment deliver market lead mobile apps across platforms devices customers use mail calendar message note task official game 2015 eni fim superbike world championship become available windows phone gorgeous graphics thrill action lara croft return new e trailer upcoming xbox game useful tool find organize tv moviewatching hunt around netflix hulu plus comedy central surprise best friends filmmakers invitation host coverage game stay tune update journey game begin july 25 thank read weekend read see ne week post news center staff', '17 2015 x last month new fund help cultivate company solutions bring affordable internet access underserved market fund part x invest new lastmile access technologies cloudbased service applications business model reduce cost internet access help people affordably get online x partner internet access providers publicandprivate sector entities innovative practical connectivity service solutions design deliver greatest socioeconomic impact greatest number people although still appro 4 billion people globally yet online universal affordable highspeed internet access achievable ever new technologies business innovations together partner already many e project underway recent progress mbc leverage new tv white space wifi technologies develop adaptrum san jose california mediatek taiwan provide lastmile broadband connectivity school students home well better connectivity within home connectivity enable school children communities online homework assignments equal foot kid help succeed school also 21st century global economy believe project could serve model school district around country around world leverage e e highcapacity infrastructure close homework gap communities adaptrum mawingu network relative startups recently begin deliver commercial products service market growth trajectory proud partner small company around world help e affordable internet access affordable access initiative grant fund hope kick start entrepreneurial process identify promise ideas like develop adaptrum mawingu network help nurture grow scale applicants must commercial organizations two fulltime employees prototype work solution preferably pay customers products business model might combine new cloud service applications lowcost form internet connectivity new payment mechanisms design consumers smaller businesses underserved market list criteria application find fund addition receive average appro 75000 fund plus free software service recipients also opportunity participate program offer x connect grant recipients potential funders already receive applications five continents far great diversity term ideas locations get great idea encourage apply paul tag 23 2016 23 2015 18 2015 25 2015 send affirm permit send email', '17 2017 week new york city x unveil latest digital innovations transform shop e customers every step journey across every channel personalization omnichannel customercentricity new theme retailers aware ever compete today world require emphasis entire customer journey technology culture change require level retail organization provide e customers e call digital transformation many retail customers already embrace shift help technologies x x power bi dynamics 365 well solutions global network partner hardware software display booth nrf week customers partner impressive include storescanning robots mobile apps intelligent vend machine smart shelve solutions x customers partner implement use technology new ways warehouse checkout pursuit continually improve customer e pilot instore beacon technology footmarks build better engage personalize shoppers e ultimately increase speed convenience today nordstrom rack use beacon gather data hop ultimately help better engage serve customers also test message display via beacon direct shoppers available fit room e checkout service show customers e product offer available online shop instore skip back nrf year macey associate food store grocery chain base salt lake city use skip app linefree checkout better personalize offer promotions customers build x skip enable shoppers build shop list home list organize aisle walk store simply scan item place cart check app finish first two months deployment macey see increase repeat usage skip guests well increase average trip store basket size reduce number cashier need since implement skip technology macey able redeploy cashier store floor better assist customers provide shop e brand know give wide range customers consumers businesses distributors best possible service work neal analytics apply x data machine learn technologies vend machine connect machine technology mar drink use remote sensors predictive compute better maintain stock level understand consumer behaviors account change demand relate factor weather holiday mar drink distributors subject fine time product stock ability better anticipate manage stock level enable avoid unnecessary revenue losses year open close appro 500 seasonal retail store within unite state canada holiday season company need way scale quickly account massive swing business solution replace four disparate legacy business systems integrate catalog mail order web retail wholesale operations single platform company automate manual process break business silos better manage inventory e many summer sausages sell ship location something able without significant effort hickory farm also e increase sales since customers place online order directly store kiosks even item stock location unstocked shelve meet match x partner harness solve low stock level incorrect product ticket available robot drone shelfie travel store scan shelve enable realtime stock report identify sales trend provide intelligent insights help optimize merchandise display data analytics solutions run shelfie empower retailers grow sales revenue optimize profit margins free employees focus task add bottomline value shelfie soon pilot youkbased supermarket coop regional supermarket chain giant eagle turn system support hitachi consult digitize inventory management run x x powershelf use sensors shelve power bi dashboards give employees uptodate insight order technology also change price electronically measure inventory life send shoppers product information mobile phone powershelf help giant eagle reduce outofstock replenishment time twothirds cut outofstock skus 50 percent give day addition help customers partner drive innovation innovate need retailers mind well last week x new app retail business deskless employees staffhub make easy retail managers manage shift schedule share information team give employees access shift information include ability easily swap shift others right x staffhub mobile app proud share space nrf week partner customers deliver stateoftheart retail solutions harness data empower workforce optimize business operations attend nrf week sure visit booth 2803 see solutions action', '16 2017 official start summer days away one slack around week saw x researchers use artificial intelligence ai master think unmasterable pacman addictive 1980s video game meet new xbox one x console system design play best game past present future hang x data insights summit seattle power bi premium introduce let go mix nostalgia sci fi case nothing researchers use divideandconquer method could team canadian deep learn startup acquire x earlier year use branch ai call reinforcement learn play atari 2600 version pacman perfectly use divideandconquer method team achieve score possible 999990 also learn fascinate detective story unveil e3 los angeles 40 percent power console e immersive xbox one x also make e library even better better te smoother frame rat faster load time even 1080p tv xbox one market e3 include 22 console e creators large small also debut week four surface laptop color burgundy cobalt blue graphite gold platinum available come months 17 new market australia austria canada china denmark finland france germany hong kong ireland japan new zealand norway sweden switzerland taiwan youk indemand recently make available canada australia new zealand also available austria china denmark finland france germany hong kong japan netherlands norway sweden switzerland uk great week data analytics news x ne step commitment empower people organizations access critical intelligence make generally available power bi premium enable without require recipients individually license also big news organization deal big news associate press x announce pilot program enable local regional news outlets easily uncover report datadriven local stories interest audiences ap use power bi come soon definitely summer slackers head x campus redmond washington show visions future compete championships slat july 27 mix student project impressive say anthony salcito x vice president worldwide education among judge see project focus create virtual coach power artificial intelligence name salcito say speak iot episode 2 animate series princess imagine internet toothbrush missive begin trust us get better educate people use iot create everything selfsustaining urban farm intelligent vehicles also get hear prince songwritermusician plan live show upcoming lose tour promote latest album mellow greene perform two others bandmates handle percussion keyboards reminiscent live video feedback behind latest artist series feature initiative celebrate forwardthinking artists use x technology transform way people create e music edition weekend read put feet relax well least monday post', '21 2014 profile x general counsel e vice president legal corporate affairs brad smith publish sunday july 20 smith describe de facto ambassador technology industry large admire respect many ongoing efforts push change governments collect data read entire profile', '4 2015 x hit road help developers pros get azure bring free oneday technical train sessions nine cities around world tour kick october events philadelphia tokyo handson train sessions cover topics include network big data storage closer azure ever azure team promise learn', '17 2015 tuesday x government cloud forum washington dc x announce plan enhance protection customer data new cyber defense operations center new x enterprise cybersecurity group stateoftheart cyber defense operations center bring together security response e across company help protect detect respond threats real time write bret arsenault x chief information security officer x enterprise cybersecurity group dedicate group worldwide security e deliver security solutions e service organizations modernize platforms securely move cloud keep data safe arsenault say keynote address tuesday x ceo satya nadella showcased innovations windows 10 office 365 x x x enterprise mobility suite work tandem partner solutions across security ecosystem deliver agile security platform arsenault write read arsenault post', '6 2016 educators school leaders invite attend x hack classroom digital event jan 30 provide inspiration new ideas tool incorporate classroom help students achieve hear hadi partovi founder codeorg dale dougherty founder make magazine hack learn space across globe provide e students allow improve computational think critical think skills creativity learn change way think learn creativity learn critical think collaboration also get look inside two classrooms teachers use technology innovative ways gain instructional time students promote studentcentered learn environments learn free event visit', '11 2016 brandswitching among customers increase recent years many customers leave brand cite poor service write kelly rigotti lead social media market x dynamics rigotti offer tip make company invite place customers include know customers well add personal touch forge strong connections learn news center', '12 2016 x edge web summit 2016 give developers inside look powerful techniques new tool space limit reservations firstcome firstserved basis sessions run day april 4 conference organize staff engineer build x edge chakra present full day technical talk cover edgehtml render engine opensource chakra javascript engine developer tool hear ne web platform power windows 10 engineer build find summit', '31 2016 open saturday new sr520 bridge reduce congestion protect environment puget sound region reminder public private sectors achieve work together success build future write brad smith x president chief legal officer continue spirit collaboration x part new initiative launch lead local company work improve region take moment admire amaze feat engineer celebrate accomplish creation sr520 bridge smith say take deep breath get ready work ne set challenge together read smith post', '26 2016 new set cloudpowered service office 365 release month design save users time produce better result new feature aim improve write word researcher editor function deliver dynamic presentations powerpoint zoom prioritize email matter outlook focus tab mention option learn improvements include detail visit', '25 2016 azure importe service allow migration large amount data azure blob storage ship hard disk drive directly datacenter generally available azure government service suitable situations want transfer several terabytes data azure storage upload download network feasible due limit bandwidth high network cost write brenda lee program manager learn visit', '9 2017 brian harry corporate vice president cloud developer service write decide part team service team foundation server work would beneficial fullfeatured wiki e enable collaboration e feel need fortunately harry say partner already build wiki e publish decide purchase e use step stone get want wikis harry say get go probably take couple sprint us get feet us start produce preview e harry write use complete reasonably functional change publisher x devlabs represent transitional state', '22 2017 merger willis group tower watson 2016 create opportunity company streamline information technology environment x key effort global advisory broking solutions firm implement office 365 support productivity platform aim empower 40000 employees 140 countries tower watson drive business performance clients help unlock potential say eoghan doyle company global head infrastructure operations aim global workforce x secure productive enterprise e5 solution provide advance enterprise security collaboration intelligence office 365 colleagues use drive business result head read post ron markezich corporate vice president x willis tower watson leverage x technologies', '3 2017 smart cities nyc x join yous launch solution potential transform industrial operations government field inspections write natalia boldyreva x director business development worldwide government together x taqtile develop new field inspection maintenance solution governments enterprises use power hololens security trust cloud platform boldyreva write taqtile manifest integrate 3d visualization predictive maintenance inspection capability manufacture utilities transportation oil gas industries learn visit', '1 2017 x announce azure sql data sync refresh thursday offer support security service users better synchronize data bidirectionally multiple azure sql databases andor onpremises sql databases release include new azure portal support powershell rest api support plus enhancements security privacy write joshua gnanayutham program manager azure sql database update available select e data sync customers available customers june 15 learn check new tutorial', '29 2017 x portal offer new administrator e x active directory ad x intune conditional access x information protection enhancements deliver unify admin e core enterprise mobility security ems service strategic role new console simplify configuration management powerful cross product workflows conditional access allow define complex access management policies across x ad intune within single interface write andrew conway general manager ema product market visit learn news center staff', '23 2017 x share new guide offer pointers utilize new security feature windows server 2016 windows server 2016 include major security innovations help protect privilege identity make harder attackers breach servers also detect attack respond faster new windows server 2016 security guide walk deploy use windows server 2016 well safeguard server workloads learn visit news center staff', '6 2017 jeremy epstein ceo never stop market discuss blockchain make way mainstream business blockchain world latest episode x partner network podcast go recreate world way make us secure trust costeffective inclusive short term see serious disruption take effect say epstein author ebook cmo primer blockchain world learn read epstein post also find link download podcast', '25 2015 ubiquitous part town landscape corner convenience store gas station many customers stop one quick anonymous transaction conduct necessity quicker better one tebased convenience store chain aim change build internet things pioneer new connect personalize e customers upend e standards engagement loyalty process create e business value potential redefine convenience industry opportunity enormous accord country 151000 convenience store post 696 billion sales 2013 singlestore operators account appro 63 percent locations scale incredible potential meaningful insights data translate bankable value across industry kwik chek new technologies connect customers mobile phone gas pump store point sale pos terminals loyalty program integrate e store infrastructure software track inventory fuel result connect system transform operations tebased chain vastly improve reliability efficiency process staff also enable unprecedented insight customer habit desire result improve sales inventory kwik chek happier loyal customers across 39 store locations te oklahoma kwik chek partner build x technologies create pair solutions mobile app enable navigation cashless payment smart digital offer rfm cloudbased solution power modern point sale system integrate forecourt system control fuel pump back office financial systems mobile app petrozone mobile commerce windows android ios enable customers connect via cloud geolocate nearest kwik chek location reserve pump convenience car find availability car wash atm service use secure multifactor authentication app allow secure payments make customers debitcredit card link check account payment accomplish scan mobile phone rather swipe card big security advantage customers say chief technology officer daniel gaddy credit card information steal sort damage occur identity theft charge online petrozone app cardholder data ever store transmit phone even lose phone ways wipe phone remotely far secure method payment clients use app check account save creditcard fee side transaction help kwik chek reduce major lineitem e potentially reduce customers gas cost much 10 cents gallon mobile commerce solution also offer optin feature track customers mobile purchase history use data generate relevant digital discount offer send customers phone real time still onsite market innovations help kwik chek address common persistent industry problem industry average appro 70 percent fuel customers never come inside store say kevin smartt ceo kwik chek offer bring result increase instore sales formerly fuelonly customers big advantage customers save money things likely buy anyway petrozone cloudbased platform power x x either license host manage p97 integrate kwik chek loyalty system purchase customers accumulate point toward future discount increase benefit repeat business customers save money new insights customer data enable kwik chek better control inventory reduce cost create much effective market winwin situation mobile e loyalty program create onetoone relationship us customers say smartt customers data really help us offer best possible service customize preferences need really transform whole e inside store p97 dynamicsbased rfm integrate critical systems include store inventory pos pinpad systems fuel pump provide better management everything purchase inventory price payments account module also work e infrastructure fuel site controllers electronic payment systems carwash systems dynamics ax modern pos build work variety interchangeable lowcost mobile tablet devices touch screen base familiar technology reduce train time cost enable selfserve help allow faster checkout timely service busy customers count us quick transactions say gaddy want save time come convenience store reliability core industry system also allow rapid update stay current new innovations x p97 partner chain previous technologies e unreliable infle simple power surge could take store hours hours days depend far store support team say gaddy real kiss death convenience industry rapid deployment systems monitor support run mobile commerce site software kwik chek new systems monitor update remotely greatly reduce number require onsite visit keep systems current run price update accomplish near real time bring new store online take less four hours far fle solution say gaddy term disaster recovery lose data live cloud get automatic software update far secure scalable faster industry long time flatout amaze fast p97 solution say p97 chief technology officer lew bezanson use card swipe pump 30 40 percent faster fuel car fumble wallet type zip cod instore e much faster technology quicker workflows better p97 plan roll solution 5000 locations 2015 kwik chek customers yous major sweep believe signal turn point convenience industry think p97 create solution industry see yet say gaddy x back think technology really take convenience industry storm', '22 2015 last week x worldwide partner conference wpc x particle announce collaboration focus enable customers rapidly develop connect internet things iot devices already transform way work live interact world estimate show five years e see 25 billion connect things collaboration use particle cloud platform couple hardware prototyping kit provide infrastructure easily connect devices x integration x x iot service enable device makers connect powerful capabilities scale 10 devices millions devices particle bring iot development tool maker communities tool include x iot service particle iot platform hardware development kit easy use makers productiongrade professionals say zach supalla ceo particleio x platform build strong reputation cloud service run many largest complex software applications combine x particle iotspecific software tool prototype ready production first moment blink lead part work together two company develop device maker kit complete particle hardware development platform shield sensors get early project jumpstart device maker kit use live demonstration current x iot service integrate particle cloud service wpc x sam george partner director program management x iot say thrill partner particle dramatically accelerate time value customers look get jump iot first phase integration use x x iot service particle webhooks result events stream seamlessly particle photons x x event hubs x stream analytics fall x particle reach lead device makers around world hackathons jointly help customers build market iot offer particle leader iot device prototyping cloud management space tens thousands device makers use platform approach development connect devices device hardware firmware connectivity provision seamlessly handle particle platform effectively abstract hardware enable developers focus deliver value software applications supalla add already familiar x x software tool build x particle iot product feel like natural e platform already know love iot e new industry use familiar tool better prepare team deliver outstanding product quickly particle complete open source fullstack solution cloudconnected devices ideal integrate x member allseen alliance recently alliance make easier connect devices older network iot additional detail new collaboration find 26 2016 18 2016 10 2017 20 2017', '31 2016 come iot cloud devices must come together create powerful solutions already make iot faster simpler customers preconfigured solutions x iot suite enable get start minutes customize meet need today e announce something new today make easier get start quickly devices lineup five new make iot accessible enable developers design prototype test new devices use x iot suite typical cost 50 160 x iot starter kit allow anyone get start iot quickly build prototypes proof concepts x iot starter kit open door innovation developers device makers inventors business owners even school program hobbyists anyone interest iot great business idea x iot starter kit include development board along actuators sensors simple userfriendly tutorials click start section kit instructions anyone windows linux rtos e get instant access kitspecific sample use x iot hub prototype ready fullscale deployment users leverage power service x iot suite potential use kit limit imagination students learn make home smarter control temperature humidity factories create device improve efficiency monitor critical equipment real time fleet operators manage vehicles effectively monitor vehicle telemetry transit lineofbusiness leaders initiate new iot project bring development team really internet things purchase x iot starter kit get start link sure check back later add come months information x iot starter kit instructions everything need get start please visit x x iot starter kit developers learn connect devices iot solution inspiration power iot transform organization visit', '7 2016 past manufacturers naturally focus sales products drill aircraft engines standalone offer service products consider cost center businesses e backend operation require products fail field today manufacture landscape shift service open door better customer outcomes decrease operational cost even potential new revenues manufacturers well opportunity differentiate competitors formerly offline tool become connect service move reactive predictive see manufacture sector move towards service core business model accord study field service organizations aberdeen group 26 percent respondents able generate new servicedriven revenue stream move standalone products service create winwin situation manufacture organizations customers organizations rely recur revenue customers benefit greater reliability lower risk evolution know servitization cover bundle goods service support knowledge let take look shift base base enable range benefit past product sell customers hear company e time upgrade replacement thank technologies like cloud rapid scalable cost effective deployment solutions products constantly connect advance analytics rich dashboards give manufacturer ongoing visibility performance rise connect devices enable ongoing interaction customers assets service organizations study aberdeen find 54 percent respondents credit iot enable creation new offer tap realtime data products field manufacturers better equip preemptively service equipment failures occur better yet monitor product performance enable manufacturers improve future products service base change customer need manufacturers continually improve products service performance productivity customers stand reap benefit customermanufacturer dynamic many forwardthinking company already use iot cloud advance analytics identify create new service line able create contrast competitors market capture consequently company leverage technologies like remote monitor cloud iot likely fall behind customers shortage choices manufacturer offer service closely align customers overall business goals make easy choice x number customers already see transformational result industry leader airlines market credit innovative enginesasaservice model first introduce mid1990s rollsroyce offer broad range service solutions include industryleading service focus keep customers engines generate value totalcare allow airlines pay time able fly plan rather repair totalcare rollsroyce assume risk responsibility engine maintenance provide engine health monitor overhaul service options rollsroyce x take totalcare digital collect aggregrating data engine health fuel usage data point use uncover new insights use enable rollsroyce proactively provide recommendations aircraft efficiency maintenance customers fuel usage flight disruptions save millions dollars per year manufacturer serve petroleum industry want gain better view global petroleum supply chain harvest process final product delivery lack insight chain make difficult help customers see potential issue address failures proactively maintain appropriate level products across locations collect sensor data remote equipment x iot suite rockwell able capture realtime information equipment performance health factor pressure temperature flow rat able drive better visibility possible problems automate service action customers result reduction costly downtime keep gas deliveries time ensure availability pump lack insight unpredicted elevator failures lead costly downtime elevator want better monitor service 11 million elevators instal around globe connect sensors embed elevators x cloud able create new service line max describe gamechanging service elevator business unit leverage capabilities x iot thyssenkrupp plan reduce maintenance cost elevator downtime arm 24000 elevator service technicians ability identify problems triage service call ahead visit initial field trials thyssenkrupp show service maintenance intervention do four time faster use today thyssenkrupp offer elevators service add recur revenue keep people cities move make customers happy reduce maintenance cost rollsroyce rockwell automation thyssenkrupp change approach service result create new value could deliver customers shift servicebased approach continue raise bar product differentiation help company capture business competitors lead manufacturers join grow list businesses engage customers ongoing basis servitization benefit contract renewals increase venue x help manufacturers better serve customers help compete new age servitization learn e service enhance customer relationships capabilities', '24 2017 unprecedented volume data generate internet things iot make analysis timeseries data powerful way gain actionable insights business performance type analytics help company uncover hide trend conduct rootbecause analyse quickly validate iot solutions yet collect manage visualize analyze timeseries data scale nearreal time tall order even capable company sensors connect devices generate billions data point every day businesses lack centralize view data ability perform unify query combine visualize disparate data type particular timeseries data reference data daunt organizations typically use multiple nonintegrated tool techniques x address challenge new update public preview manage cloud service provide global view iotscale data realtime visibility timeseries data across locations update time series insights include one company benefit x iot solutions ecolab lead provider water energy service create system help industrial customers reduce water use leverage ecolab combine appro 10tb timeseries data like water use sales data help visualize identify pattern x help company address inherent iot challenge ability combine analyze timeseries data operations process around world x continue update add functionality time series insights public preview find build lead platform analyze timeseries data read announce new time series insights capabilities also upcoming webinar unlock insights hide time series data september 19 2017 10001100 pdt', 'nudge colleagues week tell folks may today x digital crimes unit announce new cloudbased version cyber threat receive report recent email scam spoof x service agreement view', 'parent educator concern online safety family x release security update second tuesday every month bulletin announce windows live onecare beta 20 want test new version', 'big milestone achieve week article 29 work party collection windows 7 newest operate system x include several new improve security feature part 3 series article focus understand threat landscape', 'internet things iot continue gain traction enterprise question security privacy top mind business decision makers e alike work customers find many businesses struggle determine secure endtoend iot infrastructure even delay iot implementations security best practice standards establish confirm goal x keep customer iot solutions secure already multiple level range cloud beyond include x enterprisegrade security work standards body iot security provide comprehensive security recommendations guidance individual assets support secure protocols connect devices windows 10 iot core secure iot operate system important aspects iot security hear enterprises want additional security assurances make sure assemble iot solutions secure way devices connectivity cloud today thrill announce security program x iot new program bring together curated set bestinclass security auditors customers choose perform security audit iot solutions find issue provide recommendations security program x iot work grind e everything businesses devices assets gateways even communication cloud initial bestinclass security auditors include e program grow x also work security audit partner standards organizations industrial internet consortium iic establish industry protocols best practice security audit part commitment establish vibrant safe iot ecosystem security efforts x work security partner help protect businesses ultimately help us raise bar across industry select x iot customers first take advantage program evaluate endtoend iot infrastructure manage security risk come months continue provide update security program x iot global audit partner audit standards meantime invite learn whitepapers also read attend upcoming talk iot solutions world congress', 'yesterday x worldwide partner conference colleague curt kolcun vice president yous public sector lot recently ask us activex control e x release security advisory today warn fraudulent digital certificate could use', '4 2016 today mark begin annual initiative mobilize educators parent nonprofits industry inspire young people learn computer science open door promise future computer science education matter right percent bachelor degrees award unite state field computer science yet computer program job grow twice national average among top pay field tech fuel world e 2020 today already 604000 open compute job nationwide however rise digital economy nonstop pace technological change imperative prepare young people pursue career demand beyond compute job computer science education also provide computational think problem solve skills require field music fashion manufacture health care transportation young people jump chance learn skills qualify reward work answer nuanced one biggest barriers straightforward lack equitable access computer science education relate skills essential 21 century career efforts csedweek throughout year center make computer science accessible inclusive partnership nonprofit lead tech company x encourage millions young people globally spend hour week beyond get start journey learn computer science end tutorial students educators create x tutorial allow players create custom game e plug together block code control behaviors sheep zombies creatures include set 12 challenge follow free play time users create game use cod concepts learn throughout week x lead hundreds around world offer even resources find inperson cod camp well cod tutorials additionally week partnership california academy sciences kqed x host hack stem activities students apply cod relatable challenge world accessible format learn earthquakes build cod functional sensorenabled seismograph engineer equip test prototypes potential help mitigate earthquake damage many years x develop partnerships program help reach young people likely among without access computer science education girls minorities live rural areas limit connectivity collaborate closely nonprofits around world include deliver computer science learn club throughout yous across europe efforts critical reach underrepresented group close skills gap part x philanthropies also run program call technology education literacy school pair computer engineer x tech company fulltime high school teachers teach introductory advance placement ap computer science addition teals company work broad spectrum educators help prepare students digital future week include onestop shop digital curriculum fundamental technology skills certification teacher train tool role opportunity meet educators nonprofits eager collaborate creative ideas get kid e cod make positive shift public policy improve accessibility computer science visit dozens school boys girls club program see firsthand minute kid sit start cod world around disappear cod fun respond intuitively love dive e access computer science initiatives like csedweek important together work ensure young person want learn critical computational skills go study computer science community college university options hour start journey gain skills knowledge need pursue passions increasingly digital world', 'back future like forward past italy biggest grocery cooperative use futuristic technology help shoppers return sociable days openair market shopkeepers every stall ready answer question customer might war coop italia future design carlo ratti rave review thank digital design create human shop e use range offtheshelf technology concept debut e milan last year showcased x envision conference week replace typical grocery store row tower shelve airy layout include easytoreach tilt display informative screen suspend eye level motion sensors detect product shopper point look trigger visual display information ingredients potential allergens origin process food carbon footprint even wine pair recommendations e sort detail consumers see fundamental pillar shop e especially millennials grow internet fingertips coop italia hop concept help grow increasingly competitive marketplace brickandmortar store struggle engage shoppers want access everything know products look say gabriele tubertini coop italia chief information officer apple e want know type tree grow co2 produce chemical treatments receive journey supermarket shelf large easytoread screen provide information mean shoppers fumble cumbersome devices older customers get read glass like return old marketplace producers consumers food could easily interact e stories ideas tubertini say significant shift retailer well system provide instantly update information shelf inventory allow coop italia keep goods store warehouse rather shelve items need replenish design free valuable store space make famed architect carlo ratti redesign aisles food display also show real time items popular give insight shoppers make decisions move store tubertini say identify information relevant useful consumers guide coop italia interactions vendors smart merchants e categories cater new change customer behaviors also make way hybrid model shop combine digital inperson e say sahir anand analyst ekn research win combine hyper personalization deep product information connect devices inline customer buy journey anand say need shape future supermarkets offer customers smarter efficient system e frictionless shop retail e use analytics cloud stay relevant today consumers future concept develop professional service firm x partner accenture avanade rely readily available technology use sensors develop kinect x motionsensing camera start xbox 360 game controller xnucs provide compute power interactive shelve display data store x x cloudbased platforms use x sql server relational database management system x content management capabilities cash register run intelbased platform x windows software 17 million people visit coop italia test store milan 2015 sixmonth world fair e digital solutions internet things become gamechangers enhance shop e say tracy issel general manager worldwide retail industry x great e modern retailers innovate improve human element enjoyment efficiency customers issel say concept store reinforce importance design humans rather design technology sake consumers increasingly shift focus glitz practicality say john konczal avanade industry director outcome natural e shopper konczal say tech change e customer much differently wave hand coop italia plan use knowledge gain future e implement new layouts digital solutions store later year tubertini say top photo italia future system identify product customer point look thank x kinect technology instantly display wealth information digital transformations new face business', 'learn invite colleagues associate x partner network profile include step mcp id link access privilege role assignment look x partner network mpn membership support presales assistance deliver first cloud deal maybe look connect x help find assistance need team x australia create downloadable 101 guide cover commonly request support channel engagement point ne week monday 16 may 1159pm aest 2016 x australia partner award submissions close still write submit win entry mapa revenue truly innovation solutions work project passionate could redefine business watch announce today gavriella schuster streamline competency portfolio base customer demand cloud solutions help partner build demonstrate technical e cloud visit new mpn evolution competency guide utilise guide e learn best competency path participation requirements wombats work admit limit interaction australia least glamorous native animal unless task hand waddle dig chance gift want keep receipt let save burden giftsinneedofe instead gift support like unstoppable force nature festive season rapidly approach barrage good time great food company even nondenominational new years break quite like last thing want greet return news email remember renew x partner network members action pack competency level receive usd 100 monthly azure credit core benefit silver gold cloud platform competency eligible additional credit boost usd 6000 12000 respectively fair chunk credit make step x partner elite maybe one update cloud performance competencies take advantage nocost person online train wherever land however get congratulations e need give dust time launch cloud performance competencies represent significant shift way x reward success top perform cloud partner available silver cost gold reduce fee prove cloud performance primary eligibility requirement jam pack e benefit provide partner 1986 seminal punkhiphop group beastie boys issue fan call arm fight right party grow inconceivable remain members priorities change something productive fortunately x partner network members need fight right internal use right subscribe blog receive notifications new post email']\n",
            "336\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pppelx5F6Ek_",
        "colab_type": "code",
        "outputId": "feeb6dbe-3157-4ba8-817e-9a5cc6b89d5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "source": [
        "#heldout_test_data prediction\n",
        "import os \n",
        "import numpy as np\n",
        "import csv\n",
        "import pandas as pd\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Model,load_model\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Activation, Dense, Dropout,Input,Add,concatenate\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split,StratifiedKFold\n",
        "from keras.layers import Conv1D,MaxPooling1D,Embedding,GlobalMaxPooling1D\n",
        "from keras.initializers import Constant\n",
        "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix,precision_score,recall_score,f1_score\n",
        "import pickle\n",
        "\n",
        "\n",
        "#parameters same as the parameters which used for training the model\n",
        "vocab_size = 30000\n",
        "batch_size = 128\n",
        "embedding_dim = 300\n",
        "max_len = 3000\n",
        "\n",
        "# /content/drive/My Drive/ML_Datasets/genData/test_data.pickle\n",
        "\n",
        "#loading the pickled test data\n",
        "pickle_in = open(\"test_text.pickle\",\"rb\")\n",
        "X = pickle.load(pickle_in)\n",
        "\n",
        "pickle_in = open(\"test_data.pickle\",\"rb\")\n",
        "data = pickle.load(pickle_in)\n",
        "\n",
        "\n",
        "#loading the tokenizer pickled during the training of the model\n",
        "pickle_in = open(\"tokenizer.pickle\",\"rb\")\n",
        "tokenizer = pickle.load(pickle_in)\n",
        "# tokenizer = Tokenizer(num_words = vocab_size)\n",
        "# tokenizer.fit_on_texts(X)\n",
        "# word_index = tokenizer.word_index\n",
        "\n",
        "#tokenizing the texts\n",
        "train_sentences_tokenized = tokenizer.texts_to_sequences(X)\n",
        "\n",
        "#padding the sequence to have the pre decided length \n",
        "X = pad_sequences(train_sentences_tokenized, maxlen=max_len)\n",
        "\n",
        "tags = ['y','n']\n",
        "\n",
        "#concatenating the binary laabels to for n_data_samples*10 (2 for each binary label)\n",
        "\n",
        "label_enc = LabelBinarizer()\n",
        "label_enc.fit(tags)\n",
        "Y_1 = label_enc.transform(data['cSIN'])\n",
        "Y_1 = to_categorical(Y_1)\n",
        "\n",
        "Y_2 = label_enc.transform(data['cEXC'])\n",
        "Y_2 = to_categorical(Y_2)\n",
        "\n",
        "Y_3 = label_enc.transform(data['cCOM'])\n",
        "Y_3 = to_categorical(Y_3)\n",
        "\n",
        "Y_4 = label_enc.transform(data['cRUG'])\n",
        "Y_4 = to_categorical(Y_4)\n",
        "\n",
        "Y_5 = label_enc.transform(data['cSOP'])\n",
        "Y_5 = to_categorical(Y_5)\n",
        "\n",
        "Y = np.concatenate((Y_1,Y_2,Y_3,Y_4,Y_5),axis=1)\n",
        "print(Y.shape)\n",
        "\n",
        "\n",
        "\n",
        "# 'cSIN','cEXC','cCOM','cRUG','cSOP'\n",
        "\n",
        "\n",
        "\n",
        "#loading the trained models\n",
        "model1 = load_model('my_model_cSIN_tag')\n",
        "model2 = load_model('my_model_cEXC_tag')\n",
        "model3 = load_model('my_model_cCOM_tag')\n",
        "model4 = load_model('my_model_cSOP_tag')\n",
        "model5 = load_model('my_model_cRUG_tag')\n",
        "\n",
        "\n",
        "#making test data prediction for all the labels\n",
        "a,b = 0,2\n",
        "print('\\n\\nSincerity')\n",
        "\n",
        "pred = model1.predict(X)\n",
        "pred = pred.argmax(axis=1)\n",
        "c_matrix = confusion_matrix(Y[:,a:b].argmax(axis=1),pred)\n",
        "print(c_matrix)\n",
        "accuracy = accuracy_score(Y[:,a:b].argmax(axis=1),pred)\n",
        "print('Accuracy : ',accuracy)\n",
        "# precision = true positive / total predicted positive(True positive + False positive)\n",
        "# recall = true positive / total actual positive(True positive + False Negative)\n",
        "print(classification_report(Y[:,a:b].argmax(axis=1),pred))\n",
        "\n",
        "\n",
        "a,b = 2,4\n",
        "\n",
        "print('\\n\\nExcitement')\n",
        "\n",
        "    \n",
        "pred = model2.predict(X)\n",
        "pred = pred.argmax(axis=1)\n",
        "c_matrix = confusion_matrix(Y[:,a:b].argmax(axis=1),pred)\n",
        "print(c_matrix)\n",
        "accuracy = accuracy_score(Y[:,a:b].argmax(axis=1),pred)\n",
        "print('Accuracy : ',accuracy)\n",
        "# precision = true positive / total predicted positive(True positive + False positive)\n",
        "# recall = true positive / total actual positive(True positive + False Negative)\n",
        "print(classification_report(Y[:,a:b].argmax(axis=1),pred))\n",
        "\n",
        "\n",
        "a,b = 4,6\n",
        "print('\\n\\nCompetence')\n",
        "  \n",
        "    \n",
        "pred = model3.predict(X)\n",
        "pred = pred.argmax(axis=1)\n",
        "c_matrix = confusion_matrix(Y[:,a:b].argmax(axis=1),pred)\n",
        "print(c_matrix)\n",
        "accuracy = accuracy_score(Y[:,a:b].argmax(axis=1),pred)\n",
        "print('Accuracy : ',accuracy)\n",
        "# precision = true positive / total predicted positive(True positive + False positive)\n",
        "# recall = true positive / total actual positive(True positive + False Negative)\n",
        "print(classification_report(Y[:,a:b].argmax(axis=1),pred))\n",
        "\n",
        "\n",
        "a,b = 6,8\n",
        "\n",
        "print('\\n\\nRuggedness')\n",
        "\n",
        "    \n",
        "pred = model5.predict(X)\n",
        "pred = pred.argmax(axis=1)\n",
        "c_matrix = confusion_matrix(Y[:,a:b].argmax(axis=1),pred)\n",
        "print(c_matrix)\n",
        "accuracy = accuracy_score(Y[:,a:b].argmax(axis=1),pred)\n",
        "print('Accuracy : ',accuracy)\n",
        "print('Precision : ',precision_score(Y[:,a:b].argmax(axis=1),pred))\n",
        "print('Recall : ',recall_score(Y[:,a:b].argmax(axis=1),pred))\n",
        "print('F1 score : ',f1_score(Y[:,a:b].argmax(axis=1),pred))\n",
        "# precision = true positive / total predicted positive(True positive + False positive)\n",
        "# recall = true positive / total actual positive(True positive + False Negative)\n",
        "print(classification_report(Y[:,a:b].argmax(axis=1),pred))\n",
        "\n",
        "a,b = 8,10\n",
        "\n",
        "print('\\n\\nSophistication')\n",
        "\n",
        "pred = model4.predict(X)\n",
        "pred = pred.argmax(axis=1)\n",
        "c_matrix = confusion_matrix(Y[:,a:b].argmax(axis=1),pred)\n",
        "print(c_matrix)\n",
        "accuracy = accuracy_score(Y[:,a:b].argmax(axis=1),pred)\n",
        "print('Accuracy : ',accuracy)\n",
        "# precision = true positive / total predicted positive(True positive + False positive)\n",
        "# recall = true positive / total actual positive(True positive + False Negative)\n",
        "print(classification_report(Y[:,a:b].argmax(axis=1),pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(336, 10)\n",
            "\n",
            "\n",
            "Ruggedness\n",
            "[[196   5]\n",
            " [123  12]]\n",
            "Accuracy :  0.6190476190476191\n",
            "Precision :  0.7058823529411765\n",
            "Recall :  0.08888888888888889\n",
            "F1 score :  0.15789473684210528\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.98      0.75       201\n",
            "           1       0.71      0.09      0.16       135\n",
            "\n",
            "    accuracy                           0.62       336\n",
            "   macro avg       0.66      0.53      0.46       336\n",
            "weighted avg       0.65      0.62      0.51       336\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GogM4wivzkU",
        "colab_type": "code",
        "outputId": "8640b3e3-1c4a-4b1f-ff8c-54e747b2cd50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        }
      },
      "source": [
        "#ht_test_data prediction\n",
        "import os \n",
        "import numpy as np\n",
        "import csv\n",
        "import pandas as pd\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Model,load_model\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Activation, Dense, Dropout,Input,Add,concatenate\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split,StratifiedKFold\n",
        "from keras.layers import Conv1D,MaxPooling1D,Embedding,GlobalMaxPooling1D\n",
        "from keras.initializers import Constant\n",
        "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix,precision_score,recall_score,f1_score\n",
        "import pickle\n",
        "\n",
        "#hyperparameters\n",
        "vocab_size = 30000\n",
        "batch_size = 128\n",
        "embedding_dim = 300\n",
        "max_len = 3000\n",
        "\n",
        "# content/drive/My Drive/ML_Datasets/genData/test_data.pickle\n",
        "\n",
        "#loading the pickled test data file\n",
        "pickle_in = open(\"ht_test_text.pickle\",\"rb\")\n",
        "X = pickle.load(pickle_in)\n",
        "\n",
        "pickle_in = open(\"ht_test_data.pickle\",\"rb\")\n",
        "data = pickle.load(pickle_in)\n",
        "\n",
        "\n",
        "#loading the pickled tokenizer\n",
        "pickle_in = open(\"tokenizer.pickle\",\"rb\")\n",
        "tokenizer = pickle.load(pickle_in)\n",
        "# tokenizer = Tokenizer(num_words = vocab_size)\n",
        "# tokenizer.fit_on_texts(X)\n",
        "# word_index = tokenizer.word_index\n",
        "\n",
        "#tokenizing the text data\n",
        "train_sentences_tokenized = tokenizer.texts_to_sequences(X)\n",
        "\n",
        "#padding the sequences\n",
        "X = pad_sequences(train_sentences_tokenized, maxlen=max_len)\n",
        "\n",
        "tags = ['y','n']\n",
        "\n",
        "\n",
        "label_enc = LabelBinarizer()\n",
        "label_enc.fit(tags)\n",
        "\n",
        "Y_1 = label_enc.transform(data['cSIN'])\n",
        "Y_1 = to_categorical(Y_1)\n",
        "\n",
        "Y_2 = label_enc.transform(data['cEXC'])\n",
        "Y_2 = to_categorical(Y_2)\n",
        "\n",
        "Y_3 = label_enc.transform(data['cCOM'])\n",
        "Y_3 = to_categorical(Y_3)\n",
        "\n",
        "Y_4 = label_enc.transform(data['cRUG'])\n",
        "Y_4 = to_categorical(Y_4)\n",
        "\n",
        "Y_5 = label_enc.transform(data['cSOP'])\n",
        "Y_5 = to_categorical(Y_5)\n",
        "\n",
        "#concatenating the binary laabels to for n_data_samples*10 (2 for each label [y or n])\n",
        "Y = np.concatenate((Y_1,Y_2,Y_3,Y_4,Y_5),axis=1)\n",
        "print(Y.shape)\n",
        "\n",
        "\n",
        "\n",
        "# 'cSIN','cEXC','cCOM','cRUG','cSOP'\n",
        "\n",
        "#performing he seven fold validation\n",
        "kfold = StratifiedKFold(n_splits=7, shuffle=True, random_state=4991)\n",
        "\n",
        "#list to store the accuracy, precision, recall score and f1-score for the 7-fold validation\n",
        "acscores1 = []\n",
        "acscores2 = []\n",
        "acscores3 = []\n",
        "acscores4 = []\n",
        "acscores5 = []\n",
        "\n",
        "prescores1 = []\n",
        "prescores2 = []\n",
        "prescores3 = []\n",
        "prescores4 = []\n",
        "prescores5 = []\n",
        "\n",
        "rescores1 = []\n",
        "rescores2 = []\n",
        "rescores3 = []\n",
        "rescores4 = []\n",
        "rescores5 = []\n",
        "fscores1 = []\n",
        "fscores2 = []\n",
        "fscores3 = []\n",
        "fscores4 = []\n",
        "fscores5 = []\n",
        "\n",
        "#loading the trained models\n",
        "model1 = load_model('my_model_cSIN_tag')\n",
        "model2 = load_model('my_model_cEXC_tag')\n",
        "model3 = load_model('my_model_cCOM_tag')\n",
        "model4 = load_model('my_model_cSOP_tag')\n",
        "model5 = load_model('my_model_cRUG_tag')\n",
        "\n",
        "\n",
        "#performing the 7-fold validation for all the personality traits\n",
        "a,b = 0,2\n",
        "print('\\n\\nSincerity')\n",
        "    \n",
        "for train, test in kfold.split(X, Y[:,a:b].argmax(axis=1)):  \n",
        "    pred = model1.predict(X[test])\n",
        "    pred = pred.argmax(axis=1)\n",
        "    c_matrix = confusion_matrix(Y[test,a:b].argmax(axis=1),pred)\n",
        "    print(c_matrix)\n",
        "    accuracy = accuracy_score(Y[test,a:b].argmax(axis=1),pred)\n",
        "    print('Accuracy : ',accuracy)\n",
        "    # precision = true positive / total predicted positive(True positive + False positive)\n",
        "    # recall = true positive / total actual positive(True positive + False Negative)\n",
        "    print(classification_report(Y[test,a:b].argmax(axis=1),pred))\n",
        "    acscores1.append(accuracy)\n",
        "    prescores1.append(precision_score(Y[test,a:b].argmax(axis=1),pred))\n",
        "    rescores1.append(recall_score(Y[test,a:b].argmax(axis=1),pred))\n",
        "    fscores1.append(f1_score(Y[test,a:b].argmax(axis=1),pred))\n",
        "\n",
        "a,b = 2,4\n",
        "\n",
        "print('\\n\\nExcitement')\n",
        "for train, test in kfold.split(X, Y[:,a:b].argmax(axis=1)):   \n",
        "      pred = model2.predict(X[test])\n",
        "      pred = pred.argmax(axis=1)\n",
        "      c_matrix = confusion_matrix(Y[test,a:b].argmax(axis=1),pred)\n",
        "      print(c_matrix)\n",
        "      accuracy = accuracy_score(Y[test,a:b].argmax(axis=1),pred)\n",
        "      print('Accuracy : ',accuracy)\n",
        "      # # precision = true positive / total predicted positive(True positive + False positive)\n",
        "      # # recall = true positive / total actual positive(True positive + False Negative)\n",
        "      print(classification_report(Y[test,a:b].argmax(axis=1),pred))\n",
        "      acscores2.append(accuracy)\n",
        "      prescores2.append(precision_score(Y[test,a:b].argmax(axis=1),pred))\n",
        "      rescores2.append(recall_score(Y[test,a:b].argmax(axis=1),pred))\n",
        "      fscores2.append(f1_score(Y[test,a:b].argmax(axis=1),pred))\n",
        "\n",
        "a,b = 4,6\n",
        "print('\\n\\nCompetence')\n",
        "for train, test in kfold.split(X, Y[:,a:b].argmax(axis=1)):   \n",
        "    \n",
        "    pred = model3.predict(X[test])\n",
        "    pred = pred.argmax(axis=1)\n",
        "    c_matrix = confusion_matrix(Y[test,a:b].argmax(axis=1),pred)\n",
        "    print(c_matrix)\n",
        "    accuracy = accuracy_score(Y[test,a:b].argmax(axis=1),pred)\n",
        "    print('Accuracy : ',accuracy)\n",
        "    # precision = true positive / total predicted positive(True positive + False positive)\n",
        "    # recall = true positive / total actual positive(True positive + False Negative)\n",
        "    print(classification_report(Y[test,a:b].argmax(axis=1),pred))\n",
        "    acscores3.append(accuracy)\n",
        "    prescores3.append(precision_score(Y[test,a:b].argmax(axis=1),pred))\n",
        "    rescores3.append(recall_score(Y[test,a:b].argmax(axis=1),pred))\n",
        "    fscores3.append(f1_score(Y[test,a:b].argmax(axis=1),pred))\n",
        "    \n",
        "a,b = 6,8\n",
        "print('\\n\\nRuggedness')\n",
        "for train, test in kfold.split(X, Y[:,a:b].argmax(axis=1)):   \n",
        "    \n",
        "    pred = model5.predict(X[test])\n",
        "    pred = pred.argmax(axis=1)\n",
        "    c_matrix = confusion_matrix(Y[test,a:b].argmax(axis=1),pred)\n",
        "    print(c_matrix)\n",
        "    accuracy = accuracy_score(Y[test,a:b].argmax(axis=1),pred)\n",
        "    print('Accuracy : ',accuracy)\n",
        "    # precision = true positive / total predicted positive(True positive + False positive)\n",
        "    # recall = true positive / total actual positive(True positive + False Negative)\n",
        "    print(classification_report(Y[test,a:b].argmax(axis=1),pred))\n",
        "    acscores5.append(accuracy)\n",
        "    prescores5.append(precision_score(Y[test,a:b].argmax(axis=1),pred))\n",
        "    rescores5.append(recall_score(Y[test,a:b].argmax(axis=1),pred))\n",
        "    fscores5.append(f1_score(Y[test,a:b].argmax(axis=1),pred))\n",
        "\n",
        "a,b = 8,10\n",
        "\n",
        "print('\\n\\nSophistication')\n",
        "    \n",
        "for train, test in kfold.split(X, Y[:,a:b].argmax(axis=1)): \n",
        "    pred = model4.predict(X[test])\n",
        "    pred = pred.argmax(axis=1)\n",
        "    c_matrix = confusion_matrix(Y[test,a:b].argmax(axis=1),pred)\n",
        "    print(c_matrix)\n",
        "    accuracy = accuracy_score(Y[test,a:b].argmax(axis=1),pred)\n",
        "    print('Accuracy : ',accuracy)\n",
        "    # precision = true positive / total predicted positive(True positive + False positive)\n",
        "    # recall = true positive / total actual positive(True positive + False Negative)\n",
        "    print(classification_report(Y[test,a:b].argmax(axis=1),pred))\n",
        "    acscores4.append(accuracy)\n",
        "    prescores4.append(precision_score(Y[test,a:b].argmax(axis=1),pred))\n",
        "    rescores4.append(recall_score(Y[test,a:b].argmax(axis=1),pred))\n",
        "    fscores4.append(f1_score(Y[test,a:b].argmax(axis=1),pred))\n",
        "\n",
        "#printing the output for all the personaliy traits\n",
        "print('\\n\\nSincerity')   \n",
        "print(acscores1,'\\nMean : ',np.mean(acscores1),'\\nStandard deviation : ',np.std(acscores1),'\\nPrecision Score : ',np.mean(prescores1),'\\nRecall Score : ',np.mean(rescores1),'\\nF1 Score : ',np.mean(fscores1))\n",
        "print('\\n\\nExcitement')\n",
        "print(acscores2,'\\nMean : ',np.mean(acscores2),'\\nStandard deviation : ',np.std(acscores2),'\\nPrecision Score : ',np.mean(prescores2),'\\nRecall Score : ',np.mean(rescores2),'\\nF1 Score : ',np.mean(fscores2))\n",
        "print('\\n\\nCompetence')\n",
        "print(acscores3,'\\nMean : ',np.mean(acscores3),'\\nStandard deviation : ',np.std(acscores3),'\\nPrecision Score : ',np.mean(prescores3),'\\nRecall Score : ',np.mean(rescores3),'\\nF1 Score : ',np.mean(fscores3))\n",
        "print('\\n\\nSophistication')\n",
        "print(acscores4,'\\nMean : ',np.mean(acscores4),'\\nStandard deviation : ',np.std(acscores4),'\\nPrecision Score : ',np.mean(prescores4),'\\nRecall Score : ',np.mean(rescores4),'\\nF1 Score : ',np.mean(fscores4))\n",
        "\n",
        "print('\\n\\nRuggedness')\n",
        "print(acscores5,'\\nMean : ',np.mean(acscores5),'\\nStandard deviation : ',np.std(acscores5),'\\nPrecision Score : ',np.mean(prescores5),'\\nRecall Score : ',np.mean(rescores5),'\\nF1 Score : ',np.mean(fscores5))\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-331e419e3505>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mmax_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# content/drive/My Drive/ML_Datasets/genData/test_data.pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mpickle_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ht_test_text.pickle\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ht_test_text.pickle'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-WV-GHYjLBT",
        "colab_type": "code",
        "outputId": "b0958a2f-b8b6-4219-b532-ae3599b8a07b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4535
        }
      },
      "source": [
        "#model training\n",
        "!pip install imblearn\n",
        "import os \n",
        "import numpy as np\n",
        "import csv\n",
        "import pandas as pd\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Model\n",
        "from keras.utils import to_categorical,plot_model\n",
        "from keras.layers import Activation, Dense, Dropout,Input,Add,concatenate\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split,StratifiedKFold\n",
        "from keras.layers import Conv1D,MaxPooling1D,Embedding,GlobalMaxPooling1D\n",
        "from keras.initializers import Constant\n",
        "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
        "import pickle\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "#loading the training data\n",
        "pickle_in = open(\"/content/drive/My Drive/ML_Datasets/genData/text.pickle\",\"rb\")\n",
        "X = pickle.load(pickle_in)\n",
        "\n",
        "pickle_in = open(\"/content/drive/My Drive/ML_Datasets/genData/train_data.pickle\",\"rb\")\n",
        "data = pickle.load(pickle_in)\n",
        "\n",
        "\n",
        "#forming the embedding matrix\n",
        "embedding_index = {}\n",
        "with open('glove.6B.300d.txt') as f:\n",
        "    for line in f:\n",
        "        word, coefs = line.split(maxsplit=1)\n",
        "        coefs = np.fromstring(coefs,'f',sep=' ')\n",
        "        embedding_index[word] = coefs\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#hyperparameters\n",
        "vocab_size = 30000\n",
        "batch_size = 128\n",
        "embedding_dim = 300\n",
        "max_len = 3000\n",
        "\n",
        "\n",
        "#forming the numerical vector representation of the textual data\n",
        "tokenizer = Tokenizer(num_words = vocab_size)\n",
        "tokenizer.fit_on_texts(X)\n",
        "word_index = tokenizer.word_index\n",
        "train_sentences_tokenized = tokenizer.texts_to_sequences(X)\n",
        "\n",
        "X = pad_sequences(train_sentences_tokenized, maxlen=max_len)\n",
        "# print(X.shape)\n",
        "# print(X)\n",
        "# print(tokenizer.word_index)\n",
        "\n",
        "\n",
        "tags = ['y','n']\n",
        "label_enc = LabelBinarizer()\n",
        "label_enc.fit(tags)\n",
        "Y_1 = label_enc.transform(data['cSIN_tag'])\n",
        "Y_1 = to_categorical(Y_1)\n",
        "\n",
        "Y_2 = label_enc.transform(data['cEXC_tag'])\n",
        "Y_2 = to_categorical(Y_2)\n",
        "Y_3 = label_enc.transform(data['cCOM_tag'])\n",
        "Y_3 = to_categorical(Y_3)\n",
        "Y_4 = label_enc.transform(data['cRUG_tag'])\n",
        "# Y_rug = Y_4\n",
        "Y_4 = to_categorical(Y_4)\n",
        "Y_5 = label_enc.transform(data['cSOP_tag'])\n",
        "\n",
        "Y_5 = to_categorical(Y_5)\n",
        "\n",
        "#concatenating the binary laabels to for n_data_samples*10 (2 for each label [y or n])\n",
        "Y = np.concatenate((Y_1,Y_2,Y_3,Y_4,Y_5),axis=1)\n",
        "\n",
        "\n",
        "print(Y.shape)\n",
        "# for rugggedness only\n",
        "# sm = SMOTE(random_state=4991, n_jobs=8, ratio={1:2500, 0:2500})\n",
        "# new_X,new_Y = sm.fit_sample(X,Y_rug)\n",
        "# print(new_X.shape,new_Y.shape)\n",
        "# new_Y = to_categorical(np.reshape(new_Y,(-1,1)))\n",
        "###############\n",
        "\n",
        "#train test split 90% training and 10% validation \n",
        "train_X,test_X,train_Y,test_Y = train_test_split(X,Y,test_size = 0.1,random_state = 4991)\n",
        "\n",
        "print('Preparing embedding matrix')\n",
        "num_words = min(vocab_size,len(word_index))+1\n",
        "embedding_matrix = np.zeros((num_words,embedding_dim))\n",
        "\n",
        "for word,i in word_index.items():\n",
        "    if i > vocab_size:\n",
        "        continue\n",
        "\n",
        "    embedding_vector = embedding_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "\n",
        "\n",
        "embedding_layer = Embedding(num_words,\n",
        "                            embedding_dim,\n",
        "                            embeddings_initializer = Constant(embedding_matrix),\n",
        "                            input_length = max_len,\n",
        "                            trainable = False)\n",
        "\n",
        "#creating the cnn model\n",
        "\n",
        "sequence_input = Input(shape = (max_len,),dtype = 'int32')\n",
        "embedded_sequences = embedding_layer(sequence_input)\n",
        "x1 = Conv1D(64,1,activation = 'relu')(embedded_sequences)\n",
        "# x1 = GlobalMaxPooling1D()(x1)\n",
        "x2 = Conv1D(64,2,activation = 'relu')(embedded_sequences)\n",
        "# x2 = GlobalMaxPooling1D()(x2)\n",
        "x3 = Conv1D(64,3,activation = 'relu')(embedded_sequences)\n",
        "# x3 = GlobalMaxPooling1D()(x3)\n",
        "print(x1.shape,x2.shape,x3.shape)\n",
        "x = concatenate([x1,x2,x3],axis=1)\n",
        "print(x.shape)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Conv1D(128,3,activation = 'relu')(x)\n",
        "docvec = GlobalMaxPooling1D()(x)\n",
        "doc_model = Model(sequence_input,docvec)\n",
        "x = Dropout(0.4)(docvec)\n",
        "x = Dense(64,activation = 'relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "pred = Dense(2,activation = 'softmax')(x)\n",
        "model = Model(sequence_input,pred)\n",
        "# model.summary()\n",
        "\n",
        "adam = Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=0.0001, decay=0.0001)\n",
        "\n",
        "model.compile(loss = 'binary_crossentropy',optimizer = adam ,metrics = ['accuracy'])\n",
        "model.summary()\n",
        "a,b = 0,2\n",
        "model.fit(train_X,train_Y[:,a:b],batch_size = batch_size,epochs = 100,validation_data = (test_X,test_Y[:,a:b]))\n",
        "scores = model.evaluate(test_X, test_Y[:,a:b], verbose=0)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "plot_model(model, to_file='model.png',show_shapes = True)\n",
        "\n",
        "\n",
        "#saving the model\n",
        "model.save('my_model_cSIN_tag')\n",
        "doc_model.save('doc_model_cSIN')\n",
        "\n",
        "pred = model.predict(test_X)\n",
        "pred = pred.argmax(axis=1)\n",
        "    \n",
        "#printing the metrics\n",
        "c_matrix = confusion_matrix(test_Y[:,a:b].argmax(axis=1),pred)\n",
        "print(c_matrix)\n",
        "accuracy = accuracy_score(test_Y[:,a:b].argmax(axis=1),pred)\n",
        "print('Accuracy : ',accuracy)\n",
        "#precision = true positive / total predicted positive(True positive + False positive)\n",
        "#recall = true positive / total actual positive(True positive + False Negative)\n",
        "print(classification_report(test_Y[:,a:b].argmax(axis=1),pred))\n",
        "\n",
        "pickle_out = open(\"tokenizer.pickle\",\"wb\")\n",
        "pickle.dump(tokenizer, pickle_out)\n",
        "pickle_out.close()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: imblearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.6/dist-packages (from imblearn) (0.4.3)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn->imblearn) (0.21.2)\n",
            "Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn->imblearn) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn->imblearn) (1.16.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20->imbalanced-learn->imblearn) (0.13.2)\n",
            "(5000, 10)\n",
            "Preparing embedding matrix\n",
            "(?, 3000, 64) (?, 2999, 64) (?, 2998, 64)\n",
            "(?, 8997, 64)\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            (None, 3000)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_4 (Embedding)         (None, 3000, 300)    9000300     input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_13 (Conv1D)              (None, 3000, 64)     19264       embedding_4[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_14 (Conv1D)              (None, 2999, 64)     38464       embedding_4[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_15 (Conv1D)              (None, 2998, 64)     57664       embedding_4[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 8997, 64)     0           conv1d_13[0][0]                  \n",
            "                                                                 conv1d_14[0][0]                  \n",
            "                                                                 conv1d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 8997, 64)     0           concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_16 (Conv1D)              (None, 8995, 128)    24704       dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_4 (GlobalM (None, 128)          0           conv1d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 128)          0           global_max_pooling1d_4[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 64)           8256        dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 64)           0           dense_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 2)            130         dropout_12[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 9,148,782\n",
            "Trainable params: 148,482\n",
            "Non-trainable params: 9,000,300\n",
            "__________________________________________________________________________________________________\n",
            "Train on 4500 samples, validate on 500 samples\n",
            "Epoch 1/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.6614 - acc: 0.8087 - val_loss: 0.4612 - val_acc: 0.8300\n",
            "Epoch 2/100\n",
            "4500/4500 [==============================] - 8s 2ms/step - loss: 0.4710 - acc: 0.8202 - val_loss: 0.5033 - val_acc: 0.8300\n",
            "Epoch 3/100\n",
            "4500/4500 [==============================] - 8s 2ms/step - loss: 0.4462 - acc: 0.8202 - val_loss: 0.4297 - val_acc: 0.8300\n",
            "Epoch 4/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.4133 - acc: 0.8198 - val_loss: 0.3920 - val_acc: 0.8300\n",
            "Epoch 5/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.4082 - acc: 0.8244 - val_loss: 0.3788 - val_acc: 0.8300\n",
            "Epoch 6/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.3816 - acc: 0.8233 - val_loss: 0.3753 - val_acc: 0.8380\n",
            "Epoch 7/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.3558 - acc: 0.8333 - val_loss: 0.3600 - val_acc: 0.8400\n",
            "Epoch 8/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.3462 - acc: 0.8276 - val_loss: 0.3713 - val_acc: 0.8300\n",
            "Epoch 9/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.3557 - acc: 0.8204 - val_loss: 0.3924 - val_acc: 0.8300\n",
            "Epoch 10/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.3572 - acc: 0.8204 - val_loss: 0.4193 - val_acc: 0.8300\n",
            "Epoch 11/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.3197 - acc: 0.8393 - val_loss: 0.3668 - val_acc: 0.8580\n",
            "Epoch 12/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.3337 - acc: 0.8240 - val_loss: 0.3673 - val_acc: 0.8340\n",
            "Epoch 13/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.3254 - acc: 0.8391 - val_loss: 0.4097 - val_acc: 0.8460\n",
            "Epoch 14/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.3104 - acc: 0.8747 - val_loss: 0.3922 - val_acc: 0.8420\n",
            "Epoch 15/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.3155 - acc: 0.8622 - val_loss: 0.3845 - val_acc: 0.8280\n",
            "Epoch 16/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2937 - acc: 0.8742 - val_loss: 0.3802 - val_acc: 0.8280\n",
            "Epoch 17/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.3114 - acc: 0.8673 - val_loss: 0.3829 - val_acc: 0.8420\n",
            "Epoch 18/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.3072 - acc: 0.8640 - val_loss: 0.4167 - val_acc: 0.7900\n",
            "Epoch 19/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.3366 - acc: 0.8369 - val_loss: 0.4843 - val_acc: 0.8460\n",
            "Epoch 20/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.3182 - acc: 0.8427 - val_loss: 0.3922 - val_acc: 0.8320\n",
            "Epoch 21/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.3043 - acc: 0.8304 - val_loss: 0.4030 - val_acc: 0.8420\n",
            "Epoch 22/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.3006 - acc: 0.8604 - val_loss: 0.5685 - val_acc: 0.8420\n",
            "Epoch 23/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2971 - acc: 0.8804 - val_loss: 0.4778 - val_acc: 0.8480\n",
            "Epoch 24/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2671 - acc: 0.8762 - val_loss: 0.4820 - val_acc: 0.8420\n",
            "Epoch 25/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2769 - acc: 0.8811 - val_loss: 0.5270 - val_acc: 0.8420\n",
            "Epoch 26/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2973 - acc: 0.8713 - val_loss: 0.5402 - val_acc: 0.8420\n",
            "Epoch 27/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2911 - acc: 0.8742 - val_loss: 0.4184 - val_acc: 0.8060\n",
            "Epoch 28/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2564 - acc: 0.8862 - val_loss: 0.4403 - val_acc: 0.8380\n",
            "Epoch 29/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2358 - acc: 0.9022 - val_loss: 0.5151 - val_acc: 0.8340\n",
            "Epoch 30/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2614 - acc: 0.8918 - val_loss: 0.5661 - val_acc: 0.8400\n",
            "Epoch 31/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2543 - acc: 0.8907 - val_loss: 0.5327 - val_acc: 0.8360\n",
            "Epoch 32/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.3291 - acc: 0.8373 - val_loss: 0.6700 - val_acc: 0.8400\n",
            "Epoch 33/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2899 - acc: 0.8611 - val_loss: 0.5971 - val_acc: 0.8420\n",
            "Epoch 34/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2752 - acc: 0.8784 - val_loss: 0.6487 - val_acc: 0.8500\n",
            "Epoch 35/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2831 - acc: 0.8796 - val_loss: 0.4438 - val_acc: 0.8220\n",
            "Epoch 36/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2621 - acc: 0.8847 - val_loss: 0.4937 - val_acc: 0.8200\n",
            "Epoch 37/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2785 - acc: 0.8718 - val_loss: 0.4902 - val_acc: 0.8400\n",
            "Epoch 38/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2586 - acc: 0.8884 - val_loss: 0.5640 - val_acc: 0.8140\n",
            "Epoch 39/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2602 - acc: 0.8940 - val_loss: 0.4268 - val_acc: 0.8000\n",
            "Epoch 40/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2941 - acc: 0.8687 - val_loss: 0.5711 - val_acc: 0.8100\n",
            "Epoch 41/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2699 - acc: 0.8787 - val_loss: 0.5717 - val_acc: 0.7820\n",
            "Epoch 42/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2676 - acc: 0.8733 - val_loss: 0.6753 - val_acc: 0.8320\n",
            "Epoch 43/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2654 - acc: 0.8887 - val_loss: 0.5968 - val_acc: 0.8200\n",
            "Epoch 44/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2575 - acc: 0.8898 - val_loss: 0.5851 - val_acc: 0.8020\n",
            "Epoch 45/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2614 - acc: 0.8836 - val_loss: 0.7946 - val_acc: 0.8040\n",
            "Epoch 46/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2528 - acc: 0.8889 - val_loss: 0.6671 - val_acc: 0.8140\n",
            "Epoch 47/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2371 - acc: 0.8913 - val_loss: 0.6683 - val_acc: 0.8060\n",
            "Epoch 48/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2603 - acc: 0.8800 - val_loss: 0.8216 - val_acc: 0.8380\n",
            "Epoch 49/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2597 - acc: 0.8878 - val_loss: 0.7825 - val_acc: 0.8260\n",
            "Epoch 50/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2598 - acc: 0.8844 - val_loss: 0.6484 - val_acc: 0.8260\n",
            "Epoch 51/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2392 - acc: 0.8993 - val_loss: 0.7796 - val_acc: 0.8120\n",
            "Epoch 52/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2410 - acc: 0.8909 - val_loss: 0.8566 - val_acc: 0.8120\n",
            "Epoch 53/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2280 - acc: 0.9060 - val_loss: 0.8349 - val_acc: 0.8000\n",
            "Epoch 54/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2580 - acc: 0.8780 - val_loss: 0.8516 - val_acc: 0.8240\n",
            "Epoch 55/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2567 - acc: 0.8778 - val_loss: 0.7700 - val_acc: 0.8060\n",
            "Epoch 56/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2764 - acc: 0.8711 - val_loss: 0.7200 - val_acc: 0.8200\n",
            "Epoch 57/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2618 - acc: 0.8800 - val_loss: 1.3112 - val_acc: 0.8300\n",
            "Epoch 58/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2716 - acc: 0.8873 - val_loss: 0.6987 - val_acc: 0.7980\n",
            "Epoch 59/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2500 - acc: 0.8962 - val_loss: 0.9009 - val_acc: 0.8020\n",
            "Epoch 60/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2249 - acc: 0.9064 - val_loss: 0.7886 - val_acc: 0.8080\n",
            "Epoch 61/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2269 - acc: 0.8953 - val_loss: 0.8540 - val_acc: 0.8340\n",
            "Epoch 62/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2397 - acc: 0.8993 - val_loss: 0.8729 - val_acc: 0.8160\n",
            "Epoch 63/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2271 - acc: 0.9098 - val_loss: 0.8302 - val_acc: 0.8060\n",
            "Epoch 64/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2266 - acc: 0.9011 - val_loss: 0.8681 - val_acc: 0.8140\n",
            "Epoch 65/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2196 - acc: 0.9082 - val_loss: 0.7189 - val_acc: 0.7960\n",
            "Epoch 66/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2291 - acc: 0.9042 - val_loss: 0.7839 - val_acc: 0.8220\n",
            "Epoch 67/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2078 - acc: 0.9113 - val_loss: 0.9960 - val_acc: 0.8400\n",
            "Epoch 68/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2381 - acc: 0.8922 - val_loss: 0.8174 - val_acc: 0.7980\n",
            "Epoch 69/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2256 - acc: 0.9016 - val_loss: 0.9148 - val_acc: 0.8120\n",
            "Epoch 70/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2333 - acc: 0.9062 - val_loss: 0.8234 - val_acc: 0.8060\n",
            "Epoch 71/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2369 - acc: 0.8989 - val_loss: 0.8520 - val_acc: 0.8140\n",
            "Epoch 72/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2329 - acc: 0.8956 - val_loss: 0.8167 - val_acc: 0.8020\n",
            "Epoch 73/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2534 - acc: 0.8882 - val_loss: 0.8555 - val_acc: 0.8120\n",
            "Epoch 74/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2395 - acc: 0.8882 - val_loss: 0.8312 - val_acc: 0.8020\n",
            "Epoch 75/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2032 - acc: 0.9064 - val_loss: 0.9178 - val_acc: 0.8160\n",
            "Epoch 76/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2217 - acc: 0.9013 - val_loss: 1.0499 - val_acc: 0.8240\n",
            "Epoch 77/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2330 - acc: 0.8942 - val_loss: 1.0536 - val_acc: 0.8260\n",
            "Epoch 78/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2064 - acc: 0.9056 - val_loss: 1.0315 - val_acc: 0.8220\n",
            "Epoch 79/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2377 - acc: 0.8967 - val_loss: 0.8439 - val_acc: 0.8140\n",
            "Epoch 80/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2243 - acc: 0.9113 - val_loss: 0.9197 - val_acc: 0.8020\n",
            "Epoch 81/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2257 - acc: 0.9149 - val_loss: 0.9740 - val_acc: 0.8100\n",
            "Epoch 82/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2150 - acc: 0.9013 - val_loss: 1.0929 - val_acc: 0.8220\n",
            "Epoch 83/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2330 - acc: 0.9093 - val_loss: 1.0507 - val_acc: 0.8180\n",
            "Epoch 84/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2524 - acc: 0.9058 - val_loss: 1.1828 - val_acc: 0.8120\n",
            "Epoch 85/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2285 - acc: 0.8889 - val_loss: 1.2717 - val_acc: 0.8400\n",
            "Epoch 86/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2319 - acc: 0.9027 - val_loss: 1.0559 - val_acc: 0.8120\n",
            "Epoch 87/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2154 - acc: 0.8962 - val_loss: 0.9651 - val_acc: 0.8180\n",
            "Epoch 88/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2009 - acc: 0.9104 - val_loss: 1.2387 - val_acc: 0.8160\n",
            "Epoch 89/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2030 - acc: 0.9200 - val_loss: 1.0467 - val_acc: 0.8100\n",
            "Epoch 90/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2118 - acc: 0.9140 - val_loss: 1.3326 - val_acc: 0.8340\n",
            "Epoch 91/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2209 - acc: 0.9024 - val_loss: 1.1975 - val_acc: 0.8400\n",
            "Epoch 92/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.1932 - acc: 0.9178 - val_loss: 1.2575 - val_acc: 0.8220\n",
            "Epoch 93/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2307 - acc: 0.9018 - val_loss: 1.2774 - val_acc: 0.8160\n",
            "Epoch 94/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2030 - acc: 0.9178 - val_loss: 1.1849 - val_acc: 0.8120\n",
            "Epoch 95/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2219 - acc: 0.9040 - val_loss: 1.0431 - val_acc: 0.8080\n",
            "Epoch 96/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2104 - acc: 0.9056 - val_loss: 1.1676 - val_acc: 0.8260\n",
            "Epoch 97/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2021 - acc: 0.9080 - val_loss: 1.2091 - val_acc: 0.8160\n",
            "Epoch 98/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.1825 - acc: 0.9180 - val_loss: 1.2427 - val_acc: 0.8180\n",
            "Epoch 99/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.2009 - acc: 0.9160 - val_loss: 1.2349 - val_acc: 0.8300\n",
            "Epoch 100/100\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 0.1867 - acc: 0.9147 - val_loss: 1.0539 - val_acc: 0.8280\n",
            "acc: 82.80%\n",
            "[[368  47]\n",
            " [ 39  46]]\n",
            "Accuracy :  0.828\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.89      0.90       415\n",
            "           1       0.49      0.54      0.52        85\n",
            "\n",
            "    accuracy                           0.83       500\n",
            "   macro avg       0.70      0.71      0.71       500\n",
            "weighted avg       0.83      0.83      0.83       500\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJeB2ivs81M6",
        "colab_type": "code",
        "outputId": "639d1a8a-7097-479f-f725-0290d6511ba2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4602
        }
      },
      "source": [
        "#Preprocessing the ht_test data\n",
        "\n",
        "import os \n",
        "import numpy as np\n",
        "import csv\n",
        "import pandas as pd\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Model\n",
        "from keras.utils import to_categorical,plot_model\n",
        "from keras.layers import Activation, Dense, Dropout,Input,Add,concatenate\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split,StratifiedKFold\n",
        "from keras.layers import Conv1D,MaxPooling1D,Embedding,GlobalMaxPooling1D\n",
        "from keras.initializers import Constant\n",
        "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
        "import pickle\n",
        "from nltk.corpus import stopwords\n",
        "import os\n",
        "import nltk\n",
        "nltk.download('all')\n",
        "nltk.download('wordnet')\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "from keras.preprocessing.text import Tokenizer,text_to_word_sequence\n",
        "import re, string, unicodedata\n",
        "import contractions\n",
        "import inflect\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
        "\n",
        "\n",
        "#preprocessing methods\n",
        "def strip_html(text):\n",
        "    soup = BeautifulSoup(text, \"html.parser\")\n",
        "    return soup.get_text()\n",
        "\n",
        "def remove_between_square_brackets(text):\n",
        "    return re.sub('\\[[^]]*\\]', '', text)\n",
        "\n",
        "def denoise_text(text):\n",
        "    text = strip_html(text)\n",
        "    text = remove_between_square_brackets(text)\n",
        "    return text\n",
        "\n",
        "def replace_contractions(text):\n",
        "    \"\"\"Replace contractions in string of text\"\"\"\n",
        "    return contractions.fix(text)\n",
        "\n",
        "def remove_non_ascii(words):\n",
        "    \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "        new_words.append(new_word)\n",
        "    return new_words\n",
        "\n",
        "def to_lowercase(words):\n",
        "    \"\"\"Convert all characters to lowercase from list of tokenized words\"\"\"\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        new_word = word.lower()\n",
        "        new_words.append(new_word)\n",
        "    return new_words\n",
        "\n",
        "def remove_punctuation(words):\n",
        "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
        "        if new_word != '':\n",
        "            new_words.append(new_word)\n",
        "    return new_words\n",
        "\n",
        "def replace_numbers(words):\n",
        "    \"\"\"Replace all interger occurrences in list of tokenized words with textual representation\"\"\"\n",
        "    p = inflect.engine()\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        if word.isdigit():\n",
        "            new_word = p.number_to_words(word)\n",
        "            new_words.append(new_word)\n",
        "        else:\n",
        "            new_words.append(word)\n",
        "    return new_words\n",
        "\n",
        "def remove_stopwords(words):\n",
        "    \"\"\"Remove stop words from list of tokenized words\"\"\"\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        if word not in stopwords.words('english'):\n",
        "            new_words.append(word)\n",
        "    return new_words\n",
        "\n",
        "def stem_words(words):\n",
        "    \"\"\"Stem words in list of tokenized words\"\"\"\n",
        "    stemmer = LancasterStemmer()\n",
        "    stems = []\n",
        "    for word in words:\n",
        "        stem = stemmer.stem(word)\n",
        "        stems.append(stem)\n",
        "    return stems\n",
        "\n",
        "def lemmatize_verbs(words):\n",
        "    \"\"\"Lemmatize verbs in list of tokenized words\"\"\"\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemmas = []\n",
        "    for word in words:\n",
        "        lemma = lemmatizer.lemmatize(word, pos='v')\n",
        "        lemmas.append(lemma)\n",
        "    return lemmas\n",
        "\n",
        "def normalize(words):\n",
        "    words = remove_non_ascii(words)\n",
        "    words = to_lowercase(words)\n",
        "    words = remove_punctuation(words)\n",
        "    #words = replace_numbers(words)\n",
        "    words = remove_stopwords(words)\n",
        "    words = lemmatize_verbs(words)\n",
        "    return words\n",
        "# content/drive/My Drive/ML_Datasets/genData/ht4_essays_data_12thFeb.csv\n",
        "\n",
        "#path of the hr_test data\n",
        "test_path = '/content/drive/My Drive/ML_Datasets/genData/ht4_essays_data_12thFeb.csv'\n",
        "col_names = ['X.AUTHID','TEXT','cSIN','cEXC','cCOM','cRUG','cSOP']\n",
        "\n",
        "#reading the data\n",
        "reader = csv.DictReader(open(test_path,encoding='latin-1'))\n",
        "\n",
        "#creating the test data list\n",
        "datalist = []\n",
        "for raw in reader:\n",
        "    datalist.append((raw['X.AUTHID'],raw['TEXT'],raw['cSIN'],raw['cEXC'],raw['cCOM'],raw['cRUG'],raw['cSOP']))\n",
        "\n",
        "train_data = np.array(datalist)\n",
        "data = pd.DataFrame.from_records(datalist, columns=col_names)\n",
        "print(train_data.shape)\n",
        "\n",
        "pickle_out = open(\"ht_test_data.pickle\",\"wb\")\n",
        "pickle.dump(data, pickle_out)\n",
        "pickle_out.close()\n",
        "\n",
        "\n",
        "#preprocessing the texts\n",
        "words = []\n",
        "for texts in data['TEXT']:\n",
        "    text = denoise_text(texts)\n",
        "    text = replace_contractions(text)\n",
        "    word = nltk.word_tokenize(text)\n",
        "    word = normalize(word)\n",
        "    words.append(word)\n",
        "\n",
        "words = np.array(words)\n",
        "print(words.shape)\n",
        "new_text = []\n",
        "for i in range(len(words)):\n",
        "    text = \" \".join(str(x) for x in words[i])\n",
        "    new_text.append(text)\n",
        "\n",
        "print(len(new_text))\n",
        "\n",
        "\n",
        "#saving the test file\n",
        "pickle_out = open(\"ht_test_text.pickle\",\"wb\")\n",
        "pickle.dump(new_text, pickle_out)\n",
        "pickle_out.close()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Package abc is already up-to-date!\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Package alpino is already up-to-date!\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Package brown is already up-to-date!\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Package chat80 is already up-to-date!\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package city_database is already up-to-date!\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Package cmudict is already up-to-date!\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
            "[nltk_data]    |       date!\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    |   Package comtrans is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Package crubadan is already up-to-date!\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Package dolch is already up-to-date!\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Package floresta is already up-to-date!\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Package genesis is already up-to-date!\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Package ieer is already up-to-date!\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Package inaugural is already up-to-date!\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Package indian is already up-to-date!\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    |   Package jeita is already up-to-date!\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Package kimmo is already up-to-date!\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    |   Package knbc is already up-to-date!\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    |   Package machado is already up-to-date!\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Package names is already up-to-date!\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Package paradigms is already up-to-date!\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Package pil is already up-to-date!\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Package pl196x is already up-to-date!\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Package ppattach is already up-to-date!\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    |   Package propbank is already up-to-date!\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Package ptb is already up-to-date!\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Package qc is already up-to-date!\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    |   Package reuters is already up-to-date!\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Package rte is already up-to-date!\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    |   Package semcor is already up-to-date!\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Package senseval is already up-to-date!\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Package smultron is already up-to-date!\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Package state_union is already up-to-date!\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Package swadesh is already up-to-date!\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Package switchboard is already up-to-date!\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Package timit is already up-to-date!\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Package toolbox is already up-to-date!\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Package treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Package udhr is already up-to-date!\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n",
            "[nltk_data]    |       date!\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package verbnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Package verbnet3 is already up-to-date!\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Package webtext is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Package words is already up-to-date!\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Package ycoe is already up-to-date!\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Package rslp is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sample_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package spanish_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Package tagsets is already up-to-date!\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package word2vec_sample is already up-to-date!\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
            "[nltk_data]    |       up-to-date!\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package perluniprops is already up-to-date!\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Package porter_test is already up-to-date!\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Package wmt15_eval is already up-to-date!\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(500, 7)\n",
            "(500,)\n",
            "500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUjuf8oSTrpr",
        "colab_type": "code",
        "outputId": "e21cfedb-3565-400b-820e-b47d48a75f39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2486
        }
      },
      "source": [
        "# !wget https://dl.fbaipublicfiles.com/fasttext/data/cooking.stackexchange.tar.gz && tar xvzf cooking.stackexchange.tar.gz\n",
        "\n",
        "\n",
        "!git clone https://github.com/facebookresearch/fastText.git\n",
        "!cd fastText && mkdir build && cd build && cmake .. && make && make install\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'fastText'...\n",
            "remote: Enumerating objects: 2, done.\u001b[K\n",
            "remote: Counting objects:  50% (1/2)   \u001b[K\rremote: Counting objects: 100% (2/2)   \u001b[K\rremote: Counting objects: 100% (2/2), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 3197 (delta 0), reused 1 (delta 0), pack-reused 3195\n",
            "Receiving objects: 100% (3197/3197), 7.84 MiB | 32.25 MiB/s, done.\n",
            "Resolving deltas: 100% (2007/2007), done.\n",
            "-- The C compiler identification is GNU 7.4.0\n",
            "-- The CXX compiler identification is GNU 7.4.0\n",
            "-- Check for working C compiler: /usr/bin/cc\n",
            "-- Check for working C compiler: /usr/bin/cc -- works\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++\n",
            "-- Check for working CXX compiler: /usr/bin/c++ -- works\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- Configuring done\n",
            "-- Generating done\n",
            "-- Build files have been written to: /content/fastText/build\n",
            "\u001b[35m\u001b[1mScanning dependencies of target fasttext-static_pic\u001b[0m\n",
            "[  2%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-static_pic.dir/src/args.cc.o\u001b[0m\n",
            "[  4%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-static_pic.dir/src/densematrix.cc.o\u001b[0m\n",
            "[  6%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-static_pic.dir/src/dictionary.cc.o\u001b[0m\n",
            "[  9%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-static_pic.dir/src/fasttext.cc.o\u001b[0m\n",
            "\u001b[01m\u001b[K/content/fastText/src/fasttext.cc:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kvoid fasttext::FastText::quantize(const fasttext::Args&)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/fastText/src/fasttext.cc:323:45:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kstd::vector<int> fasttext::FastText::selectEmbeddings(int32_t) const\u001b[m\u001b[K’ is deprecated: selectEmbeddings is being deprecated. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     auto idx = selectEmbeddings(qargs.cutoff\u001b[01;35m\u001b[K)\u001b[m\u001b[K;\n",
            "                                             \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/fastText/src/fasttext.cc:293:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " std::vector<int32_t> \u001b[01;36m\u001b[KFastText\u001b[m\u001b[K::selectEmbeddings(int32_t cutoff) const {\n",
            "                      \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/fastText/src/fasttext.cc:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kvoid fasttext::FastText::lazyComputeWordVectors()\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/fastText/src/fasttext.cc:551:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid fasttext::FastText::precomputeWordVectors(fasttext::DenseMatrix&)\u001b[m\u001b[K’ is deprecated: precomputeWordVectors is being deprecated. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     precomputeWordVectors(*wordVectors_\u001b[01;35m\u001b[K)\u001b[m\u001b[K;\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/fastText/src/fasttext.cc:534:6:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " void \u001b[01;36m\u001b[KFastText\u001b[m\u001b[K::precomputeWordVectors(DenseMatrix& wordVectors) {\n",
            "      \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "[ 11%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-static_pic.dir/src/loss.cc.o\u001b[0m\n",
            "[ 13%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-static_pic.dir/src/main.cc.o\u001b[0m\n",
            "[ 15%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-static_pic.dir/src/matrix.cc.o\u001b[0m\n",
            "[ 18%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-static_pic.dir/src/meter.cc.o\u001b[0m\n",
            "[ 20%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-static_pic.dir/src/model.cc.o\u001b[0m\n",
            "[ 22%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-static_pic.dir/src/productquantizer.cc.o\u001b[0m\n",
            "[ 25%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-static_pic.dir/src/quantmatrix.cc.o\u001b[0m\n",
            "[ 27%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-static_pic.dir/src/utils.cc.o\u001b[0m\n",
            "[ 29%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-static_pic.dir/src/vector.cc.o\u001b[0m\n",
            "[ 31%] \u001b[32m\u001b[1mLinking CXX static library libfasttext_pic.a\u001b[0m\n",
            "[ 31%] Built target fasttext-static_pic\n",
            "\u001b[35m\u001b[1mScanning dependencies of target fasttext-static\u001b[0m\n",
            "[ 34%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-static.dir/src/args.cc.o\u001b[0m\n",
            "[ 36%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-static.dir/src/densematrix.cc.o\u001b[0m\n",
            "[ 38%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-static.dir/src/dictionary.cc.o\u001b[0m\n",
            "[ 40%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-static.dir/src/fasttext.cc.o\u001b[0m\n",
            "\u001b[01m\u001b[K/content/fastText/src/fasttext.cc:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kvoid fasttext::FastText::quantize(const fasttext::Args&)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/fastText/src/fasttext.cc:323:45:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kstd::vector<int> fasttext::FastText::selectEmbeddings(int32_t) const\u001b[m\u001b[K’ is deprecated: selectEmbeddings is being deprecated. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     auto idx = selectEmbeddings(qargs.cutoff\u001b[01;35m\u001b[K)\u001b[m\u001b[K;\n",
            "                                             \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/fastText/src/fasttext.cc:293:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " std::vector<int32_t> \u001b[01;36m\u001b[KFastText\u001b[m\u001b[K::selectEmbeddings(int32_t cutoff) const {\n",
            "                      \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/fastText/src/fasttext.cc:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kvoid fasttext::FastText::lazyComputeWordVectors()\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/fastText/src/fasttext.cc:551:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid fasttext::FastText::precomputeWordVectors(fasttext::DenseMatrix&)\u001b[m\u001b[K’ is deprecated: precomputeWordVectors is being deprecated. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     precomputeWordVectors(*wordVectors_\u001b[01;35m\u001b[K)\u001b[m\u001b[K;\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/fastText/src/fasttext.cc:534:6:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " void \u001b[01;36m\u001b[KFastText\u001b[m\u001b[K::precomputeWordVectors(DenseMatrix& wordVectors) {\n",
            "      \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "[ 43%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-static.dir/src/loss.cc.o\u001b[0m\n",
            "[ 45%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-static.dir/src/main.cc.o\u001b[0m\n",
            "[ 47%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-static.dir/src/matrix.cc.o\u001b[0m\n",
            "[ 50%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-static.dir/src/meter.cc.o\u001b[0m\n",
            "[ 52%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-static.dir/src/model.cc.o\u001b[0m\n",
            "[ 54%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-static.dir/src/productquantizer.cc.o\u001b[0m\n",
            "[ 56%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-static.dir/src/quantmatrix.cc.o\u001b[0m\n",
            "[ 59%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-static.dir/src/utils.cc.o\u001b[0m\n",
            "[ 61%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-static.dir/src/vector.cc.o\u001b[0m\n",
            "[ 63%] \u001b[32m\u001b[1mLinking CXX static library libfasttext.a\u001b[0m\n",
            "[ 63%] Built target fasttext-static\n",
            "\u001b[35m\u001b[1mScanning dependencies of target fasttext-bin\u001b[0m\n",
            "[ 65%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-bin.dir/src/main.cc.o\u001b[0m\n",
            "[ 68%] \u001b[32m\u001b[1mLinking CXX executable fasttext\u001b[0m\n",
            "[ 68%] Built target fasttext-bin\n",
            "\u001b[35m\u001b[1mScanning dependencies of target fasttext-shared\u001b[0m\n",
            "[ 70%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-shared.dir/src/args.cc.o\u001b[0m\n",
            "[ 72%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-shared.dir/src/densematrix.cc.o\u001b[0m\n",
            "[ 75%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-shared.dir/src/dictionary.cc.o\u001b[0m\n",
            "[ 77%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-shared.dir/src/fasttext.cc.o\u001b[0m\n",
            "\u001b[01m\u001b[K/content/fastText/src/fasttext.cc:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kvoid fasttext::FastText::quantize(const fasttext::Args&)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/fastText/src/fasttext.cc:323:45:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kstd::vector<int> fasttext::FastText::selectEmbeddings(int32_t) const\u001b[m\u001b[K’ is deprecated: selectEmbeddings is being deprecated. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     auto idx = selectEmbeddings(qargs.cutoff\u001b[01;35m\u001b[K)\u001b[m\u001b[K;\n",
            "                                             \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/fastText/src/fasttext.cc:293:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " std::vector<int32_t> \u001b[01;36m\u001b[KFastText\u001b[m\u001b[K::selectEmbeddings(int32_t cutoff) const {\n",
            "                      \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/fastText/src/fasttext.cc:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kvoid fasttext::FastText::lazyComputeWordVectors()\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/fastText/src/fasttext.cc:551:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid fasttext::FastText::precomputeWordVectors(fasttext::DenseMatrix&)\u001b[m\u001b[K’ is deprecated: precomputeWordVectors is being deprecated. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     precomputeWordVectors(*wordVectors_\u001b[01;35m\u001b[K)\u001b[m\u001b[K;\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/fastText/src/fasttext.cc:534:6:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " void \u001b[01;36m\u001b[KFastText\u001b[m\u001b[K::precomputeWordVectors(DenseMatrix& wordVectors) {\n",
            "      \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "[ 79%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-shared.dir/src/loss.cc.o\u001b[0m\n",
            "[ 81%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-shared.dir/src/main.cc.o\u001b[0m\n",
            "[ 84%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-shared.dir/src/matrix.cc.o\u001b[0m\n",
            "[ 86%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-shared.dir/src/meter.cc.o\u001b[0m\n",
            "[ 88%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-shared.dir/src/model.cc.o\u001b[0m\n",
            "[ 90%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-shared.dir/src/productquantizer.cc.o\u001b[0m\n",
            "[ 93%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-shared.dir/src/quantmatrix.cc.o\u001b[0m\n",
            "[ 95%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-shared.dir/src/utils.cc.o\u001b[0m\n",
            "[ 97%] \u001b[32mBuilding CXX object CMakeFiles/fasttext-shared.dir/src/vector.cc.o\u001b[0m\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX shared library libfasttext.so\u001b[0m\n",
            "[100%] Built target fasttext-shared\n",
            "[ 31%] Built target fasttext-static_pic\n",
            "[ 63%] Built target fasttext-static\n",
            "[ 68%] Built target fasttext-bin\n",
            "[100%] Built target fasttext-shared\n",
            "\u001b[36mInstall the project...\u001b[0m\n",
            "-- Install configuration: \"\"\n",
            "-- Installing: /usr/local/lib/libfasttext.so\n",
            "-- Installing: /usr/local/lib/libfasttext.a\n",
            "-- Installing: /usr/local/lib/libfasttext_pic.a\n",
            "-- Installing: /usr/local/bin/fasttext\n",
            "-- Installing: /usr/local/include/fasttext/args.h\n",
            "-- Installing: /usr/local/include/fasttext/densematrix.h\n",
            "-- Installing: /usr/local/include/fasttext/dictionary.h\n",
            "-- Installing: /usr/local/include/fasttext/fasttext.h\n",
            "-- Installing: /usr/local/include/fasttext/loss.h\n",
            "-- Installing: /usr/local/include/fasttext/matrix.h\n",
            "-- Installing: /usr/local/include/fasttext/meter.h\n",
            "-- Installing: /usr/local/include/fasttext/model.h\n",
            "-- Installing: /usr/local/include/fasttext/productquantizer.h\n",
            "-- Installing: /usr/local/include/fasttext/quantmatrix.h\n",
            "-- Installing: /usr/local/include/fasttext/real.h\n",
            "-- Installing: /usr/local/include/fasttext/utils.h\n",
            "-- Installing: /usr/local/include/fasttext/vector.h\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApJm2viWVxs8",
        "colab_type": "code",
        "outputId": "c7895c90-f0d6-4ad8-d51d-cb5d5ab3606d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "! cd fastText/build && ./fasttext supervised -input /content/cSIN_text.txt -output /content/model_cSIN2 -lr 0.5 -epoch 50 -wordNgrams 3,5 -minCount 2 -ws 20 -loss softmax -verbose 2 -dim 100\n",
        "! cd fastText/build && ./fasttext supervised -input /content/cEXC_text.txt -output /content/model_cEXC2 -lr 0.5 -epoch 50 -wordNgrams 3,5 -minCount 2 -ws 20 -loss softmax -verbose 2 -dim 100\n",
        "! cd fastText/build && ./fasttext supervised -input /content/cCOM_text.txt -output /content/model_cCOM2 -lr 0.5 -epoch 50 -wordNgrams 3,5 -minCount 2 -ws 20 -loss softmax -verbose 2 -dim 100\n",
        "! cd fastText/build && ./fasttext supervised -input /content/cSOP_text.txt -output /content/model_cSOP2 -lr 0.5 -epoch 50 -wordNgrams 3,5 -minCount 2 -ws 20 -loss softmax -verbose 2 -dim 100\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Read 13M words\n",
            "Number of words:  204856\n",
            "Number of labels: 2\n",
            "Progress: 100.0% words/sec/thread:   69233 lr:  0.000000 loss:  0.031816 ETA:   0h 0m\n",
            "Read 13M words\n",
            "Number of words:  204856\n",
            "Number of labels: 2\n",
            "Progress: 100.0% words/sec/thread:   69903 lr:  0.000000 loss:  0.024041 ETA:   0h 0m\n",
            "Read 13M words\n",
            "Number of words:  204856\n",
            "Number of labels: 2\n",
            "Progress: 100.0% words/sec/thread:   70381 lr:  0.000000 loss:  0.039233 ETA:   0h 0m\n",
            "Read 13M words\n",
            "Number of words:  204856\n",
            "Number of labels: 2\n",
            "Progress: 100.0% words/sec/thread:   70240 lr:  0.000000 loss:  0.033728 ETA:   0h 0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRPX16E850uN",
        "colab_type": "code",
        "outputId": "c29e2a42-a4c5-4e57-f0ba-2171a51f3168",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "! cd fastText/build && ./fasttext test /content/model_cSIN.bin /content/cSIN_heldout_text.txt 1\n",
        "\n",
        "! cd fastText/build && ./fasttext test /content/model_cEXC.bin /content/cEXC_heldout_text.txt 1\n",
        "\n",
        "! cd fastText/build && ./fasttext test /content/model_cCOM.bin /content/cCOM_heldout_text.txt 1\n",
        "\n",
        "! cd fastText/build && ./fasttext test /content/model_cSOP.bin /content/cSOP_heldout_text.txt 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "N\t336\n",
            "P@1\t0.286\n",
            "R@1\t0.286\n",
            "N\t336\n",
            "P@1\t0.396\n",
            "R@1\t0.396\n",
            "N\t336\n",
            "P@1\t0.244\n",
            "R@1\t0.244\n",
            "N\t336\n",
            "P@1\t0.622\n",
            "R@1\t0.622\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTvkqot288ak",
        "colab_type": "code",
        "outputId": "cec43a32-0eb4-4875-8d37-832ecc67be70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "! cd fastText/build && ./fasttext test /content/model_cSIN.bin /content/cSIN_ht_text.txt 1\n",
        "\n",
        "! cd fastText/build && ./fasttext test /content/model_cEXC.bin /content/cEXC_ht_text.txt 1\n",
        "\n",
        "! cd fastText/build && ./fasttext test /content/model_cCOM.bin /content/cCOM_ht_text.txt 1\n",
        "\n",
        "! cd fastText/build && ./fasttext test /content/model_cSOP.bin /content/cSOP_ht_text.txt 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "N\t500\n",
            "P@1\t0.374\n",
            "R@1\t0.374\n",
            "N\t500\n",
            "P@1\t0.458\n",
            "R@1\t0.458\n",
            "N\t500\n",
            "P@1\t0.272\n",
            "R@1\t0.272\n",
            "N\t500\n",
            "P@1\t0.674\n",
            "R@1\t0.674\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPBgpL891IR9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os \n",
        "import csv\n",
        "train_path =  '/content/drive/My Drive/ML_Datasets/genData/MTdata'\n",
        "col_names = ['X.AUTHID','site.content','cSIN_tag','cEXC_tag','cCOM_tag','cRUG_tag','cSOP_tag']\n",
        "file_names = ['com_mt_essays_16thMay.csv','exc_mt_essays_16thMay.csv','sinc_mt_essays_16thMay.csv','sop_mt_essays_16thMay.csv']\n",
        "x = 0\n",
        "n_writes = 0\n",
        "for files in os.listdir(train_path):\n",
        "    if files in file_names:\n",
        "        reader = csv.DictReader(open(train_path+'/'+files,encoding='latin-1'))\n",
        "        \n",
        "        for raw in reader:\n",
        "            if x == 0:\n",
        "                with open('cSIN_text.txt','w') as f:\n",
        "                    f.write('__label__SINC'+raw['cSIN_tag']+' '+raw['site.content']+'\\n')\n",
        "                    n_writes += 1\n",
        "                x+=1\n",
        "            else:\n",
        "                with open('cSIN_text.txt','a') as f:\n",
        "                    f.write('__label__SINC'+raw['cSIN_tag']+' '+raw['site.content']+'\\n')\n",
        "                    n_writes += 1\n",
        "x = 0                   \n",
        "for files in os.listdir(train_path):\n",
        "    if files in file_names:\n",
        "        reader = csv.DictReader(open(train_path+'/'+files,encoding='latin-1'))\n",
        "        \n",
        "        for raw in reader:\n",
        "            if x == 0:\n",
        "                with open('cEXC_text.txt','w') as f:\n",
        "                    f.write('__label__EXC'+raw['cEXC_tag']+' '+raw['site.content']+'\\n')\n",
        "                    x+=1\n",
        "            else:\n",
        "                with open('cEXC_text.txt','a') as f:\n",
        "                    f.write('__label__EXC'+raw['cEXC_tag']+' '+raw['site.content']+'\\n')\n",
        "x = 0                    \n",
        "\n",
        "for files in os.listdir(train_path):\n",
        "    if files in file_names:\n",
        "        reader = csv.DictReader(open(train_path+'/'+files,encoding='latin-1'))\n",
        "        \n",
        "        for raw in reader:\n",
        "            if x == 0:\n",
        "                with open('cCOM_text.txt','w') as f:\n",
        "                    f.write('__label__COM'+raw['cCOM_tag']+' '+raw['site.content']+'\\n')\n",
        "                    x+=1\n",
        "            else:\n",
        "                with open('cCOM_text.txt','a') as f:\n",
        "                    f.write('__label__COM'+raw['cCOM_tag']+' '+raw['site.content']+'\\n')\n",
        "\n",
        "x=0\n",
        "for files in os.listdir(train_path):\n",
        "    if files in file_names:\n",
        "        reader = csv.DictReader(open(train_path+'/'+files,encoding='latin-1'))\n",
        "        \n",
        "        for raw in reader:\n",
        "            if x == 0:\n",
        "                with open('cSOP_text.txt','w') as f:\n",
        "                    f.write('__label__SOP'+raw['cSOP_tag']+' '+raw['site.content']+'\\n')\n",
        "                    x+=1\n",
        "            else:\n",
        "                with open('cSOP_text.txt','a') as f:\n",
        "                    f.write('__label__SOP'+raw['cSOP_tag']+' '+raw['site.content']+'\\n')\n",
        "                    \n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgkaOvSA68lK",
        "colab_type": "code",
        "outputId": "bc2a5777-c26d-4ec3-f55f-a57c873c9a23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "heldout_test_path = '/content/drive/My Drive/ML_Datasets/genData/heldout_essays_16thMay.csv'\n",
        "\n",
        "col_names = ['X.AUTHID','TEXT','cSIN','cEXC','cCOM','cRUG','cSOP']\n",
        "\n",
        "reader = csv.DictReader(open(heldout_test_path,encoding='latin-1'))\n",
        "x = 0\n",
        "for raw in reader:\n",
        "    if x == 0:\n",
        "        with open('cSIN_heldout_text.txt','w') as f:\n",
        "            f.write('__label__SINC'+raw['cSIN']+' '+raw['TEXT']+'\\n')\n",
        "        with open('cEXC_heldout_text.txt','w') as f:\n",
        "            f.write('__label__EXC'+raw['cEXC']+' '+raw['TEXT']+'\\n')\n",
        "        with open('cCOM_heldout_text.txt','w') as f:\n",
        "            f.write('__label__COM'+raw['cCOM']+' '+raw['TEXT']+'\\n')\n",
        "        with open('cSOP_heldout_text.txt','w') as f:\n",
        "            f.write('__label__SOP'+raw['cSOP']+' '+raw['TEXT']+'\\n')\n",
        "        x+=1\n",
        "    else:\n",
        "        with open('cSIN_heldout_text.txt','a') as f:\n",
        "            f.write('__label__SINC'+raw['cSIN']+' '+raw['TEXT']+'\\n')\n",
        "        with open('cEXC_heldout_text.txt','a') as f:\n",
        "            f.write('__label__EXC'+raw['cEXC']+' '+raw['TEXT']+'\\n')\n",
        "        with open('cCOM_heldout_text.txt','a') as f:\n",
        "            f.write('__label__COM'+raw['cCOM']+' '+raw['TEXT']+'\\n')\n",
        "        with open('cSOP_heldout_text.txt','a') as f:\n",
        "            f.write('__label__SOP'+raw['cSOP']+' '+raw['TEXT']+'\\n')\n",
        "            \n",
        "print(x)\n",
        "print('Done')\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URpgRAv28eue",
        "colab_type": "code",
        "outputId": "adb601e8-6372-44b0-e3a3-0e68170df946",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "ht_test_path = '/content/drive/My Drive/ML_Datasets/genData/ht4_essays_data_12thFeb.csv'\n",
        "\n",
        "col_names = ['X.AUTHID','TEXT','cSIN','cEXC','cCOM','cRUG','cSOP']\n",
        "\n",
        "reader = csv.DictReader(open(ht_test_path,encoding='latin-1'))\n",
        "x = 0\n",
        "for raw in reader:\n",
        "    if x == 0:\n",
        "        with open('cSIN_ht_text.txt','w') as f:\n",
        "            f.write('__label__SINC'+raw['cSIN']+' '+raw['TEXT']+'\\n')\n",
        "        with open('cEXC_ht_text.txt','w') as f:\n",
        "            f.write('__label__EXC'+raw['cEXC']+' '+raw['TEXT']+'\\n')\n",
        "        with open('cCOM_ht_text.txt','w') as f:\n",
        "            f.write('__label__COM'+raw['cCOM']+' '+raw['TEXT']+'\\n')\n",
        "        with open('cSOP_ht_text.txt','w') as f:\n",
        "            f.write('__label__SOP'+raw['cSOP']+' '+raw['TEXT']+'\\n')\n",
        "        x+=1\n",
        "    else:\n",
        "        with open('cSIN_ht_text.txt','a') as f:\n",
        "            f.write('__label__SINC'+raw['cSIN']+' '+raw['TEXT']+'\\n')\n",
        "        with open('cEXC_ht_text.txt','a') as f:\n",
        "            f.write('__label__EXC'+raw['cEXC']+' '+raw['TEXT']+'\\n')\n",
        "        with open('cCOM_ht_text.txt','a') as f:\n",
        "            f.write('__label__COM'+raw['cCOM']+' '+raw['TEXT']+'\\n')\n",
        "        with open('cSOP_ht_text.txt','a') as f:\n",
        "            f.write('__label__SOP'+raw['cSOP']+' '+raw['TEXT']+'\\n')\n",
        "            \n",
        "print(x)\n",
        "print('Done')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcOv3VOn61md",
        "colab_type": "code",
        "outputId": "d6d99a56-83a4-424e-ce83-fe681d9296e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        }
      },
      "source": [
        "\n",
        "!pip install pyfasttext\n",
        "from pyfasttext import FastText\n",
        "\n",
        "model1 = FastText()\n",
        "model1.supervised(input='cSIN_text.txt', output='model_cSIN', epoch=100, lr=1.0,wordNgrams=2,loss='softmax',dim=100)\n",
        "print('Done')\n",
        "model2 = FastText()\n",
        "model2.supervised(input='cEXC_text.txt', output='model_cEXC', epoch=100, lr=1.0,wordNgrams=2,loss='softmax',dim=100)\n",
        "print('Done')\n",
        "model3 = FastText()\n",
        "model3.supervised(input='cCOM_text.txt', output='model_cCOM', epoch=100, lr=1.0,wordNgrams=2,loss='softmax',dim=100)\n",
        "print('Done')\n",
        "model4 = FastText()\n",
        "model4.supervised(input='cSOP_text.txt', output='model_cSOP', epoch=100, lr=1.0,wordNgrams=2,loss='softmax',dim=100)\n",
        "print('Done')\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyfasttext\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/ef/90606442481d1e4ab10eba8c2b2c449ceaa70c60e9b8d5898bb7504e3634/pyfasttext-0.4.6.tar.gz (244kB)\n",
            "\r\u001b[K     |█▍                              | 10kB 17.8MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20kB 7.1MB/s eta 0:00:01\r\u001b[K     |████                            | 30kB 9.9MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 40kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 51kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████                        | 61kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 71kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 81kB 10.6MB/s eta 0:00:01\r\u001b[K     |████████████                    | 92kB 11.7MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 102kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 112kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████████                | 122kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 133kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 143kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 153kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 163kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 174kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 184kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 194kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 204kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 215kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 225kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 235kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 245kB 9.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyfasttext) (0.16.0)\n",
            "Requirement already satisfied: cysignals in /usr/local/lib/python3.6/dist-packages (from pyfasttext) (1.10.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pyfasttext) (1.16.3)\n",
            "Requirement already satisfied: Cython>=0.28 in /usr/local/lib/python3.6/dist-packages (from cysignals->pyfasttext) (0.29.7)\n",
            "Building wheels for collected packages: pyfasttext\n",
            "  Building wheel for pyfasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/de/c6/3d26a304c069689a7bf5ef2cc774588663700c8381dbf3d947\n",
            "Successfully built pyfasttext\n",
            "Installing collected packages: pyfasttext\n",
            "Successfully installed pyfasttext-0.4.6\n",
            "Done\n",
            "Done\n",
            "Done\n",
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YA0sc809QAkR",
        "colab_type": "code",
        "outputId": "de789a79-abec-4d4c-abd2-bd2675191535",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1218
        }
      },
      "source": [
        "!pip install pyfasttext\n",
        "from pyfasttext import FastText\n",
        "import csv\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "import pandas as pd\n",
        "# from sklearn.utils import to_categorical\n",
        "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix,precision_score,f1_score\n",
        "\n",
        "sin_model = FastText('model_cSIN2.bin')\n",
        "exc_model = FastText('model_cEXC2.bin')\n",
        "com_model = FastText('model_cCOM2.bin')\n",
        "sop_model = FastText('model_cSOP2.bin')\n",
        "heldout_test_path = '/content/drive/My Drive/ML_Datasets/genData/heldout_essays_16thMay.csv'\n",
        "reader = csv.DictReader(open(heldout_test_path,encoding='latin-1'))\n",
        "\n",
        "\n",
        "output = []\n",
        "data = []\n",
        "col_names = ['X.AUTHID','TEXT','cSIN','cEXC','cCOM','cRUG','cSOP']\n",
        "for raw in reader:\n",
        "    output.append(sin_model.predict_single(raw['TEXT'],k=1)[0])\n",
        "    data.append((raw['X.AUTHID'],raw['TEXT'],raw['cSIN'],raw['cEXC'],raw['cCOM'],raw['cRUG'],raw['cSOP']))\n",
        "\n",
        "\n",
        "data = pd.DataFrame.from_records(data, columns=col_names)\n",
        "\n",
        "tags = ['SINCn','SINCy']\n",
        "label_enc = LabelBinarizer()\n",
        "label_enc.fit(tags)\n",
        "pred_Y = label_enc.transform(output)\n",
        "\n",
        "\n",
        "tags = ['n','y']\n",
        "label_enc = LabelBinarizer()\n",
        "label_enc.fit(tags)\n",
        "actual_Y = label_enc.transform(data['cSIN'])\n",
        "\n",
        "c_matrix = confusion_matrix(actual_Y,pred_Y)\n",
        "print(c_matrix)\n",
        "accuracy = accuracy_score(actual_Y,pred_Y)\n",
        "precision = precision_score(actual_Y,pred_Y)\n",
        "f = f1_score(actual_Y,pred_Y)\n",
        "print('Accuracy : ',accuracy)\n",
        "print('Precision : ',precision)\n",
        "print('F1_score : ',f)\n",
        "#precision = true positive / total predicted positive(True positive + False positive)\n",
        "#recall = true positive / total actual positive(True positive + False Negative)\n",
        "print(classification_report(actual_Y,pred_Y))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for raw in reader:\n",
        "    output.append(exc_model.predict_single(raw['TEXT'],k=1)[0])\n",
        "    \n",
        "tags = ['EXCn','EXCy']\n",
        "label_enc = LabelBinarizer()\n",
        "label_enc.fit(tags)\n",
        "pred_Y = label_enc.transform(output)\n",
        "\n",
        "#concatenating the binary labels to for n_data_samples*10 (2 for each label [y or n])\n",
        "tags = ['n','y']\n",
        "label_enc = LabelBinarizer()\n",
        "label_enc.fit(tags)\n",
        "actual_Y = label_enc.transform(data['cEXC'])\n",
        "\n",
        "c_matrix = confusion_matrix(actual_Y,pred_Y)\n",
        "print(c_matrix)\n",
        "accuracy = accuracy_score(actual_Y,pred_Y)\n",
        "precision = precision_score(actual_Y,pred_Y)\n",
        "f = f1_score(actual_Y,pred_Y)\n",
        "print('Accuracy : ',accuracy)\n",
        "print('Precision : ',precision)\n",
        "print('F1_score : ',f)\n",
        "#precision = true positive / total predicted positive(True positive + False positive)\n",
        "#recall = true positive / total actual positive(True positive + False Negative)\n",
        "print(classification_report(actual_Y,pred_Y))\n",
        "\n",
        "for raw in reader:\n",
        "    output.append(com_model.predict_single(raw['TEXT'],k=1)[0])\n",
        "    \n",
        "tags = ['COMn','COMy']\n",
        "label_enc = LabelBinarizer()\n",
        "label_enc.fit(tags)\n",
        "pred_Y = label_enc.transform(output)\n",
        "\n",
        "\n",
        "tags = ['n','y']\n",
        "label_enc = LabelBinarizer()\n",
        "label_enc.fit(tags)\n",
        "actual_Y = label_enc.transform(data['cCOM'])\n",
        "\n",
        "c_matrix = confusion_matrix(actual_Y,pred_Y)\n",
        "print(c_matrix)\n",
        "accuracy = accuracy_score(actual_Y,pred_Y)\n",
        "precision = precision_score(actual_Y,pred_Y)\n",
        "f = f1_score(actual_Y,pred_Y)\n",
        "print('Accuracy : ',accuracy)\n",
        "print('Precision : ',precision)\n",
        "print('F1_score : ',f)\n",
        "#precision = true positive / total predicted positive(True positive + False positive)\n",
        "#recall = true positive / total actual positive(True positive + False Negative)\n",
        "print(classification_report(actual_Y,pred_Y))\n",
        "\n",
        "for raw in reader:\n",
        "    output.append(sop_model.predict_single(raw['TEXT'],k=1)[0])\n",
        "    \n",
        "tags = ['SOPn','SOPy']\n",
        "label_enc = LabelBinarizer()\n",
        "label_enc.fit(tags)\n",
        "pred_Y = label_enc.transform(output)\n",
        "\n",
        "\n",
        "tags = ['n','y']\n",
        "label_enc = LabelBinarizer()\n",
        "label_enc.fit(tags)\n",
        "actual_Y = label_enc.transform(data['cSOP'])\n",
        "\n",
        "c_matrix = confusion_matrix(actual_Y,pred_Y)\n",
        "print(c_matrix)\n",
        "accuracy = accuracy_score(actual_Y,pred_Y)\n",
        "precision = precision_score(actual_Y,pred_Y)\n",
        "f = f1_score(actual_Y,pred_Y)\n",
        "print('Accuracy : ',accuracy)\n",
        "print('Precision : ',precision)\n",
        "print('F1_score : ',f)\n",
        "#precision = true positive / total predicted positive(True positive + False positive)\n",
        "#recall = true positive / total actual positive(True positive + False Negative)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyfasttext in /usr/local/lib/python3.6/dist-packages (0.4.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pyfasttext) (1.16.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyfasttext) (0.16.0)\n",
            "Requirement already satisfied: cysignals in /usr/local/lib/python3.6/dist-packages (from pyfasttext) (1.10.2)\n",
            "Requirement already satisfied: Cython>=0.28 in /usr/local/lib/python3.6/dist-packages (from cysignals->pyfasttext) (0.29.7)\n",
            "[[ 66   1]\n",
            " [263 170]]\n",
            "Accuracy :  0.472\n",
            "Precision :  0.9941520467836257\n",
            "F1_score :  0.5629139072847683\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.20      0.99      0.33        67\n",
            "           1       0.99      0.39      0.56       433\n",
            "\n",
            "    accuracy                           0.47       500\n",
            "   macro avg       0.60      0.69      0.45       500\n",
            "weighted avg       0.89      0.47      0.53       500\n",
            "\n",
            "[[161   0]\n",
            " [339   0]]\n",
            "Accuracy :  0.322\n",
            "Precision :  0.0\n",
            "F1_score :  0.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.32      1.00      0.49       161\n",
            "           1       0.00      0.00      0.00       339\n",
            "\n",
            "    accuracy                           0.32       500\n",
            "   macro avg       0.16      0.50      0.24       500\n",
            "weighted avg       0.10      0.32      0.16       500\n",
            "\n",
            "[[ 30   0]\n",
            " [470   0]]\n",
            "Accuracy :  0.06\n",
            "Precision :  0.0\n",
            "F1_score :  0.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.06      1.00      0.11        30\n",
            "           1       0.00      0.00      0.00       470\n",
            "\n",
            "    accuracy                           0.06       500\n",
            "   macro avg       0.03      0.50      0.06       500\n",
            "weighted avg       0.00      0.06      0.01       500\n",
            "\n",
            "[[224   0]\n",
            " [276   0]]\n",
            "Accuracy :  0.448\n",
            "Precision :  0.0\n",
            "F1_score :  0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQKuTTNf97Kw",
        "colab_type": "code",
        "outputId": "790293a5-0063-4fab-f16d-0b5aed821633",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137008
        }
      },
      "source": [
        "#transfer learning\n",
        "import os \n",
        "import numpy as np\n",
        "import csv\n",
        "import pandas as pd\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Model,load_model,Sequential\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Activation, Dense, Dropout,Input,Add,concatenate\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split,StratifiedKFold\n",
        "from keras.layers import Conv1D,MaxPooling1D,Embedding,GlobalMaxPooling1D\n",
        "from keras.initializers import Constant\n",
        "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix,precision_score,recall_score,f1_score\n",
        "import pickle\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "\n",
        "vocab_size = 30000\n",
        "batch_size = 25\n",
        "embedding_dim = 300\n",
        "max_len = 3000\n",
        "\n",
        "#loading the ht_test pickle\n",
        "pickle_in = open(\"ht_test_text.pickle\",\"rb\")\n",
        "X = pickle.load(pickle_in)\n",
        "\n",
        "pickle_in = open(\"ht_test_data.pickle\",\"rb\")\n",
        "data = pickle.load(pickle_in)\n",
        "\n",
        "\n",
        "# pickle_in = open(\"tokenizer.pickle\",\"rb\")\n",
        "# tokenizer = pickle.load(pickle_in)\n",
        "tokenizer = Tokenizer(num_words = vocab_size)\n",
        "tokenizer.fit_on_texts(X)\n",
        "word_index = tokenizer.word_index\n",
        "train_sentences_tokenized = tokenizer.texts_to_sequences(X)\n",
        "\n",
        "X = pad_sequences(train_sentences_tokenized, maxlen=max_len)\n",
        "\n",
        "tags = ['y','n']\n",
        "\n",
        "#concatenating the binary labels to for n_data_samples*10 (2 for each label [y or n])\n",
        "label_enc = LabelBinarizer()\n",
        "label_enc.fit(tags)\n",
        "Y_1 = label_enc.transform(data['cSIN'])\n",
        "Y_1 = to_categorical(Y_1)\n",
        "\n",
        "Y_2 = label_enc.transform(data['cEXC'])\n",
        "Y_2 = to_categorical(Y_2)\n",
        "\n",
        "Y_3 = label_enc.transform(data['cCOM'])\n",
        "Y_3 = to_categorical(Y_3)\n",
        "\n",
        "Y_4 = label_enc.transform(data['cRUG'])\n",
        "Y_4 = to_categorical(Y_4)\n",
        "\n",
        "Y_5 = label_enc.transform(data['cSOP'])\n",
        "Y_5 = to_categorical(Y_5)\n",
        "\n",
        "Y = np.concatenate((Y_1,Y_2,Y_3,Y_4,Y_5),axis=1)\n",
        "print(Y.shape)\n",
        "\n",
        "\n",
        "\n",
        "# 'cSIN','cEXC','cCOM','cRUG','cSOP'\n",
        "\n",
        "#7-fold validation, 6/7 for transfer learning and 1/7 for testing \n",
        "kfold = StratifiedKFold(n_splits=7, shuffle=True, random_state=4991)\n",
        "acscores1 = []\n",
        "acscores2 = []\n",
        "acscores3 = []\n",
        "acscores4 = []\n",
        "acscores5 = []\n",
        "\n",
        "prescores1 = []\n",
        "prescores2 = []\n",
        "prescores3 = []\n",
        "prescores4 = []\n",
        "prescores5 = []\n",
        "\n",
        "rescores1 = []\n",
        "rescores2 = []\n",
        "rescores3 = []\n",
        "rescores4 = []\n",
        "rescores5 = []\n",
        "fscores1 = []\n",
        "fscores2 = []\n",
        "fscores3 = []\n",
        "fscores4 = []\n",
        "fscores5 = []\n",
        "\n",
        "#loading the models\n",
        "model1 = load_model('my_model_cSIN_tag')\n",
        "\n",
        "model2 = load_model('my_model_cEXC_tag')\n",
        "model3 = load_model('my_model_cCOM_tag')\n",
        "model4 = load_model('my_model_cSOP_tag')\n",
        "model5 = load_model('my_model_cRUG_tag')\n",
        "a,b = 0,2\n",
        "\n",
        "#transfer learning on all the personality traits\n",
        "print('\\n\\nSincerity')\n",
        "    \n",
        "for train, test in kfold.split(X, Y[:,a:b].argmax(axis=1)):\n",
        "    for layer in model1.layers[:-3]:\n",
        "        layer.trainable = False\n",
        "    model = Sequential()\n",
        "    model.add(model1)\n",
        "    model.summary()\n",
        "    adam = Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=0.0001, decay=0.0001)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy']) \n",
        "    model.fit(X[train],Y[train,a:b],epochs = 100,batch_size = batch_size,validation_data = (X[test],Y[test,a:b]))\n",
        "    model.save('DL_Final_SIN2')\n",
        "    pred = model.predict(X[test])\n",
        "    pred = pred.argmax(axis=1)\n",
        "    c_matrix = confusion_matrix(Y[test,a:b].argmax(axis=1),pred)\n",
        "    print(c_matrix)\n",
        "    accuracy = accuracy_score(Y[test,a:b].argmax(axis=1),pred)\n",
        "    print('Accuracy : ',accuracy)\n",
        "    # precision = true positive / total predicted positive(True positive + False positive)\n",
        "    # recall = true positive / total actual positive(True positive + False Negative)\n",
        "    print(classification_report(Y[test,a:b].argmax(axis=1),pred))\n",
        "    acscores1.append(accuracy)\n",
        "    prescores1.append(precision_score(Y[test,a:b].argmax(axis=1),pred))\n",
        "    rescores1.append(recall_score(Y[test,a:b].argmax(axis=1),pred))\n",
        "    fscores1.append(f1_score(Y[test,a:b].argmax(axis=1),pred))\n",
        "\n",
        "a,b = 2,4\n",
        "\n",
        "print('\\n\\nExcitement')\n",
        "for train, test in kfold.split(X, Y[:,a:b].argmax(axis=1)):\n",
        "      \n",
        "      for layer in model2.layers[:-3]:\n",
        "          layer.trainable = False\n",
        "      model = Sequential()\n",
        "      model.add(model2)\n",
        "      model.summary()\n",
        "      adam = Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=0.0001, decay=0.0001)\n",
        "      model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
        "      model.fit(X[train],Y[train,a:b],epochs = 100,batch_size = batch_size,validation_data = (X[test],Y[test,a:b]))\n",
        "      model.save('DL_Final_EXC2')\n",
        "      pred = model.predict(X[test])\n",
        "      pred = pred.argmax(axis=1)\n",
        "      c_matrix = confusion_matrix(Y[test,a:b].argmax(axis=1),pred)\n",
        "      print(c_matrix)\n",
        "      accuracy = accuracy_score(Y[test,a:b].argmax(axis=1),pred)\n",
        "      print('Accuracy : ',accuracy)\n",
        "      # # precision = true positive / total predicted positive(True positive + False positive)\n",
        "      # # recall = true positive / total actual positive(True positive + False Negative)\n",
        "      print(classification_report(Y[test,a:b].argmax(axis=1),pred))\n",
        "      acscores2.append(accuracy)\n",
        "      prescores2.append(precision_score(Y[test,a:b].argmax(axis=1),pred))\n",
        "      rescores2.append(recall_score(Y[test,a:b].argmax(axis=1),pred))\n",
        "      fscores2.append(f1_score(Y[test,a:b].argmax(axis=1),pred))\n",
        "\n",
        "a,b = 4,6\n",
        "print('\\n\\nCompetence')\n",
        "for train, test in kfold.split(X, Y[:,a:b].argmax(axis=1)):   \n",
        "    \n",
        "    for layer in model3.layers[:-3]:\n",
        "        layer.trainable = False\n",
        "    model = Sequential()\n",
        "    model.add(model3)\n",
        "    model.summary()\n",
        "    adam = Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=0.0001, decay=0.0001)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy']) \n",
        "    model.fit(X[train],Y[train,a:b],epochs = 100,batch_size = batch_size,validation_data = (X[test],Y[test,a:b]))\n",
        "    model.save('DL_Final_COM2')\n",
        "    pred = model.predict(X[test])\n",
        "    pred = pred.argmax(axis=1)\n",
        "    c_matrix = confusion_matrix(Y[test,a:b].argmax(axis=1),pred)\n",
        "    print(c_matrix)\n",
        "    accuracy = accuracy_score(Y[test,a:b].argmax(axis=1),pred)\n",
        "    print('Accuracy : ',accuracy)\n",
        "    # precision = true positive / total predicted positive(True positive + False positive)\n",
        "    # recall = true positive / total actual positive(True positive + False Negative)\n",
        "    print(classification_report(Y[test,a:b].argmax(axis=1),pred))\n",
        "    acscores3.append(accuracy)\n",
        "    prescores3.append(precision_score(Y[test,a:b].argmax(axis=1),pred))\n",
        "    rescores3.append(recall_score(Y[test,a:b].argmax(axis=1),pred))\n",
        "    fscores3.append(f1_score(Y[test,a:b].argmax(axis=1),pred))\n",
        "    \n",
        "    \n",
        "a,b = 6,8\n",
        "print('\\n\\nRuggedness')\n",
        "\n",
        "\n",
        "sm = SMOTE(random_state=4991, n_jobs=8, ratio={1:500, 0:500})\n",
        "for train, test in kfold.split(X, Y[:,a:b].argmax(axis=1)):\n",
        "    new_Y = Y[train,a:b].argmax(axis=1)\n",
        "    \n",
        "    new_X,new_Y = sm.fit_sample(X[train],new_Y)\n",
        "    new_Y = to_categorical(new_Y)\n",
        "\n",
        "    for layer in model5.layers[:-3]:\n",
        "        layer.trainable = False\n",
        "    model = Sequential()\n",
        "    model.add(model5)\n",
        "    model.summary()\n",
        "    adam = Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=0.0001, decay=0.0001)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy']) \n",
        "    model.fit(new_X,new_Y,epochs = 100,batch_size = batch_size,validation_data = (X[test],Y[test,a:b]))\n",
        "    model.save('DL_Final_RUG2')\n",
        "    pred = model.predict(X[test])\n",
        "    pred = pred.argmax(axis=1)\n",
        "    c_matrix = confusion_matrix(Y[test,a:b].argmax(axis=1),pred)\n",
        "    print(c_matrix)\n",
        "    accuracy = accuracy_score(Y[test,a:b].argmax(axis=1),pred)\n",
        "    print('Accuracy : ',accuracy)\n",
        "    # precision = true positive / total predicted positive(True positive + False positive)\n",
        "    # recall = true positive / total actual positive(True positive + False Negative)\n",
        "    print(classification_report(Y[test,a:b].argmax(axis=1),pred))\n",
        "    acscores5.append(accuracy)\n",
        "    prescores5.append(precision_score(Y[test,a:b].argmax(axis=1),pred))\n",
        "    rescores5.append(recall_score(Y[test,a:b].argmax(axis=1),pred))\n",
        "    fscores5.append(f1_score(Y[test,a:b].argmax(axis=1),pred))\n",
        "\n",
        "\n",
        "a,b = 8,10\n",
        "\n",
        "print('\\n\\nSophistication')\n",
        "    \n",
        "for train, test in kfold.split(X, Y[:,a:b].argmax(axis=1)):\n",
        "  \n",
        "    for layer in model4.layers[:-3]:\n",
        "        layer.trainable = False\n",
        "    model = Sequential()\n",
        "    model.add(model4)\n",
        "    model.summary()\n",
        "    adam = Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=0.0001, decay=0.0001)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy']) \n",
        "    model.fit(X[train],Y[train,a:b],epochs = 100,batch_size = batch_size,validation_data = (X[test],Y[test,a:b]))\n",
        "    model.save('DL_Final_SOP2')\n",
        "    pred = model.predict(X[test])\n",
        "    pred = pred.argmax(axis=1)\n",
        "    c_matrix = confusion_matrix(Y[test,a:b].argmax(axis=1),pred)\n",
        "    print(c_matrix)\n",
        "    accuracy = accuracy_score(Y[test,a:b].argmax(axis=1),pred)\n",
        "    print('Accuracy : ',accuracy)\n",
        "    # precision = true positive / total predicted positive(True positive + False positive)\n",
        "    # recall = true positive / total actual positive(True positive + False Negative)\n",
        "    print(classification_report(Y[test,a:b].argmax(axis=1),pred))\n",
        "    acscores4.append(accuracy)\n",
        "    prescores4.append(precision_score(Y[test,a:b].argmax(axis=1),pred))\n",
        "    rescores4.append(recall_score(Y[test,a:b].argmax(axis=1),pred))\n",
        "    fscores4.append(f1_score(Y[test,a:b].argmax(axis=1),pred))\n",
        "    \n",
        "#printing the results of transfer learning\n",
        "print('\\n\\nSincerity')   \n",
        "print(acscores1,'\\nMean : ',np.mean(acscores1),'\\nStandard deviation : ',np.std(acscores1),'\\nPrecision Score : ',np.mean(prescores1),'\\nRecall Score : ',np.mean(rescores1),'\\nF1 Score : ',np.mean(fscores1))\n",
        "print('\\n\\nExcitement')\n",
        "print(acscores2,'\\nMean : ',np.mean(acscores2),'\\nStandard deviation : ',np.std(acscores2),'\\nPrecision Score : ',np.mean(prescores2),'\\nRecall Score : ',np.mean(rescores2),'\\nF1 Score : ',np.mean(fscores2))\n",
        "print('\\n\\nCompetence')\n",
        "print(acscores3,'\\nMean : ',np.mean(acscores3),'\\nStandard deviation : ',np.std(acscores3),'\\nPrecision Score : ',np.mean(prescores3),'\\nRecall Score : ',np.mean(rescores3),'\\nF1 Score : ',np.mean(fscores3))\n",
        "print('\\n\\nSophistication')\n",
        "print(acscores4,'\\nMean : ',np.mean(acscores4),'\\nStandard deviation : ',np.std(acscores4),'\\nPrecision Score : ',np.mean(prescores4),'\\nRecall Score : ',np.mean(rescores4),'\\nF1 Score : ',np.mean(fscores4))\n",
        "print('\\n\\nRuggedness')\n",
        "print(acscores5,'\\nMean : ',np.mean(acscores5),'\\nStandard deviation : ',np.std(acscores5),'\\nPrecision Score : ',np.mean(prescores5),'\\nRecall Score : ',np.mean(rescores5),'\\nF1 Score : ',np.mean(fscores5))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(500, 10)\n",
            "\n",
            "\n",
            "Sincerity\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "model_8 (Model)              (None, 2)                 9148782   \n",
            "=================================================================\n",
            "Total params: 9,148,782\n",
            "Trainable params: 8,386\n",
            "Non-trainable params: 9,140,396\n",
            "_________________________________________________________________\n",
            "Train on 428 samples, validate on 72 samples\n",
            "Epoch 1/100\n",
            "428/428 [==============================] - 3s 6ms/step - loss: 2.6910 - acc: 0.7103 - val_loss: 1.8244 - val_acc: 0.8611\n",
            "Epoch 2/100\n",
            "428/428 [==============================] - 0s 836us/step - loss: 1.1219 - acc: 0.8621 - val_loss: 1.5781 - val_acc: 0.8611\n",
            "Epoch 3/100\n",
            "428/428 [==============================] - 0s 820us/step - loss: 0.9825 - acc: 0.8598 - val_loss: 0.9844 - val_acc: 0.8611\n",
            "Epoch 4/100\n",
            "428/428 [==============================] - 0s 816us/step - loss: 0.6841 - acc: 0.8528 - val_loss: 1.0864 - val_acc: 0.8611\n",
            "Epoch 5/100\n",
            "428/428 [==============================] - 0s 821us/step - loss: 0.5715 - acc: 0.8668 - val_loss: 0.7640 - val_acc: 0.8611\n",
            "Epoch 6/100\n",
            "428/428 [==============================] - 0s 814us/step - loss: 0.4750 - acc: 0.8598 - val_loss: 0.5658 - val_acc: 0.8611\n",
            "Epoch 7/100\n",
            "428/428 [==============================] - 0s 815us/step - loss: 0.4583 - acc: 0.8528 - val_loss: 0.5148 - val_acc: 0.8611\n",
            "Epoch 8/100\n",
            "428/428 [==============================] - 0s 822us/step - loss: 0.4479 - acc: 0.8598 - val_loss: 0.4953 - val_acc: 0.8611\n",
            "Epoch 9/100\n",
            "428/428 [==============================] - 0s 807us/step - loss: 0.4516 - acc: 0.8645 - val_loss: 0.4644 - val_acc: 0.8611\n",
            "Epoch 10/100\n",
            "428/428 [==============================] - 0s 815us/step - loss: 0.4512 - acc: 0.8645 - val_loss: 0.4342 - val_acc: 0.8611\n",
            "Epoch 11/100\n",
            "428/428 [==============================] - 0s 822us/step - loss: 0.4123 - acc: 0.8668 - val_loss: 0.4062 - val_acc: 0.8611\n",
            "Epoch 12/100\n",
            "428/428 [==============================] - 0s 817us/step - loss: 0.4736 - acc: 0.8575 - val_loss: 0.4219 - val_acc: 0.8611\n",
            "Epoch 13/100\n",
            "428/428 [==============================] - 0s 812us/step - loss: 0.4064 - acc: 0.8645 - val_loss: 0.4374 - val_acc: 0.8611\n",
            "Epoch 14/100\n",
            "428/428 [==============================] - 0s 823us/step - loss: 0.4250 - acc: 0.8668 - val_loss: 0.4017 - val_acc: 0.8611\n",
            "Epoch 15/100\n",
            "428/428 [==============================] - 0s 814us/step - loss: 0.4737 - acc: 0.8575 - val_loss: 0.3978 - val_acc: 0.8611\n",
            "Epoch 16/100\n",
            "428/428 [==============================] - 0s 820us/step - loss: 0.3968 - acc: 0.8621 - val_loss: 0.3994 - val_acc: 0.8611\n",
            "Epoch 17/100\n",
            "428/428 [==============================] - 0s 815us/step - loss: 0.4031 - acc: 0.8668 - val_loss: 0.4082 - val_acc: 0.8611\n",
            "Epoch 18/100\n",
            "428/428 [==============================] - 0s 806us/step - loss: 0.4407 - acc: 0.8645 - val_loss: 0.4149 - val_acc: 0.8611\n",
            "Epoch 19/100\n",
            "428/428 [==============================] - 0s 808us/step - loss: 0.4146 - acc: 0.8668 - val_loss: 0.4041 - val_acc: 0.8611\n",
            "Epoch 20/100\n",
            "428/428 [==============================] - 0s 811us/step - loss: 0.3929 - acc: 0.8668 - val_loss: 0.4051 - val_acc: 0.8611\n",
            "Epoch 21/100\n",
            "428/428 [==============================] - 0s 822us/step - loss: 0.3929 - acc: 0.8668 - val_loss: 0.4055 - val_acc: 0.8611\n",
            "Epoch 22/100\n",
            "428/428 [==============================] - 0s 826us/step - loss: 0.3954 - acc: 0.8645 - val_loss: 0.4060 - val_acc: 0.8611\n",
            "Epoch 23/100\n",
            "428/428 [==============================] - 0s 816us/step - loss: 0.3932 - acc: 0.8668 - val_loss: 0.4088 - val_acc: 0.8611\n",
            "Epoch 24/100\n",
            "428/428 [==============================] - 0s 808us/step - loss: 0.4018 - acc: 0.8621 - val_loss: 0.4522 - val_acc: 0.8611\n",
            "Epoch 25/100\n",
            "428/428 [==============================] - 0s 816us/step - loss: 0.4391 - acc: 0.8668 - val_loss: 0.4071 - val_acc: 0.8611\n",
            "Epoch 26/100\n",
            "428/428 [==============================] - 0s 828us/step - loss: 0.3916 - acc: 0.8668 - val_loss: 0.4065 - val_acc: 0.8611\n",
            "Epoch 27/100\n",
            "428/428 [==============================] - 0s 825us/step - loss: 0.4009 - acc: 0.8668 - val_loss: 0.4076 - val_acc: 0.8611\n",
            "Epoch 28/100\n",
            "428/428 [==============================] - 0s 839us/step - loss: 0.4004 - acc: 0.8645 - val_loss: 0.4059 - val_acc: 0.8611\n",
            "Epoch 29/100\n",
            "428/428 [==============================] - 0s 828us/step - loss: 0.3925 - acc: 0.8668 - val_loss: 0.4053 - val_acc: 0.8611\n",
            "Epoch 30/100\n",
            "428/428 [==============================] - 0s 820us/step - loss: 0.3928 - acc: 0.8668 - val_loss: 0.4058 - val_acc: 0.8611\n",
            "Epoch 31/100\n",
            "428/428 [==============================] - 0s 824us/step - loss: 0.3940 - acc: 0.8668 - val_loss: 0.4039 - val_acc: 0.8611\n",
            "Epoch 32/100\n",
            "428/428 [==============================] - 0s 828us/step - loss: 0.3968 - acc: 0.8668 - val_loss: 0.4091 - val_acc: 0.8611\n",
            "Epoch 33/100\n",
            "428/428 [==============================] - 0s 811us/step - loss: 0.3933 - acc: 0.8668 - val_loss: 0.4042 - val_acc: 0.8611\n",
            "Epoch 34/100\n",
            "428/428 [==============================] - 0s 825us/step - loss: 0.3992 - acc: 0.8668 - val_loss: 0.4047 - val_acc: 0.8611\n",
            "Epoch 35/100\n",
            "428/428 [==============================] - 0s 821us/step - loss: 0.3917 - acc: 0.8668 - val_loss: 0.4043 - val_acc: 0.8611\n",
            "Epoch 36/100\n",
            "428/428 [==============================] - 0s 825us/step - loss: 0.3907 - acc: 0.8668 - val_loss: 0.4249 - val_acc: 0.8611\n",
            "Epoch 37/100\n",
            "428/428 [==============================] - 0s 835us/step - loss: 0.4258 - acc: 0.8668 - val_loss: 0.4071 - val_acc: 0.8611\n",
            "Epoch 38/100\n",
            "428/428 [==============================] - 0s 830us/step - loss: 0.3931 - acc: 0.8668 - val_loss: 0.4075 - val_acc: 0.8611\n",
            "Epoch 39/100\n",
            "428/428 [==============================] - 0s 820us/step - loss: 0.3968 - acc: 0.8645 - val_loss: 0.4061 - val_acc: 0.8611\n",
            "Epoch 40/100\n",
            "428/428 [==============================] - 0s 830us/step - loss: 0.4056 - acc: 0.8645 - val_loss: 0.4029 - val_acc: 0.8611\n",
            "Epoch 41/100\n",
            "428/428 [==============================] - 0s 819us/step - loss: 0.3917 - acc: 0.8668 - val_loss: 0.4018 - val_acc: 0.8611\n",
            "Epoch 42/100\n",
            "428/428 [==============================] - 0s 825us/step - loss: 0.3999 - acc: 0.8645 - val_loss: 0.3863 - val_acc: 0.8611\n",
            "Epoch 43/100\n",
            "428/428 [==============================] - 0s 826us/step - loss: 0.4009 - acc: 0.8668 - val_loss: 0.4026 - val_acc: 0.8611\n",
            "Epoch 44/100\n",
            "428/428 [==============================] - 0s 822us/step - loss: 0.3936 - acc: 0.8668 - val_loss: 0.4013 - val_acc: 0.8611\n",
            "Epoch 45/100\n",
            "428/428 [==============================] - 0s 824us/step - loss: 0.4250 - acc: 0.8668 - val_loss: 0.4012 - val_acc: 0.8611\n",
            "Epoch 46/100\n",
            "428/428 [==============================] - 0s 831us/step - loss: 0.3921 - acc: 0.8668 - val_loss: 0.4015 - val_acc: 0.8611\n",
            "Epoch 47/100\n",
            "428/428 [==============================] - 0s 821us/step - loss: 0.3935 - acc: 0.8668 - val_loss: 0.4014 - val_acc: 0.8611\n",
            "Epoch 48/100\n",
            "428/428 [==============================] - 0s 825us/step - loss: 0.3941 - acc: 0.8668 - val_loss: 0.3987 - val_acc: 0.8611\n",
            "Epoch 49/100\n",
            "428/428 [==============================] - 0s 821us/step - loss: 0.3912 - acc: 0.8668 - val_loss: 0.3972 - val_acc: 0.8611\n",
            "Epoch 50/100\n",
            "428/428 [==============================] - 0s 824us/step - loss: 0.3972 - acc: 0.8668 - val_loss: 0.5821 - val_acc: 0.8611\n",
            "Epoch 51/100\n",
            "428/428 [==============================] - 0s 830us/step - loss: 0.4198 - acc: 0.8645 - val_loss: 0.3994 - val_acc: 0.8611\n",
            "Epoch 52/100\n",
            "428/428 [==============================] - 0s 817us/step - loss: 0.3916 - acc: 0.8668 - val_loss: 0.4005 - val_acc: 0.8611\n",
            "Epoch 53/100\n",
            "428/428 [==============================] - 0s 823us/step - loss: 0.3929 - acc: 0.8668 - val_loss: 0.4011 - val_acc: 0.8611\n",
            "Epoch 54/100\n",
            "428/428 [==============================] - 0s 825us/step - loss: 0.3913 - acc: 0.8668 - val_loss: 0.3942 - val_acc: 0.8611\n",
            "Epoch 55/100\n",
            "428/428 [==============================] - 0s 822us/step - loss: 0.4253 - acc: 0.8668 - val_loss: 0.3887 - val_acc: 0.8611\n",
            "Epoch 56/100\n",
            "428/428 [==============================] - 0s 836us/step - loss: 0.3902 - acc: 0.8645 - val_loss: 1.0874 - val_acc: 0.8611\n",
            "Epoch 57/100\n",
            "428/428 [==============================] - 0s 821us/step - loss: 0.4459 - acc: 0.8645 - val_loss: 0.4048 - val_acc: 0.8611\n",
            "Epoch 58/100\n",
            "428/428 [==============================] - 0s 825us/step - loss: 0.4011 - acc: 0.8668 - val_loss: 0.4010 - val_acc: 0.8611\n",
            "Epoch 59/100\n",
            "428/428 [==============================] - 0s 833us/step - loss: 0.3936 - acc: 0.8668 - val_loss: 0.4005 - val_acc: 0.8611\n",
            "Epoch 60/100\n",
            "428/428 [==============================] - 0s 826us/step - loss: 0.4130 - acc: 0.8668 - val_loss: 0.4043 - val_acc: 0.8611\n",
            "Epoch 61/100\n",
            "428/428 [==============================] - 0s 824us/step - loss: 0.3928 - acc: 0.8668 - val_loss: 0.4035 - val_acc: 0.8611\n",
            "Epoch 62/100\n",
            "428/428 [==============================] - 0s 826us/step - loss: 0.3927 - acc: 0.8668 - val_loss: 0.4042 - val_acc: 0.8611\n",
            "Epoch 63/100\n",
            "428/428 [==============================] - 0s 829us/step - loss: 0.3941 - acc: 0.8668 - val_loss: 0.4060 - val_acc: 0.8611\n",
            "Epoch 64/100\n",
            "428/428 [==============================] - 0s 829us/step - loss: 0.3925 - acc: 0.8668 - val_loss: 0.4066 - val_acc: 0.8611\n",
            "Epoch 65/100\n",
            "428/428 [==============================] - 0s 827us/step - loss: 0.3956 - acc: 0.8668 - val_loss: 0.4075 - val_acc: 0.8611\n",
            "Epoch 66/100\n",
            "428/428 [==============================] - 0s 838us/step - loss: 0.3927 - acc: 0.8668 - val_loss: 0.4086 - val_acc: 0.8611\n",
            "Epoch 67/100\n",
            "428/428 [==============================] - 0s 825us/step - loss: 0.4058 - acc: 0.8645 - val_loss: 0.4073 - val_acc: 0.8611\n",
            "Epoch 68/100\n",
            "428/428 [==============================] - 0s 829us/step - loss: 0.3928 - acc: 0.8668 - val_loss: 0.4078 - val_acc: 0.8611\n",
            "Epoch 69/100\n",
            "428/428 [==============================] - 0s 842us/step - loss: 0.3919 - acc: 0.8668 - val_loss: 0.4094 - val_acc: 0.8611\n",
            "Epoch 70/100\n",
            "428/428 [==============================] - 0s 824us/step - loss: 0.3922 - acc: 0.8668 - val_loss: 0.4102 - val_acc: 0.8611\n",
            "Epoch 71/100\n",
            "428/428 [==============================] - 0s 838us/step - loss: 0.3941 - acc: 0.8668 - val_loss: 0.4103 - val_acc: 0.8611\n",
            "Epoch 72/100\n",
            "428/428 [==============================] - 0s 837us/step - loss: 0.3932 - acc: 0.8668 - val_loss: 0.4106 - val_acc: 0.8611\n",
            "Epoch 73/100\n",
            "428/428 [==============================] - 0s 838us/step - loss: 0.3934 - acc: 0.8668 - val_loss: 0.4102 - val_acc: 0.8611\n",
            "Epoch 74/100\n",
            "428/428 [==============================] - 0s 862us/step - loss: 0.3931 - acc: 0.8668 - val_loss: 0.4101 - val_acc: 0.8611\n",
            "Epoch 75/100\n",
            "428/428 [==============================] - 0s 838us/step - loss: 0.3926 - acc: 0.8668 - val_loss: 0.4115 - val_acc: 0.8611\n",
            "Epoch 76/100\n",
            "428/428 [==============================] - 0s 850us/step - loss: 0.3954 - acc: 0.8668 - val_loss: 0.4130 - val_acc: 0.8611\n",
            "Epoch 77/100\n",
            "428/428 [==============================] - 0s 849us/step - loss: 0.3925 - acc: 0.8668 - val_loss: 0.4121 - val_acc: 0.8611\n",
            "Epoch 78/100\n",
            "428/428 [==============================] - 0s 836us/step - loss: 0.3927 - acc: 0.8668 - val_loss: 0.4122 - val_acc: 0.8611\n",
            "Epoch 79/100\n",
            "428/428 [==============================] - 0s 852us/step - loss: 0.3922 - acc: 0.8668 - val_loss: 0.4126 - val_acc: 0.8611\n",
            "Epoch 80/100\n",
            "428/428 [==============================] - 0s 849us/step - loss: 0.3938 - acc: 0.8668 - val_loss: 0.4103 - val_acc: 0.8611\n",
            "Epoch 81/100\n",
            "428/428 [==============================] - 0s 830us/step - loss: 0.3924 - acc: 0.8668 - val_loss: 0.4077 - val_acc: 0.8611\n",
            "Epoch 82/100\n",
            "428/428 [==============================] - 0s 835us/step - loss: 0.3927 - acc: 0.8668 - val_loss: 0.4073 - val_acc: 0.8611\n",
            "Epoch 83/100\n",
            "428/428 [==============================] - 0s 845us/step - loss: 0.3954 - acc: 0.8668 - val_loss: 0.4020 - val_acc: 0.8611\n",
            "Epoch 84/100\n",
            "428/428 [==============================] - 0s 823us/step - loss: 0.3928 - acc: 0.8668 - val_loss: 0.4012 - val_acc: 0.8611\n",
            "Epoch 85/100\n",
            "428/428 [==============================] - 0s 836us/step - loss: 0.3923 - acc: 0.8668 - val_loss: 0.4012 - val_acc: 0.8611\n",
            "Epoch 86/100\n",
            "428/428 [==============================] - 0s 844us/step - loss: 0.3935 - acc: 0.8668 - val_loss: 0.4015 - val_acc: 0.8611\n",
            "Epoch 87/100\n",
            "428/428 [==============================] - 0s 825us/step - loss: 0.3923 - acc: 0.8668 - val_loss: 0.4013 - val_acc: 0.8611\n",
            "Epoch 88/100\n",
            "428/428 [==============================] - 0s 832us/step - loss: 0.3931 - acc: 0.8668 - val_loss: 0.4049 - val_acc: 0.8611\n",
            "Epoch 89/100\n",
            "428/428 [==============================] - 0s 853us/step - loss: 0.3920 - acc: 0.8668 - val_loss: 0.4035 - val_acc: 0.8611\n",
            "Epoch 90/100\n",
            "428/428 [==============================] - 0s 826us/step - loss: 0.4002 - acc: 0.8645 - val_loss: 0.4014 - val_acc: 0.8611\n",
            "Epoch 91/100\n",
            "428/428 [==============================] - 0s 841us/step - loss: 0.4251 - acc: 0.8668 - val_loss: 0.4021 - val_acc: 0.8611\n",
            "Epoch 92/100\n",
            "428/428 [==============================] - 0s 863us/step - loss: 0.3923 - acc: 0.8668 - val_loss: 0.4034 - val_acc: 0.8611\n",
            "Epoch 93/100\n",
            "428/428 [==============================] - 0s 830us/step - loss: 0.5496 - acc: 0.8645 - val_loss: 0.4288 - val_acc: 0.8611\n",
            "Epoch 94/100\n",
            "428/428 [==============================] - 0s 840us/step - loss: 0.5144 - acc: 0.8528 - val_loss: 0.3972 - val_acc: 0.8611\n",
            "Epoch 95/100\n",
            "428/428 [==============================] - 0s 826us/step - loss: 0.3933 - acc: 0.8668 - val_loss: 0.4029 - val_acc: 0.8611\n",
            "Epoch 96/100\n",
            "428/428 [==============================] - 0s 841us/step - loss: 0.3926 - acc: 0.8668 - val_loss: 0.4048 - val_acc: 0.8611\n",
            "Epoch 97/100\n",
            "428/428 [==============================] - 0s 842us/step - loss: 0.3908 - acc: 0.8668 - val_loss: 0.4065 - val_acc: 0.8611\n",
            "Epoch 98/100\n",
            "428/428 [==============================] - 0s 830us/step - loss: 0.3929 - acc: 0.8668 - val_loss: 0.4074 - val_acc: 0.8611\n",
            "Epoch 99/100\n",
            "428/428 [==============================] - 0s 837us/step - loss: 0.3953 - acc: 0.8668 - val_loss: 0.4077 - val_acc: 0.8611\n",
            "Epoch 100/100\n",
            "428/428 [==============================] - 0s 843us/step - loss: 0.3951 - acc: 0.8645 - val_loss: 0.4058 - val_acc: 0.8611\n",
            "[[ 0 10]\n",
            " [ 0 62]]\n",
            "Accuracy :  0.8611111111111112\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        10\n",
            "           1       0.86      1.00      0.93        62\n",
            "\n",
            "    accuracy                           0.86        72\n",
            "   macro avg       0.43      0.50      0.46        72\n",
            "weighted avg       0.74      0.86      0.80        72\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "model_8 (Model)              (None, 2)                 9148782   \n",
            "=================================================================\n",
            "Total params: 9,148,782\n",
            "Trainable params: 8,386\n",
            "Non-trainable params: 9,140,396\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 428 samples, validate on 72 samples\n",
            "Epoch 1/100\n",
            "428/428 [==============================] - 2s 6ms/step - loss: 0.3946 - acc: 0.8668 - val_loss: 0.4058 - val_acc: 0.8611\n",
            "Epoch 2/100\n",
            "428/428 [==============================] - 0s 817us/step - loss: 0.3937 - acc: 0.8668 - val_loss: 0.4009 - val_acc: 0.8611\n",
            "Epoch 3/100\n",
            "428/428 [==============================] - 0s 819us/step - loss: 0.4080 - acc: 0.8645 - val_loss: 0.3955 - val_acc: 0.8611\n",
            "Epoch 4/100\n",
            "428/428 [==============================] - 0s 822us/step - loss: 0.4194 - acc: 0.8668 - val_loss: 0.3988 - val_acc: 0.8611\n",
            "Epoch 5/100\n",
            "428/428 [==============================] - 0s 814us/step - loss: 0.3921 - acc: 0.8668 - val_loss: 0.3999 - val_acc: 0.8611\n",
            "Epoch 6/100\n",
            "428/428 [==============================] - 0s 815us/step - loss: 0.4172 - acc: 0.8645 - val_loss: 0.3989 - val_acc: 0.8611\n",
            "Epoch 7/100\n",
            "428/428 [==============================] - 0s 817us/step - loss: 0.3913 - acc: 0.8668 - val_loss: 0.4434 - val_acc: 0.8611\n",
            "Epoch 8/100\n",
            "428/428 [==============================] - 0s 825us/step - loss: 0.3953 - acc: 0.8668 - val_loss: 0.4989 - val_acc: 0.8611\n",
            "Epoch 9/100\n",
            "428/428 [==============================] - 0s 823us/step - loss: 0.4108 - acc: 0.8668 - val_loss: 0.4038 - val_acc: 0.8611\n",
            "Epoch 10/100\n",
            "428/428 [==============================] - 0s 830us/step - loss: 0.3946 - acc: 0.8668 - val_loss: 0.4040 - val_acc: 0.8611\n",
            "Epoch 11/100\n",
            "428/428 [==============================] - 0s 817us/step - loss: 0.4086 - acc: 0.8668 - val_loss: 0.4052 - val_acc: 0.8611\n",
            "Epoch 12/100\n",
            "428/428 [==============================] - 0s 815us/step - loss: 0.3938 - acc: 0.8645 - val_loss: 0.4042 - val_acc: 0.8611\n",
            "Epoch 13/100\n",
            "428/428 [==============================] - 0s 846us/step - loss: 0.3940 - acc: 0.8668 - val_loss: 0.4033 - val_acc: 0.8611\n",
            "Epoch 14/100\n",
            "428/428 [==============================] - 0s 808us/step - loss: 0.3927 - acc: 0.8668 - val_loss: 0.4027 - val_acc: 0.8611\n",
            "Epoch 15/100\n",
            "428/428 [==============================] - 0s 822us/step - loss: 0.3934 - acc: 0.8668 - val_loss: 0.4020 - val_acc: 0.8611\n",
            "Epoch 16/100\n",
            "428/428 [==============================] - 0s 832us/step - loss: 0.3916 - acc: 0.8668 - val_loss: 0.3965 - val_acc: 0.8611\n",
            "Epoch 17/100\n",
            "428/428 [==============================] - 0s 835us/step - loss: 0.4469 - acc: 0.8668 - val_loss: 0.4015 - val_acc: 0.8611\n",
            "Epoch 18/100\n",
            "428/428 [==============================] - 0s 821us/step - loss: 0.4107 - acc: 0.8598 - val_loss: 0.4049 - val_acc: 0.8611\n",
            "Epoch 19/100\n",
            "428/428 [==============================] - 0s 852us/step - loss: 0.3966 - acc: 0.8645 - val_loss: 0.4083 - val_acc: 0.8611\n",
            "Epoch 20/100\n",
            "428/428 [==============================] - 0s 826us/step - loss: 0.4265 - acc: 0.8645 - val_loss: 0.4095 - val_acc: 0.8611\n",
            "Epoch 21/100\n",
            "428/428 [==============================] - 0s 817us/step - loss: 0.4059 - acc: 0.8668 - val_loss: 0.4163 - val_acc: 0.8611\n",
            "Epoch 22/100\n",
            "428/428 [==============================] - 0s 831us/step - loss: 0.4050 - acc: 0.8668 - val_loss: 0.4037 - val_acc: 0.8611\n",
            "Epoch 23/100\n",
            "428/428 [==============================] - 0s 823us/step - loss: 0.4053 - acc: 0.8668 - val_loss: 0.4240 - val_acc: 0.8611\n",
            "Epoch 24/100\n",
            "428/428 [==============================] - 0s 820us/step - loss: 0.3969 - acc: 0.8668 - val_loss: 0.4057 - val_acc: 0.8611\n",
            "Epoch 25/100\n",
            "428/428 [==============================] - 0s 829us/step - loss: 0.3932 - acc: 0.8668 - val_loss: 0.4050 - val_acc: 0.8611\n",
            "Epoch 26/100\n",
            "428/428 [==============================] - 0s 822us/step - loss: 0.3920 - acc: 0.8668 - val_loss: 0.4050 - val_acc: 0.8611\n",
            "Epoch 27/100\n",
            "428/428 [==============================] - 0s 825us/step - loss: 0.3953 - acc: 0.8668 - val_loss: 0.4049 - val_acc: 0.8611\n",
            "Epoch 28/100\n",
            "428/428 [==============================] - 0s 828us/step - loss: 0.3976 - acc: 0.8645 - val_loss: 0.4096 - val_acc: 0.8611\n",
            "Epoch 29/100\n",
            "428/428 [==============================] - 0s 828us/step - loss: 0.3944 - acc: 0.8668 - val_loss: 0.4160 - val_acc: 0.8611\n",
            "Epoch 30/100\n",
            "428/428 [==============================] - 0s 824us/step - loss: 0.3980 - acc: 0.8645 - val_loss: 0.4041 - val_acc: 0.8611\n",
            "Epoch 31/100\n",
            "428/428 [==============================] - 0s 831us/step - loss: 0.3937 - acc: 0.8668 - val_loss: 0.4035 - val_acc: 0.8611\n",
            "Epoch 32/100\n",
            "428/428 [==============================] - 0s 825us/step - loss: 0.3924 - acc: 0.8668 - val_loss: 0.4036 - val_acc: 0.8611\n",
            "Epoch 33/100\n",
            "428/428 [==============================] - 0s 834us/step - loss: 0.3923 - acc: 0.8668 - val_loss: 0.4034 - val_acc: 0.8611\n",
            "Epoch 34/100\n",
            "428/428 [==============================] - 0s 829us/step - loss: 0.3922 - acc: 0.8668 - val_loss: 0.4036 - val_acc: 0.8611\n",
            "Epoch 35/100\n",
            "428/428 [==============================] - 0s 826us/step - loss: 0.3923 - acc: 0.8668 - val_loss: 0.4036 - val_acc: 0.8611\n",
            "Epoch 36/100\n",
            "428/428 [==============================] - 0s 856us/step - loss: 0.3926 - acc: 0.8668 - val_loss: 0.4034 - val_acc: 0.8611\n",
            "Epoch 37/100\n",
            "428/428 [==============================] - 0s 829us/step - loss: 0.3923 - acc: 0.8668 - val_loss: 0.4034 - val_acc: 0.8611\n",
            "Epoch 38/100\n",
            "428/428 [==============================] - 0s 832us/step - loss: 0.3922 - acc: 0.8668 - val_loss: 0.4028 - val_acc: 0.8611\n",
            "Epoch 39/100\n",
            "428/428 [==============================] - 0s 857us/step - loss: 0.3927 - acc: 0.8668 - val_loss: 0.4029 - val_acc: 0.8611\n",
            "Epoch 40/100\n",
            "428/428 [==============================] - 0s 830us/step - loss: 0.3992 - acc: 0.8645 - val_loss: 0.4022 - val_acc: 0.8611\n",
            "Epoch 41/100\n",
            "428/428 [==============================] - 0s 835us/step - loss: 0.3920 - acc: 0.8668 - val_loss: 0.4028 - val_acc: 0.8611\n",
            "Epoch 42/100\n",
            "428/428 [==============================] - 0s 848us/step - loss: 0.4024 - acc: 0.8645 - val_loss: 0.4022 - val_acc: 0.8611\n",
            "Epoch 43/100\n",
            "428/428 [==============================] - 0s 839us/step - loss: 0.3931 - acc: 0.8668 - val_loss: 0.4014 - val_acc: 0.8611\n",
            "Epoch 44/100\n",
            "428/428 [==============================] - 0s 834us/step - loss: 0.3921 - acc: 0.8668 - val_loss: 0.4007 - val_acc: 0.8611\n",
            "Epoch 45/100\n",
            "428/428 [==============================] - 0s 846us/step - loss: 0.3987 - acc: 0.8668 - val_loss: 0.4026 - val_acc: 0.8611\n",
            "Epoch 46/100\n",
            "428/428 [==============================] - 0s 842us/step - loss: 0.3932 - acc: 0.8668 - val_loss: 0.4031 - val_acc: 0.8611\n",
            "Epoch 47/100\n",
            "428/428 [==============================] - 0s 835us/step - loss: 0.3926 - acc: 0.8668 - val_loss: 0.4025 - val_acc: 0.8611\n",
            "Epoch 48/100\n",
            "428/428 [==============================] - 0s 833us/step - loss: 0.3925 - acc: 0.8668 - val_loss: 0.4023 - val_acc: 0.8611\n",
            "Epoch 49/100\n",
            "428/428 [==============================] - 0s 835us/step - loss: 0.3932 - acc: 0.8668 - val_loss: 0.4023 - val_acc: 0.8611\n",
            "Epoch 50/100\n",
            "428/428 [==============================] - 0s 835us/step - loss: 0.3929 - acc: 0.8668 - val_loss: 0.4004 - val_acc: 0.8611\n",
            "Epoch 51/100\n",
            "428/428 [==============================] - 0s 838us/step - loss: 0.3922 - acc: 0.8668 - val_loss: 0.3986 - val_acc: 0.8611\n",
            "Epoch 52/100\n",
            "428/428 [==============================] - 0s 836us/step - loss: 0.4057 - acc: 0.8668 - val_loss: 0.4001 - val_acc: 0.8611\n",
            "Epoch 53/100\n",
            "428/428 [==============================] - 0s 838us/step - loss: 0.4238 - acc: 0.8621 - val_loss: 0.4088 - val_acc: 0.8611\n",
            "Epoch 54/100\n",
            "428/428 [==============================] - 0s 843us/step - loss: 0.3996 - acc: 0.8645 - val_loss: 0.4034 - val_acc: 0.8611\n",
            "Epoch 55/100\n",
            "428/428 [==============================] - 0s 837us/step - loss: 0.3919 - acc: 0.8668 - val_loss: 0.4046 - val_acc: 0.8611\n",
            "Epoch 56/100\n",
            "428/428 [==============================] - 0s 841us/step - loss: 0.3914 - acc: 0.8668 - val_loss: 0.4072 - val_acc: 0.8611\n",
            "Epoch 57/100\n",
            "428/428 [==============================] - 0s 842us/step - loss: 0.4189 - acc: 0.8668 - val_loss: 0.4012 - val_acc: 0.8611\n",
            "Epoch 58/100\n",
            "428/428 [==============================] - 0s 845us/step - loss: 0.3921 - acc: 0.8668 - val_loss: 0.3997 - val_acc: 0.8611\n",
            "Epoch 59/100\n",
            "428/428 [==============================] - 0s 841us/step - loss: 0.3922 - acc: 0.8668 - val_loss: 0.3988 - val_acc: 0.8611\n",
            "Epoch 60/100\n",
            "428/428 [==============================] - 0s 852us/step - loss: 0.4524 - acc: 0.8668 - val_loss: 0.8715 - val_acc: 0.8611\n",
            "Epoch 61/100\n",
            "428/428 [==============================] - 0s 853us/step - loss: 0.4882 - acc: 0.8598 - val_loss: 0.4028 - val_acc: 0.8611\n",
            "Epoch 62/100\n",
            "428/428 [==============================] - 0s 839us/step - loss: 0.3936 - acc: 0.8668 - val_loss: 0.4024 - val_acc: 0.8611\n",
            "Epoch 63/100\n",
            "428/428 [==============================] - 0s 831us/step - loss: 0.3939 - acc: 0.8668 - val_loss: 0.4025 - val_acc: 0.8611\n",
            "Epoch 64/100\n",
            "428/428 [==============================] - 0s 850us/step - loss: 0.3924 - acc: 0.8668 - val_loss: 0.4027 - val_acc: 0.8611\n",
            "Epoch 65/100\n",
            "428/428 [==============================] - 0s 826us/step - loss: 0.3925 - acc: 0.8668 - val_loss: 0.4028 - val_acc: 0.8611\n",
            "Epoch 66/100\n",
            "428/428 [==============================] - 0s 841us/step - loss: 0.3923 - acc: 0.8668 - val_loss: 0.4024 - val_acc: 0.8611\n",
            "Epoch 67/100\n",
            "428/428 [==============================] - 0s 838us/step - loss: 0.3927 - acc: 0.8668 - val_loss: 0.4024 - val_acc: 0.8611\n",
            "Epoch 68/100\n",
            "428/428 [==============================] - 0s 837us/step - loss: 0.3930 - acc: 0.8668 - val_loss: 0.4025 - val_acc: 0.8611\n",
            "Epoch 69/100\n",
            "428/428 [==============================] - 0s 840us/step - loss: 0.3929 - acc: 0.8668 - val_loss: 0.4027 - val_acc: 0.8611\n",
            "Epoch 70/100\n",
            "428/428 [==============================] - 0s 846us/step - loss: 0.3920 - acc: 0.8668 - val_loss: 0.4024 - val_acc: 0.8611\n",
            "Epoch 71/100\n",
            "428/428 [==============================] - 0s 833us/step - loss: 0.3924 - acc: 0.8668 - val_loss: 0.4022 - val_acc: 0.8611\n",
            "Epoch 72/100\n",
            "428/428 [==============================] - 0s 822us/step - loss: 0.3929 - acc: 0.8668 - val_loss: 0.4024 - val_acc: 0.8611\n",
            "Epoch 73/100\n",
            "428/428 [==============================] - 0s 858us/step - loss: 0.3923 - acc: 0.8668 - val_loss: 0.4025 - val_acc: 0.8611\n",
            "Epoch 74/100\n",
            "428/428 [==============================] - 0s 845us/step - loss: 0.3923 - acc: 0.8668 - val_loss: 0.4023 - val_acc: 0.8611\n",
            "Epoch 75/100\n",
            "428/428 [==============================] - 0s 823us/step - loss: 0.3927 - acc: 0.8668 - val_loss: 0.4008 - val_acc: 0.8611\n",
            "Epoch 76/100\n",
            "428/428 [==============================] - 0s 838us/step - loss: 0.3914 - acc: 0.8668 - val_loss: 0.4006 - val_acc: 0.8611\n",
            "Epoch 77/100\n",
            "428/428 [==============================] - 0s 832us/step - loss: 0.4236 - acc: 0.8668 - val_loss: 0.4796 - val_acc: 0.8611\n",
            "Epoch 78/100\n",
            "428/428 [==============================] - 0s 835us/step - loss: 0.4469 - acc: 0.8668 - val_loss: 0.4802 - val_acc: 0.8611\n",
            "Epoch 79/100\n",
            "428/428 [==============================] - 0s 838us/step - loss: 0.6003 - acc: 0.8668 - val_loss: 1.3880 - val_acc: 0.8611\n",
            "Epoch 80/100\n",
            "428/428 [==============================] - 0s 842us/step - loss: 0.8737 - acc: 0.8668 - val_loss: 0.4176 - val_acc: 0.8611\n",
            "Epoch 81/100\n",
            "428/428 [==============================] - 0s 831us/step - loss: 0.4369 - acc: 0.8598 - val_loss: 0.4027 - val_acc: 0.8611\n",
            "Epoch 82/100\n",
            "428/428 [==============================] - 0s 842us/step - loss: 0.3964 - acc: 0.8668 - val_loss: 0.4027 - val_acc: 0.8611\n",
            "Epoch 83/100\n",
            "428/428 [==============================] - 0s 833us/step - loss: 0.3954 - acc: 0.8645 - val_loss: 0.4027 - val_acc: 0.8611\n",
            "Epoch 84/100\n",
            "428/428 [==============================] - 0s 834us/step - loss: 0.3925 - acc: 0.8668 - val_loss: 0.4022 - val_acc: 0.8611\n",
            "Epoch 85/100\n",
            "428/428 [==============================] - 0s 839us/step - loss: 0.3947 - acc: 0.8645 - val_loss: 0.4024 - val_acc: 0.8611\n",
            "Epoch 86/100\n",
            "428/428 [==============================] - 0s 827us/step - loss: 0.3925 - acc: 0.8668 - val_loss: 0.4026 - val_acc: 0.8611\n",
            "Epoch 87/100\n",
            "428/428 [==============================] - 0s 839us/step - loss: 0.3925 - acc: 0.8668 - val_loss: 0.4026 - val_acc: 0.8611\n",
            "Epoch 88/100\n",
            "428/428 [==============================] - 0s 839us/step - loss: 0.3927 - acc: 0.8668 - val_loss: 0.4024 - val_acc: 0.8611\n",
            "Epoch 89/100\n",
            "428/428 [==============================] - 0s 832us/step - loss: 0.3921 - acc: 0.8668 - val_loss: 0.4025 - val_acc: 0.8611\n",
            "Epoch 90/100\n",
            "428/428 [==============================] - 0s 827us/step - loss: 0.3925 - acc: 0.8668 - val_loss: 0.4029 - val_acc: 0.8611\n",
            "Epoch 91/100\n",
            "428/428 [==============================] - 0s 847us/step - loss: 0.3929 - acc: 0.8668 - val_loss: 0.4026 - val_acc: 0.8611\n",
            "Epoch 92/100\n",
            "428/428 [==============================] - 0s 830us/step - loss: 0.3929 - acc: 0.8668 - val_loss: 0.4024 - val_acc: 0.8611\n",
            "Epoch 93/100\n",
            "428/428 [==============================] - 0s 832us/step - loss: 0.3924 - acc: 0.8668 - val_loss: 0.3991 - val_acc: 0.8611\n",
            "Epoch 94/100\n",
            "428/428 [==============================] - 0s 829us/step - loss: 0.4078 - acc: 0.8668 - val_loss: 0.4007 - val_acc: 0.8611\n",
            "Epoch 95/100\n",
            "428/428 [==============================] - 0s 829us/step - loss: 0.3948 - acc: 0.8668 - val_loss: 0.4031 - val_acc: 0.8611\n",
            "Epoch 96/100\n",
            "428/428 [==============================] - 0s 838us/step - loss: 0.3970 - acc: 0.8668 - val_loss: 0.4034 - val_acc: 0.8611\n",
            "Epoch 97/100\n",
            "428/428 [==============================] - 0s 822us/step - loss: 0.3927 - acc: 0.8668 - val_loss: 0.4033 - val_acc: 0.8611\n",
            "Epoch 98/100\n",
            "428/428 [==============================] - 0s 833us/step - loss: 0.3924 - acc: 0.8668 - val_loss: 0.4032 - val_acc: 0.8611\n",
            "Epoch 99/100\n",
            "428/428 [==============================] - 0s 845us/step - loss: 0.3925 - acc: 0.8668 - val_loss: 0.4032 - val_acc: 0.8611\n",
            "Epoch 100/100\n",
            "428/428 [==============================] - 0s 829us/step - loss: 0.3928 - acc: 0.8668 - val_loss: 0.4028 - val_acc: 0.8611\n",
            "[[ 0 10]\n",
            " [ 0 62]]\n",
            "Accuracy :  0.8611111111111112\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        10\n",
            "           1       0.86      1.00      0.93        62\n",
            "\n",
            "    accuracy                           0.86        72\n",
            "   macro avg       0.43      0.50      0.46        72\n",
            "weighted avg       0.74      0.86      0.80        72\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "model_8 (Model)              (None, 2)                 9148782   \n",
            "=================================================================\n",
            "Total params: 9,148,782\n",
            "Trainable params: 8,386\n",
            "Non-trainable params: 9,140,396\n",
            "_________________________________________________________________\n",
            "Train on 428 samples, validate on 72 samples\n",
            "Epoch 1/100\n",
            "428/428 [==============================] - 2s 6ms/step - loss: 0.3930 - acc: 0.8668 - val_loss: 0.4040 - val_acc: 0.8611\n",
            "Epoch 2/100\n",
            "428/428 [==============================] - 0s 821us/step - loss: 0.3920 - acc: 0.8668 - val_loss: 0.4041 - val_acc: 0.8611\n",
            "Epoch 3/100\n",
            "428/428 [==============================] - 0s 821us/step - loss: 0.3925 - acc: 0.8668 - val_loss: 0.4043 - val_acc: 0.8611\n",
            "Epoch 4/100\n",
            "428/428 [==============================] - 0s 823us/step - loss: 0.4065 - acc: 0.8668 - val_loss: 0.4047 - val_acc: 0.8611\n",
            "Epoch 5/100\n",
            "428/428 [==============================] - 0s 811us/step - loss: 0.3928 - acc: 0.8668 - val_loss: 0.4047 - val_acc: 0.8611\n",
            "Epoch 6/100\n",
            "428/428 [==============================] - 0s 808us/step - loss: 0.3931 - acc: 0.8668 - val_loss: 0.4042 - val_acc: 0.8611\n",
            "Epoch 7/100\n",
            "428/428 [==============================] - 0s 840us/step - loss: 0.3930 - acc: 0.8668 - val_loss: 0.4045 - val_acc: 0.8611\n",
            "Epoch 8/100\n",
            "428/428 [==============================] - 0s 817us/step - loss: 0.4072 - acc: 0.8668 - val_loss: 0.4043 - val_acc: 0.8611\n",
            "Epoch 9/100\n",
            "428/428 [==============================] - 0s 819us/step - loss: 0.3929 - acc: 0.8668 - val_loss: 0.4045 - val_acc: 0.8611\n",
            "Epoch 10/100\n",
            "428/428 [==============================] - 0s 822us/step - loss: 0.3929 - acc: 0.8668 - val_loss: 0.4044 - val_acc: 0.8611\n",
            "Epoch 11/100\n",
            "428/428 [==============================] - 0s 817us/step - loss: 0.3969 - acc: 0.8668 - val_loss: 0.4029 - val_acc: 0.8611\n",
            "Epoch 12/100\n",
            "428/428 [==============================] - 0s 811us/step - loss: 0.3922 - acc: 0.8668 - val_loss: 0.4032 - val_acc: 0.8611\n",
            "Epoch 13/100\n",
            "428/428 [==============================] - 0s 825us/step - loss: 0.3922 - acc: 0.8668 - val_loss: 0.4221 - val_acc: 0.8611\n",
            "Epoch 14/100\n",
            "428/428 [==============================] - 0s 814us/step - loss: 0.3926 - acc: 0.8668 - val_loss: 0.4408 - val_acc: 0.8611\n",
            "Epoch 15/100\n",
            "428/428 [==============================] - 0s 816us/step - loss: 0.3912 - acc: 0.8668 - val_loss: 0.4494 - val_acc: 0.8611\n",
            "Epoch 16/100\n",
            "428/428 [==============================] - 0s 825us/step - loss: 0.4036 - acc: 0.8668 - val_loss: 0.4104 - val_acc: 0.8611\n",
            "Epoch 17/100\n",
            "428/428 [==============================] - 0s 816us/step - loss: 0.3931 - acc: 0.8668 - val_loss: 0.4077 - val_acc: 0.8611\n",
            "Epoch 18/100\n",
            "428/428 [==============================] - 0s 822us/step - loss: 0.3918 - acc: 0.8668 - val_loss: 0.4080 - val_acc: 0.8611\n",
            "Epoch 19/100\n",
            "428/428 [==============================] - 0s 819us/step - loss: 0.3909 - acc: 0.8668 - val_loss: 0.4078 - val_acc: 0.8611\n",
            "Epoch 20/100\n",
            "428/428 [==============================] - 0s 815us/step - loss: 0.3920 - acc: 0.8668 - val_loss: 0.4088 - val_acc: 0.8611\n",
            "Epoch 21/100\n",
            "428/428 [==============================] - 0s 823us/step - loss: 0.4095 - acc: 0.8668 - val_loss: 0.4028 - val_acc: 0.8611\n",
            "Epoch 22/100\n",
            "428/428 [==============================] - 0s 832us/step - loss: 0.3925 - acc: 0.8668 - val_loss: 0.4054 - val_acc: 0.8611\n",
            "Epoch 23/100\n",
            "428/428 [==============================] - 0s 819us/step - loss: 0.3927 - acc: 0.8668 - val_loss: 0.4054 - val_acc: 0.8611\n",
            "Epoch 24/100\n",
            "428/428 [==============================] - 0s 833us/step - loss: 0.3925 - acc: 0.8668 - val_loss: 0.4054 - val_acc: 0.8611\n",
            "Epoch 25/100\n",
            "428/428 [==============================] - 0s 826us/step - loss: 0.4114 - acc: 0.8668 - val_loss: 0.4061 - val_acc: 0.8611\n",
            "Epoch 26/100\n",
            "428/428 [==============================] - 0s 828us/step - loss: 0.3926 - acc: 0.8668 - val_loss: 0.4007 - val_acc: 0.8611\n",
            "Epoch 27/100\n",
            "428/428 [==============================] - 0s 823us/step - loss: 0.4176 - acc: 0.8645 - val_loss: 0.4014 - val_acc: 0.8611\n",
            "Epoch 28/100\n",
            "428/428 [==============================] - 0s 822us/step - loss: 0.3924 - acc: 0.8668 - val_loss: 0.4028 - val_acc: 0.8611\n",
            "Epoch 29/100\n",
            "428/428 [==============================] - 0s 823us/step - loss: 0.3921 - acc: 0.8668 - val_loss: 0.4033 - val_acc: 0.8611\n",
            "Epoch 30/100\n",
            "428/428 [==============================] - 0s 823us/step - loss: 0.3942 - acc: 0.8645 - val_loss: 0.4041 - val_acc: 0.8611\n",
            "Epoch 31/100\n",
            "428/428 [==============================] - 0s 830us/step - loss: 0.3927 - acc: 0.8668 - val_loss: 0.4043 - val_acc: 0.8611\n",
            "Epoch 32/100\n",
            "428/428 [==============================] - 0s 822us/step - loss: 0.4029 - acc: 0.8645 - val_loss: 0.4032 - val_acc: 0.8611\n",
            "Epoch 33/100\n",
            "428/428 [==============================] - 0s 831us/step - loss: 0.3924 - acc: 0.8668 - val_loss: 0.4029 - val_acc: 0.8611\n",
            "Epoch 34/100\n",
            "428/428 [==============================] - 0s 826us/step - loss: 0.3923 - acc: 0.8668 - val_loss: 0.4149 - val_acc: 0.8611\n",
            "Epoch 35/100\n",
            "428/428 [==============================] - 0s 822us/step - loss: 0.4027 - acc: 0.8668 - val_loss: 0.4033 - val_acc: 0.8611\n",
            "Epoch 36/100\n",
            "428/428 [==============================] - 0s 824us/step - loss: 0.3927 - acc: 0.8668 - val_loss: 0.4030 - val_acc: 0.8611\n",
            "Epoch 37/100\n",
            "428/428 [==============================] - 0s 833us/step - loss: 0.3925 - acc: 0.8668 - val_loss: 0.4029 - val_acc: 0.8611\n",
            "Epoch 38/100\n",
            "428/428 [==============================] - 0s 835us/step - loss: 0.3926 - acc: 0.8668 - val_loss: 0.4030 - val_acc: 0.8611\n",
            "Epoch 39/100\n",
            "428/428 [==============================] - 0s 832us/step - loss: 0.3933 - acc: 0.8668 - val_loss: 0.4030 - val_acc: 0.8611\n",
            "Epoch 40/100\n",
            "428/428 [==============================] - 0s 824us/step - loss: 0.3925 - acc: 0.8668 - val_loss: 0.4029 - val_acc: 0.8611\n",
            "Epoch 41/100\n",
            "428/428 [==============================] - 0s 837us/step - loss: 0.3927 - acc: 0.8668 - val_loss: 0.4028 - val_acc: 0.8611\n",
            "Epoch 42/100\n",
            "428/428 [==============================] - 0s 836us/step - loss: 0.3921 - acc: 0.8668 - val_loss: 0.4030 - val_acc: 0.8611\n",
            "Epoch 43/100\n",
            "428/428 [==============================] - 0s 816us/step - loss: 0.3916 - acc: 0.8668 - val_loss: 0.4031 - val_acc: 0.8611\n",
            "Epoch 44/100\n",
            "428/428 [==============================] - 0s 826us/step - loss: 0.3925 - acc: 0.8668 - val_loss: 0.4032 - val_acc: 0.8611\n",
            "Epoch 45/100\n",
            "428/428 [==============================] - 0s 842us/step - loss: 0.3948 - acc: 0.8645 - val_loss: 0.4020 - val_acc: 0.8611\n",
            "Epoch 46/100\n",
            "428/428 [==============================] - 0s 832us/step - loss: 0.3924 - acc: 0.8668 - val_loss: 0.4009 - val_acc: 0.8611\n",
            "Epoch 47/100\n",
            "428/428 [==============================] - 0s 829us/step - loss: 0.3923 - acc: 0.8668 - val_loss: 0.4008 - val_acc: 0.8611\n",
            "Epoch 48/100\n",
            "428/428 [==============================] - 0s 837us/step - loss: 0.3939 - acc: 0.8668 - val_loss: 0.4009 - val_acc: 0.8611\n",
            "Epoch 49/100\n",
            "428/428 [==============================] - 0s 824us/step - loss: 0.3931 - acc: 0.8668 - val_loss: 0.4016 - val_acc: 0.8611\n",
            "Epoch 50/100\n",
            "428/428 [==============================] - 0s 828us/step - loss: 0.3926 - acc: 0.8668 - val_loss: 0.4010 - val_acc: 0.8611\n",
            "Epoch 51/100\n",
            "428/428 [==============================] - 0s 852us/step - loss: 0.3923 - acc: 0.8668 - val_loss: 0.4011 - val_acc: 0.8611\n",
            "Epoch 52/100\n",
            "428/428 [==============================] - 0s 826us/step - loss: 0.3920 - acc: 0.8668 - val_loss: 0.4193 - val_acc: 0.8611\n",
            "Epoch 53/100\n",
            "428/428 [==============================] - 0s 826us/step - loss: 0.4253 - acc: 0.8668 - val_loss: 0.4152 - val_acc: 0.8611\n",
            "Epoch 54/100\n",
            "428/428 [==============================] - 0s 838us/step - loss: 0.4072 - acc: 0.8668 - val_loss: 0.4000 - val_acc: 0.8611\n",
            "Epoch 55/100\n",
            "428/428 [==============================] - 0s 825us/step - loss: 0.3923 - acc: 0.8668 - val_loss: 0.3996 - val_acc: 0.8611\n",
            "Epoch 56/100\n",
            "428/428 [==============================] - 0s 839us/step - loss: 0.3915 - acc: 0.8668 - val_loss: 0.3993 - val_acc: 0.8611\n",
            "Epoch 57/100\n",
            "428/428 [==============================] - 0s 839us/step - loss: 0.3917 - acc: 0.8668 - val_loss: 0.3987 - val_acc: 0.8611\n",
            "Epoch 58/100\n",
            "428/428 [==============================] - 0s 827us/step - loss: 0.3900 - acc: 0.8668 - val_loss: 0.3956 - val_acc: 0.8611\n",
            "Epoch 59/100\n",
            "428/428 [==============================] - 0s 835us/step - loss: 0.3958 - acc: 0.8668 - val_loss: 0.3994 - val_acc: 0.8611\n",
            "Epoch 60/100\n",
            "428/428 [==============================] - 0s 837us/step - loss: 0.3963 - acc: 0.8645 - val_loss: 0.3982 - val_acc: 0.8611\n",
            "Epoch 61/100\n",
            "428/428 [==============================] - 0s 831us/step - loss: 0.3918 - acc: 0.8668 - val_loss: 0.3982 - val_acc: 0.8611\n",
            "Epoch 62/100\n",
            "428/428 [==============================] - 0s 836us/step - loss: 0.3917 - acc: 0.8668 - val_loss: 0.3982 - val_acc: 0.8611\n",
            "Epoch 63/100\n",
            "428/428 [==============================] - 0s 825us/step - loss: 0.4077 - acc: 0.8668 - val_loss: 0.3993 - val_acc: 0.8611\n",
            "Epoch 64/100\n",
            "428/428 [==============================] - 0s 840us/step - loss: 0.3921 - acc: 0.8668 - val_loss: 0.3999 - val_acc: 0.8611\n",
            "Epoch 65/100\n",
            "428/428 [==============================] - 0s 852us/step - loss: 0.3920 - acc: 0.8668 - val_loss: 0.4108 - val_acc: 0.8611\n",
            "Epoch 66/100\n",
            "428/428 [==============================] - 0s 840us/step - loss: 0.3909 - acc: 0.8668 - val_loss: 0.4221 - val_acc: 0.8611\n",
            "Epoch 67/100\n",
            "428/428 [==============================] - 0s 833us/step - loss: 0.3930 - acc: 0.8668 - val_loss: 0.4014 - val_acc: 0.8611\n",
            "Epoch 68/100\n",
            "428/428 [==============================] - 0s 831us/step - loss: 0.3988 - acc: 0.8645 - val_loss: 0.4863 - val_acc: 0.8611\n",
            "Epoch 69/100\n",
            "428/428 [==============================] - 0s 835us/step - loss: 0.6999 - acc: 0.8668 - val_loss: 0.8383 - val_acc: 0.8611\n",
            "Epoch 70/100\n",
            "428/428 [==============================] - 0s 833us/step - loss: 0.6214 - acc: 0.8668 - val_loss: 0.4016 - val_acc: 0.8611\n",
            "Epoch 71/100\n",
            "428/428 [==============================] - 0s 839us/step - loss: 0.3872 - acc: 0.8692 - val_loss: 0.4206 - val_acc: 0.8472\n",
            "Epoch 72/100\n",
            "428/428 [==============================] - 0s 832us/step - loss: 0.4491 - acc: 0.8621 - val_loss: 0.4451 - val_acc: 0.8611\n",
            "Epoch 73/100\n",
            "428/428 [==============================] - 0s 832us/step - loss: 0.3880 - acc: 0.8692 - val_loss: 0.4773 - val_acc: 0.8611\n",
            "Epoch 74/100\n",
            "428/428 [==============================] - 0s 840us/step - loss: 0.4558 - acc: 0.8645 - val_loss: 0.6410 - val_acc: 0.8611\n",
            "Epoch 75/100\n",
            "428/428 [==============================] - 0s 835us/step - loss: 0.4713 - acc: 0.8668 - val_loss: 0.4660 - val_acc: 0.8611\n",
            "Epoch 76/100\n",
            "428/428 [==============================] - 0s 834us/step - loss: 0.4251 - acc: 0.8668 - val_loss: 0.4011 - val_acc: 0.8611\n",
            "Epoch 77/100\n",
            "428/428 [==============================] - 0s 838us/step - loss: 0.3979 - acc: 0.8645 - val_loss: 0.3995 - val_acc: 0.8611\n",
            "Epoch 78/100\n",
            "428/428 [==============================] - 0s 833us/step - loss: 0.4262 - acc: 0.8668 - val_loss: 0.4023 - val_acc: 0.8611\n",
            "Epoch 79/100\n",
            "428/428 [==============================] - 0s 835us/step - loss: 0.4254 - acc: 0.8668 - val_loss: 0.4484 - val_acc: 0.8611\n",
            "Epoch 80/100\n",
            "428/428 [==============================] - 0s 837us/step - loss: 0.3908 - acc: 0.8668 - val_loss: 0.4822 - val_acc: 0.8611\n",
            "Epoch 81/100\n",
            "428/428 [==============================] - 0s 841us/step - loss: 0.4518 - acc: 0.8668 - val_loss: 0.4390 - val_acc: 0.8611\n",
            "Epoch 82/100\n",
            "428/428 [==============================] - 0s 855us/step - loss: 0.3892 - acc: 0.8668 - val_loss: 0.4351 - val_acc: 0.8611\n",
            "Epoch 83/100\n",
            "428/428 [==============================] - 0s 834us/step - loss: 0.3917 - acc: 0.8668 - val_loss: 0.4617 - val_acc: 0.8611\n",
            "Epoch 84/100\n",
            "428/428 [==============================] - 0s 838us/step - loss: 0.4501 - acc: 0.8668 - val_loss: 0.6593 - val_acc: 0.8611\n",
            "Epoch 85/100\n",
            "428/428 [==============================] - 0s 834us/step - loss: 0.6534 - acc: 0.8645 - val_loss: 0.4084 - val_acc: 0.8611\n",
            "Epoch 86/100\n",
            "428/428 [==============================] - 0s 820us/step - loss: 0.3928 - acc: 0.8668 - val_loss: 0.4014 - val_acc: 0.8611\n",
            "Epoch 87/100\n",
            "428/428 [==============================] - 0s 833us/step - loss: 0.4299 - acc: 0.8645 - val_loss: 0.3999 - val_acc: 0.8611\n",
            "Epoch 88/100\n",
            "428/428 [==============================] - 0s 851us/step - loss: 0.3934 - acc: 0.8668 - val_loss: 0.3997 - val_acc: 0.8611\n",
            "Epoch 89/100\n",
            "428/428 [==============================] - 0s 848us/step - loss: 0.3920 - acc: 0.8668 - val_loss: 0.4166 - val_acc: 0.8611\n",
            "Epoch 90/100\n",
            "428/428 [==============================] - 0s 837us/step - loss: 0.4481 - acc: 0.8668 - val_loss: 0.6277 - val_acc: 0.8611\n",
            "Epoch 91/100\n",
            "428/428 [==============================] - 0s 829us/step - loss: 0.5160 - acc: 0.8668 - val_loss: 0.4009 - val_acc: 0.8611\n",
            "Epoch 92/100\n",
            "428/428 [==============================] - 0s 833us/step - loss: 0.3923 - acc: 0.8668 - val_loss: 0.4017 - val_acc: 0.8611\n",
            "Epoch 93/100\n",
            "428/428 [==============================] - 0s 840us/step - loss: 0.3935 - acc: 0.8668 - val_loss: 0.4017 - val_acc: 0.8611\n",
            "Epoch 94/100\n",
            "428/428 [==============================] - 0s 850us/step - loss: 0.3975 - acc: 0.8645 - val_loss: 0.4010 - val_acc: 0.8611\n",
            "Epoch 95/100\n",
            "428/428 [==============================] - 0s 829us/step - loss: 0.3934 - acc: 0.8668 - val_loss: 0.4011 - val_acc: 0.8611\n",
            "Epoch 96/100\n",
            "428/428 [==============================] - 0s 837us/step - loss: 0.3932 - acc: 0.8668 - val_loss: 0.4005 - val_acc: 0.8611\n",
            "Epoch 97/100\n",
            "428/428 [==============================] - 0s 848us/step - loss: 0.3927 - acc: 0.8668 - val_loss: 0.4008 - val_acc: 0.8611\n",
            "Epoch 98/100\n",
            "428/428 [==============================] - 0s 831us/step - loss: 0.3919 - acc: 0.8668 - val_loss: 0.4008 - val_acc: 0.8611\n",
            "Epoch 99/100\n",
            "428/428 [==============================] - 0s 829us/step - loss: 0.3923 - acc: 0.8668 - val_loss: 0.4009 - val_acc: 0.8611\n",
            "Epoch 100/100\n",
            "428/428 [==============================] - 0s 850us/step - loss: 0.3926 - acc: 0.8668 - val_loss: 0.4007 - val_acc: 0.8611\n",
            "[[ 0 10]\n",
            " [ 0 62]]\n",
            "Accuracy :  0.8611111111111112\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        10\n",
            "           1       0.86      1.00      0.93        62\n",
            "\n",
            "    accuracy                           0.86        72\n",
            "   macro avg       0.43      0.50      0.46        72\n",
            "weighted avg       0.74      0.86      0.80        72\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "model_8 (Model)              (None, 2)                 9148782   \n",
            "=================================================================\n",
            "Total params: 9,148,782\n",
            "Trainable params: 8,386\n",
            "Non-trainable params: 9,140,396\n",
            "_________________________________________________________________\n",
            "Train on 428 samples, validate on 72 samples\n",
            "Epoch 1/100\n",
            "428/428 [==============================] - 3s 6ms/step - loss: 0.3930 - acc: 0.8668 - val_loss: 0.3992 - val_acc: 0.8611\n",
            "Epoch 2/100\n",
            "428/428 [==============================] - 0s 820us/step - loss: 0.3910 - acc: 0.8668 - val_loss: 0.3991 - val_acc: 0.8611\n",
            "Epoch 3/100\n",
            "428/428 [==============================] - 0s 807us/step - loss: 0.3914 - acc: 0.8668 - val_loss: 0.3978 - val_acc: 0.8611\n",
            "Epoch 4/100\n",
            "428/428 [==============================] - 0s 834us/step - loss: 0.3920 - acc: 0.8668 - val_loss: 0.3974 - val_acc: 0.8611\n",
            "Epoch 5/100\n",
            "428/428 [==============================] - 0s 812us/step - loss: 0.4251 - acc: 0.8668 - val_loss: 0.3970 - val_acc: 0.8611\n",
            "Epoch 6/100\n",
            "428/428 [==============================] - 0s 818us/step - loss: 0.3916 - acc: 0.8668 - val_loss: 0.3954 - val_acc: 0.8611\n",
            "Epoch 7/100\n",
            "428/428 [==============================] - 0s 831us/step - loss: 0.3909 - acc: 0.8668 - val_loss: 0.3937 - val_acc: 0.8611\n",
            "Epoch 8/100\n",
            "428/428 [==============================] - 0s 813us/step - loss: 0.3905 - acc: 0.8668 - val_loss: 0.3909 - val_acc: 0.8611\n",
            "Epoch 9/100\n",
            "428/428 [==============================] - 0s 807us/step - loss: 0.4034 - acc: 0.8645 - val_loss: 0.3963 - val_acc: 0.8611\n",
            "Epoch 10/100\n",
            "428/428 [==============================] - 0s 815us/step - loss: 0.4392 - acc: 0.8668 - val_loss: 0.3982 - val_acc: 0.8611\n",
            "Epoch 11/100\n",
            "428/428 [==============================] - 0s 814us/step - loss: 0.4012 - acc: 0.8668 - val_loss: 0.3990 - val_acc: 0.8611\n",
            "Epoch 12/100\n",
            "428/428 [==============================] - 0s 825us/step - loss: 0.4235 - acc: 0.8668 - val_loss: 0.3992 - val_acc: 0.8611\n",
            "Epoch 13/100\n",
            "428/428 [==============================] - 0s 815us/step - loss: 0.4322 - acc: 0.8645 - val_loss: 0.3996 - val_acc: 0.8611\n",
            "Epoch 14/100\n",
            "428/428 [==============================] - 0s 809us/step - loss: 0.3915 - acc: 0.8668 - val_loss: 0.4000 - val_acc: 0.8611\n",
            "Epoch 15/100\n",
            "428/428 [==============================] - 0s 814us/step - loss: 0.3927 - acc: 0.8668 - val_loss: 0.3986 - val_acc: 0.8611\n",
            "Epoch 16/100\n",
            "428/428 [==============================] - 0s 828us/step - loss: 0.3922 - acc: 0.8668 - val_loss: 0.3984 - val_acc: 0.8611\n",
            "Epoch 17/100\n",
            "428/428 [==============================] - 0s 824us/step - loss: 0.3899 - acc: 0.8668 - val_loss: 0.3964 - val_acc: 0.8611\n",
            "Epoch 18/100\n",
            "428/428 [==============================] - 0s 824us/step - loss: 0.5082 - acc: 0.8668 - val_loss: 0.3969 - val_acc: 0.8611\n",
            "Epoch 19/100\n",
            "428/428 [==============================] - 0s 821us/step - loss: 0.4535 - acc: 0.8668 - val_loss: 0.3987 - val_acc: 0.8611\n",
            "Epoch 20/100\n",
            "428/428 [==============================] - 0s 820us/step - loss: 0.4605 - acc: 0.8645 - val_loss: 0.3988 - val_acc: 0.8611\n",
            "Epoch 21/100\n",
            "428/428 [==============================] - 0s 825us/step - loss: 0.3959 - acc: 0.8668 - val_loss: 0.3709 - val_acc: 0.8611\n",
            "Epoch 22/100\n",
            "428/428 [==============================] - 0s 825us/step - loss: 0.4534 - acc: 0.8668 - val_loss: 0.3892 - val_acc: 0.8611\n",
            "Epoch 23/100\n",
            "428/428 [==============================] - 0s 827us/step - loss: 0.3909 - acc: 0.8668 - val_loss: 0.3972 - val_acc: 0.8611\n",
            "Epoch 24/100\n",
            "428/428 [==============================] - 0s 832us/step - loss: 0.3924 - acc: 0.8668 - val_loss: 0.3977 - val_acc: 0.8611\n",
            "Epoch 25/100\n",
            "428/428 [==============================] - 0s 816us/step - loss: 0.3912 - acc: 0.8668 - val_loss: 0.3974 - val_acc: 0.8611\n",
            "Epoch 26/100\n",
            "428/428 [==============================] - 0s 820us/step - loss: 0.3940 - acc: 0.8668 - val_loss: 0.3993 - val_acc: 0.8611\n",
            "Epoch 27/100\n",
            "428/428 [==============================] - 0s 815us/step - loss: 0.4258 - acc: 0.8668 - val_loss: 0.3988 - val_acc: 0.8611\n",
            "Epoch 28/100\n",
            "428/428 [==============================] - 0s 823us/step - loss: 0.4091 - acc: 0.8668 - val_loss: 0.4021 - val_acc: 0.8611\n",
            "Epoch 29/100\n",
            "428/428 [==============================] - 0s 822us/step - loss: 0.3919 - acc: 0.8668 - val_loss: 0.4028 - val_acc: 0.8611\n",
            "Epoch 30/100\n",
            "428/428 [==============================] - 0s 821us/step - loss: 0.3917 - acc: 0.8668 - val_loss: 0.4042 - val_acc: 0.8611\n",
            "Epoch 31/100\n",
            "428/428 [==============================] - 0s 826us/step - loss: 0.3934 - acc: 0.8668 - val_loss: 0.4074 - val_acc: 0.8611\n",
            "Epoch 32/100\n",
            "428/428 [==============================] - 0s 825us/step - loss: 0.4016 - acc: 0.8668 - val_loss: 0.4111 - val_acc: 0.8611\n",
            "Epoch 33/100\n",
            "428/428 [==============================] - 0s 821us/step - loss: 0.3922 - acc: 0.8668 - val_loss: 0.4130 - val_acc: 0.8611\n",
            "Epoch 34/100\n",
            "428/428 [==============================] - 0s 828us/step - loss: 0.3935 - acc: 0.8668 - val_loss: 0.4138 - val_acc: 0.8611\n",
            "Epoch 35/100\n",
            "428/428 [==============================] - 0s 812us/step - loss: 0.3941 - acc: 0.8668 - val_loss: 0.4063 - val_acc: 0.8611\n",
            "Epoch 36/100\n",
            "428/428 [==============================] - 0s 832us/step - loss: 0.3926 - acc: 0.8668 - val_loss: 0.4036 - val_acc: 0.8611\n",
            "Epoch 37/100\n",
            "428/428 [==============================] - 0s 826us/step - loss: 0.3911 - acc: 0.8668 - val_loss: 0.4037 - val_acc: 0.8611\n",
            "Epoch 38/100\n",
            "428/428 [==============================] - 0s 827us/step - loss: 0.3915 - acc: 0.8668 - val_loss: 0.4048 - val_acc: 0.8611\n",
            "Epoch 39/100\n",
            "428/428 [==============================] - 0s 826us/step - loss: 0.3922 - acc: 0.8668 - val_loss: 0.4044 - val_acc: 0.8611\n",
            "Epoch 40/100\n",
            "428/428 [==============================] - 0s 829us/step - loss: 0.3918 - acc: 0.8668 - val_loss: 0.4134 - val_acc: 0.8611\n",
            "Epoch 41/100\n",
            "428/428 [==============================] - 0s 829us/step - loss: 0.4078 - acc: 0.8668 - val_loss: 0.4025 - val_acc: 0.8611\n",
            "Epoch 42/100\n",
            "428/428 [==============================] - 0s 831us/step - loss: 0.3920 - acc: 0.8668 - val_loss: 0.4057 - val_acc: 0.8611\n",
            "Epoch 43/100\n",
            "428/428 [==============================] - 0s 829us/step - loss: 0.3908 - acc: 0.8668 - val_loss: 0.4091 - val_acc: 0.8611\n",
            "Epoch 44/100\n",
            "428/428 [==============================] - 0s 822us/step - loss: 0.3980 - acc: 0.8668 - val_loss: 0.4005 - val_acc: 0.8611\n",
            "Epoch 45/100\n",
            "428/428 [==============================] - 0s 830us/step - loss: 0.3926 - acc: 0.8668 - val_loss: 0.4018 - val_acc: 0.8611\n",
            "Epoch 46/100\n",
            "428/428 [==============================] - 0s 823us/step - loss: 0.3921 - acc: 0.8668 - val_loss: 0.4026 - val_acc: 0.8611\n",
            "Epoch 47/100\n",
            "428/428 [==============================] - 0s 844us/step - loss: 0.3920 - acc: 0.8668 - val_loss: 0.4023 - val_acc: 0.8611\n",
            "Epoch 48/100\n",
            "428/428 [==============================] - 0s 843us/step - loss: 0.3918 - acc: 0.8668 - val_loss: 0.4021 - val_acc: 0.8611\n",
            "Epoch 49/100\n",
            "428/428 [==============================] - 0s 824us/step - loss: 0.3921 - acc: 0.8668 - val_loss: 0.4022 - val_acc: 0.8611\n",
            "Epoch 50/100\n",
            "428/428 [==============================] - 0s 824us/step - loss: 0.3923 - acc: 0.8668 - val_loss: 0.4022 - val_acc: 0.8611\n",
            "Epoch 51/100\n",
            "428/428 [==============================] - 0s 833us/step - loss: 0.3919 - acc: 0.8668 - val_loss: 0.4022 - val_acc: 0.8611\n",
            "Epoch 52/100\n",
            "428/428 [==============================] - 0s 829us/step - loss: 0.3930 - acc: 0.8668 - val_loss: 0.4022 - val_acc: 0.8611\n",
            "Epoch 53/100\n",
            "428/428 [==============================] - 0s 827us/step - loss: 0.3916 - acc: 0.8668 - val_loss: 0.4021 - val_acc: 0.8611\n",
            "Epoch 54/100\n",
            "428/428 [==============================] - 0s 833us/step - loss: 0.4239 - acc: 0.8668 - val_loss: 0.4022 - val_acc: 0.8611\n",
            "Epoch 55/100\n",
            "428/428 [==============================] - 0s 834us/step - loss: 0.3931 - acc: 0.8668 - val_loss: 0.4021 - val_acc: 0.8611\n",
            "Epoch 56/100\n",
            "428/428 [==============================] - 0s 833us/step - loss: 0.3901 - acc: 0.8668 - val_loss: 0.4380 - val_acc: 0.8611\n",
            "Epoch 57/100\n",
            "428/428 [==============================] - 0s 829us/step - loss: 0.4618 - acc: 0.8645 - val_loss: 0.4220 - val_acc: 0.8333\n",
            "Epoch 58/100\n",
            "428/428 [==============================] - 0s 822us/step - loss: 0.4387 - acc: 0.8621 - val_loss: 0.4022 - val_acc: 0.8611\n",
            "Epoch 59/100\n",
            "428/428 [==============================] - 0s 838us/step - loss: 0.3923 - acc: 0.8668 - val_loss: 0.4023 - val_acc: 0.8611\n",
            "Epoch 60/100\n",
            "428/428 [==============================] - 0s 832us/step - loss: 0.3917 - acc: 0.8668 - val_loss: 0.4024 - val_acc: 0.8611\n",
            "Epoch 61/100\n",
            "428/428 [==============================] - 0s 826us/step - loss: 0.3917 - acc: 0.8668 - val_loss: 0.4027 - val_acc: 0.8611\n",
            "Epoch 62/100\n",
            "428/428 [==============================] - 0s 842us/step - loss: 0.3911 - acc: 0.8668 - val_loss: 0.4021 - val_acc: 0.8611\n",
            "Epoch 63/100\n",
            "428/428 [==============================] - 0s 842us/step - loss: 0.4097 - acc: 0.8668 - val_loss: 0.4020 - val_acc: 0.8611\n",
            "Epoch 64/100\n",
            "428/428 [==============================] - 0s 828us/step - loss: 0.4127 - acc: 0.8621 - val_loss: 0.4028 - val_acc: 0.8611\n",
            "Epoch 65/100\n",
            "428/428 [==============================] - 0s 835us/step - loss: 0.3904 - acc: 0.8668 - val_loss: 0.4029 - val_acc: 0.8611\n",
            "Epoch 66/100\n",
            "428/428 [==============================] - 0s 832us/step - loss: 0.3920 - acc: 0.8668 - val_loss: 0.4030 - val_acc: 0.8611\n",
            "Epoch 67/100\n",
            "428/428 [==============================] - 0s 832us/step - loss: 0.3930 - acc: 0.8668 - val_loss: 0.4035 - val_acc: 0.8611\n",
            "Epoch 68/100\n",
            "428/428 [==============================] - 0s 836us/step - loss: 0.3918 - acc: 0.8668 - val_loss: 0.4048 - val_acc: 0.8611\n",
            "Epoch 69/100\n",
            "428/428 [==============================] - 0s 834us/step - loss: 0.4120 - acc: 0.8668 - val_loss: 0.4015 - val_acc: 0.8611\n",
            "Epoch 70/100\n",
            "428/428 [==============================] - 0s 840us/step - loss: 0.3926 - acc: 0.8668 - val_loss: 0.4300 - val_acc: 0.8611\n",
            "Epoch 71/100\n",
            "428/428 [==============================] - 0s 828us/step - loss: 0.4235 - acc: 0.8668 - val_loss: 0.4601 - val_acc: 0.8611\n",
            "Epoch 72/100\n",
            "428/428 [==============================] - 0s 830us/step - loss: 0.3959 - acc: 0.8668 - val_loss: 0.4752 - val_acc: 0.8611\n",
            "Epoch 73/100\n",
            "428/428 [==============================] - 0s 833us/step - loss: 0.3903 - acc: 0.8668 - val_loss: 0.4797 - val_acc: 0.8611\n",
            "Epoch 74/100\n",
            "428/428 [==============================] - 0s 842us/step - loss: 0.3892 - acc: 0.8668 - val_loss: 0.4798 - val_acc: 0.8611\n",
            "Epoch 75/100\n",
            "428/428 [==============================] - 0s 830us/step - loss: 0.4099 - acc: 0.8668 - val_loss: 0.5384 - val_acc: 0.8611\n",
            "Epoch 76/100\n",
            "428/428 [==============================] - 0s 836us/step - loss: 0.4674 - acc: 0.8668 - val_loss: 0.4316 - val_acc: 0.8611\n",
            "Epoch 77/100\n",
            "428/428 [==============================] - 0s 836us/step - loss: 0.3926 - acc: 0.8668 - val_loss: 0.4066 - val_acc: 0.8611\n",
            "Epoch 78/100\n",
            "428/428 [==============================] - 0s 838us/step - loss: 0.3927 - acc: 0.8668 - val_loss: 0.4065 - val_acc: 0.8611\n",
            "Epoch 79/100\n",
            "428/428 [==============================] - 0s 833us/step - loss: 0.4169 - acc: 0.8621 - val_loss: 0.4066 - val_acc: 0.8611\n",
            "Epoch 80/100\n",
            "428/428 [==============================] - 0s 836us/step - loss: 0.3916 - acc: 0.8668 - val_loss: 0.4068 - val_acc: 0.8611\n",
            "Epoch 81/100\n",
            "428/428 [==============================] - 0s 843us/step - loss: 0.3920 - acc: 0.8668 - val_loss: 0.4067 - val_acc: 0.8611\n",
            "Epoch 82/100\n",
            "428/428 [==============================] - 0s 844us/step - loss: 0.3996 - acc: 0.8668 - val_loss: 0.4068 - val_acc: 0.8611\n",
            "Epoch 83/100\n",
            "428/428 [==============================] - 0s 836us/step - loss: 0.3922 - acc: 0.8668 - val_loss: 0.4068 - val_acc: 0.8611\n",
            "Epoch 84/100\n",
            "428/428 [==============================] - 0s 838us/step - loss: 0.3924 - acc: 0.8668 - val_loss: 0.4067 - val_acc: 0.8611\n",
            "Epoch 85/100\n",
            "428/428 [==============================] - 0s 850us/step - loss: 0.3919 - acc: 0.8668 - val_loss: 0.4068 - val_acc: 0.8611\n",
            "Epoch 86/100\n",
            "428/428 [==============================] - 0s 831us/step - loss: 0.3883 - acc: 0.8692 - val_loss: 0.4072 - val_acc: 0.8611\n",
            "Epoch 87/100\n",
            "428/428 [==============================] - 0s 845us/step - loss: 0.4570 - acc: 0.8645 - val_loss: 0.4090 - val_acc: 0.8611\n",
            "Epoch 88/100\n",
            "428/428 [==============================] - 0s 843us/step - loss: 0.4262 - acc: 0.8668 - val_loss: 0.4107 - val_acc: 0.8611\n",
            "Epoch 89/100\n",
            "428/428 [==============================] - 0s 845us/step - loss: 0.3916 - acc: 0.8668 - val_loss: 0.4106 - val_acc: 0.8611\n",
            "Epoch 90/100\n",
            "428/428 [==============================] - 0s 838us/step - loss: 0.3916 - acc: 0.8668 - val_loss: 0.4128 - val_acc: 0.8611\n",
            "Epoch 91/100\n",
            "428/428 [==============================] - 0s 853us/step - loss: 0.3931 - acc: 0.8668 - val_loss: 0.4140 - val_acc: 0.8611\n",
            "Epoch 92/100\n",
            "428/428 [==============================] - 0s 843us/step - loss: 0.3921 - acc: 0.8668 - val_loss: 0.4151 - val_acc: 0.8611\n",
            "Epoch 93/100\n",
            "428/428 [==============================] - 0s 834us/step - loss: 0.4250 - acc: 0.8668 - val_loss: 0.4163 - val_acc: 0.8611\n",
            "Epoch 94/100\n",
            "428/428 [==============================] - 0s 832us/step - loss: 0.3908 - acc: 0.8668 - val_loss: 0.4148 - val_acc: 0.8611\n",
            "Epoch 95/100\n",
            "428/428 [==============================] - 0s 844us/step - loss: 0.3967 - acc: 0.8645 - val_loss: 0.4133 - val_acc: 0.8611\n",
            "Epoch 96/100\n",
            "428/428 [==============================] - 0s 834us/step - loss: 0.3914 - acc: 0.8668 - val_loss: 0.4123 - val_acc: 0.8611\n",
            "Epoch 97/100\n",
            "428/428 [==============================] - 0s 836us/step - loss: 0.3916 - acc: 0.8668 - val_loss: 0.4136 - val_acc: 0.8611\n",
            "Epoch 98/100\n",
            "428/428 [==============================] - 0s 838us/step - loss: 0.3918 - acc: 0.8668 - val_loss: 0.4135 - val_acc: 0.8611\n",
            "Epoch 99/100\n",
            "428/428 [==============================] - 0s 848us/step - loss: 0.3923 - acc: 0.8668 - val_loss: 0.4141 - val_acc: 0.8611\n",
            "Epoch 100/100\n",
            "428/428 [==============================] - 0s 832us/step - loss: 0.3919 - acc: 0.8668 - val_loss: 0.4143 - val_acc: 0.8611\n",
            "[[ 0 10]\n",
            " [ 0 62]]\n",
            "Accuracy :  0.8611111111111112\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        10\n",
            "           1       0.86      1.00      0.93        62\n",
            "\n",
            "    accuracy                           0.86        72\n",
            "   macro avg       0.43      0.50      0.46        72\n",
            "weighted avg       0.74      0.86      0.80        72\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "model_8 (Model)              (None, 2)                 9148782   \n",
            "=================================================================\n",
            "Total params: 9,148,782\n",
            "Trainable params: 8,386\n",
            "Non-trainable params: 9,140,396\n",
            "_________________________________________________________________\n",
            "Train on 429 samples, validate on 71 samples\n",
            "Epoch 1/100\n",
            "429/429 [==============================] - 3s 6ms/step - loss: 0.4064 - acc: 0.8648 - val_loss: 0.3758 - val_acc: 0.8732\n",
            "Epoch 2/100\n",
            "429/429 [==============================] - 0s 824us/step - loss: 0.4002 - acc: 0.8625 - val_loss: 0.3758 - val_acc: 0.8732\n",
            "Epoch 3/100\n",
            "429/429 [==============================] - 0s 805us/step - loss: 0.3946 - acc: 0.8648 - val_loss: 0.3751 - val_acc: 0.8732\n",
            "Epoch 4/100\n",
            "429/429 [==============================] - 0s 810us/step - loss: 0.3959 - acc: 0.8648 - val_loss: 0.3741 - val_acc: 0.8732\n",
            "Epoch 5/100\n",
            "429/429 [==============================] - 0s 809us/step - loss: 0.4051 - acc: 0.8648 - val_loss: 0.3738 - val_acc: 0.8732\n",
            "Epoch 6/100\n",
            "429/429 [==============================] - 0s 807us/step - loss: 0.4211 - acc: 0.8648 - val_loss: 0.3761 - val_acc: 0.8732\n",
            "Epoch 7/100\n",
            "429/429 [==============================] - 0s 807us/step - loss: 0.4215 - acc: 0.8648 - val_loss: 0.3909 - val_acc: 0.8732\n",
            "Epoch 8/100\n",
            "429/429 [==============================] - 0s 815us/step - loss: 0.4076 - acc: 0.8648 - val_loss: 0.5085 - val_acc: 0.8732\n",
            "Epoch 9/100\n",
            "429/429 [==============================] - 0s 818us/step - loss: 0.4382 - acc: 0.8648 - val_loss: 0.8395 - val_acc: 0.8732\n",
            "Epoch 10/100\n",
            "429/429 [==============================] - 0s 818us/step - loss: 0.4591 - acc: 0.8648 - val_loss: 0.9490 - val_acc: 0.8732\n",
            "Epoch 11/100\n",
            "429/429 [==============================] - 0s 820us/step - loss: 0.4541 - acc: 0.8648 - val_loss: 1.0314 - val_acc: 0.8732\n",
            "Epoch 12/100\n",
            "429/429 [==============================] - 0s 814us/step - loss: 0.5292 - acc: 0.8648 - val_loss: 0.6432 - val_acc: 0.8732\n",
            "Epoch 13/100\n",
            "429/429 [==============================] - 0s 822us/step - loss: 0.4177 - acc: 0.8648 - val_loss: 0.4103 - val_acc: 0.8732\n",
            "Epoch 14/100\n",
            "429/429 [==============================] - 0s 848us/step - loss: 0.4281 - acc: 0.8648 - val_loss: 0.4044 - val_acc: 0.8732\n",
            "Epoch 15/100\n",
            "429/429 [==============================] - 0s 821us/step - loss: 0.3961 - acc: 0.8648 - val_loss: 0.4134 - val_acc: 0.8732\n",
            "Epoch 16/100\n",
            "429/429 [==============================] - 0s 820us/step - loss: 0.4529 - acc: 0.8648 - val_loss: 0.3835 - val_acc: 0.8732\n",
            "Epoch 17/100\n",
            "429/429 [==============================] - 0s 824us/step - loss: 0.4020 - acc: 0.8648 - val_loss: 0.3783 - val_acc: 0.8732\n",
            "Epoch 18/100\n",
            "429/429 [==============================] - 0s 824us/step - loss: 0.3941 - acc: 0.8648 - val_loss: 0.3789 - val_acc: 0.8732\n",
            "Epoch 19/100\n",
            "429/429 [==============================] - 0s 829us/step - loss: 0.4269 - acc: 0.8648 - val_loss: 0.3778 - val_acc: 0.8732\n",
            "Epoch 20/100\n",
            "429/429 [==============================] - 0s 818us/step - loss: 0.3977 - acc: 0.8648 - val_loss: 0.4019 - val_acc: 0.8732\n",
            "Epoch 21/100\n",
            "429/429 [==============================] - 0s 817us/step - loss: 0.4265 - acc: 0.8648 - val_loss: 0.4106 - val_acc: 0.8732\n",
            "Epoch 22/100\n",
            "429/429 [==============================] - 0s 822us/step - loss: 0.5510 - acc: 0.8648 - val_loss: 1.3017 - val_acc: 0.8732\n",
            "Epoch 23/100\n",
            "429/429 [==============================] - 0s 820us/step - loss: 0.6788 - acc: 0.8648 - val_loss: 1.3087 - val_acc: 0.8732\n",
            "Epoch 24/100\n",
            "429/429 [==============================] - 0s 821us/step - loss: 0.5773 - acc: 0.8648 - val_loss: 1.3068 - val_acc: 0.8732\n",
            "Epoch 25/100\n",
            "429/429 [==============================] - 0s 819us/step - loss: 0.6392 - acc: 0.8648 - val_loss: 1.2854 - val_acc: 0.8732\n",
            "Epoch 26/100\n",
            "429/429 [==============================] - 0s 818us/step - loss: 0.6907 - acc: 0.8625 - val_loss: 1.2800 - val_acc: 0.8732\n",
            "Epoch 27/100\n",
            "429/429 [==============================] - 0s 823us/step - loss: 0.7473 - acc: 0.8625 - val_loss: 1.2753 - val_acc: 0.8732\n",
            "Epoch 28/100\n",
            "429/429 [==============================] - 0s 823us/step - loss: 0.4232 - acc: 0.8648 - val_loss: 0.8498 - val_acc: 0.8732\n",
            "Epoch 29/100\n",
            "429/429 [==============================] - 0s 828us/step - loss: 0.3940 - acc: 0.8648 - val_loss: 0.7879 - val_acc: 0.8732\n",
            "Epoch 30/100\n",
            "429/429 [==============================] - 0s 821us/step - loss: 0.4591 - acc: 0.8648 - val_loss: 0.7879 - val_acc: 0.8732\n",
            "Epoch 31/100\n",
            "429/429 [==============================] - 0s 827us/step - loss: 0.4599 - acc: 0.8648 - val_loss: 0.7935 - val_acc: 0.8732\n",
            "Epoch 32/100\n",
            "429/429 [==============================] - 0s 815us/step - loss: 0.4296 - acc: 0.8648 - val_loss: 0.6217 - val_acc: 0.8732\n",
            "Epoch 33/100\n",
            "429/429 [==============================] - 0s 819us/step - loss: 0.4263 - acc: 0.8648 - val_loss: 0.4592 - val_acc: 0.8732\n",
            "Epoch 34/100\n",
            "429/429 [==============================] - 0s 820us/step - loss: 0.4181 - acc: 0.8648 - val_loss: 0.4349 - val_acc: 0.8732\n",
            "Epoch 35/100\n",
            "429/429 [==============================] - 0s 820us/step - loss: 0.4293 - acc: 0.8648 - val_loss: 0.4315 - val_acc: 0.8732\n",
            "Epoch 36/100\n",
            "429/429 [==============================] - 0s 819us/step - loss: 0.4274 - acc: 0.8648 - val_loss: 0.4315 - val_acc: 0.8732\n",
            "Epoch 37/100\n",
            "429/429 [==============================] - 0s 828us/step - loss: 0.4591 - acc: 0.8648 - val_loss: 0.4341 - val_acc: 0.8732\n",
            "Epoch 38/100\n",
            "429/429 [==============================] - 0s 834us/step - loss: 0.3932 - acc: 0.8648 - val_loss: 0.4401 - val_acc: 0.8732\n",
            "Epoch 39/100\n",
            "429/429 [==============================] - 0s 823us/step - loss: 0.3944 - acc: 0.8648 - val_loss: 0.4406 - val_acc: 0.8732\n",
            "Epoch 40/100\n",
            "429/429 [==============================] - 0s 839us/step - loss: 0.4256 - acc: 0.8648 - val_loss: 0.4453 - val_acc: 0.8732\n",
            "Epoch 41/100\n",
            "429/429 [==============================] - 0s 823us/step - loss: 0.3978 - acc: 0.8648 - val_loss: 0.4537 - val_acc: 0.8732\n",
            "Epoch 42/100\n",
            "429/429 [==============================] - 0s 821us/step - loss: 0.4045 - acc: 0.8648 - val_loss: 0.3789 - val_acc: 0.8732\n",
            "Epoch 43/100\n",
            "429/429 [==============================] - 0s 840us/step - loss: 0.3980 - acc: 0.8648 - val_loss: 0.5917 - val_acc: 0.8732\n",
            "Epoch 44/100\n",
            "429/429 [==============================] - 0s 826us/step - loss: 0.4277 - acc: 0.8648 - val_loss: 0.7702 - val_acc: 0.8732\n",
            "Epoch 45/100\n",
            "429/429 [==============================] - 0s 828us/step - loss: 0.4074 - acc: 0.8625 - val_loss: 0.4696 - val_acc: 0.8732\n",
            "Epoch 46/100\n",
            "429/429 [==============================] - 0s 828us/step - loss: 0.4271 - acc: 0.8648 - val_loss: 0.4475 - val_acc: 0.8732\n",
            "Epoch 47/100\n",
            "429/429 [==============================] - 0s 821us/step - loss: 0.4829 - acc: 0.8601 - val_loss: 0.3808 - val_acc: 0.8732\n",
            "Epoch 48/100\n",
            "429/429 [==============================] - 0s 838us/step - loss: 0.4106 - acc: 0.8648 - val_loss: 0.3803 - val_acc: 0.8732\n",
            "Epoch 49/100\n",
            "429/429 [==============================] - 0s 820us/step - loss: 0.3955 - acc: 0.8648 - val_loss: 0.3797 - val_acc: 0.8732\n",
            "Epoch 50/100\n",
            "429/429 [==============================] - 0s 826us/step - loss: 0.4042 - acc: 0.8625 - val_loss: 0.3791 - val_acc: 0.8732\n",
            "Epoch 51/100\n",
            "429/429 [==============================] - 0s 833us/step - loss: 0.4056 - acc: 0.8625 - val_loss: 0.3794 - val_acc: 0.8732\n",
            "Epoch 52/100\n",
            "429/429 [==============================] - 0s 823us/step - loss: 0.3959 - acc: 0.8648 - val_loss: 0.4873 - val_acc: 0.8732\n",
            "Epoch 53/100\n",
            "429/429 [==============================] - 0s 824us/step - loss: 0.4506 - acc: 0.8648 - val_loss: 0.3957 - val_acc: 0.8732\n",
            "Epoch 54/100\n",
            "429/429 [==============================] - 0s 832us/step - loss: 0.4456 - acc: 0.8648 - val_loss: 0.3796 - val_acc: 0.8732\n",
            "Epoch 55/100\n",
            "429/429 [==============================] - 0s 838us/step - loss: 0.3964 - acc: 0.8648 - val_loss: 0.3785 - val_acc: 0.8732\n",
            "Epoch 56/100\n",
            "429/429 [==============================] - 0s 826us/step - loss: 0.3960 - acc: 0.8648 - val_loss: 0.3785 - val_acc: 0.8732\n",
            "Epoch 57/100\n",
            "429/429 [==============================] - 0s 828us/step - loss: 0.3957 - acc: 0.8648 - val_loss: 0.3789 - val_acc: 0.8732\n",
            "Epoch 58/100\n",
            "429/429 [==============================] - 0s 829us/step - loss: 0.3964 - acc: 0.8648 - val_loss: 0.3791 - val_acc: 0.8732\n",
            "Epoch 59/100\n",
            "429/429 [==============================] - 0s 820us/step - loss: 0.3968 - acc: 0.8648 - val_loss: 0.3798 - val_acc: 0.8732\n",
            "Epoch 60/100\n",
            "429/429 [==============================] - 0s 838us/step - loss: 0.3958 - acc: 0.8648 - val_loss: 0.3796 - val_acc: 0.8732\n",
            "Epoch 61/100\n",
            "429/429 [==============================] - 0s 825us/step - loss: 0.4110 - acc: 0.8648 - val_loss: 0.3803 - val_acc: 0.8732\n",
            "Epoch 62/100\n",
            "429/429 [==============================] - 0s 828us/step - loss: 0.3983 - acc: 0.8648 - val_loss: 0.3800 - val_acc: 0.8732\n",
            "Epoch 63/100\n",
            "429/429 [==============================] - 0s 834us/step - loss: 0.3964 - acc: 0.8648 - val_loss: 0.3796 - val_acc: 0.8732\n",
            "Epoch 64/100\n",
            "429/429 [==============================] - 0s 833us/step - loss: 0.3962 - acc: 0.8648 - val_loss: 0.3801 - val_acc: 0.8732\n",
            "Epoch 65/100\n",
            "429/429 [==============================] - 0s 838us/step - loss: 0.3947 - acc: 0.8648 - val_loss: 0.3801 - val_acc: 0.8732\n",
            "Epoch 66/100\n",
            "429/429 [==============================] - 0s 857us/step - loss: 0.3950 - acc: 0.8648 - val_loss: 0.3802 - val_acc: 0.8732\n",
            "Epoch 67/100\n",
            "429/429 [==============================] - 0s 831us/step - loss: 0.3990 - acc: 0.8648 - val_loss: 0.3809 - val_acc: 0.8732\n",
            "Epoch 68/100\n",
            "429/429 [==============================] - 0s 834us/step - loss: 0.3953 - acc: 0.8648 - val_loss: 0.3783 - val_acc: 0.8732\n",
            "Epoch 69/100\n",
            "429/429 [==============================] - 0s 832us/step - loss: 0.3939 - acc: 0.8648 - val_loss: 0.5377 - val_acc: 0.8732\n",
            "Epoch 70/100\n",
            "429/429 [==============================] - 0s 833us/step - loss: 0.6150 - acc: 0.8648 - val_loss: 0.4631 - val_acc: 0.8732\n",
            "Epoch 71/100\n",
            "429/429 [==============================] - 0s 830us/step - loss: 0.4212 - acc: 0.8555 - val_loss: 0.3794 - val_acc: 0.8732\n",
            "Epoch 72/100\n",
            "429/429 [==============================] - 0s 823us/step - loss: 0.3946 - acc: 0.8648 - val_loss: 0.3798 - val_acc: 0.8732\n",
            "Epoch 73/100\n",
            "429/429 [==============================] - 0s 829us/step - loss: 0.3962 - acc: 0.8648 - val_loss: 0.3803 - val_acc: 0.8732\n",
            "Epoch 74/100\n",
            "429/429 [==============================] - 0s 833us/step - loss: 0.3947 - acc: 0.8648 - val_loss: 0.3808 - val_acc: 0.8732\n",
            "Epoch 75/100\n",
            "429/429 [==============================] - 0s 834us/step - loss: 0.3949 - acc: 0.8648 - val_loss: 0.3805 - val_acc: 0.8732\n",
            "Epoch 76/100\n",
            "429/429 [==============================] - 0s 828us/step - loss: 0.4167 - acc: 0.8648 - val_loss: 0.3803 - val_acc: 0.8732\n",
            "Epoch 77/100\n",
            "429/429 [==============================] - 0s 837us/step - loss: 0.3955 - acc: 0.8648 - val_loss: 0.3799 - val_acc: 0.8732\n",
            "Epoch 78/100\n",
            "429/429 [==============================] - 0s 829us/step - loss: 0.3945 - acc: 0.8648 - val_loss: 0.3798 - val_acc: 0.8732\n",
            "Epoch 79/100\n",
            "429/429 [==============================] - 0s 830us/step - loss: 0.3960 - acc: 0.8648 - val_loss: 0.3797 - val_acc: 0.8732\n",
            "Epoch 80/100\n",
            "429/429 [==============================] - 0s 837us/step - loss: 0.3944 - acc: 0.8648 - val_loss: 0.3803 - val_acc: 0.8732\n",
            "Epoch 81/100\n",
            "429/429 [==============================] - 0s 839us/step - loss: 0.3942 - acc: 0.8648 - val_loss: 0.3749 - val_acc: 0.8732\n",
            "Epoch 82/100\n",
            "429/429 [==============================] - 0s 839us/step - loss: 0.4504 - acc: 0.8648 - val_loss: 0.3705 - val_acc: 0.8732\n",
            "Epoch 83/100\n",
            "429/429 [==============================] - 0s 840us/step - loss: 0.4158 - acc: 0.8648 - val_loss: 0.3841 - val_acc: 0.8732\n",
            "Epoch 84/100\n",
            "429/429 [==============================] - 0s 836us/step - loss: 0.3953 - acc: 0.8648 - val_loss: 0.3853 - val_acc: 0.8732\n",
            "Epoch 85/100\n",
            "429/429 [==============================] - 0s 839us/step - loss: 0.3951 - acc: 0.8648 - val_loss: 0.3903 - val_acc: 0.8732\n",
            "Epoch 86/100\n",
            "429/429 [==============================] - 0s 841us/step - loss: 0.3971 - acc: 0.8648 - val_loss: 0.3823 - val_acc: 0.8732\n",
            "Epoch 87/100\n",
            "429/429 [==============================] - 0s 835us/step - loss: 0.3951 - acc: 0.8648 - val_loss: 0.3820 - val_acc: 0.8732\n",
            "Epoch 88/100\n",
            "429/429 [==============================] - 0s 832us/step - loss: 0.4151 - acc: 0.8648 - val_loss: 0.3781 - val_acc: 0.8732\n",
            "Epoch 89/100\n",
            "429/429 [==============================] - 0s 839us/step - loss: 0.4097 - acc: 0.8648 - val_loss: 0.3804 - val_acc: 0.8732\n",
            "Epoch 90/100\n",
            "429/429 [==============================] - 0s 838us/step - loss: 0.3960 - acc: 0.8648 - val_loss: 0.3808 - val_acc: 0.8732\n",
            "Epoch 91/100\n",
            "429/429 [==============================] - 0s 844us/step - loss: 0.3961 - acc: 0.8648 - val_loss: 0.3803 - val_acc: 0.8732\n",
            "Epoch 92/100\n",
            "429/429 [==============================] - 0s 846us/step - loss: 0.4181 - acc: 0.8578 - val_loss: 0.3826 - val_acc: 0.8732\n",
            "Epoch 93/100\n",
            "429/429 [==============================] - 0s 853us/step - loss: 0.4328 - acc: 0.8625 - val_loss: 0.3819 - val_acc: 0.8732\n",
            "Epoch 94/100\n",
            "429/429 [==============================] - 0s 849us/step - loss: 0.3945 - acc: 0.8648 - val_loss: 0.3790 - val_acc: 0.8732\n",
            "Epoch 95/100\n",
            "429/429 [==============================] - 0s 836us/step - loss: 0.4241 - acc: 0.8648 - val_loss: 0.3809 - val_acc: 0.8732\n",
            "Epoch 96/100\n",
            "429/429 [==============================] - 0s 852us/step - loss: 0.4104 - acc: 0.8625 - val_loss: 0.3807 - val_acc: 0.8732\n",
            "Epoch 97/100\n",
            "429/429 [==============================] - 0s 829us/step - loss: 0.3947 - acc: 0.8648 - val_loss: 0.3803 - val_acc: 0.8732\n",
            "Epoch 98/100\n",
            "429/429 [==============================] - 0s 845us/step - loss: 0.4081 - acc: 0.8648 - val_loss: 0.3802 - val_acc: 0.8732\n",
            "Epoch 99/100\n",
            "429/429 [==============================] - 0s 843us/step - loss: 0.4004 - acc: 0.8601 - val_loss: 0.3796 - val_acc: 0.8732\n",
            "Epoch 100/100\n",
            "429/429 [==============================] - 0s 834us/step - loss: 0.3972 - acc: 0.8648 - val_loss: 0.3791 - val_acc: 0.8732\n",
            "[[ 0  9]\n",
            " [ 0 62]]\n",
            "Accuracy :  0.8732394366197183\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         9\n",
            "           1       0.87      1.00      0.93        62\n",
            "\n",
            "    accuracy                           0.87        71\n",
            "   macro avg       0.44      0.50      0.47        71\n",
            "weighted avg       0.76      0.87      0.81        71\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "model_8 (Model)              (None, 2)                 9148782   \n",
            "=================================================================\n",
            "Total params: 9,148,782\n",
            "Trainable params: 8,386\n",
            "Non-trainable params: 9,140,396\n",
            "_________________________________________________________________\n",
            "Train on 429 samples, validate on 71 samples\n",
            "Epoch 1/100\n",
            "429/429 [==============================] - 3s 6ms/step - loss: 0.3961 - acc: 0.8625 - val_loss: 0.3819 - val_acc: 0.8732\n",
            "Epoch 2/100\n",
            "429/429 [==============================] - 0s 817us/step - loss: 0.4328 - acc: 0.8625 - val_loss: 0.3805 - val_acc: 0.8732\n",
            "Epoch 3/100\n",
            "429/429 [==============================] - 0s 814us/step - loss: 0.3970 - acc: 0.8648 - val_loss: 0.3809 - val_acc: 0.8732\n",
            "Epoch 4/100\n",
            "429/429 [==============================] - 0s 833us/step - loss: 0.3954 - acc: 0.8648 - val_loss: 0.3820 - val_acc: 0.8732\n",
            "Epoch 5/100\n",
            "429/429 [==============================] - 0s 806us/step - loss: 0.3956 - acc: 0.8648 - val_loss: 0.3822 - val_acc: 0.8732\n",
            "Epoch 6/100\n",
            "429/429 [==============================] - 0s 811us/step - loss: 0.4490 - acc: 0.8601 - val_loss: 0.3826 - val_acc: 0.8732\n",
            "Epoch 7/100\n",
            "429/429 [==============================] - 0s 816us/step - loss: 0.4227 - acc: 0.8648 - val_loss: 0.3828 - val_acc: 0.8732\n",
            "Epoch 8/100\n",
            "429/429 [==============================] - 0s 810us/step - loss: 0.4030 - acc: 0.8648 - val_loss: 0.3840 - val_acc: 0.8732\n",
            "Epoch 9/100\n",
            "429/429 [==============================] - 0s 812us/step - loss: 0.4273 - acc: 0.8648 - val_loss: 0.3878 - val_acc: 0.8732\n",
            "Epoch 10/100\n",
            "429/429 [==============================] - 0s 821us/step - loss: 0.4289 - acc: 0.8648 - val_loss: 0.3843 - val_acc: 0.8732\n",
            "Epoch 11/100\n",
            "429/429 [==============================] - 0s 825us/step - loss: 0.3955 - acc: 0.8648 - val_loss: 0.3825 - val_acc: 0.8732\n",
            "Epoch 12/100\n",
            "429/429 [==============================] - 0s 816us/step - loss: 0.3939 - acc: 0.8648 - val_loss: 0.3775 - val_acc: 0.8732\n",
            "Epoch 13/100\n",
            "429/429 [==============================] - 0s 830us/step - loss: 0.4352 - acc: 0.8648 - val_loss: 0.3701 - val_acc: 0.8732\n",
            "Epoch 14/100\n",
            "429/429 [==============================] - 0s 821us/step - loss: 0.4478 - acc: 0.8555 - val_loss: 0.3785 - val_acc: 0.8732\n",
            "Epoch 15/100\n",
            "429/429 [==============================] - 0s 822us/step - loss: 0.3926 - acc: 0.8671 - val_loss: 0.3782 - val_acc: 0.8732\n",
            "Epoch 16/100\n",
            "429/429 [==============================] - 0s 820us/step - loss: 0.3984 - acc: 0.8648 - val_loss: 0.3777 - val_acc: 0.8732\n",
            "Epoch 17/100\n",
            "429/429 [==============================] - 0s 823us/step - loss: 0.3961 - acc: 0.8648 - val_loss: 0.3779 - val_acc: 0.8732\n",
            "Epoch 18/100\n",
            "429/429 [==============================] - 0s 817us/step - loss: 0.3957 - acc: 0.8648 - val_loss: 0.3765 - val_acc: 0.8732\n",
            "Epoch 19/100\n",
            "429/429 [==============================] - 0s 817us/step - loss: 0.3959 - acc: 0.8648 - val_loss: 0.3760 - val_acc: 0.8732\n",
            "Epoch 20/100\n",
            "429/429 [==============================] - 0s 828us/step - loss: 0.3958 - acc: 0.8648 - val_loss: 0.3759 - val_acc: 0.8732\n",
            "Epoch 21/100\n",
            "429/429 [==============================] - 0s 825us/step - loss: 0.3960 - acc: 0.8648 - val_loss: 0.3762 - val_acc: 0.8732\n",
            "Epoch 22/100\n",
            "429/429 [==============================] - 0s 825us/step - loss: 0.3945 - acc: 0.8648 - val_loss: 0.3758 - val_acc: 0.8732\n",
            "Epoch 23/100\n",
            "429/429 [==============================] - 0s 818us/step - loss: 0.3917 - acc: 0.8671 - val_loss: 0.3759 - val_acc: 0.8732\n",
            "Epoch 24/100\n",
            "429/429 [==============================] - 0s 819us/step - loss: 0.4279 - acc: 0.8648 - val_loss: 0.3793 - val_acc: 0.8732\n",
            "Epoch 25/100\n",
            "429/429 [==============================] - 0s 829us/step - loss: 0.4296 - acc: 0.8648 - val_loss: 0.3793 - val_acc: 0.8732\n",
            "Epoch 26/100\n",
            "429/429 [==============================] - 0s 820us/step - loss: 0.4074 - acc: 0.8648 - val_loss: 0.3802 - val_acc: 0.8732\n",
            "Epoch 27/100\n",
            "429/429 [==============================] - 0s 825us/step - loss: 0.3940 - acc: 0.8648 - val_loss: 0.3781 - val_acc: 0.8732\n",
            "Epoch 28/100\n",
            "429/429 [==============================] - 0s 821us/step - loss: 0.4269 - acc: 0.8648 - val_loss: 0.3707 - val_acc: 0.8732\n",
            "Epoch 29/100\n",
            "429/429 [==============================] - 0s 824us/step - loss: 0.4929 - acc: 0.8625 - val_loss: 0.3728 - val_acc: 0.8732\n",
            "Epoch 30/100\n",
            "429/429 [==============================] - 0s 822us/step - loss: 0.4121 - acc: 0.8625 - val_loss: 0.3752 - val_acc: 0.8732\n",
            "Epoch 31/100\n",
            "429/429 [==============================] - 0s 838us/step - loss: 0.4030 - acc: 0.8648 - val_loss: 0.3915 - val_acc: 0.8732\n",
            "Epoch 32/100\n",
            "429/429 [==============================] - 0s 821us/step - loss: 0.4381 - acc: 0.8648 - val_loss: 0.3728 - val_acc: 0.8732\n",
            "Epoch 33/100\n",
            "429/429 [==============================] - 0s 817us/step - loss: 0.3959 - acc: 0.8648 - val_loss: 0.3778 - val_acc: 0.8732\n",
            "Epoch 34/100\n",
            "429/429 [==============================] - 0s 828us/step - loss: 0.4113 - acc: 0.8625 - val_loss: 0.3763 - val_acc: 0.8732\n",
            "Epoch 35/100\n",
            "429/429 [==============================] - 0s 837us/step - loss: 0.3974 - acc: 0.8648 - val_loss: 0.3758 - val_acc: 0.8732\n",
            "Epoch 36/100\n",
            "429/429 [==============================] - 0s 835us/step - loss: 0.3950 - acc: 0.8648 - val_loss: 0.3756 - val_acc: 0.8732\n",
            "Epoch 37/100\n",
            "429/429 [==============================] - 0s 826us/step - loss: 0.3962 - acc: 0.8648 - val_loss: 0.3759 - val_acc: 0.8732\n",
            "Epoch 38/100\n",
            "429/429 [==============================] - 0s 826us/step - loss: 0.3960 - acc: 0.8648 - val_loss: 0.3757 - val_acc: 0.8732\n",
            "Epoch 39/100\n",
            "429/429 [==============================] - 0s 822us/step - loss: 0.4359 - acc: 0.8625 - val_loss: 0.3739 - val_acc: 0.8732\n",
            "Epoch 40/100\n",
            "429/429 [==============================] - 0s 836us/step - loss: 0.3939 - acc: 0.8648 - val_loss: 0.3706 - val_acc: 0.8732\n",
            "Epoch 41/100\n",
            "429/429 [==============================] - 0s 817us/step - loss: 0.4268 - acc: 0.8648 - val_loss: 0.3661 - val_acc: 0.8732\n",
            "Epoch 42/100\n",
            "429/429 [==============================] - 0s 829us/step - loss: 0.4269 - acc: 0.8648 - val_loss: 0.3699 - val_acc: 0.8732\n",
            "Epoch 43/100\n",
            "429/429 [==============================] - 0s 819us/step - loss: 0.3947 - acc: 0.8648 - val_loss: 0.3707 - val_acc: 0.8732\n",
            "Epoch 44/100\n",
            "429/429 [==============================] - 0s 825us/step - loss: 0.3931 - acc: 0.8648 - val_loss: 0.3880 - val_acc: 0.8732\n",
            "Epoch 45/100\n",
            "429/429 [==============================] - 0s 831us/step - loss: 0.4534 - acc: 0.8648 - val_loss: 0.3793 - val_acc: 0.8732\n",
            "Epoch 46/100\n",
            "429/429 [==============================] - 0s 837us/step - loss: 0.3970 - acc: 0.8648 - val_loss: 0.3722 - val_acc: 0.8732\n",
            "Epoch 47/100\n",
            "429/429 [==============================] - 0s 827us/step - loss: 0.4233 - acc: 0.8648 - val_loss: 0.3792 - val_acc: 0.8732\n",
            "Epoch 48/100\n",
            "429/429 [==============================] - 0s 840us/step - loss: 0.4278 - acc: 0.8648 - val_loss: 0.3781 - val_acc: 0.8732\n",
            "Epoch 49/100\n",
            "429/429 [==============================] - 0s 826us/step - loss: 0.4086 - acc: 0.8648 - val_loss: 0.3770 - val_acc: 0.8732\n",
            "Epoch 50/100\n",
            "429/429 [==============================] - 0s 829us/step - loss: 0.3941 - acc: 0.8648 - val_loss: 0.3769 - val_acc: 0.8732\n",
            "Epoch 51/100\n",
            "429/429 [==============================] - 0s 838us/step - loss: 0.3942 - acc: 0.8648 - val_loss: 0.3758 - val_acc: 0.8732\n",
            "Epoch 52/100\n",
            "429/429 [==============================] - 0s 838us/step - loss: 0.4354 - acc: 0.8648 - val_loss: 0.3755 - val_acc: 0.8732\n",
            "Epoch 53/100\n",
            "429/429 [==============================] - 0s 850us/step - loss: 0.4138 - acc: 0.8648 - val_loss: 0.3753 - val_acc: 0.8732\n",
            "Epoch 54/100\n",
            "429/429 [==============================] - 0s 848us/step - loss: 0.4409 - acc: 0.8601 - val_loss: 0.3746 - val_acc: 0.8732\n",
            "Epoch 55/100\n",
            "429/429 [==============================] - 0s 849us/step - loss: 0.4007 - acc: 0.8648 - val_loss: 0.3813 - val_acc: 0.8732\n",
            "Epoch 56/100\n",
            "429/429 [==============================] - 0s 849us/step - loss: 0.4107 - acc: 0.8625 - val_loss: 0.3793 - val_acc: 0.8732\n",
            "Epoch 57/100\n",
            "429/429 [==============================] - 0s 837us/step - loss: 0.3951 - acc: 0.8648 - val_loss: 0.3792 - val_acc: 0.8732\n",
            "Epoch 58/100\n",
            "429/429 [==============================] - 0s 821us/step - loss: 0.4032 - acc: 0.8625 - val_loss: 0.3791 - val_acc: 0.8732\n",
            "Epoch 59/100\n",
            "429/429 [==============================] - 0s 835us/step - loss: 0.3957 - acc: 0.8648 - val_loss: 0.3794 - val_acc: 0.8732\n",
            "Epoch 60/100\n",
            "429/429 [==============================] - 0s 833us/step - loss: 0.3964 - acc: 0.8648 - val_loss: 0.3791 - val_acc: 0.8732\n",
            "Epoch 61/100\n",
            "429/429 [==============================] - 0s 828us/step - loss: 0.4025 - acc: 0.8648 - val_loss: 0.3809 - val_acc: 0.8732\n",
            "Epoch 62/100\n",
            "429/429 [==============================] - 0s 838us/step - loss: 0.3964 - acc: 0.8648 - val_loss: 0.3810 - val_acc: 0.8732\n",
            "Epoch 63/100\n",
            "429/429 [==============================] - 0s 831us/step - loss: 0.3959 - acc: 0.8648 - val_loss: 0.3802 - val_acc: 0.8732\n",
            "Epoch 64/100\n",
            "429/429 [==============================] - 0s 832us/step - loss: 0.3948 - acc: 0.8648 - val_loss: 0.3785 - val_acc: 0.8732\n",
            "Epoch 65/100\n",
            "429/429 [==============================] - 0s 846us/step - loss: 0.4277 - acc: 0.8648 - val_loss: 0.3873 - val_acc: 0.8732\n",
            "Epoch 66/100\n",
            "429/429 [==============================] - 0s 833us/step - loss: 0.4027 - acc: 0.8648 - val_loss: 0.3803 - val_acc: 0.8732\n",
            "Epoch 67/100\n",
            "429/429 [==============================] - 0s 829us/step - loss: 0.3948 - acc: 0.8648 - val_loss: 0.3799 - val_acc: 0.8732\n",
            "Epoch 68/100\n",
            "429/429 [==============================] - 0s 847us/step - loss: 0.3952 - acc: 0.8648 - val_loss: 0.3801 - val_acc: 0.8732\n",
            "Epoch 69/100\n",
            "429/429 [==============================] - 0s 821us/step - loss: 0.4189 - acc: 0.8648 - val_loss: 0.3866 - val_acc: 0.8732\n",
            "Epoch 70/100\n",
            "429/429 [==============================] - 0s 840us/step - loss: 0.3927 - acc: 0.8648 - val_loss: 0.3882 - val_acc: 0.8732\n",
            "Epoch 71/100\n",
            "429/429 [==============================] - 0s 853us/step - loss: 0.4605 - acc: 0.8648 - val_loss: 0.3803 - val_acc: 0.8732\n",
            "Epoch 72/100\n",
            "429/429 [==============================] - 0s 848us/step - loss: 0.3963 - acc: 0.8648 - val_loss: 0.3801 - val_acc: 0.8732\n",
            "Epoch 73/100\n",
            "429/429 [==============================] - 0s 833us/step - loss: 0.3949 - acc: 0.8648 - val_loss: 0.3799 - val_acc: 0.8732\n",
            "Epoch 74/100\n",
            "429/429 [==============================] - 0s 833us/step - loss: 0.4008 - acc: 0.8625 - val_loss: 0.3801 - val_acc: 0.8732\n",
            "Epoch 75/100\n",
            "429/429 [==============================] - 0s 839us/step - loss: 0.3961 - acc: 0.8648 - val_loss: 0.3807 - val_acc: 0.8732\n",
            "Epoch 76/100\n",
            "429/429 [==============================] - 0s 843us/step - loss: 0.3957 - acc: 0.8648 - val_loss: 0.3806 - val_acc: 0.8732\n",
            "Epoch 77/100\n",
            "429/429 [==============================] - 0s 830us/step - loss: 0.3960 - acc: 0.8648 - val_loss: 0.3800 - val_acc: 0.8732\n",
            "Epoch 78/100\n",
            "429/429 [==============================] - 0s 829us/step - loss: 0.3959 - acc: 0.8648 - val_loss: 0.3799 - val_acc: 0.8732\n",
            "Epoch 79/100\n",
            "429/429 [==============================] - 0s 843us/step - loss: 0.3965 - acc: 0.8648 - val_loss: 0.3799 - val_acc: 0.8732\n",
            "Epoch 80/100\n",
            "429/429 [==============================] - 0s 821us/step - loss: 0.3951 - acc: 0.8648 - val_loss: 0.3798 - val_acc: 0.8732\n",
            "Epoch 81/100\n",
            "429/429 [==============================] - 0s 836us/step - loss: 0.3956 - acc: 0.8648 - val_loss: 0.3799 - val_acc: 0.8732\n",
            "Epoch 82/100\n",
            "429/429 [==============================] - 0s 845us/step - loss: 0.3964 - acc: 0.8648 - val_loss: 0.3799 - val_acc: 0.8732\n",
            "Epoch 83/100\n",
            "429/429 [==============================] - 0s 838us/step - loss: 0.3964 - acc: 0.8648 - val_loss: 0.3801 - val_acc: 0.8732\n",
            "Epoch 84/100\n",
            "429/429 [==============================] - 0s 841us/step - loss: 0.3945 - acc: 0.8648 - val_loss: 0.3808 - val_acc: 0.8732\n",
            "Epoch 85/100\n",
            "429/429 [==============================] - 0s 836us/step - loss: 0.3969 - acc: 0.8625 - val_loss: 0.3809 - val_acc: 0.8732\n",
            "Epoch 86/100\n",
            "429/429 [==============================] - 0s 827us/step - loss: 0.3965 - acc: 0.8648 - val_loss: 0.3803 - val_acc: 0.8732\n",
            "Epoch 87/100\n",
            "429/429 [==============================] - 0s 832us/step - loss: 0.3960 - acc: 0.8648 - val_loss: 0.3803 - val_acc: 0.8732\n",
            "Epoch 88/100\n",
            "429/429 [==============================] - 0s 836us/step - loss: 0.4019 - acc: 0.8648 - val_loss: 0.3805 - val_acc: 0.8732\n",
            "Epoch 89/100\n",
            "429/429 [==============================] - 0s 833us/step - loss: 0.3950 - acc: 0.8648 - val_loss: 0.3804 - val_acc: 0.8732\n",
            "Epoch 90/100\n",
            "429/429 [==============================] - 0s 836us/step - loss: 0.4316 - acc: 0.8625 - val_loss: 0.3803 - val_acc: 0.8732\n",
            "Epoch 91/100\n",
            "429/429 [==============================] - 0s 845us/step - loss: 0.3977 - acc: 0.8648 - val_loss: 0.3806 - val_acc: 0.8732\n",
            "Epoch 92/100\n",
            "429/429 [==============================] - 0s 830us/step - loss: 0.4285 - acc: 0.8648 - val_loss: 0.3805 - val_acc: 0.8732\n",
            "Epoch 93/100\n",
            "429/429 [==============================] - 0s 838us/step - loss: 0.3962 - acc: 0.8648 - val_loss: 0.3802 - val_acc: 0.8732\n",
            "Epoch 94/100\n",
            "429/429 [==============================] - 0s 841us/step - loss: 0.3956 - acc: 0.8648 - val_loss: 0.3801 - val_acc: 0.8732\n",
            "Epoch 95/100\n",
            "429/429 [==============================] - 0s 831us/step - loss: 0.3956 - acc: 0.8648 - val_loss: 0.3806 - val_acc: 0.8732\n",
            "Epoch 96/100\n",
            "429/429 [==============================] - 0s 837us/step - loss: 0.4276 - acc: 0.8648 - val_loss: 0.3810 - val_acc: 0.8732\n",
            "Epoch 97/100\n",
            "429/429 [==============================] - 0s 832us/step - loss: 0.3965 - acc: 0.8648 - val_loss: 0.3808 - val_acc: 0.8732\n",
            "Epoch 98/100\n",
            "429/429 [==============================] - 0s 832us/step - loss: 0.4353 - acc: 0.8648 - val_loss: 0.3817 - val_acc: 0.8732\n",
            "Epoch 99/100\n",
            "429/429 [==============================] - 0s 836us/step - loss: 0.3957 - acc: 0.8648 - val_loss: 0.3804 - val_acc: 0.8732\n",
            "Epoch 100/100\n",
            "429/429 [==============================] - 0s 827us/step - loss: 0.3999 - acc: 0.8625 - val_loss: 0.3806 - val_acc: 0.8732\n",
            "[[ 0  9]\n",
            " [ 0 62]]\n",
            "Accuracy :  0.8732394366197183\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         9\n",
            "           1       0.87      1.00      0.93        62\n",
            "\n",
            "    accuracy                           0.87        71\n",
            "   macro avg       0.44      0.50      0.47        71\n",
            "weighted avg       0.76      0.87      0.81        71\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "model_8 (Model)              (None, 2)                 9148782   \n",
            "=================================================================\n",
            "Total params: 9,148,782\n",
            "Trainable params: 8,386\n",
            "Non-trainable params: 9,140,396\n",
            "_________________________________________________________________\n",
            "Train on 430 samples, validate on 70 samples\n",
            "Epoch 1/100\n",
            "430/430 [==============================] - 3s 7ms/step - loss: 0.3956 - acc: 0.8651 - val_loss: 0.3798 - val_acc: 0.8714\n",
            "Epoch 2/100\n",
            "430/430 [==============================] - 0s 819us/step - loss: 0.3944 - acc: 0.8651 - val_loss: 0.3803 - val_acc: 0.8714\n",
            "Epoch 3/100\n",
            "430/430 [==============================] - 0s 815us/step - loss: 0.3951 - acc: 0.8651 - val_loss: 0.3797 - val_acc: 0.8714\n",
            "Epoch 4/100\n",
            "430/430 [==============================] - 0s 838us/step - loss: 0.4148 - acc: 0.8628 - val_loss: 0.3800 - val_acc: 0.8714\n",
            "Epoch 5/100\n",
            "430/430 [==============================] - 0s 809us/step - loss: 0.3961 - acc: 0.8651 - val_loss: 0.3798 - val_acc: 0.8714\n",
            "Epoch 6/100\n",
            "430/430 [==============================] - 0s 815us/step - loss: 0.3946 - acc: 0.8651 - val_loss: 0.3803 - val_acc: 0.8714\n",
            "Epoch 7/100\n",
            "430/430 [==============================] - 0s 817us/step - loss: 0.3956 - acc: 0.8651 - val_loss: 0.3807 - val_acc: 0.8714\n",
            "Epoch 8/100\n",
            "430/430 [==============================] - 0s 815us/step - loss: 0.3953 - acc: 0.8651 - val_loss: 0.3808 - val_acc: 0.8714\n",
            "Epoch 9/100\n",
            "430/430 [==============================] - 0s 817us/step - loss: 0.4032 - acc: 0.8651 - val_loss: 0.3820 - val_acc: 0.8714\n",
            "Epoch 10/100\n",
            "430/430 [==============================] - 0s 825us/step - loss: 0.3934 - acc: 0.8651 - val_loss: 0.3802 - val_acc: 0.8714\n",
            "Epoch 11/100\n",
            "430/430 [==============================] - 0s 816us/step - loss: 0.3933 - acc: 0.8651 - val_loss: 0.3706 - val_acc: 0.8714\n",
            "Epoch 12/100\n",
            "430/430 [==============================] - 0s 815us/step - loss: 0.5329 - acc: 0.8651 - val_loss: 0.3995 - val_acc: 0.8714\n",
            "Epoch 13/100\n",
            "430/430 [==============================] - 0s 829us/step - loss: 0.4719 - acc: 0.8651 - val_loss: 0.3753 - val_acc: 0.8714\n",
            "Epoch 14/100\n",
            "430/430 [==============================] - 0s 806us/step - loss: 0.4278 - acc: 0.8651 - val_loss: 0.3788 - val_acc: 0.8714\n",
            "Epoch 15/100\n",
            "430/430 [==============================] - 0s 816us/step - loss: 0.3972 - acc: 0.8651 - val_loss: 0.3797 - val_acc: 0.8714\n",
            "Epoch 16/100\n",
            "430/430 [==============================] - 0s 840us/step - loss: 0.3943 - acc: 0.8651 - val_loss: 0.3785 - val_acc: 0.8714\n",
            "Epoch 17/100\n",
            "430/430 [==============================] - 0s 820us/step - loss: 0.4084 - acc: 0.8651 - val_loss: 0.3790 - val_acc: 0.8714\n",
            "Epoch 18/100\n",
            "430/430 [==============================] - 0s 828us/step - loss: 0.3951 - acc: 0.8651 - val_loss: 0.3789 - val_acc: 0.8714\n",
            "Epoch 19/100\n",
            "430/430 [==============================] - 0s 825us/step - loss: 0.3965 - acc: 0.8628 - val_loss: 0.3789 - val_acc: 0.8714\n",
            "Epoch 20/100\n",
            "430/430 [==============================] - 0s 831us/step - loss: 0.3953 - acc: 0.8651 - val_loss: 0.3793 - val_acc: 0.8714\n",
            "Epoch 21/100\n",
            "430/430 [==============================] - 0s 825us/step - loss: 0.3974 - acc: 0.8651 - val_loss: 0.3794 - val_acc: 0.8714\n",
            "Epoch 22/100\n",
            "430/430 [==============================] - 0s 820us/step - loss: 0.3956 - acc: 0.8651 - val_loss: 0.3792 - val_acc: 0.8714\n",
            "Epoch 23/100\n",
            "430/430 [==============================] - 0s 819us/step - loss: 0.3956 - acc: 0.8651 - val_loss: 0.3797 - val_acc: 0.8714\n",
            "Epoch 24/100\n",
            "430/430 [==============================] - 0s 841us/step - loss: 0.4150 - acc: 0.8651 - val_loss: 0.3795 - val_acc: 0.8714\n",
            "Epoch 25/100\n",
            "430/430 [==============================] - 0s 820us/step - loss: 0.3963 - acc: 0.8651 - val_loss: 0.3795 - val_acc: 0.8714\n",
            "Epoch 26/100\n",
            "430/430 [==============================] - 0s 827us/step - loss: 0.4158 - acc: 0.8628 - val_loss: 0.3790 - val_acc: 0.8714\n",
            "Epoch 27/100\n",
            "430/430 [==============================] - 0s 835us/step - loss: 0.3955 - acc: 0.8651 - val_loss: 0.3774 - val_acc: 0.8714\n",
            "Epoch 28/100\n",
            "430/430 [==============================] - 0s 813us/step - loss: 0.4280 - acc: 0.8651 - val_loss: 0.3771 - val_acc: 0.8714\n",
            "Epoch 29/100\n",
            "430/430 [==============================] - 0s 835us/step - loss: 0.4280 - acc: 0.8651 - val_loss: 0.3766 - val_acc: 0.8714\n",
            "Epoch 30/100\n",
            "430/430 [==============================] - 0s 834us/step - loss: 0.3944 - acc: 0.8651 - val_loss: 0.3755 - val_acc: 0.8714\n",
            "Epoch 31/100\n",
            "430/430 [==============================] - 0s 817us/step - loss: 0.3942 - acc: 0.8651 - val_loss: 0.3744 - val_acc: 0.8714\n",
            "Epoch 32/100\n",
            "430/430 [==============================] - 0s 827us/step - loss: 0.3945 - acc: 0.8651 - val_loss: 0.3721 - val_acc: 0.8714\n",
            "Epoch 33/100\n",
            "430/430 [==============================] - 0s 834us/step - loss: 0.3949 - acc: 0.8651 - val_loss: 0.3714 - val_acc: 0.8714\n",
            "Epoch 34/100\n",
            "430/430 [==============================] - 0s 836us/step - loss: 0.4035 - acc: 0.8628 - val_loss: 0.3717 - val_acc: 0.8714\n",
            "Epoch 35/100\n",
            "430/430 [==============================] - 0s 839us/step - loss: 0.4304 - acc: 0.8651 - val_loss: 0.3717 - val_acc: 0.8714\n",
            "Epoch 36/100\n",
            "430/430 [==============================] - 0s 839us/step - loss: 0.3943 - acc: 0.8651 - val_loss: 0.3717 - val_acc: 0.8714\n",
            "Epoch 37/100\n",
            "430/430 [==============================] - 0s 832us/step - loss: 0.4200 - acc: 0.8651 - val_loss: 0.3713 - val_acc: 0.8714\n",
            "Epoch 38/100\n",
            "430/430 [==============================] - 0s 841us/step - loss: 0.3963 - acc: 0.8651 - val_loss: 0.3715 - val_acc: 0.8714\n",
            "Epoch 39/100\n",
            "430/430 [==============================] - 0s 832us/step - loss: 0.3949 - acc: 0.8651 - val_loss: 0.3737 - val_acc: 0.8714\n",
            "Epoch 40/100\n",
            "430/430 [==============================] - 0s 823us/step - loss: 0.4259 - acc: 0.8651 - val_loss: 0.4063 - val_acc: 0.8714\n",
            "Epoch 41/100\n",
            "430/430 [==============================] - 0s 829us/step - loss: 0.4266 - acc: 0.8651 - val_loss: 0.4479 - val_acc: 0.8714\n",
            "Epoch 42/100\n",
            "430/430 [==============================] - 0s 854us/step - loss: 0.4290 - acc: 0.8651 - val_loss: 0.4273 - val_acc: 0.8714\n",
            "Epoch 43/100\n",
            "430/430 [==============================] - 0s 840us/step - loss: 0.3917 - acc: 0.8651 - val_loss: 0.4473 - val_acc: 0.8714\n",
            "Epoch 44/100\n",
            "430/430 [==============================] - 0s 850us/step - loss: 0.4488 - acc: 0.8628 - val_loss: 0.3777 - val_acc: 0.8714\n",
            "Epoch 45/100\n",
            "430/430 [==============================] - 0s 842us/step - loss: 0.3957 - acc: 0.8651 - val_loss: 0.3777 - val_acc: 0.8714\n",
            "Epoch 46/100\n",
            "430/430 [==============================] - 0s 863us/step - loss: 0.4001 - acc: 0.8651 - val_loss: 0.3774 - val_acc: 0.8714\n",
            "Epoch 47/100\n",
            "430/430 [==============================] - 0s 857us/step - loss: 0.3944 - acc: 0.8651 - val_loss: 0.3773 - val_acc: 0.8714\n",
            "Epoch 48/100\n",
            "430/430 [==============================] - 0s 844us/step - loss: 0.3946 - acc: 0.8651 - val_loss: 0.3767 - val_acc: 0.8714\n",
            "Epoch 49/100\n",
            "430/430 [==============================] - 0s 844us/step - loss: 0.4356 - acc: 0.8651 - val_loss: 0.3779 - val_acc: 0.8714\n",
            "Epoch 50/100\n",
            "430/430 [==============================] - 0s 840us/step - loss: 0.4278 - acc: 0.8651 - val_loss: 0.3808 - val_acc: 0.8714\n",
            "Epoch 51/100\n",
            "430/430 [==============================] - 0s 831us/step - loss: 0.3956 - acc: 0.8651 - val_loss: 0.3806 - val_acc: 0.8714\n",
            "Epoch 52/100\n",
            "430/430 [==============================] - 0s 842us/step - loss: 0.3973 - acc: 0.8651 - val_loss: 0.3805 - val_acc: 0.8714\n",
            "Epoch 53/100\n",
            "430/430 [==============================] - 0s 845us/step - loss: 0.3948 - acc: 0.8651 - val_loss: 0.3804 - val_acc: 0.8714\n",
            "Epoch 54/100\n",
            "430/430 [==============================] - 0s 836us/step - loss: 0.3948 - acc: 0.8651 - val_loss: 0.3803 - val_acc: 0.8714\n",
            "Epoch 55/100\n",
            "430/430 [==============================] - 0s 840us/step - loss: 0.3940 - acc: 0.8651 - val_loss: 0.3802 - val_acc: 0.8714\n",
            "Epoch 56/100\n",
            "430/430 [==============================] - 0s 838us/step - loss: 0.3945 - acc: 0.8651 - val_loss: 0.3800 - val_acc: 0.8714\n",
            "Epoch 57/100\n",
            "430/430 [==============================] - 0s 835us/step - loss: 0.3946 - acc: 0.8651 - val_loss: 0.3801 - val_acc: 0.8714\n",
            "Epoch 58/100\n",
            "430/430 [==============================] - 0s 836us/step - loss: 0.3949 - acc: 0.8651 - val_loss: 0.3799 - val_acc: 0.8714\n",
            "Epoch 59/100\n",
            "430/430 [==============================] - 0s 837us/step - loss: 0.3939 - acc: 0.8651 - val_loss: 0.3800 - val_acc: 0.8714\n",
            "Epoch 60/100\n",
            "430/430 [==============================] - 0s 826us/step - loss: 0.3951 - acc: 0.8651 - val_loss: 0.3801 - val_acc: 0.8714\n",
            "Epoch 61/100\n",
            "430/430 [==============================] - 0s 850us/step - loss: 0.3946 - acc: 0.8651 - val_loss: 0.3798 - val_acc: 0.8714\n",
            "Epoch 62/100\n",
            "430/430 [==============================] - 0s 831us/step - loss: 0.4270 - acc: 0.8651 - val_loss: 0.3797 - val_acc: 0.8714\n",
            "Epoch 63/100\n",
            "430/430 [==============================] - 0s 815us/step - loss: 0.4091 - acc: 0.8628 - val_loss: 0.3796 - val_acc: 0.8714\n",
            "Epoch 64/100\n",
            "430/430 [==============================] - 0s 826us/step - loss: 0.3940 - acc: 0.8651 - val_loss: 0.3795 - val_acc: 0.8714\n",
            "Epoch 65/100\n",
            "430/430 [==============================] - 0s 823us/step - loss: 0.4094 - acc: 0.8651 - val_loss: 0.4389 - val_acc: 0.8571\n",
            "Epoch 66/100\n",
            "430/430 [==============================] - 0s 823us/step - loss: 0.3989 - acc: 0.8628 - val_loss: 0.3840 - val_acc: 0.8714\n",
            "Epoch 67/100\n",
            "430/430 [==============================] - 0s 842us/step - loss: 0.4450 - acc: 0.8651 - val_loss: 0.3939 - val_acc: 0.8571\n",
            "Epoch 68/100\n",
            "430/430 [==============================] - 0s 825us/step - loss: 0.4591 - acc: 0.8651 - val_loss: 0.3914 - val_acc: 0.8571\n",
            "Epoch 69/100\n",
            "430/430 [==============================] - 0s 833us/step - loss: 0.3930 - acc: 0.8651 - val_loss: 0.3899 - val_acc: 0.8571\n",
            "Epoch 70/100\n",
            "430/430 [==============================] - 0s 842us/step - loss: 0.4285 - acc: 0.8651 - val_loss: 0.3958 - val_acc: 0.8571\n",
            "Epoch 71/100\n",
            "430/430 [==============================] - 0s 827us/step - loss: 0.3975 - acc: 0.8628 - val_loss: 0.3949 - val_acc: 0.8571\n",
            "Epoch 72/100\n",
            "430/430 [==============================] - 0s 825us/step - loss: 0.4048 - acc: 0.8628 - val_loss: 0.3943 - val_acc: 0.8571\n",
            "Epoch 73/100\n",
            "430/430 [==============================] - 0s 836us/step - loss: 0.4001 - acc: 0.8628 - val_loss: 0.3921 - val_acc: 0.8571\n",
            "Epoch 74/100\n",
            "430/430 [==============================] - 0s 838us/step - loss: 0.3956 - acc: 0.8651 - val_loss: 0.3904 - val_acc: 0.8571\n",
            "Epoch 75/100\n",
            "430/430 [==============================] - 0s 832us/step - loss: 0.3956 - acc: 0.8651 - val_loss: 0.3903 - val_acc: 0.8714\n",
            "Epoch 76/100\n",
            "430/430 [==============================] - 0s 828us/step - loss: 0.3951 - acc: 0.8651 - val_loss: 0.3902 - val_acc: 0.8714\n",
            "Epoch 77/100\n",
            "430/430 [==============================] - 0s 826us/step - loss: 0.3952 - acc: 0.8651 - val_loss: 0.3903 - val_acc: 0.8571\n",
            "Epoch 78/100\n",
            "430/430 [==============================] - 0s 829us/step - loss: 0.3957 - acc: 0.8651 - val_loss: 0.3946 - val_acc: 0.8571\n",
            "Epoch 79/100\n",
            "430/430 [==============================] - 0s 840us/step - loss: 0.3954 - acc: 0.8651 - val_loss: 0.3964 - val_acc: 0.8571\n",
            "Epoch 80/100\n",
            "430/430 [==============================] - 0s 827us/step - loss: 0.3956 - acc: 0.8651 - val_loss: 0.3966 - val_acc: 0.8571\n",
            "Epoch 81/100\n",
            "430/430 [==============================] - 0s 837us/step - loss: 0.3951 - acc: 0.8651 - val_loss: 0.3970 - val_acc: 0.8571\n",
            "Epoch 82/100\n",
            "430/430 [==============================] - 0s 838us/step - loss: 0.4283 - acc: 0.8651 - val_loss: 0.3973 - val_acc: 0.8571\n",
            "Epoch 83/100\n",
            "430/430 [==============================] - 0s 833us/step - loss: 0.3973 - acc: 0.8628 - val_loss: 0.3973 - val_acc: 0.8571\n",
            "Epoch 84/100\n",
            "430/430 [==============================] - 0s 834us/step - loss: 0.4225 - acc: 0.8628 - val_loss: 0.3986 - val_acc: 0.8714\n",
            "Epoch 85/100\n",
            "430/430 [==============================] - 0s 836us/step - loss: 0.4115 - acc: 0.8651 - val_loss: 0.3982 - val_acc: 0.8714\n",
            "Epoch 86/100\n",
            "430/430 [==============================] - 0s 840us/step - loss: 0.4203 - acc: 0.8651 - val_loss: 0.3853 - val_acc: 0.8714\n",
            "Epoch 87/100\n",
            "430/430 [==============================] - 0s 826us/step - loss: 0.3962 - acc: 0.8651 - val_loss: 0.3846 - val_acc: 0.8714\n",
            "Epoch 88/100\n",
            "430/430 [==============================] - 0s 829us/step - loss: 0.3950 - acc: 0.8651 - val_loss: 0.3848 - val_acc: 0.8714\n",
            "Epoch 89/100\n",
            "430/430 [==============================] - 0s 830us/step - loss: 0.3960 - acc: 0.8651 - val_loss: 0.3847 - val_acc: 0.8714\n",
            "Epoch 90/100\n",
            "430/430 [==============================] - 0s 842us/step - loss: 0.3930 - acc: 0.8651 - val_loss: 0.3847 - val_acc: 0.8714\n",
            "Epoch 91/100\n",
            "430/430 [==============================] - 0s 845us/step - loss: 0.4277 - acc: 0.8651 - val_loss: 0.3847 - val_acc: 0.8714\n",
            "Epoch 92/100\n",
            "430/430 [==============================] - 0s 829us/step - loss: 0.3954 - acc: 0.8651 - val_loss: 0.3846 - val_acc: 0.8714\n",
            "Epoch 93/100\n",
            "430/430 [==============================] - 0s 835us/step - loss: 0.4329 - acc: 0.8628 - val_loss: 0.3846 - val_acc: 0.8714\n",
            "Epoch 94/100\n",
            "430/430 [==============================] - 0s 830us/step - loss: 0.3954 - acc: 0.8651 - val_loss: 0.3846 - val_acc: 0.8714\n",
            "Epoch 95/100\n",
            "430/430 [==============================] - 0s 823us/step - loss: 0.3950 - acc: 0.8651 - val_loss: 0.3857 - val_acc: 0.8714\n",
            "Epoch 96/100\n",
            "430/430 [==============================] - 0s 836us/step - loss: 0.3954 - acc: 0.8651 - val_loss: 0.3866 - val_acc: 0.8714\n",
            "Epoch 97/100\n",
            "430/430 [==============================] - 0s 830us/step - loss: 0.3964 - acc: 0.8651 - val_loss: 0.3870 - val_acc: 0.8714\n",
            "Epoch 98/100\n",
            "430/430 [==============================] - 0s 825us/step - loss: 0.3956 - acc: 0.8651 - val_loss: 0.3869 - val_acc: 0.8714\n",
            "Epoch 99/100\n",
            "430/430 [==============================] - 0s 836us/step - loss: 0.3951 - acc: 0.8651 - val_loss: 0.3878 - val_acc: 0.8714\n",
            "Epoch 100/100\n",
            "430/430 [==============================] - 0s 835us/step - loss: 0.4043 - acc: 0.8651 - val_loss: 0.3837 - val_acc: 0.8714\n",
            "[[ 0  9]\n",
            " [ 0 61]]\n",
            "Accuracy :  0.8714285714285714\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         9\n",
            "           1       0.87      1.00      0.93        61\n",
            "\n",
            "    accuracy                           0.87        70\n",
            "   macro avg       0.44      0.50      0.47        70\n",
            "weighted avg       0.76      0.87      0.81        70\n",
            "\n",
            "\n",
            "\n",
            "Excitement\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "model_6 (Model)              (None, 2)                 9148782   \n",
            "=================================================================\n",
            "Total params: 9,148,782\n",
            "Trainable params: 8,386\n",
            "Non-trainable params: 9,140,396\n",
            "_________________________________________________________________\n",
            "Train on 428 samples, validate on 72 samples\n",
            "Epoch 1/100\n",
            "428/428 [==============================] - 3s 7ms/step - loss: 3.5840 - acc: 0.5234 - val_loss: 3.2362 - val_acc: 0.4583\n",
            "Epoch 2/100\n",
            "428/428 [==============================] - 0s 819us/step - loss: 2.4905 - acc: 0.5491 - val_loss: 2.4040 - val_acc: 0.4861\n",
            "Epoch 3/100\n",
            "428/428 [==============================] - 0s 811us/step - loss: 1.7805 - acc: 0.5818 - val_loss: 1.7792 - val_acc: 0.4861\n",
            "Epoch 4/100\n",
            "428/428 [==============================] - 0s 821us/step - loss: 1.6210 - acc: 0.6449 - val_loss: 1.3433 - val_acc: 0.5833\n",
            "Epoch 5/100\n",
            "428/428 [==============================] - 0s 806us/step - loss: 1.2151 - acc: 0.6449 - val_loss: 0.9814 - val_acc: 0.6389\n",
            "Epoch 6/100\n",
            "428/428 [==============================] - 0s 825us/step - loss: 1.1634 - acc: 0.6519 - val_loss: 0.9201 - val_acc: 0.6667\n",
            "Epoch 7/100\n",
            "428/428 [==============================] - 0s 822us/step - loss: 1.2539 - acc: 0.6519 - val_loss: 0.8323 - val_acc: 0.6667\n",
            "Epoch 8/100\n",
            "428/428 [==============================] - 0s 819us/step - loss: 1.1214 - acc: 0.6355 - val_loss: 0.7388 - val_acc: 0.6528\n",
            "Epoch 9/100\n",
            "428/428 [==============================] - 0s 819us/step - loss: 0.8168 - acc: 0.6355 - val_loss: 0.7298 - val_acc: 0.6667\n",
            "Epoch 10/100\n",
            "428/428 [==============================] - 0s 829us/step - loss: 0.9769 - acc: 0.6752 - val_loss: 0.6906 - val_acc: 0.6389\n",
            "Epoch 11/100\n",
            "428/428 [==============================] - 0s 818us/step - loss: 0.8307 - acc: 0.6355 - val_loss: 0.6725 - val_acc: 0.6389\n",
            "Epoch 12/100\n",
            "428/428 [==============================] - 0s 827us/step - loss: 0.8828 - acc: 0.6379 - val_loss: 0.7424 - val_acc: 0.6528\n",
            "Epoch 13/100\n",
            "428/428 [==============================] - 0s 826us/step - loss: 0.7350 - acc: 0.6612 - val_loss: 0.6578 - val_acc: 0.6389\n",
            "Epoch 14/100\n",
            "428/428 [==============================] - 0s 825us/step - loss: 0.7160 - acc: 0.6589 - val_loss: 0.6726 - val_acc: 0.6667\n",
            "Epoch 15/100\n",
            "428/428 [==============================] - 0s 824us/step - loss: 0.7394 - acc: 0.6519 - val_loss: 0.6556 - val_acc: 0.6667\n",
            "Epoch 16/100\n",
            "428/428 [==============================] - 0s 823us/step - loss: 0.6920 - acc: 0.6636 - val_loss: 0.6516 - val_acc: 0.6528\n",
            "Epoch 17/100\n",
            "428/428 [==============================] - 0s 822us/step - loss: 0.7196 - acc: 0.6565 - val_loss: 0.6468 - val_acc: 0.6667\n",
            "Epoch 18/100\n",
            "428/428 [==============================] - 0s 824us/step - loss: 0.6731 - acc: 0.6636 - val_loss: 0.6396 - val_acc: 0.6667\n",
            "Epoch 19/100\n",
            "428/428 [==============================] - 0s 824us/step - loss: 0.6678 - acc: 0.6542 - val_loss: 0.6345 - val_acc: 0.6806\n",
            "Epoch 20/100\n",
            "428/428 [==============================] - 0s 821us/step - loss: 0.6882 - acc: 0.6729 - val_loss: 0.6339 - val_acc: 0.6806\n",
            "Epoch 21/100\n",
            "428/428 [==============================] - 0s 827us/step - loss: 0.6826 - acc: 0.6729 - val_loss: 0.6250 - val_acc: 0.6806\n",
            "Epoch 22/100\n",
            "428/428 [==============================] - 0s 824us/step - loss: 0.6601 - acc: 0.6682 - val_loss: 0.6306 - val_acc: 0.6806\n",
            "Epoch 23/100\n",
            "428/428 [==============================] - 0s 818us/step - loss: 0.6359 - acc: 0.6612 - val_loss: 0.6129 - val_acc: 0.6806\n",
            "Epoch 24/100\n",
            "428/428 [==============================] - 0s 830us/step - loss: 0.6514 - acc: 0.6682 - val_loss: 0.6221 - val_acc: 0.6806\n",
            "Epoch 25/100\n",
            "428/428 [==============================] - 0s 826us/step - loss: 0.6345 - acc: 0.6776 - val_loss: 0.6199 - val_acc: 0.6806\n",
            "Epoch 26/100\n",
            "428/428 [==============================] - 0s 824us/step - loss: 0.6383 - acc: 0.6636 - val_loss: 0.6112 - val_acc: 0.6806\n",
            "Epoch 27/100\n",
            "428/428 [==============================] - 0s 818us/step - loss: 0.6371 - acc: 0.6659 - val_loss: 0.6143 - val_acc: 0.6806\n",
            "Epoch 28/100\n",
            "428/428 [==============================] - 0s 824us/step - loss: 0.6427 - acc: 0.6752 - val_loss: 0.6185 - val_acc: 0.6806\n",
            "Epoch 29/100\n",
            "428/428 [==============================] - 0s 837us/step - loss: 0.6501 - acc: 0.6706 - val_loss: 0.6115 - val_acc: 0.6806\n",
            "Epoch 30/100\n",
            "428/428 [==============================] - 0s 822us/step - loss: 0.6459 - acc: 0.6565 - val_loss: 0.6071 - val_acc: 0.6806\n",
            "Epoch 31/100\n",
            "428/428 [==============================] - 0s 830us/step - loss: 0.6347 - acc: 0.6799 - val_loss: 0.6125 - val_acc: 0.6806\n",
            "Epoch 32/100\n",
            "428/428 [==============================] - 0s 819us/step - loss: 0.6480 - acc: 0.6752 - val_loss: 0.6126 - val_acc: 0.6806\n",
            "Epoch 33/100\n",
            "428/428 [==============================] - 0s 828us/step - loss: 0.6404 - acc: 0.6752 - val_loss: 0.6097 - val_acc: 0.6806\n",
            "Epoch 34/100\n",
            "428/428 [==============================] - 0s 830us/step - loss: 0.6462 - acc: 0.6706 - val_loss: 0.6199 - val_acc: 0.6806\n",
            "Epoch 35/100\n",
            "428/428 [==============================] - 0s 829us/step - loss: 0.6422 - acc: 0.6706 - val_loss: 0.6126 - val_acc: 0.6806\n",
            "Epoch 36/100\n",
            "428/428 [==============================] - 0s 825us/step - loss: 0.6295 - acc: 0.6776 - val_loss: 0.6168 - val_acc: 0.6944\n",
            "Epoch 37/100\n",
            "428/428 [==============================] - 0s 849us/step - loss: 0.6302 - acc: 0.6822 - val_loss: 0.6150 - val_acc: 0.6944\n",
            "Epoch 38/100\n",
            "428/428 [==============================] - 0s 836us/step - loss: 0.6371 - acc: 0.6729 - val_loss: 0.6153 - val_acc: 0.6944\n",
            "Epoch 39/100\n",
            "428/428 [==============================] - 0s 824us/step - loss: 0.6415 - acc: 0.6682 - val_loss: 0.6063 - val_acc: 0.6944\n",
            "Epoch 40/100\n",
            "428/428 [==============================] - 0s 842us/step - loss: 0.6516 - acc: 0.6729 - val_loss: 0.6126 - val_acc: 0.6806\n",
            "Epoch 41/100\n",
            "428/428 [==============================] - 0s 840us/step - loss: 0.6205 - acc: 0.6706 - val_loss: 0.6136 - val_acc: 0.6806\n",
            "Epoch 42/100\n",
            "428/428 [==============================] - 0s 821us/step - loss: 0.6280 - acc: 0.6752 - val_loss: 0.6264 - val_acc: 0.6806\n",
            "Epoch 43/100\n",
            "428/428 [==============================] - 0s 822us/step - loss: 0.6449 - acc: 0.6636 - val_loss: 0.6130 - val_acc: 0.6806\n",
            "Epoch 44/100\n",
            "428/428 [==============================] - 0s 840us/step - loss: 0.6675 - acc: 0.6682 - val_loss: 0.6097 - val_acc: 0.6806\n",
            "Epoch 45/100\n",
            "428/428 [==============================] - 0s 831us/step - loss: 0.6302 - acc: 0.6706 - val_loss: 0.6124 - val_acc: 0.6806\n",
            "Epoch 46/100\n",
            "428/428 [==============================] - 0s 826us/step - loss: 0.6292 - acc: 0.6799 - val_loss: 0.6221 - val_acc: 0.6806\n",
            "Epoch 47/100\n",
            "428/428 [==============================] - 0s 841us/step - loss: 0.6357 - acc: 0.6729 - val_loss: 0.6101 - val_acc: 0.6806\n",
            "Epoch 48/100\n",
            "428/428 [==============================] - 0s 830us/step - loss: 0.6392 - acc: 0.6916 - val_loss: 0.6457 - val_acc: 0.6667\n",
            "Epoch 49/100\n",
            "428/428 [==============================] - 0s 834us/step - loss: 0.6731 - acc: 0.6425 - val_loss: 0.6058 - val_acc: 0.6806\n",
            "Epoch 50/100\n",
            "428/428 [==============================] - 0s 835us/step - loss: 0.6521 - acc: 0.6822 - val_loss: 0.6134 - val_acc: 0.6944\n",
            "Epoch 51/100\n",
            "428/428 [==============================] - 0s 831us/step - loss: 0.6600 - acc: 0.6706 - val_loss: 0.6420 - val_acc: 0.6667\n",
            "Epoch 52/100\n",
            "428/428 [==============================] - 0s 840us/step - loss: 0.6433 - acc: 0.6659 - val_loss: 0.6018 - val_acc: 0.6806\n",
            "Epoch 53/100\n",
            "428/428 [==============================] - 0s 828us/step - loss: 0.6727 - acc: 0.6776 - val_loss: 0.6152 - val_acc: 0.6806\n",
            "Epoch 54/100\n",
            "428/428 [==============================] - 0s 833us/step - loss: 0.6335 - acc: 0.6776 - val_loss: 0.6039 - val_acc: 0.6944\n",
            "Epoch 55/100\n",
            "428/428 [==============================] - 0s 840us/step - loss: 0.6480 - acc: 0.6729 - val_loss: 0.6051 - val_acc: 0.6806\n",
            "Epoch 56/100\n",
            "428/428 [==============================] - 0s 827us/step - loss: 0.6325 - acc: 0.6729 - val_loss: 0.6060 - val_acc: 0.6944\n",
            "Epoch 57/100\n",
            "428/428 [==============================] - 0s 843us/step - loss: 0.6686 - acc: 0.6612 - val_loss: 0.6120 - val_acc: 0.6806\n",
            "Epoch 58/100\n",
            "428/428 [==============================] - 0s 848us/step - loss: 0.6496 - acc: 0.6799 - val_loss: 0.6227 - val_acc: 0.6806\n",
            "Epoch 59/100\n",
            "428/428 [==============================] - 0s 841us/step - loss: 0.6511 - acc: 0.6565 - val_loss: 0.6220 - val_acc: 0.6806\n",
            "Epoch 60/100\n",
            "428/428 [==============================] - 0s 834us/step - loss: 0.6222 - acc: 0.6776 - val_loss: 0.6183 - val_acc: 0.6806\n",
            "Epoch 61/100\n",
            "428/428 [==============================] - 0s 856us/step - loss: 0.6299 - acc: 0.6776 - val_loss: 0.6145 - val_acc: 0.6806\n",
            "Epoch 62/100\n",
            "428/428 [==============================] - 0s 831us/step - loss: 0.6308 - acc: 0.6776 - val_loss: 0.6132 - val_acc: 0.6806\n",
            "Epoch 63/100\n",
            "428/428 [==============================] - 0s 830us/step - loss: 0.6435 - acc: 0.6752 - val_loss: 0.6106 - val_acc: 0.6806\n",
            "Epoch 64/100\n",
            "428/428 [==============================] - 0s 845us/step - loss: 0.6184 - acc: 0.6893 - val_loss: 0.6051 - val_acc: 0.6944\n",
            "Epoch 65/100\n",
            "428/428 [==============================] - 0s 837us/step - loss: 0.6292 - acc: 0.6916 - val_loss: 0.6080 - val_acc: 0.6944\n",
            "Epoch 66/100\n",
            "428/428 [==============================] - 0s 836us/step - loss: 0.6337 - acc: 0.6799 - val_loss: 0.6121 - val_acc: 0.6806\n",
            "Epoch 67/100\n",
            "428/428 [==============================] - 0s 855us/step - loss: 0.6217 - acc: 0.6776 - val_loss: 0.6196 - val_acc: 0.6806\n",
            "Epoch 68/100\n",
            "428/428 [==============================] - 0s 841us/step - loss: 0.6328 - acc: 0.6776 - val_loss: 0.6206 - val_acc: 0.6806\n",
            "Epoch 69/100\n",
            "428/428 [==============================] - 0s 833us/step - loss: 0.6389 - acc: 0.6682 - val_loss: 0.6126 - val_acc: 0.6806\n",
            "Epoch 70/100\n",
            "428/428 [==============================] - 0s 857us/step - loss: 0.6361 - acc: 0.6776 - val_loss: 0.6105 - val_acc: 0.6806\n",
            "Epoch 71/100\n",
            "428/428 [==============================] - 0s 829us/step - loss: 0.6343 - acc: 0.6729 - val_loss: 0.6261 - val_acc: 0.6806\n",
            "Epoch 72/100\n",
            "428/428 [==============================] - 0s 839us/step - loss: 0.6258 - acc: 0.6776 - val_loss: 0.6093 - val_acc: 0.6944\n",
            "Epoch 73/100\n",
            "428/428 [==============================] - 0s 826us/step - loss: 0.6318 - acc: 0.6729 - val_loss: 0.6062 - val_acc: 0.6806\n",
            "Epoch 74/100\n",
            "428/428 [==============================] - 0s 843us/step - loss: 0.6405 - acc: 0.6776 - val_loss: 0.6063 - val_acc: 0.6944\n",
            "Epoch 75/100\n",
            "428/428 [==============================] - 0s 846us/step - loss: 0.6804 - acc: 0.6869 - val_loss: 0.6285 - val_acc: 0.6806\n",
            "Epoch 76/100\n",
            "428/428 [==============================] - 0s 834us/step - loss: 0.6239 - acc: 0.6752 - val_loss: 0.6186 - val_acc: 0.6806\n",
            "Epoch 77/100\n",
            "428/428 [==============================] - 0s 828us/step - loss: 0.6475 - acc: 0.6682 - val_loss: 0.6176 - val_acc: 0.6806\n",
            "Epoch 78/100\n",
            "428/428 [==============================] - 0s 842us/step - loss: 0.6333 - acc: 0.6752 - val_loss: 0.6208 - val_acc: 0.6806\n",
            "Epoch 79/100\n",
            "428/428 [==============================] - 0s 848us/step - loss: 0.6444 - acc: 0.6799 - val_loss: 0.6104 - val_acc: 0.6944\n",
            "Epoch 80/100\n",
            "428/428 [==============================] - 0s 835us/step - loss: 0.6318 - acc: 0.6682 - val_loss: 0.6106 - val_acc: 0.6944\n",
            "Epoch 81/100\n",
            "428/428 [==============================] - 0s 841us/step - loss: 0.6336 - acc: 0.6706 - val_loss: 0.6080 - val_acc: 0.6806\n",
            "Epoch 82/100\n",
            "428/428 [==============================] - 0s 837us/step - loss: 0.6503 - acc: 0.6776 - val_loss: 0.6087 - val_acc: 0.6806\n",
            "Epoch 83/100\n",
            "428/428 [==============================] - 0s 839us/step - loss: 0.6535 - acc: 0.6706 - val_loss: 0.6222 - val_acc: 0.6806\n",
            "Epoch 84/100\n",
            "428/428 [==============================] - 0s 840us/step - loss: 0.6325 - acc: 0.6776 - val_loss: 0.6125 - val_acc: 0.6806\n",
            "Epoch 85/100\n",
            "428/428 [==============================] - 0s 832us/step - loss: 0.6852 - acc: 0.6682 - val_loss: 0.6122 - val_acc: 0.6944\n",
            "Epoch 86/100\n",
            "428/428 [==============================] - 0s 838us/step - loss: 0.6463 - acc: 0.6682 - val_loss: 0.6094 - val_acc: 0.6806\n",
            "Epoch 87/100\n",
            "428/428 [==============================] - 0s 835us/step - loss: 0.6441 - acc: 0.6799 - val_loss: 0.6100 - val_acc: 0.6806\n",
            "Epoch 88/100\n",
            "428/428 [==============================] - 0s 829us/step - loss: 0.6212 - acc: 0.6846 - val_loss: 0.6120 - val_acc: 0.6944\n",
            "Epoch 89/100\n",
            "428/428 [==============================] - 0s 848us/step - loss: 0.6357 - acc: 0.6682 - val_loss: 0.6157 - val_acc: 0.6806\n",
            "Epoch 90/100\n",
            "428/428 [==============================] - 0s 856us/step - loss: 0.6514 - acc: 0.6729 - val_loss: 0.6221 - val_acc: 0.6806\n",
            "Epoch 91/100\n",
            "428/428 [==============================] - 0s 835us/step - loss: 0.7265 - acc: 0.6402 - val_loss: 0.6328 - val_acc: 0.6806\n",
            "Epoch 92/100\n",
            "428/428 [==============================] - 0s 843us/step - loss: 0.6463 - acc: 0.6589 - val_loss: 0.6109 - val_acc: 0.6944\n",
            "Epoch 93/100\n",
            "428/428 [==============================] - 0s 836us/step - loss: 0.6588 - acc: 0.6729 - val_loss: 0.6078 - val_acc: 0.6944\n",
            "Epoch 94/100\n",
            "428/428 [==============================] - 0s 844us/step - loss: 0.6407 - acc: 0.6706 - val_loss: 0.6116 - val_acc: 0.6806\n",
            "Epoch 95/100\n",
            "428/428 [==============================] - 0s 846us/step - loss: 0.6384 - acc: 0.6799 - val_loss: 0.6149 - val_acc: 0.6806\n",
            "Epoch 96/100\n",
            "428/428 [==============================] - 0s 833us/step - loss: 0.6409 - acc: 0.6682 - val_loss: 0.6140 - val_acc: 0.6806\n",
            "Epoch 97/100\n",
            "428/428 [==============================] - 0s 841us/step - loss: 0.6440 - acc: 0.6729 - val_loss: 0.6130 - val_acc: 0.6806\n",
            "Epoch 98/100\n",
            "428/428 [==============================] - 0s 841us/step - loss: 0.6232 - acc: 0.6752 - val_loss: 0.6189 - val_acc: 0.6806\n",
            "Epoch 99/100\n",
            "428/428 [==============================] - 0s 834us/step - loss: 0.6155 - acc: 0.6846 - val_loss: 0.6077 - val_acc: 0.6806\n",
            "Epoch 100/100\n",
            "428/428 [==============================] - 0s 840us/step - loss: 0.6339 - acc: 0.6729 - val_loss: 0.6080 - val_acc: 0.6944\n",
            "[[ 2 21]\n",
            " [ 1 48]]\n",
            "Accuracy :  0.6944444444444444\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.09      0.15        23\n",
            "           1       0.70      0.98      0.81        49\n",
            "\n",
            "    accuracy                           0.69        72\n",
            "   macro avg       0.68      0.53      0.48        72\n",
            "weighted avg       0.69      0.69      0.60        72\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "model_6 (Model)              (None, 2)                 9148782   \n",
            "=================================================================\n",
            "Total params: 9,148,782\n",
            "Trainable params: 8,386\n",
            "Non-trainable params: 9,140,396\n",
            "_________________________________________________________________\n",
            "Train on 428 samples, validate on 72 samples\n",
            "Epoch 1/100\n",
            "428/428 [==============================] - 3s 7ms/step - loss: 0.6500 - acc: 0.6799 - val_loss: 0.6124 - val_acc: 0.6944\n",
            "Epoch 2/100\n",
            "428/428 [==============================] - 0s 814us/step - loss: 0.6322 - acc: 0.6846 - val_loss: 0.6051 - val_acc: 0.6944\n",
            "Epoch 3/100\n",
            "428/428 [==============================] - 0s 820us/step - loss: 0.6278 - acc: 0.6752 - val_loss: 0.6115 - val_acc: 0.6806\n",
            "Epoch 4/100\n",
            "428/428 [==============================] - 0s 828us/step - loss: 0.6601 - acc: 0.6752 - val_loss: 0.6137 - val_acc: 0.6806\n",
            "Epoch 5/100\n",
            "428/428 [==============================] - 0s 818us/step - loss: 0.6321 - acc: 0.6822 - val_loss: 0.6044 - val_acc: 0.6944\n",
            "Epoch 6/100\n",
            "428/428 [==============================] - 0s 825us/step - loss: 0.6416 - acc: 0.6682 - val_loss: 0.6134 - val_acc: 0.6806\n",
            "Epoch 7/100\n",
            "428/428 [==============================] - 0s 817us/step - loss: 0.6452 - acc: 0.6752 - val_loss: 0.6342 - val_acc: 0.6806\n",
            "Epoch 8/100\n",
            "428/428 [==============================] - 0s 816us/step - loss: 0.6402 - acc: 0.6682 - val_loss: 0.6103 - val_acc: 0.6806\n",
            "Epoch 9/100\n",
            "428/428 [==============================] - 0s 832us/step - loss: 0.6275 - acc: 0.6776 - val_loss: 0.6062 - val_acc: 0.6806\n",
            "Epoch 10/100\n",
            "428/428 [==============================] - 0s 820us/step - loss: 0.6432 - acc: 0.6752 - val_loss: 0.6186 - val_acc: 0.6806\n",
            "Epoch 11/100\n",
            "428/428 [==============================] - 0s 819us/step - loss: 0.6206 - acc: 0.6752 - val_loss: 0.6207 - val_acc: 0.6806\n",
            "Epoch 12/100\n",
            "428/428 [==============================] - 0s 834us/step - loss: 0.6310 - acc: 0.6729 - val_loss: 0.6116 - val_acc: 0.6806\n",
            "Epoch 13/100\n",
            "428/428 [==============================] - 0s 818us/step - loss: 0.6383 - acc: 0.6776 - val_loss: 0.6155 - val_acc: 0.6944\n",
            "Epoch 14/100\n",
            "428/428 [==============================] - 0s 826us/step - loss: 0.6504 - acc: 0.6589 - val_loss: 0.6075 - val_acc: 0.6944\n",
            "Epoch 15/100\n",
            "428/428 [==============================] - 0s 820us/step - loss: 0.6349 - acc: 0.6752 - val_loss: 0.6084 - val_acc: 0.6806\n",
            "Epoch 16/100\n",
            "428/428 [==============================] - 0s 831us/step - loss: 0.6338 - acc: 0.6776 - val_loss: 0.6153 - val_acc: 0.6806\n",
            "Epoch 17/100\n",
            "428/428 [==============================] - 0s 839us/step - loss: 0.6356 - acc: 0.6752 - val_loss: 0.6066 - val_acc: 0.6944\n",
            "Epoch 18/100\n",
            "428/428 [==============================] - 0s 820us/step - loss: 0.6384 - acc: 0.6729 - val_loss: 0.6051 - val_acc: 0.6944\n",
            "Epoch 19/100\n",
            "428/428 [==============================] - 0s 835us/step - loss: 0.6214 - acc: 0.6729 - val_loss: 0.6048 - val_acc: 0.6944\n",
            "Epoch 20/100\n",
            "428/428 [==============================] - 0s 819us/step - loss: 0.6385 - acc: 0.6706 - val_loss: 0.6095 - val_acc: 0.6806\n",
            "Epoch 21/100\n",
            "428/428 [==============================] - 0s 828us/step - loss: 0.6296 - acc: 0.6799 - val_loss: 0.6087 - val_acc: 0.6806\n",
            "Epoch 22/100\n",
            "428/428 [==============================] - 0s 818us/step - loss: 0.6234 - acc: 0.6799 - val_loss: 0.6050 - val_acc: 0.6944\n",
            "Epoch 23/100\n",
            "428/428 [==============================] - 0s 827us/step - loss: 0.6334 - acc: 0.6799 - val_loss: 0.6200 - val_acc: 0.6806\n",
            "Epoch 24/100\n",
            "428/428 [==============================] - 0s 824us/step - loss: 0.6563 - acc: 0.6752 - val_loss: 0.6088 - val_acc: 0.6944\n",
            "Epoch 25/100\n",
            "428/428 [==============================] - 0s 816us/step - loss: 0.6184 - acc: 0.6776 - val_loss: 0.5985 - val_acc: 0.6944\n",
            "Epoch 26/100\n",
            "428/428 [==============================] - 0s 827us/step - loss: 0.6415 - acc: 0.6869 - val_loss: 0.5980 - val_acc: 0.6944\n",
            "Epoch 27/100\n",
            "428/428 [==============================] - 0s 827us/step - loss: 0.6177 - acc: 0.6799 - val_loss: 0.5985 - val_acc: 0.6944\n",
            "Epoch 28/100\n",
            "428/428 [==============================] - 0s 827us/step - loss: 0.6246 - acc: 0.6799 - val_loss: 0.5984 - val_acc: 0.6944\n",
            "Epoch 29/100\n",
            "428/428 [==============================] - 0s 829us/step - loss: 0.6432 - acc: 0.6799 - val_loss: 0.5997 - val_acc: 0.6944\n",
            "Epoch 30/100\n",
            "428/428 [==============================] - 0s 825us/step - loss: 0.6401 - acc: 0.6752 - val_loss: 0.6100 - val_acc: 0.6806\n",
            "Epoch 31/100\n",
            "428/428 [==============================] - 0s 826us/step - loss: 0.6337 - acc: 0.6729 - val_loss: 0.6128 - val_acc: 0.6806\n",
            "Epoch 32/100\n",
            "428/428 [==============================] - 0s 830us/step - loss: 0.6322 - acc: 0.6776 - val_loss: 0.5996 - val_acc: 0.6944\n",
            "Epoch 33/100\n",
            "428/428 [==============================] - 0s 828us/step - loss: 0.6267 - acc: 0.6776 - val_loss: 0.5953 - val_acc: 0.6944\n",
            "Epoch 34/100\n",
            "428/428 [==============================] - 0s 817us/step - loss: 0.6473 - acc: 0.6729 - val_loss: 0.5972 - val_acc: 0.6944\n",
            "Epoch 35/100\n",
            "428/428 [==============================] - 0s 839us/step - loss: 0.6187 - acc: 0.6776 - val_loss: 0.6014 - val_acc: 0.6944\n",
            "Epoch 36/100\n",
            "428/428 [==============================] - 0s 838us/step - loss: 0.6275 - acc: 0.6822 - val_loss: 0.6016 - val_acc: 0.6944\n",
            "Epoch 37/100\n",
            "428/428 [==============================] - 0s 832us/step - loss: 0.6185 - acc: 0.6869 - val_loss: 0.6010 - val_acc: 0.6944\n",
            "Epoch 38/100\n",
            "428/428 [==============================] - 0s 832us/step - loss: 0.6383 - acc: 0.6706 - val_loss: 0.6013 - val_acc: 0.6944\n",
            "Epoch 39/100\n",
            "428/428 [==============================] - 0s 829us/step - loss: 0.6346 - acc: 0.6822 - val_loss: 0.6044 - val_acc: 0.6944\n",
            "Epoch 40/100\n",
            "428/428 [==============================] - 0s 832us/step - loss: 0.6334 - acc: 0.6729 - val_loss: 0.6049 - val_acc: 0.6944\n",
            "Epoch 41/100\n",
            "428/428 [==============================] - 0s 823us/step - loss: 0.6456 - acc: 0.6729 - val_loss: 0.6050 - val_acc: 0.6944\n",
            "Epoch 42/100\n",
            "428/428 [==============================] - 0s 826us/step - loss: 0.6298 - acc: 0.6752 - val_loss: 0.6346 - val_acc: 0.6806\n",
            "Epoch 43/100\n",
            "428/428 [==============================] - 0s 826us/step - loss: 0.6387 - acc: 0.6776 - val_loss: 0.6240 - val_acc: 0.6806\n",
            "Epoch 44/100\n",
            "428/428 [==============================] - 0s 826us/step - loss: 0.6320 - acc: 0.6776 - val_loss: 0.6153 - val_acc: 0.6806\n",
            "Epoch 45/100\n",
            "428/428 [==============================] - 0s 831us/step - loss: 0.6292 - acc: 0.6846 - val_loss: 0.6064 - val_acc: 0.6806\n",
            "Epoch 46/100\n",
            "428/428 [==============================] - 0s 845us/step - loss: 0.6205 - acc: 0.6799 - val_loss: 0.5984 - val_acc: 0.6944\n",
            "Epoch 47/100\n",
            "428/428 [==============================] - 0s 825us/step - loss: 0.6296 - acc: 0.6729 - val_loss: 0.5973 - val_acc: 0.6944\n",
            "Epoch 48/100\n",
            "428/428 [==============================] - 0s 829us/step - loss: 0.6365 - acc: 0.6776 - val_loss: 0.6039 - val_acc: 0.6944\n",
            "Epoch 49/100\n",
            "428/428 [==============================] - 0s 856us/step - loss: 0.6234 - acc: 0.6776 - val_loss: 0.6143 - val_acc: 0.6944\n",
            "Epoch 50/100\n",
            "428/428 [==============================] - 0s 849us/step - loss: 0.6262 - acc: 0.6822 - val_loss: 0.6105 - val_acc: 0.6944\n",
            "Epoch 51/100\n",
            "428/428 [==============================] - 0s 836us/step - loss: 0.6296 - acc: 0.6682 - val_loss: 0.6042 - val_acc: 0.6944\n",
            "Epoch 52/100\n",
            "428/428 [==============================] - 0s 844us/step - loss: 0.6178 - acc: 0.6822 - val_loss: 0.6000 - val_acc: 0.6944\n",
            "Epoch 53/100\n",
            "428/428 [==============================] - 0s 830us/step - loss: 0.6182 - acc: 0.6822 - val_loss: 0.6002 - val_acc: 0.6944\n",
            "Epoch 54/100\n",
            "428/428 [==============================] - 0s 826us/step - loss: 0.6400 - acc: 0.6752 - val_loss: 0.6102 - val_acc: 0.6944\n",
            "Epoch 55/100\n",
            "428/428 [==============================] - 0s 846us/step - loss: 0.6242 - acc: 0.6799 - val_loss: 0.6114 - val_acc: 0.6944\n",
            "Epoch 56/100\n",
            "428/428 [==============================] - 0s 828us/step - loss: 0.6152 - acc: 0.6822 - val_loss: 0.6105 - val_acc: 0.6944\n",
            "Epoch 57/100\n",
            "428/428 [==============================] - 0s 838us/step - loss: 0.6369 - acc: 0.6822 - val_loss: 0.6084 - val_acc: 0.6944\n",
            "Epoch 58/100\n",
            "428/428 [==============================] - 0s 839us/step - loss: 0.6307 - acc: 0.6752 - val_loss: 0.6043 - val_acc: 0.6944\n",
            "Epoch 59/100\n",
            "428/428 [==============================] - 0s 837us/step - loss: 0.6326 - acc: 0.6799 - val_loss: 0.6082 - val_acc: 0.6944\n",
            "Epoch 60/100\n",
            "428/428 [==============================] - 0s 842us/step - loss: 0.6379 - acc: 0.6846 - val_loss: 0.6057 - val_acc: 0.6944\n",
            "Epoch 61/100\n",
            "428/428 [==============================] - 0s 849us/step - loss: 0.6204 - acc: 0.6799 - val_loss: 0.6027 - val_acc: 0.6944\n",
            "Epoch 62/100\n",
            "428/428 [==============================] - 0s 833us/step - loss: 0.6181 - acc: 0.6799 - val_loss: 0.6020 - val_acc: 0.6944\n",
            "Epoch 63/100\n",
            "428/428 [==============================] - 0s 851us/step - loss: 0.6277 - acc: 0.6846 - val_loss: 0.6031 - val_acc: 0.6944\n",
            "Epoch 64/100\n",
            "428/428 [==============================] - 0s 827us/step - loss: 0.6317 - acc: 0.6682 - val_loss: 0.6036 - val_acc: 0.6944\n",
            "Epoch 65/100\n",
            "428/428 [==============================] - 0s 827us/step - loss: 0.6312 - acc: 0.6822 - val_loss: 0.6105 - val_acc: 0.6806\n",
            "Epoch 66/100\n",
            "428/428 [==============================] - 0s 841us/step - loss: 0.6315 - acc: 0.6822 - val_loss: 0.6063 - val_acc: 0.6944\n",
            "Epoch 67/100\n",
            "428/428 [==============================] - 0s 828us/step - loss: 0.6234 - acc: 0.6799 - val_loss: 0.6149 - val_acc: 0.6944\n",
            "Epoch 68/100\n",
            "428/428 [==============================] - 0s 837us/step - loss: 0.6363 - acc: 0.6682 - val_loss: 0.6076 - val_acc: 0.6944\n",
            "Epoch 69/100\n",
            "428/428 [==============================] - 0s 833us/step - loss: 0.6191 - acc: 0.6752 - val_loss: 0.6043 - val_acc: 0.6944\n",
            "Epoch 70/100\n",
            "428/428 [==============================] - 0s 831us/step - loss: 0.6265 - acc: 0.6822 - val_loss: 0.6071 - val_acc: 0.6944\n",
            "Epoch 71/100\n",
            "428/428 [==============================] - 0s 831us/step - loss: 0.6195 - acc: 0.6799 - val_loss: 0.6086 - val_acc: 0.6944\n",
            "Epoch 72/100\n",
            "428/428 [==============================] - 0s 844us/step - loss: 0.6326 - acc: 0.6822 - val_loss: 0.6035 - val_acc: 0.6944\n",
            "Epoch 73/100\n",
            "428/428 [==============================] - 0s 830us/step - loss: 0.6276 - acc: 0.6822 - val_loss: 0.6048 - val_acc: 0.6944\n",
            "Epoch 74/100\n",
            "428/428 [==============================] - 0s 831us/step - loss: 0.6265 - acc: 0.6846 - val_loss: 0.6043 - val_acc: 0.6944\n",
            "Epoch 75/100\n",
            "428/428 [==============================] - 0s 837us/step - loss: 0.6198 - acc: 0.6893 - val_loss: 0.6075 - val_acc: 0.6944\n",
            "Epoch 76/100\n",
            "428/428 [==============================] - 0s 838us/step - loss: 0.6145 - acc: 0.6799 - val_loss: 0.6077 - val_acc: 0.6944\n",
            "Epoch 77/100\n",
            "428/428 [==============================] - 0s 830us/step - loss: 0.6297 - acc: 0.6822 - val_loss: 0.6069 - val_acc: 0.6944\n",
            "Epoch 78/100\n",
            "428/428 [==============================] - 0s 827us/step - loss: 0.6195 - acc: 0.6846 - val_loss: 0.6039 - val_acc: 0.6944\n",
            "Epoch 79/100\n",
            "428/428 [==============================] - 0s 834us/step - loss: 0.6300 - acc: 0.6776 - val_loss: 0.6045 - val_acc: 0.6944\n",
            "Epoch 80/100\n",
            "428/428 [==============================] - 0s 833us/step - loss: 0.6208 - acc: 0.6822 - val_loss: 0.6046 - val_acc: 0.6944\n",
            "Epoch 81/100\n",
            "428/428 [==============================] - 0s 850us/step - loss: 0.6301 - acc: 0.6752 - val_loss: 0.6025 - val_acc: 0.6944\n",
            "Epoch 82/100\n",
            "428/428 [==============================] - 0s 828us/step - loss: 0.6392 - acc: 0.6776 - val_loss: 0.6070 - val_acc: 0.6944\n",
            "Epoch 83/100\n",
            "428/428 [==============================] - 0s 845us/step - loss: 0.6267 - acc: 0.6706 - val_loss: 0.6113 - val_acc: 0.6944\n",
            "Epoch 84/100\n",
            "428/428 [==============================] - 0s 828us/step - loss: 0.6199 - acc: 0.6846 - val_loss: 0.6054 - val_acc: 0.6944\n",
            "Epoch 85/100\n",
            "428/428 [==============================] - 0s 833us/step - loss: 0.6307 - acc: 0.6752 - val_loss: 0.6042 - val_acc: 0.6944\n",
            "Epoch 86/100\n",
            "428/428 [==============================] - 0s 841us/step - loss: 0.6298 - acc: 0.6893 - val_loss: 0.6054 - val_acc: 0.6944\n",
            "Epoch 87/100\n",
            "428/428 [==============================] - 0s 834us/step - loss: 0.6179 - acc: 0.6822 - val_loss: 0.6080 - val_acc: 0.6944\n",
            "Epoch 88/100\n",
            "428/428 [==============================] - 0s 830us/step - loss: 0.6269 - acc: 0.6846 - val_loss: 0.6084 - val_acc: 0.6944\n",
            "Epoch 89/100\n",
            "428/428 [==============================] - 0s 844us/step - loss: 0.6202 - acc: 0.6822 - val_loss: 0.6182 - val_acc: 0.6944\n",
            "Epoch 90/100\n",
            "428/428 [==============================] - 0s 837us/step - loss: 0.6339 - acc: 0.6659 - val_loss: 0.6148 - val_acc: 0.6944\n",
            "Epoch 91/100\n",
            "428/428 [==============================] - 0s 832us/step - loss: 0.6404 - acc: 0.6706 - val_loss: 0.6126 - val_acc: 0.6944\n",
            "Epoch 92/100\n",
            "428/428 [==============================] - 0s 840us/step - loss: 0.6173 - acc: 0.6846 - val_loss: 0.6114 - val_acc: 0.6944\n",
            "Epoch 93/100\n",
            "428/428 [==============================] - 0s 836us/step - loss: 0.6179 - acc: 0.6799 - val_loss: 0.6073 - val_acc: 0.6944\n",
            "Epoch 94/100\n",
            "428/428 [==============================] - 0s 844us/step - loss: 0.6241 - acc: 0.6776 - val_loss: 0.6069 - val_acc: 0.6944\n",
            "Epoch 95/100\n",
            "428/428 [==============================] - 0s 839us/step - loss: 0.6145 - acc: 0.6799 - val_loss: 0.6046 - val_acc: 0.6944\n",
            "Epoch 96/100\n",
            "428/428 [==============================] - 0s 834us/step - loss: 0.6137 - acc: 0.6846 - val_loss: 0.6033 - val_acc: 0.6944\n",
            "Epoch 97/100\n",
            "428/428 [==============================] - 0s 850us/step - loss: 0.6196 - acc: 0.6869 - val_loss: 0.6026 - val_acc: 0.6944\n",
            "Epoch 98/100\n",
            "428/428 [==============================] - 0s 852us/step - loss: 0.6279 - acc: 0.6799 - val_loss: 0.6072 - val_acc: 0.6944\n",
            "Epoch 99/100\n",
            "428/428 [==============================] - 0s 834us/step - loss: 0.6240 - acc: 0.6752 - val_loss: 0.6068 - val_acc: 0.6944\n",
            "Epoch 100/100\n",
            "428/428 [==============================] - 0s 853us/step - loss: 0.6269 - acc: 0.6776 - val_loss: 0.6093 - val_acc: 0.6944\n",
            "[[ 1 22]\n",
            " [ 0 49]]\n",
            "Accuracy :  0.6944444444444444\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.04      0.08        23\n",
            "           1       0.69      1.00      0.82        49\n",
            "\n",
            "    accuracy                           0.69        72\n",
            "   macro avg       0.85      0.52      0.45        72\n",
            "weighted avg       0.79      0.69      0.58        72\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "model_6 (Model)              (None, 2)                 9148782   \n",
            "=================================================================\n",
            "Total params: 9,148,782\n",
            "Trainable params: 8,386\n",
            "Non-trainable params: 9,140,396\n",
            "_________________________________________________________________\n",
            "Train on 428 samples, validate on 72 samples\n",
            "Epoch 1/100\n",
            "428/428 [==============================] - 3s 7ms/step - loss: 0.6214 - acc: 0.6776 - val_loss: 0.5897 - val_acc: 0.6806\n",
            "Epoch 2/100\n",
            "428/428 [==============================] - 0s 802us/step - loss: 0.6243 - acc: 0.6776 - val_loss: 0.5888 - val_acc: 0.6806\n",
            "Epoch 3/100\n",
            "428/428 [==============================] - 0s 810us/step - loss: 0.6336 - acc: 0.6752 - val_loss: 0.5856 - val_acc: 0.7083\n",
            "Epoch 4/100\n",
            "428/428 [==============================] - 0s 815us/step - loss: 0.6317 - acc: 0.6822 - val_loss: 0.5874 - val_acc: 0.7083\n",
            "Epoch 5/100\n",
            "428/428 [==============================] - 0s 812us/step - loss: 0.6248 - acc: 0.6869 - val_loss: 0.5892 - val_acc: 0.7083\n",
            "Epoch 6/100\n",
            "428/428 [==============================] - 0s 815us/step - loss: 0.6269 - acc: 0.6752 - val_loss: 0.5858 - val_acc: 0.7083\n",
            "Epoch 7/100\n",
            "428/428 [==============================] - 0s 835us/step - loss: 0.6410 - acc: 0.6729 - val_loss: 0.5884 - val_acc: 0.7083\n",
            "Epoch 8/100\n",
            "428/428 [==============================] - 0s 823us/step - loss: 0.6432 - acc: 0.6822 - val_loss: 0.5860 - val_acc: 0.7083\n",
            "Epoch 9/100\n",
            "428/428 [==============================] - 0s 815us/step - loss: 0.6301 - acc: 0.6846 - val_loss: 0.5922 - val_acc: 0.7083\n",
            "Epoch 10/100\n",
            "428/428 [==============================] - 0s 830us/step - loss: 0.6304 - acc: 0.6706 - val_loss: 0.6005 - val_acc: 0.6806\n",
            "Epoch 11/100\n",
            "428/428 [==============================] - 0s 823us/step - loss: 0.6304 - acc: 0.6776 - val_loss: 0.5961 - val_acc: 0.6806\n",
            "Epoch 12/100\n",
            "428/428 [==============================] - 0s 819us/step - loss: 0.6182 - acc: 0.6822 - val_loss: 0.5871 - val_acc: 0.6944\n",
            "Epoch 13/100\n",
            "428/428 [==============================] - 0s 812us/step - loss: 0.6437 - acc: 0.6729 - val_loss: 0.5940 - val_acc: 0.6806\n",
            "Epoch 14/100\n",
            "428/428 [==============================] - 0s 820us/step - loss: 0.6275 - acc: 0.6822 - val_loss: 0.5832 - val_acc: 0.7083\n",
            "Epoch 15/100\n",
            "428/428 [==============================] - 0s 813us/step - loss: 0.6568 - acc: 0.6799 - val_loss: 0.5865 - val_acc: 0.7083\n",
            "Epoch 16/100\n",
            "428/428 [==============================] - 0s 815us/step - loss: 0.6202 - acc: 0.6799 - val_loss: 0.5966 - val_acc: 0.6944\n",
            "Epoch 17/100\n",
            "428/428 [==============================] - 0s 823us/step - loss: 0.6408 - acc: 0.6752 - val_loss: 0.6032 - val_acc: 0.6806\n",
            "Epoch 18/100\n",
            "428/428 [==============================] - 0s 827us/step - loss: 0.6214 - acc: 0.6799 - val_loss: 0.6010 - val_acc: 0.6806\n",
            "Epoch 19/100\n",
            "428/428 [==============================] - 0s 825us/step - loss: 0.6273 - acc: 0.6706 - val_loss: 0.6027 - val_acc: 0.6806\n",
            "Epoch 20/100\n",
            "428/428 [==============================] - 0s 821us/step - loss: 0.6413 - acc: 0.6776 - val_loss: 0.6041 - val_acc: 0.6806\n",
            "Epoch 21/100\n",
            "428/428 [==============================] - 0s 817us/step - loss: 0.6167 - acc: 0.6799 - val_loss: 0.5988 - val_acc: 0.6806\n",
            "Epoch 22/100\n",
            "428/428 [==============================] - 0s 830us/step - loss: 0.6204 - acc: 0.6822 - val_loss: 0.5939 - val_acc: 0.7083\n",
            "Epoch 23/100\n",
            "428/428 [==============================] - 0s 820us/step - loss: 0.6175 - acc: 0.6846 - val_loss: 0.5922 - val_acc: 0.7083\n",
            "Epoch 24/100\n",
            "428/428 [==============================] - 0s 821us/step - loss: 0.6390 - acc: 0.6729 - val_loss: 0.5927 - val_acc: 0.6944\n",
            "Epoch 25/100\n",
            "428/428 [==============================] - 0s 829us/step - loss: 0.6344 - acc: 0.6776 - val_loss: 0.6016 - val_acc: 0.6806\n",
            "Epoch 26/100\n",
            "428/428 [==============================] - 0s 818us/step - loss: 0.6118 - acc: 0.6846 - val_loss: 0.6041 - val_acc: 0.6806\n",
            "Epoch 27/100\n",
            "428/428 [==============================] - 0s 819us/step - loss: 0.6351 - acc: 0.6776 - val_loss: 0.6016 - val_acc: 0.6806\n",
            "Epoch 28/100\n",
            "428/428 [==============================] - 0s 830us/step - loss: 0.6145 - acc: 0.6799 - val_loss: 0.6040 - val_acc: 0.6944\n",
            "Epoch 29/100\n",
            "428/428 [==============================] - 0s 824us/step - loss: 0.6362 - acc: 0.6706 - val_loss: 0.6039 - val_acc: 0.6806\n",
            "Epoch 30/100\n",
            "428/428 [==============================] - 0s 830us/step - loss: 0.6213 - acc: 0.6822 - val_loss: 0.6007 - val_acc: 0.6944\n",
            "Epoch 31/100\n",
            "428/428 [==============================] - 0s 822us/step - loss: 0.6110 - acc: 0.6893 - val_loss: 0.5990 - val_acc: 0.6944\n",
            "Epoch 32/100\n",
            "428/428 [==============================] - 0s 820us/step - loss: 0.6498 - acc: 0.6682 - val_loss: 0.6030 - val_acc: 0.6944\n",
            "Epoch 33/100\n",
            "428/428 [==============================] - 0s 826us/step - loss: 0.6484 - acc: 0.6752 - val_loss: 0.5952 - val_acc: 0.6806\n",
            "Epoch 34/100\n",
            "428/428 [==============================] - 0s 828us/step - loss: 0.6391 - acc: 0.6752 - val_loss: 0.6033 - val_acc: 0.6806\n",
            "Epoch 35/100\n",
            "428/428 [==============================] - 0s 823us/step - loss: 0.6360 - acc: 0.6776 - val_loss: 0.6099 - val_acc: 0.6806\n",
            "Epoch 36/100\n",
            "428/428 [==============================] - 0s 843us/step - loss: 0.6208 - acc: 0.6776 - val_loss: 0.6097 - val_acc: 0.6806\n",
            "Epoch 37/100\n",
            "428/428 [==============================] - 0s 823us/step - loss: 0.6218 - acc: 0.6799 - val_loss: 0.6005 - val_acc: 0.6806\n",
            "Epoch 38/100\n",
            "428/428 [==============================] - 0s 822us/step - loss: 0.6428 - acc: 0.6729 - val_loss: 0.6014 - val_acc: 0.6806\n",
            "Epoch 39/100\n",
            "428/428 [==============================] - 0s 821us/step - loss: 0.6388 - acc: 0.6706 - val_loss: 0.6026 - val_acc: 0.6806\n",
            "Epoch 40/100\n",
            "428/428 [==============================] - 0s 829us/step - loss: 0.6292 - acc: 0.6776 - val_loss: 0.6015 - val_acc: 0.6806\n",
            "Epoch 41/100\n",
            "428/428 [==============================] - 0s 821us/step - loss: 0.6187 - acc: 0.6752 - val_loss: 0.5996 - val_acc: 0.6806\n",
            "Epoch 42/100\n",
            "428/428 [==============================] - 0s 825us/step - loss: 0.6185 - acc: 0.6822 - val_loss: 0.6004 - val_acc: 0.6806\n",
            "Epoch 43/100\n",
            "428/428 [==============================] - 0s 825us/step - loss: 0.6326 - acc: 0.6752 - val_loss: 0.6041 - val_acc: 0.6806\n",
            "Epoch 44/100\n",
            "428/428 [==============================] - 0s 820us/step - loss: 0.6174 - acc: 0.6799 - val_loss: 0.6060 - val_acc: 0.6806\n",
            "Epoch 45/100\n",
            "428/428 [==============================] - 0s 841us/step - loss: 0.6180 - acc: 0.6776 - val_loss: 0.6038 - val_acc: 0.6806\n",
            "Epoch 46/100\n",
            "428/428 [==============================] - 0s 837us/step - loss: 0.6189 - acc: 0.6799 - val_loss: 0.6003 - val_acc: 0.6806\n",
            "Epoch 47/100\n",
            "428/428 [==============================] - 0s 833us/step - loss: 0.6280 - acc: 0.6822 - val_loss: 0.5995 - val_acc: 0.6944\n",
            "Epoch 48/100\n",
            "428/428 [==============================] - 0s 825us/step - loss: 0.6237 - acc: 0.6893 - val_loss: 0.6000 - val_acc: 0.6944\n",
            "Epoch 49/100\n",
            "428/428 [==============================] - 0s 826us/step - loss: 0.6401 - acc: 0.6729 - val_loss: 0.6020 - val_acc: 0.6944\n",
            "Epoch 50/100\n",
            "428/428 [==============================] - 0s 825us/step - loss: 0.6207 - acc: 0.6776 - val_loss: 0.6011 - val_acc: 0.7083\n",
            "Epoch 51/100\n",
            "428/428 [==============================] - 0s 829us/step - loss: 0.6527 - acc: 0.6682 - val_loss: 0.6186 - val_acc: 0.6806\n",
            "Epoch 52/100\n",
            "428/428 [==============================] - 0s 825us/step - loss: 0.6457 - acc: 0.6776 - val_loss: 0.6327 - val_acc: 0.6667\n",
            "Epoch 53/100\n",
            "428/428 [==============================] - 0s 834us/step - loss: 0.6306 - acc: 0.6799 - val_loss: 0.6216 - val_acc: 0.6806\n",
            "Epoch 54/100\n",
            "428/428 [==============================] - 0s 859us/step - loss: 0.6433 - acc: 0.6706 - val_loss: 0.6144 - val_acc: 0.6806\n",
            "Epoch 55/100\n",
            "428/428 [==============================] - 0s 840us/step - loss: 0.6158 - acc: 0.6869 - val_loss: 0.6104 - val_acc: 0.6806\n",
            "Epoch 56/100\n",
            "428/428 [==============================] - 0s 853us/step - loss: 0.6250 - acc: 0.6822 - val_loss: 0.6093 - val_acc: 0.6806\n",
            "Epoch 57/100\n",
            "428/428 [==============================] - 0s 830us/step - loss: 0.6273 - acc: 0.6776 - val_loss: 0.6102 - val_acc: 0.6806\n",
            "Epoch 58/100\n",
            "428/428 [==============================] - 0s 821us/step - loss: 0.6242 - acc: 0.6869 - val_loss: 0.6065 - val_acc: 0.6944\n",
            "Epoch 59/100\n",
            "428/428 [==============================] - 0s 838us/step - loss: 0.6306 - acc: 0.6822 - val_loss: 0.6072 - val_acc: 0.6944\n",
            "Epoch 60/100\n",
            "428/428 [==============================] - 0s 823us/step - loss: 0.6311 - acc: 0.6729 - val_loss: 0.6050 - val_acc: 0.6806\n",
            "Epoch 61/100\n",
            "428/428 [==============================] - 0s 836us/step - loss: 0.6195 - acc: 0.6752 - val_loss: 0.6071 - val_acc: 0.6806\n",
            "Epoch 62/100\n",
            "428/428 [==============================] - 0s 846us/step - loss: 0.6225 - acc: 0.6822 - val_loss: 0.6051 - val_acc: 0.6806\n",
            "Epoch 63/100\n",
            "428/428 [==============================] - 0s 828us/step - loss: 0.6298 - acc: 0.6706 - val_loss: 0.5992 - val_acc: 0.7083\n",
            "Epoch 64/100\n",
            "428/428 [==============================] - 0s 841us/step - loss: 0.6249 - acc: 0.6729 - val_loss: 0.5999 - val_acc: 0.6944\n",
            "Epoch 65/100\n",
            "428/428 [==============================] - 0s 840us/step - loss: 0.6198 - acc: 0.6846 - val_loss: 0.5963 - val_acc: 0.7083\n",
            "Epoch 66/100\n",
            "428/428 [==============================] - 0s 839us/step - loss: 0.6259 - acc: 0.6729 - val_loss: 0.5931 - val_acc: 0.7083\n",
            "Epoch 67/100\n",
            "428/428 [==============================] - 0s 833us/step - loss: 0.6256 - acc: 0.6729 - val_loss: 0.5958 - val_acc: 0.7083\n",
            "Epoch 68/100\n",
            "428/428 [==============================] - 0s 835us/step - loss: 0.6161 - acc: 0.6752 - val_loss: 0.5948 - val_acc: 0.6944\n",
            "Epoch 69/100\n",
            "428/428 [==============================] - 0s 823us/step - loss: 0.6331 - acc: 0.6799 - val_loss: 0.5937 - val_acc: 0.7083\n",
            "Epoch 70/100\n",
            "428/428 [==============================] - 0s 830us/step - loss: 0.6126 - acc: 0.6869 - val_loss: 0.5902 - val_acc: 0.7083\n",
            "Epoch 71/100\n",
            "428/428 [==============================] - 0s 840us/step - loss: 0.6307 - acc: 0.6822 - val_loss: 0.5917 - val_acc: 0.7083\n",
            "Epoch 72/100\n",
            "428/428 [==============================] - 0s 827us/step - loss: 0.6283 - acc: 0.6939 - val_loss: 0.5972 - val_acc: 0.7083\n",
            "Epoch 73/100\n",
            "428/428 [==============================] - 0s 831us/step - loss: 0.6353 - acc: 0.6776 - val_loss: 0.5992 - val_acc: 0.6944\n",
            "Epoch 74/100\n",
            "428/428 [==============================] - 0s 829us/step - loss: 0.6203 - acc: 0.6799 - val_loss: 0.6013 - val_acc: 0.6944\n",
            "Epoch 75/100\n",
            "428/428 [==============================] - 0s 831us/step - loss: 0.6234 - acc: 0.6799 - val_loss: 0.6014 - val_acc: 0.6944\n",
            "Epoch 76/100\n",
            "428/428 [==============================] - 0s 834us/step - loss: 0.6225 - acc: 0.6799 - val_loss: 0.6029 - val_acc: 0.6806\n",
            "Epoch 77/100\n",
            "428/428 [==============================] - 0s 850us/step - loss: 0.6252 - acc: 0.6776 - val_loss: 0.6047 - val_acc: 0.6806\n",
            "Epoch 78/100\n",
            "428/428 [==============================] - 0s 838us/step - loss: 0.6431 - acc: 0.6776 - val_loss: 0.6042 - val_acc: 0.6944\n",
            "Epoch 79/100\n",
            "428/428 [==============================] - 0s 833us/step - loss: 0.6259 - acc: 0.6636 - val_loss: 0.6032 - val_acc: 0.6806\n",
            "Epoch 80/100\n",
            "428/428 [==============================] - 0s 837us/step - loss: 0.6237 - acc: 0.6799 - val_loss: 0.6014 - val_acc: 0.6806\n",
            "Epoch 81/100\n",
            "428/428 [==============================] - 0s 839us/step - loss: 0.6271 - acc: 0.6729 - val_loss: 0.6057 - val_acc: 0.6806\n",
            "Epoch 82/100\n",
            "428/428 [==============================] - 0s 830us/step - loss: 0.6294 - acc: 0.6776 - val_loss: 0.5999 - val_acc: 0.6944\n",
            "Epoch 83/100\n",
            "428/428 [==============================] - 0s 833us/step - loss: 0.6373 - acc: 0.6776 - val_loss: 0.5967 - val_acc: 0.7083\n",
            "Epoch 84/100\n",
            "428/428 [==============================] - 0s 837us/step - loss: 0.6113 - acc: 0.6916 - val_loss: 0.5969 - val_acc: 0.7083\n",
            "Epoch 85/100\n",
            "428/428 [==============================] - 0s 833us/step - loss: 0.6232 - acc: 0.6822 - val_loss: 0.6040 - val_acc: 0.7083\n",
            "Epoch 86/100\n",
            "428/428 [==============================] - 0s 834us/step - loss: 0.6198 - acc: 0.6822 - val_loss: 0.6098 - val_acc: 0.7083\n",
            "Epoch 87/100\n",
            "428/428 [==============================] - 0s 841us/step - loss: 0.6241 - acc: 0.6799 - val_loss: 0.6016 - val_acc: 0.6944\n",
            "Epoch 88/100\n",
            "428/428 [==============================] - 0s 834us/step - loss: 0.6214 - acc: 0.6822 - val_loss: 0.5989 - val_acc: 0.6944\n",
            "Epoch 89/100\n",
            "428/428 [==============================] - 0s 835us/step - loss: 0.6290 - acc: 0.6752 - val_loss: 0.6019 - val_acc: 0.6944\n",
            "Epoch 90/100\n",
            "428/428 [==============================] - 0s 849us/step - loss: 0.6215 - acc: 0.6799 - val_loss: 0.6015 - val_acc: 0.6944\n",
            "Epoch 91/100\n",
            "428/428 [==============================] - 0s 846us/step - loss: 0.6468 - acc: 0.6729 - val_loss: 0.5981 - val_acc: 0.7083\n",
            "Epoch 92/100\n",
            "428/428 [==============================] - 0s 839us/step - loss: 0.6301 - acc: 0.6706 - val_loss: 0.5976 - val_acc: 0.7083\n",
            "Epoch 93/100\n",
            "428/428 [==============================] - 0s 846us/step - loss: 0.6335 - acc: 0.6682 - val_loss: 0.5982 - val_acc: 0.6944\n",
            "Epoch 94/100\n",
            "428/428 [==============================] - 0s 851us/step - loss: 0.6315 - acc: 0.6752 - val_loss: 0.5977 - val_acc: 0.6944\n",
            "Epoch 95/100\n",
            "428/428 [==============================] - 0s 843us/step - loss: 0.6253 - acc: 0.6776 - val_loss: 0.5987 - val_acc: 0.6944\n",
            "Epoch 96/100\n",
            "428/428 [==============================] - 0s 840us/step - loss: 0.6316 - acc: 0.6682 - val_loss: 0.6032 - val_acc: 0.6806\n",
            "Epoch 97/100\n",
            "428/428 [==============================] - 0s 837us/step - loss: 0.6232 - acc: 0.6799 - val_loss: 0.6070 - val_acc: 0.6806\n",
            "Epoch 98/100\n",
            "428/428 [==============================] - 0s 837us/step - loss: 0.6324 - acc: 0.6822 - val_loss: 0.6037 - val_acc: 0.6806\n",
            "Epoch 99/100\n",
            "428/428 [==============================] - 0s 836us/step - loss: 0.6204 - acc: 0.6799 - val_loss: 0.6028 - val_acc: 0.6806\n",
            "Epoch 100/100\n",
            "428/428 [==============================] - 0s 835us/step - loss: 0.6178 - acc: 0.6822 - val_loss: 0.6015 - val_acc: 0.6806\n",
            "[[ 0 23]\n",
            " [ 0 49]]\n",
            "Accuracy :  0.6805555555555556\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        23\n",
            "           1       0.68      1.00      0.81        49\n",
            "\n",
            "    accuracy                           0.68        72\n",
            "   macro avg       0.34      0.50      0.40        72\n",
            "weighted avg       0.46      0.68      0.55        72\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "model_6 (Model)              (None, 2)                 9148782   \n",
            "=================================================================\n",
            "Total params: 9,148,782\n",
            "Trainable params: 8,386\n",
            "Non-trainable params: 9,140,396\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 429 samples, validate on 71 samples\n",
            "Epoch 1/100\n",
            "429/429 [==============================] - 3s 7ms/step - loss: 0.6221 - acc: 0.6830 - val_loss: 0.6270 - val_acc: 0.6761\n",
            "Epoch 2/100\n",
            "429/429 [==============================] - 0s 821us/step - loss: 0.6054 - acc: 0.6853 - val_loss: 0.6293 - val_acc: 0.6761\n",
            "Epoch 3/100\n",
            "429/429 [==============================] - 0s 821us/step - loss: 0.6533 - acc: 0.6713 - val_loss: 0.6318 - val_acc: 0.6761\n",
            "Epoch 4/100\n",
            "429/429 [==============================] - 0s 843us/step - loss: 0.6249 - acc: 0.6807 - val_loss: 0.6344 - val_acc: 0.6761\n",
            "Epoch 5/100\n",
            "429/429 [==============================] - 0s 824us/step - loss: 0.6224 - acc: 0.6783 - val_loss: 0.6374 - val_acc: 0.6761\n",
            "Epoch 6/100\n",
            "429/429 [==============================] - 0s 816us/step - loss: 0.6323 - acc: 0.6783 - val_loss: 0.6520 - val_acc: 0.6761\n",
            "Epoch 7/100\n",
            "429/429 [==============================] - 0s 829us/step - loss: 0.6295 - acc: 0.6760 - val_loss: 0.6548 - val_acc: 0.6761\n",
            "Epoch 8/100\n",
            "429/429 [==============================] - 0s 823us/step - loss: 0.6137 - acc: 0.6760 - val_loss: 0.6622 - val_acc: 0.6761\n",
            "Epoch 9/100\n",
            "429/429 [==============================] - 0s 821us/step - loss: 0.6142 - acc: 0.6853 - val_loss: 0.6759 - val_acc: 0.6761\n",
            "Epoch 10/100\n",
            "429/429 [==============================] - 0s 821us/step - loss: 0.6326 - acc: 0.6900 - val_loss: 0.6762 - val_acc: 0.6761\n",
            "Epoch 11/100\n",
            "429/429 [==============================] - 0s 831us/step - loss: 0.6364 - acc: 0.6783 - val_loss: 0.6769 - val_acc: 0.6761\n",
            "Epoch 12/100\n",
            "429/429 [==============================] - 0s 820us/step - loss: 0.6157 - acc: 0.6830 - val_loss: 0.6814 - val_acc: 0.6761\n",
            "Epoch 13/100\n",
            "429/429 [==============================] - 0s 822us/step - loss: 0.6273 - acc: 0.6946 - val_loss: 0.6739 - val_acc: 0.6761\n",
            "Epoch 14/100\n",
            "429/429 [==============================] - 0s 827us/step - loss: 0.6244 - acc: 0.6853 - val_loss: 0.6654 - val_acc: 0.6761\n",
            "Epoch 15/100\n",
            "429/429 [==============================] - 0s 829us/step - loss: 0.6121 - acc: 0.6923 - val_loss: 0.6715 - val_acc: 0.6761\n",
            "Epoch 16/100\n",
            "429/429 [==============================] - 0s 837us/step - loss: 0.6711 - acc: 0.6783 - val_loss: 0.6654 - val_acc: 0.6761\n",
            "Epoch 17/100\n",
            "429/429 [==============================] - 0s 826us/step - loss: 0.6294 - acc: 0.6830 - val_loss: 0.6621 - val_acc: 0.6761\n",
            "Epoch 18/100\n",
            "429/429 [==============================] - 0s 826us/step - loss: 0.6354 - acc: 0.6760 - val_loss: 0.6530 - val_acc: 0.6761\n",
            "Epoch 19/100\n",
            "429/429 [==============================] - 0s 828us/step - loss: 0.6188 - acc: 0.6807 - val_loss: 0.6579 - val_acc: 0.6761\n",
            "Epoch 20/100\n",
            "429/429 [==============================] - 0s 832us/step - loss: 0.6215 - acc: 0.6807 - val_loss: 0.6566 - val_acc: 0.6761\n",
            "Epoch 21/100\n",
            "429/429 [==============================] - 0s 834us/step - loss: 0.6188 - acc: 0.6853 - val_loss: 0.6521 - val_acc: 0.6761\n",
            "Epoch 22/100\n",
            "429/429 [==============================] - 0s 833us/step - loss: 0.6265 - acc: 0.6737 - val_loss: 0.6550 - val_acc: 0.6761\n",
            "Epoch 23/100\n",
            "429/429 [==============================] - 0s 819us/step - loss: 0.6319 - acc: 0.6876 - val_loss: 0.6515 - val_acc: 0.6761\n",
            "Epoch 24/100\n",
            "429/429 [==============================] - 0s 827us/step - loss: 0.6329 - acc: 0.6830 - val_loss: 0.6501 - val_acc: 0.6761\n",
            "Epoch 25/100\n",
            "429/429 [==============================] - 0s 831us/step - loss: 0.6508 - acc: 0.6760 - val_loss: 0.6598 - val_acc: 0.6761\n",
            "Epoch 26/100\n",
            "429/429 [==============================] - 0s 834us/step - loss: 0.6189 - acc: 0.6830 - val_loss: 0.6516 - val_acc: 0.6761\n",
            "Epoch 27/100\n",
            "429/429 [==============================] - 0s 831us/step - loss: 0.6231 - acc: 0.6783 - val_loss: 0.6514 - val_acc: 0.6761\n",
            "Epoch 28/100\n",
            "429/429 [==============================] - 0s 835us/step - loss: 0.6231 - acc: 0.6900 - val_loss: 0.6439 - val_acc: 0.6761\n",
            "Epoch 29/100\n",
            "429/429 [==============================] - 0s 819us/step - loss: 0.6269 - acc: 0.6783 - val_loss: 0.6548 - val_acc: 0.6761\n",
            "Epoch 30/100\n",
            "429/429 [==============================] - 0s 813us/step - loss: 0.6371 - acc: 0.6760 - val_loss: 0.6530 - val_acc: 0.6761\n",
            "Epoch 31/100\n",
            "429/429 [==============================] - 0s 828us/step - loss: 0.6291 - acc: 0.6783 - val_loss: 0.6440 - val_acc: 0.6761\n",
            "Epoch 32/100\n",
            "429/429 [==============================] - 0s 832us/step - loss: 0.6199 - acc: 0.6783 - val_loss: 0.6374 - val_acc: 0.6761\n",
            "Epoch 33/100\n",
            "429/429 [==============================] - 0s 826us/step - loss: 0.6243 - acc: 0.6807 - val_loss: 0.6383 - val_acc: 0.6761\n",
            "Epoch 34/100\n",
            "429/429 [==============================] - 0s 830us/step - loss: 0.6198 - acc: 0.6807 - val_loss: 0.6438 - val_acc: 0.6761\n",
            "Epoch 35/100\n",
            "429/429 [==============================] - 0s 822us/step - loss: 0.6240 - acc: 0.6783 - val_loss: 0.6440 - val_acc: 0.6761\n",
            "Epoch 36/100\n",
            "429/429 [==============================] - 0s 827us/step - loss: 0.6170 - acc: 0.6830 - val_loss: 0.6363 - val_acc: 0.6761\n",
            "Epoch 37/100\n",
            "429/429 [==============================] - 0s 821us/step - loss: 0.6356 - acc: 0.6783 - val_loss: 0.6391 - val_acc: 0.6761\n",
            "Epoch 38/100\n",
            "429/429 [==============================] - 0s 831us/step - loss: 0.6221 - acc: 0.6807 - val_loss: 0.6343 - val_acc: 0.6761\n",
            "Epoch 39/100\n",
            "429/429 [==============================] - 0s 840us/step - loss: 0.6410 - acc: 0.6760 - val_loss: 0.6313 - val_acc: 0.6761\n",
            "Epoch 40/100\n",
            "429/429 [==============================] - 0s 829us/step - loss: 0.6234 - acc: 0.6783 - val_loss: 0.6345 - val_acc: 0.6761\n",
            "Epoch 41/100\n",
            "429/429 [==============================] - 0s 827us/step - loss: 0.6098 - acc: 0.6807 - val_loss: 0.6361 - val_acc: 0.6761\n",
            "Epoch 42/100\n",
            "429/429 [==============================] - 0s 824us/step - loss: 0.6405 - acc: 0.6690 - val_loss: 0.6376 - val_acc: 0.6761\n",
            "Epoch 43/100\n",
            "429/429 [==============================] - 0s 825us/step - loss: 0.6209 - acc: 0.6853 - val_loss: 0.6406 - val_acc: 0.6761\n",
            "Epoch 44/100\n",
            "429/429 [==============================] - 0s 832us/step - loss: 0.6186 - acc: 0.6853 - val_loss: 0.6380 - val_acc: 0.6761\n",
            "Epoch 45/100\n",
            "429/429 [==============================] - 0s 836us/step - loss: 0.6087 - acc: 0.6853 - val_loss: 0.6378 - val_acc: 0.6761\n",
            "Epoch 46/100\n",
            "429/429 [==============================] - 0s 831us/step - loss: 0.6266 - acc: 0.6760 - val_loss: 0.6342 - val_acc: 0.6761\n",
            "Epoch 47/100\n",
            "429/429 [==============================] - 0s 833us/step - loss: 0.6245 - acc: 0.6807 - val_loss: 0.6340 - val_acc: 0.6761\n",
            "Epoch 48/100\n",
            "429/429 [==============================] - 0s 829us/step - loss: 0.6276 - acc: 0.6737 - val_loss: 0.6398 - val_acc: 0.6761\n",
            "Epoch 49/100\n",
            "429/429 [==============================] - 0s 824us/step - loss: 0.6199 - acc: 0.6713 - val_loss: 0.6479 - val_acc: 0.6761\n",
            "Epoch 50/100\n",
            "429/429 [==============================] - 0s 829us/step - loss: 0.6220 - acc: 0.6783 - val_loss: 0.6484 - val_acc: 0.6761\n",
            "Epoch 51/100\n",
            "429/429 [==============================] - 0s 823us/step - loss: 0.6188 - acc: 0.6923 - val_loss: 0.6436 - val_acc: 0.6761\n",
            "Epoch 52/100\n",
            "429/429 [==============================] - 0s 824us/step - loss: 0.6281 - acc: 0.6737 - val_loss: 0.6416 - val_acc: 0.6761\n",
            "Epoch 53/100\n",
            "429/429 [==============================] - 0s 828us/step - loss: 0.6251 - acc: 0.6760 - val_loss: 0.6423 - val_acc: 0.6761\n",
            "Epoch 54/100\n",
            "429/429 [==============================] - 0s 840us/step - loss: 0.6236 - acc: 0.6760 - val_loss: 0.6424 - val_acc: 0.6761\n",
            "Epoch 55/100\n",
            "429/429 [==============================] - 0s 818us/step - loss: 0.6198 - acc: 0.6830 - val_loss: 0.6422 - val_acc: 0.6761\n",
            "Epoch 56/100\n",
            "429/429 [==============================] - 0s 829us/step - loss: 0.6369 - acc: 0.6737 - val_loss: 0.6482 - val_acc: 0.6761\n",
            "Epoch 57/100\n",
            "429/429 [==============================] - 0s 831us/step - loss: 0.6217 - acc: 0.6760 - val_loss: 0.6478 - val_acc: 0.6761\n",
            "Epoch 58/100\n",
            "429/429 [==============================] - 0s 831us/step - loss: 0.6227 - acc: 0.6783 - val_loss: 0.6433 - val_acc: 0.6761\n",
            "Epoch 59/100\n",
            "429/429 [==============================] - 0s 846us/step - loss: 0.6137 - acc: 0.6807 - val_loss: 0.6478 - val_acc: 0.6761\n",
            "Epoch 60/100\n",
            "429/429 [==============================] - 0s 836us/step - loss: 0.6123 - acc: 0.6853 - val_loss: 0.6479 - val_acc: 0.6761\n",
            "Epoch 61/100\n",
            "429/429 [==============================] - 0s 830us/step - loss: 0.6231 - acc: 0.6760 - val_loss: 0.6559 - val_acc: 0.6761\n",
            "Epoch 62/100\n",
            "429/429 [==============================] - 0s 841us/step - loss: 0.6270 - acc: 0.6737 - val_loss: 0.6584 - val_acc: 0.6761\n",
            "Epoch 63/100\n",
            "429/429 [==============================] - 0s 848us/step - loss: 0.6316 - acc: 0.6807 - val_loss: 0.6509 - val_acc: 0.6761\n",
            "Epoch 64/100\n",
            "429/429 [==============================] - 0s 834us/step - loss: 0.6250 - acc: 0.6737 - val_loss: 0.6518 - val_acc: 0.6761\n",
            "Epoch 65/100\n",
            "429/429 [==============================] - 0s 825us/step - loss: 0.6298 - acc: 0.6783 - val_loss: 0.6533 - val_acc: 0.6761\n",
            "Epoch 66/100\n",
            "429/429 [==============================] - 0s 833us/step - loss: 0.6211 - acc: 0.6807 - val_loss: 0.6554 - val_acc: 0.6761\n",
            "Epoch 67/100\n",
            "429/429 [==============================] - 0s 831us/step - loss: 0.6190 - acc: 0.6807 - val_loss: 0.6592 - val_acc: 0.6761\n",
            "Epoch 68/100\n",
            "429/429 [==============================] - 0s 837us/step - loss: 0.6112 - acc: 0.6923 - val_loss: 0.6696 - val_acc: 0.6761\n",
            "Epoch 69/100\n",
            "429/429 [==============================] - 0s 825us/step - loss: 0.6173 - acc: 0.6853 - val_loss: 0.6545 - val_acc: 0.6761\n",
            "Epoch 70/100\n",
            "429/429 [==============================] - 0s 837us/step - loss: 0.6314 - acc: 0.6643 - val_loss: 0.6574 - val_acc: 0.6761\n",
            "Epoch 71/100\n",
            "429/429 [==============================] - 0s 835us/step - loss: 0.6393 - acc: 0.6760 - val_loss: 0.6535 - val_acc: 0.6761\n",
            "Epoch 72/100\n",
            "429/429 [==============================] - 0s 832us/step - loss: 0.6140 - acc: 0.6830 - val_loss: 0.6467 - val_acc: 0.6761\n",
            "Epoch 73/100\n",
            "429/429 [==============================] - 0s 823us/step - loss: 0.6189 - acc: 0.6876 - val_loss: 0.6450 - val_acc: 0.6761\n",
            "Epoch 74/100\n",
            "429/429 [==============================] - 0s 852us/step - loss: 0.6146 - acc: 0.6900 - val_loss: 0.6440 - val_acc: 0.6761\n",
            "Epoch 75/100\n",
            "429/429 [==============================] - 0s 838us/step - loss: 0.6185 - acc: 0.6853 - val_loss: 0.6410 - val_acc: 0.6761\n",
            "Epoch 76/100\n",
            "429/429 [==============================] - 0s 832us/step - loss: 0.6092 - acc: 0.7063 - val_loss: 0.6370 - val_acc: 0.6761\n",
            "Epoch 77/100\n",
            "429/429 [==============================] - 0s 830us/step - loss: 0.6261 - acc: 0.6853 - val_loss: 0.6365 - val_acc: 0.6761\n",
            "Epoch 78/100\n",
            "429/429 [==============================] - 0s 839us/step - loss: 0.6308 - acc: 0.6713 - val_loss: 0.6415 - val_acc: 0.6761\n",
            "Epoch 79/100\n",
            "429/429 [==============================] - 0s 848us/step - loss: 0.6187 - acc: 0.6783 - val_loss: 0.6472 - val_acc: 0.6761\n",
            "Epoch 80/100\n",
            "429/429 [==============================] - 0s 829us/step - loss: 0.6322 - acc: 0.6807 - val_loss: 0.6515 - val_acc: 0.6761\n",
            "Epoch 81/100\n",
            "429/429 [==============================] - 0s 826us/step - loss: 0.6108 - acc: 0.6830 - val_loss: 0.6585 - val_acc: 0.6761\n",
            "Epoch 82/100\n",
            "429/429 [==============================] - 0s 843us/step - loss: 0.6171 - acc: 0.6783 - val_loss: 0.6616 - val_acc: 0.6761\n",
            "Epoch 83/100\n",
            "429/429 [==============================] - 0s 830us/step - loss: 0.6230 - acc: 0.6783 - val_loss: 0.6726 - val_acc: 0.6761\n",
            "Epoch 84/100\n",
            "429/429 [==============================] - 0s 845us/step - loss: 0.6367 - acc: 0.6783 - val_loss: 0.6720 - val_acc: 0.6761\n",
            "Epoch 85/100\n",
            "429/429 [==============================] - 0s 847us/step - loss: 0.6553 - acc: 0.6783 - val_loss: 0.6562 - val_acc: 0.6761\n",
            "Epoch 86/100\n",
            "429/429 [==============================] - 0s 828us/step - loss: 0.6330 - acc: 0.6760 - val_loss: 0.6416 - val_acc: 0.6761\n",
            "Epoch 87/100\n",
            "429/429 [==============================] - 0s 836us/step - loss: 0.6152 - acc: 0.6830 - val_loss: 0.6417 - val_acc: 0.6761\n",
            "Epoch 88/100\n",
            "429/429 [==============================] - 0s 834us/step - loss: 0.6060 - acc: 0.6876 - val_loss: 0.6451 - val_acc: 0.6761\n",
            "Epoch 89/100\n",
            "429/429 [==============================] - 0s 840us/step - loss: 0.6160 - acc: 0.6830 - val_loss: 0.6414 - val_acc: 0.6761\n",
            "Epoch 90/100\n",
            "429/429 [==============================] - 0s 833us/step - loss: 0.6356 - acc: 0.6690 - val_loss: 0.6497 - val_acc: 0.6761\n",
            "Epoch 91/100\n",
            "429/429 [==============================] - 0s 830us/step - loss: 0.6308 - acc: 0.6783 - val_loss: 0.6449 - val_acc: 0.6761\n",
            "Epoch 92/100\n",
            "429/429 [==============================] - 0s 833us/step - loss: 0.6281 - acc: 0.6760 - val_loss: 0.6415 - val_acc: 0.6761\n",
            "Epoch 93/100\n",
            "429/429 [==============================] - 0s 833us/step - loss: 0.6204 - acc: 0.6783 - val_loss: 0.6412 - val_acc: 0.6761\n",
            "Epoch 94/100\n",
            "429/429 [==============================] - 0s 846us/step - loss: 0.6179 - acc: 0.6783 - val_loss: 0.6429 - val_acc: 0.6761\n",
            "Epoch 95/100\n",
            "429/429 [==============================] - 0s 843us/step - loss: 0.6252 - acc: 0.6876 - val_loss: 0.6365 - val_acc: 0.6761\n",
            "Epoch 96/100\n",
            "429/429 [==============================] - 0s 837us/step - loss: 0.6231 - acc: 0.6713 - val_loss: 0.6431 - val_acc: 0.6761\n",
            "Epoch 97/100\n",
            "429/429 [==============================] - 0s 833us/step - loss: 0.6258 - acc: 0.6760 - val_loss: 0.6464 - val_acc: 0.6761\n",
            "Epoch 98/100\n",
            "429/429 [==============================] - 0s 839us/step - loss: 0.6236 - acc: 0.6830 - val_loss: 0.6470 - val_acc: 0.6761\n",
            "Epoch 99/100\n",
            "429/429 [==============================] - 0s 829us/step - loss: 0.6041 - acc: 0.6900 - val_loss: 0.6478 - val_acc: 0.6761\n",
            "Epoch 100/100\n",
            "429/429 [==============================] - 0s 832us/step - loss: 0.6184 - acc: 0.6993 - val_loss: 0.6413 - val_acc: 0.6761\n",
            "[[ 0 23]\n",
            " [ 0 48]]\n",
            "Accuracy :  0.676056338028169\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        23\n",
            "           1       0.68      1.00      0.81        48\n",
            "\n",
            "    accuracy                           0.68        71\n",
            "   macro avg       0.34      0.50      0.40        71\n",
            "weighted avg       0.46      0.68      0.55        71\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "model_6 (Model)              (None, 2)                 9148782   \n",
            "=================================================================\n",
            "Total params: 9,148,782\n",
            "Trainable params: 8,386\n",
            "Non-trainable params: 9,140,396\n",
            "_________________________________________________________________\n",
            "Train on 429 samples, validate on 71 samples\n",
            "Epoch 1/100\n",
            "429/429 [==============================] - 3s 8ms/step - loss: 0.6233 - acc: 0.6760 - val_loss: 0.6148 - val_acc: 0.6761\n",
            "Epoch 2/100\n",
            "429/429 [==============================] - 0s 812us/step - loss: 0.6301 - acc: 0.6830 - val_loss: 0.6160 - val_acc: 0.6761\n",
            "Epoch 3/100\n",
            "429/429 [==============================] - 0s 821us/step - loss: 0.6327 - acc: 0.6853 - val_loss: 0.6148 - val_acc: 0.6761\n",
            "Epoch 4/100\n",
            "429/429 [==============================] - 0s 822us/step - loss: 0.6112 - acc: 0.6783 - val_loss: 0.6166 - val_acc: 0.6761\n",
            "Epoch 5/100\n",
            "429/429 [==============================] - 0s 818us/step - loss: 0.6466 - acc: 0.6760 - val_loss: 0.6169 - val_acc: 0.6761\n",
            "Epoch 6/100\n",
            "429/429 [==============================] - 0s 822us/step - loss: 0.6273 - acc: 0.6783 - val_loss: 0.6179 - val_acc: 0.6761\n",
            "Epoch 7/100\n",
            "429/429 [==============================] - 0s 810us/step - loss: 0.6281 - acc: 0.6900 - val_loss: 0.6191 - val_acc: 0.6761\n",
            "Epoch 8/100\n",
            "429/429 [==============================] - 0s 813us/step - loss: 0.6167 - acc: 0.6900 - val_loss: 0.6220 - val_acc: 0.6761\n",
            "Epoch 9/100\n",
            "429/429 [==============================] - 0s 840us/step - loss: 0.6225 - acc: 0.6807 - val_loss: 0.6255 - val_acc: 0.6761\n",
            "Epoch 10/100\n",
            "429/429 [==============================] - 0s 827us/step - loss: 0.6375 - acc: 0.6760 - val_loss: 0.6219 - val_acc: 0.6761\n",
            "Epoch 11/100\n",
            "429/429 [==============================] - 0s 833us/step - loss: 0.6198 - acc: 0.6807 - val_loss: 0.6199 - val_acc: 0.6761\n",
            "Epoch 12/100\n",
            "429/429 [==============================] - 0s 824us/step - loss: 0.6198 - acc: 0.6946 - val_loss: 0.6185 - val_acc: 0.6761\n",
            "Epoch 13/100\n",
            "429/429 [==============================] - 0s 840us/step - loss: 0.6117 - acc: 0.6946 - val_loss: 0.6156 - val_acc: 0.6761\n",
            "Epoch 14/100\n",
            "429/429 [==============================] - 0s 847us/step - loss: 0.6268 - acc: 0.6760 - val_loss: 0.6181 - val_acc: 0.6761\n",
            "Epoch 15/100\n",
            "429/429 [==============================] - 0s 846us/step - loss: 0.6295 - acc: 0.6830 - val_loss: 0.6185 - val_acc: 0.6761\n",
            "Epoch 16/100\n",
            "429/429 [==============================] - 0s 834us/step - loss: 0.6715 - acc: 0.6876 - val_loss: 0.6168 - val_acc: 0.6761\n",
            "Epoch 17/100\n",
            "429/429 [==============================] - 0s 851us/step - loss: 0.6213 - acc: 0.6900 - val_loss: 0.6140 - val_acc: 0.6761\n",
            "Epoch 18/100\n",
            "429/429 [==============================] - 0s 840us/step - loss: 0.6196 - acc: 0.6830 - val_loss: 0.6154 - val_acc: 0.6761\n",
            "Epoch 19/100\n",
            "429/429 [==============================] - 0s 849us/step - loss: 0.6165 - acc: 0.6900 - val_loss: 0.6179 - val_acc: 0.6761\n",
            "Epoch 20/100\n",
            "429/429 [==============================] - 0s 847us/step - loss: 0.6050 - acc: 0.6853 - val_loss: 0.6199 - val_acc: 0.6761\n",
            "Epoch 21/100\n",
            "429/429 [==============================] - 0s 834us/step - loss: 0.6188 - acc: 0.6737 - val_loss: 0.6228 - val_acc: 0.6761\n",
            "Epoch 22/100\n",
            "429/429 [==============================] - 0s 831us/step - loss: 0.6516 - acc: 0.6783 - val_loss: 0.6273 - val_acc: 0.6761\n",
            "Epoch 23/100\n",
            "429/429 [==============================] - 0s 847us/step - loss: 0.6246 - acc: 0.6783 - val_loss: 0.6311 - val_acc: 0.6761\n",
            "Epoch 24/100\n",
            "429/429 [==============================] - 0s 834us/step - loss: 0.6366 - acc: 0.6807 - val_loss: 0.6315 - val_acc: 0.6761\n",
            "Epoch 25/100\n",
            "429/429 [==============================] - 0s 823us/step - loss: 0.6154 - acc: 0.6807 - val_loss: 0.6307 - val_acc: 0.6761\n",
            "Epoch 26/100\n",
            "429/429 [==============================] - 0s 846us/step - loss: 0.6374 - acc: 0.6737 - val_loss: 0.6284 - val_acc: 0.6761\n",
            "Epoch 27/100\n",
            "429/429 [==============================] - 0s 826us/step - loss: 0.6226 - acc: 0.6876 - val_loss: 0.6254 - val_acc: 0.6761\n",
            "Epoch 28/100\n",
            "429/429 [==============================] - 0s 835us/step - loss: 0.6426 - acc: 0.6876 - val_loss: 0.6226 - val_acc: 0.6761\n",
            "Epoch 29/100\n",
            "429/429 [==============================] - 0s 839us/step - loss: 0.6250 - acc: 0.6807 - val_loss: 0.6241 - val_acc: 0.6761\n",
            "Epoch 30/100\n",
            "429/429 [==============================] - 0s 837us/step - loss: 0.6232 - acc: 0.6876 - val_loss: 0.6229 - val_acc: 0.6761\n",
            "Epoch 31/100\n",
            "429/429 [==============================] - 0s 832us/step - loss: 0.6274 - acc: 0.6783 - val_loss: 0.6247 - val_acc: 0.6761\n",
            "Epoch 32/100\n",
            "429/429 [==============================] - 0s 848us/step - loss: 0.6103 - acc: 0.6900 - val_loss: 0.6242 - val_acc: 0.6761\n",
            "Epoch 33/100\n",
            "429/429 [==============================] - 0s 825us/step - loss: 0.6222 - acc: 0.6737 - val_loss: 0.6273 - val_acc: 0.6761\n",
            "Epoch 34/100\n",
            "429/429 [==============================] - 0s 830us/step - loss: 0.6419 - acc: 0.6737 - val_loss: 0.6263 - val_acc: 0.6761\n",
            "Epoch 35/100\n",
            "429/429 [==============================] - 0s 848us/step - loss: 0.6109 - acc: 0.6853 - val_loss: 0.6264 - val_acc: 0.6761\n",
            "Epoch 36/100\n",
            "429/429 [==============================] - 0s 834us/step - loss: 0.6141 - acc: 0.6923 - val_loss: 0.6249 - val_acc: 0.6761\n",
            "Epoch 37/100\n",
            "429/429 [==============================] - 0s 834us/step - loss: 0.6396 - acc: 0.6830 - val_loss: 0.6287 - val_acc: 0.6761\n",
            "Epoch 38/100\n",
            "429/429 [==============================] - 0s 839us/step - loss: 0.6082 - acc: 0.6970 - val_loss: 0.6282 - val_acc: 0.6761\n",
            "Epoch 39/100\n",
            "429/429 [==============================] - 0s 849us/step - loss: 0.6126 - acc: 0.6830 - val_loss: 0.6268 - val_acc: 0.6761\n",
            "Epoch 40/100\n",
            "429/429 [==============================] - 0s 836us/step - loss: 0.6151 - acc: 0.6853 - val_loss: 0.6255 - val_acc: 0.6761\n",
            "Epoch 41/100\n",
            "429/429 [==============================] - 0s 847us/step - loss: 0.6207 - acc: 0.6760 - val_loss: 0.6248 - val_acc: 0.6761\n",
            "Epoch 42/100\n",
            "429/429 [==============================] - 0s 842us/step - loss: 0.6229 - acc: 0.6853 - val_loss: 0.6215 - val_acc: 0.6761\n",
            "Epoch 43/100\n",
            "429/429 [==============================] - 0s 827us/step - loss: 0.6166 - acc: 0.6830 - val_loss: 0.6193 - val_acc: 0.6761\n",
            "Epoch 44/100\n",
            "429/429 [==============================] - 0s 819us/step - loss: 0.6281 - acc: 0.6853 - val_loss: 0.6184 - val_acc: 0.6761\n",
            "Epoch 45/100\n",
            "429/429 [==============================] - 0s 829us/step - loss: 0.6165 - acc: 0.6876 - val_loss: 0.6174 - val_acc: 0.6761\n",
            "Epoch 46/100\n",
            "429/429 [==============================] - 0s 833us/step - loss: 0.6213 - acc: 0.6900 - val_loss: 0.6157 - val_acc: 0.6761\n",
            "Epoch 47/100\n",
            "429/429 [==============================] - 0s 829us/step - loss: 0.6333 - acc: 0.6830 - val_loss: 0.6165 - val_acc: 0.6761\n",
            "Epoch 48/100\n",
            "429/429 [==============================] - 0s 832us/step - loss: 0.6207 - acc: 0.6876 - val_loss: 0.6176 - val_acc: 0.6761\n",
            "Epoch 49/100\n",
            "429/429 [==============================] - 0s 817us/step - loss: 0.6253 - acc: 0.6783 - val_loss: 0.6188 - val_acc: 0.6761\n",
            "Epoch 50/100\n",
            "429/429 [==============================] - 0s 833us/step - loss: 0.6148 - acc: 0.6853 - val_loss: 0.6186 - val_acc: 0.6761\n",
            "Epoch 51/100\n",
            "429/429 [==============================] - 0s 831us/step - loss: 0.6166 - acc: 0.6876 - val_loss: 0.6168 - val_acc: 0.6761\n",
            "Epoch 52/100\n",
            "429/429 [==============================] - 0s 823us/step - loss: 0.6224 - acc: 0.6783 - val_loss: 0.6161 - val_acc: 0.6761\n",
            "Epoch 53/100\n",
            "429/429 [==============================] - 0s 828us/step - loss: 0.6198 - acc: 0.6783 - val_loss: 0.6164 - val_acc: 0.6761\n",
            "Epoch 54/100\n",
            "429/429 [==============================] - 0s 831us/step - loss: 0.6231 - acc: 0.6760 - val_loss: 0.6153 - val_acc: 0.6761\n",
            "Epoch 55/100\n",
            "429/429 [==============================] - 0s 836us/step - loss: 0.6335 - acc: 0.6783 - val_loss: 0.6150 - val_acc: 0.6761\n",
            "Epoch 56/100\n",
            "429/429 [==============================] - 0s 831us/step - loss: 0.6433 - acc: 0.6620 - val_loss: 0.6173 - val_acc: 0.6761\n",
            "Epoch 57/100\n",
            "429/429 [==============================] - 0s 842us/step - loss: 0.6237 - acc: 0.6783 - val_loss: 0.6178 - val_acc: 0.6761\n",
            "Epoch 58/100\n",
            "429/429 [==============================] - 0s 822us/step - loss: 0.6261 - acc: 0.6783 - val_loss: 0.6156 - val_acc: 0.6761\n",
            "Epoch 59/100\n",
            "429/429 [==============================] - 0s 832us/step - loss: 0.6338 - acc: 0.6853 - val_loss: 0.6148 - val_acc: 0.6761\n",
            "Epoch 60/100\n",
            "429/429 [==============================] - 0s 841us/step - loss: 0.6073 - acc: 0.6876 - val_loss: 0.6156 - val_acc: 0.6761\n",
            "Epoch 61/100\n",
            "429/429 [==============================] - 0s 827us/step - loss: 0.6150 - acc: 0.7040 - val_loss: 0.6161 - val_acc: 0.6761\n",
            "Epoch 62/100\n",
            "429/429 [==============================] - 0s 831us/step - loss: 0.6219 - acc: 0.6946 - val_loss: 0.6183 - val_acc: 0.6761\n",
            "Epoch 63/100\n",
            "429/429 [==============================] - 0s 827us/step - loss: 0.6262 - acc: 0.6876 - val_loss: 0.6193 - val_acc: 0.6761\n",
            "Epoch 64/100\n",
            "429/429 [==============================] - 0s 840us/step - loss: 0.6230 - acc: 0.6830 - val_loss: 0.6200 - val_acc: 0.6761\n",
            "Epoch 65/100\n",
            "429/429 [==============================] - 0s 835us/step - loss: 0.6265 - acc: 0.6853 - val_loss: 0.6202 - val_acc: 0.6761\n",
            "Epoch 66/100\n",
            "429/429 [==============================] - 0s 836us/step - loss: 0.6222 - acc: 0.6830 - val_loss: 0.6206 - val_acc: 0.6761\n",
            "Epoch 67/100\n",
            "429/429 [==============================] - 0s 834us/step - loss: 0.6112 - acc: 0.6830 - val_loss: 0.6201 - val_acc: 0.6761\n",
            "Epoch 68/100\n",
            "429/429 [==============================] - 0s 827us/step - loss: 0.6184 - acc: 0.6783 - val_loss: 0.6196 - val_acc: 0.6761\n",
            "Epoch 69/100\n",
            "429/429 [==============================] - 0s 854us/step - loss: 0.6207 - acc: 0.6783 - val_loss: 0.6188 - val_acc: 0.6761\n",
            "Epoch 70/100\n",
            "429/429 [==============================] - 0s 833us/step - loss: 0.6165 - acc: 0.6900 - val_loss: 0.6177 - val_acc: 0.6761\n",
            "Epoch 71/100\n",
            "429/429 [==============================] - 0s 834us/step - loss: 0.6344 - acc: 0.6690 - val_loss: 0.6188 - val_acc: 0.6761\n",
            "Epoch 72/100\n",
            "429/429 [==============================] - 0s 851us/step - loss: 0.6143 - acc: 0.6900 - val_loss: 0.6203 - val_acc: 0.6761\n",
            "Epoch 73/100\n",
            "429/429 [==============================] - 0s 826us/step - loss: 0.6296 - acc: 0.6643 - val_loss: 0.6204 - val_acc: 0.6761\n",
            "Epoch 74/100\n",
            "429/429 [==============================] - 0s 833us/step - loss: 0.6236 - acc: 0.6807 - val_loss: 0.6223 - val_acc: 0.6761\n",
            "Epoch 75/100\n",
            "429/429 [==============================] - 0s 839us/step - loss: 0.6331 - acc: 0.6783 - val_loss: 0.6215 - val_acc: 0.6761\n",
            "Epoch 76/100\n",
            "429/429 [==============================] - 0s 832us/step - loss: 0.6154 - acc: 0.6876 - val_loss: 0.6195 - val_acc: 0.6761\n",
            "Epoch 77/100\n",
            "429/429 [==============================] - 0s 846us/step - loss: 0.6335 - acc: 0.6783 - val_loss: 0.6186 - val_acc: 0.6761\n",
            "Epoch 78/100\n",
            "429/429 [==============================] - 0s 838us/step - loss: 0.6425 - acc: 0.6853 - val_loss: 0.6175 - val_acc: 0.6761\n",
            "Epoch 79/100\n",
            "429/429 [==============================] - 0s 827us/step - loss: 0.6197 - acc: 0.6807 - val_loss: 0.6185 - val_acc: 0.6761\n",
            "Epoch 80/100\n",
            "429/429 [==============================] - 0s 831us/step - loss: 0.6186 - acc: 0.6830 - val_loss: 0.6192 - val_acc: 0.6761\n",
            "Epoch 81/100\n",
            "429/429 [==============================] - 0s 830us/step - loss: 0.6265 - acc: 0.6807 - val_loss: 0.6190 - val_acc: 0.6761\n",
            "Epoch 82/100\n",
            "429/429 [==============================] - 0s 836us/step - loss: 0.6235 - acc: 0.6830 - val_loss: 0.6181 - val_acc: 0.6761\n",
            "Epoch 83/100\n",
            "429/429 [==============================] - 0s 833us/step - loss: 0.6191 - acc: 0.6783 - val_loss: 0.6183 - val_acc: 0.6761\n",
            "Epoch 84/100\n",
            "429/429 [==============================] - 0s 836us/step - loss: 0.6128 - acc: 0.6876 - val_loss: 0.6182 - val_acc: 0.6761\n",
            "Epoch 85/100\n",
            "429/429 [==============================] - 0s 833us/step - loss: 0.6269 - acc: 0.6760 - val_loss: 0.6177 - val_acc: 0.6761\n",
            "Epoch 86/100\n",
            "429/429 [==============================] - 0s 835us/step - loss: 0.6240 - acc: 0.6783 - val_loss: 0.6179 - val_acc: 0.6761\n",
            "Epoch 87/100\n",
            "429/429 [==============================] - 0s 837us/step - loss: 0.6214 - acc: 0.6807 - val_loss: 0.6182 - val_acc: 0.6761\n",
            "Epoch 88/100\n",
            "429/429 [==============================] - 0s 844us/step - loss: 0.6173 - acc: 0.6783 - val_loss: 0.6181 - val_acc: 0.6761\n",
            "Epoch 89/100\n",
            "429/429 [==============================] - 0s 865us/step - loss: 0.6290 - acc: 0.6760 - val_loss: 0.6186 - val_acc: 0.6761\n",
            "Epoch 90/100\n",
            "429/429 [==============================] - 0s 844us/step - loss: 0.6540 - acc: 0.6783 - val_loss: 0.6183 - val_acc: 0.6761\n",
            "Epoch 91/100\n",
            "429/429 [==============================] - 0s 843us/step - loss: 0.6220 - acc: 0.6760 - val_loss: 0.6177 - val_acc: 0.6761\n",
            "Epoch 92/100\n",
            "429/429 [==============================] - 0s 849us/step - loss: 0.6165 - acc: 0.6830 - val_loss: 0.6182 - val_acc: 0.6761\n",
            "Epoch 93/100\n",
            "429/429 [==============================] - 0s 851us/step - loss: 0.6224 - acc: 0.6830 - val_loss: 0.6181 - val_acc: 0.6761\n",
            "Epoch 94/100\n",
            "429/429 [==============================] - 0s 856us/step - loss: 0.6233 - acc: 0.6830 - val_loss: 0.6171 - val_acc: 0.6761\n",
            "Epoch 95/100\n",
            "429/429 [==============================] - 0s 833us/step - loss: 0.6154 - acc: 0.6830 - val_loss: 0.6182 - val_acc: 0.6761\n",
            "Epoch 96/100\n",
            "429/429 [==============================] - 0s 837us/step - loss: 0.6236 - acc: 0.6760 - val_loss: 0.6181 - val_acc: 0.6761\n",
            "Epoch 97/100\n",
            "429/429 [==============================] - 0s 843us/step - loss: 0.6201 - acc: 0.6853 - val_loss: 0.6171 - val_acc: 0.6761\n",
            "Epoch 98/100\n",
            "429/429 [==============================] - 0s 838us/step - loss: 0.6214 - acc: 0.6876 - val_loss: 0.6161 - val_acc: 0.6761\n",
            "Epoch 99/100\n",
            "429/429 [==============================] - 0s 854us/step - loss: 0.6182 - acc: 0.6830 - val_loss: 0.6160 - val_acc: 0.6761\n",
            "Epoch 100/100\n",
            "429/429 [==============================] - 0s 857us/step - loss: 0.6108 - acc: 0.6923 - val_loss: 0.6164 - val_acc: 0.6761\n",
            "[[ 0 23]\n",
            " [ 0 48]]\n",
            "Accuracy :  0.676056338028169\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        23\n",
            "           1       0.68      1.00      0.81        48\n",
            "\n",
            "    accuracy                           0.68        71\n",
            "   macro avg       0.34      0.50      0.40        71\n",
            "weighted avg       0.46      0.68      0.55        71\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "model_6 (Model)              (None, 2)                 9148782   \n",
            "=================================================================\n",
            "Total params: 9,148,782\n",
            "Trainable params: 8,386\n",
            "Non-trainable params: 9,140,396\n",
            "_________________________________________________________________\n",
            "Train on 429 samples, validate on 71 samples\n",
            "Epoch 1/100\n",
            "429/429 [==============================] - 3s 8ms/step - loss: 0.6360 - acc: 0.6830 - val_loss: 0.6240 - val_acc: 0.6761\n",
            "Epoch 2/100\n",
            "429/429 [==============================] - 0s 816us/step - loss: 0.6248 - acc: 0.6760 - val_loss: 0.6255 - val_acc: 0.6761\n",
            "Epoch 3/100\n",
            "429/429 [==============================] - 0s 810us/step - loss: 0.6352 - acc: 0.6830 - val_loss: 0.6269 - val_acc: 0.6761\n",
            "Epoch 4/100\n",
            "429/429 [==============================] - 0s 833us/step - loss: 0.6358 - acc: 0.6760 - val_loss: 0.6271 - val_acc: 0.6761\n",
            "Epoch 5/100\n",
            "429/429 [==============================] - 0s 811us/step - loss: 0.6154 - acc: 0.6923 - val_loss: 0.6267 - val_acc: 0.6761\n",
            "Epoch 6/100\n",
            "429/429 [==============================] - 0s 810us/step - loss: 0.6197 - acc: 0.6830 - val_loss: 0.6230 - val_acc: 0.6761\n",
            "Epoch 7/100\n",
            "429/429 [==============================] - 0s 831us/step - loss: 0.6224 - acc: 0.6830 - val_loss: 0.6231 - val_acc: 0.6761\n",
            "Epoch 8/100\n",
            "429/429 [==============================] - 0s 817us/step - loss: 0.6290 - acc: 0.6830 - val_loss: 0.6285 - val_acc: 0.6761\n",
            "Epoch 9/100\n",
            "429/429 [==============================] - 0s 821us/step - loss: 0.6153 - acc: 0.6830 - val_loss: 0.6286 - val_acc: 0.6761\n",
            "Epoch 10/100\n",
            "429/429 [==============================] - 0s 833us/step - loss: 0.6198 - acc: 0.6853 - val_loss: 0.6292 - val_acc: 0.6761\n",
            "Epoch 11/100\n",
            "429/429 [==============================] - 0s 819us/step - loss: 0.6282 - acc: 0.6760 - val_loss: 0.6382 - val_acc: 0.6761\n",
            "Epoch 12/100\n",
            "429/429 [==============================] - 0s 815us/step - loss: 0.6206 - acc: 0.6807 - val_loss: 0.6369 - val_acc: 0.6761\n",
            "Epoch 13/100\n",
            "429/429 [==============================] - 0s 834us/step - loss: 0.6249 - acc: 0.6807 - val_loss: 0.6342 - val_acc: 0.6761\n",
            "Epoch 14/100\n",
            "429/429 [==============================] - 0s 815us/step - loss: 0.6220 - acc: 0.6760 - val_loss: 0.6399 - val_acc: 0.6761\n",
            "Epoch 15/100\n",
            "429/429 [==============================] - 0s 825us/step - loss: 0.6250 - acc: 0.6783 - val_loss: 0.6420 - val_acc: 0.6761\n",
            "Epoch 16/100\n",
            "429/429 [==============================] - 0s 833us/step - loss: 0.6115 - acc: 0.6783 - val_loss: 0.6418 - val_acc: 0.6761\n",
            "Epoch 17/100\n",
            "429/429 [==============================] - 0s 819us/step - loss: 0.6479 - acc: 0.6783 - val_loss: 0.6387 - val_acc: 0.6761\n",
            "Epoch 18/100\n",
            "429/429 [==============================] - 0s 820us/step - loss: 0.6096 - acc: 0.6900 - val_loss: 0.6353 - val_acc: 0.6761\n",
            "Epoch 19/100\n",
            "429/429 [==============================] - 0s 831us/step - loss: 0.6160 - acc: 0.6876 - val_loss: 0.6269 - val_acc: 0.6761\n",
            "Epoch 20/100\n",
            "429/429 [==============================] - 0s 827us/step - loss: 0.6315 - acc: 0.6783 - val_loss: 0.6243 - val_acc: 0.6761\n",
            "Epoch 21/100\n",
            "429/429 [==============================] - 0s 816us/step - loss: 0.6429 - acc: 0.6783 - val_loss: 0.6226 - val_acc: 0.6761\n",
            "Epoch 22/100\n",
            "429/429 [==============================] - 0s 824us/step - loss: 0.6349 - acc: 0.6713 - val_loss: 0.6221 - val_acc: 0.6761\n",
            "Epoch 23/100\n",
            "429/429 [==============================] - 0s 823us/step - loss: 0.6412 - acc: 0.6830 - val_loss: 0.6244 - val_acc: 0.6761\n",
            "Epoch 24/100\n",
            "429/429 [==============================] - 0s 822us/step - loss: 0.6094 - acc: 0.6876 - val_loss: 0.6215 - val_acc: 0.6761\n",
            "Epoch 25/100\n",
            "429/429 [==============================] - 0s 814us/step - loss: 0.6144 - acc: 0.6760 - val_loss: 0.6227 - val_acc: 0.6761\n",
            "Epoch 26/100\n",
            "429/429 [==============================] - 0s 827us/step - loss: 0.6178 - acc: 0.6830 - val_loss: 0.6237 - val_acc: 0.6761\n",
            "Epoch 27/100\n",
            "429/429 [==============================] - 0s 834us/step - loss: 0.6435 - acc: 0.6783 - val_loss: 0.6251 - val_acc: 0.6761\n",
            "Epoch 28/100\n",
            "429/429 [==============================] - 0s 827us/step - loss: 0.6142 - acc: 0.6876 - val_loss: 0.6253 - val_acc: 0.6761\n",
            "Epoch 29/100\n",
            "429/429 [==============================] - 0s 822us/step - loss: 0.6064 - acc: 0.6900 - val_loss: 0.6269 - val_acc: 0.6761\n",
            "Epoch 30/100\n",
            "429/429 [==============================] - 0s 821us/step - loss: 0.6269 - acc: 0.6760 - val_loss: 0.6274 - val_acc: 0.6761\n",
            "Epoch 31/100\n",
            "429/429 [==============================] - 0s 827us/step - loss: 0.6251 - acc: 0.6690 - val_loss: 0.6262 - val_acc: 0.6761\n",
            "Epoch 32/100\n",
            "429/429 [==============================] - 0s 824us/step - loss: 0.6435 - acc: 0.6807 - val_loss: 0.6342 - val_acc: 0.6761\n",
            "Epoch 33/100\n",
            "429/429 [==============================] - 0s 841us/step - loss: 0.6083 - acc: 0.6876 - val_loss: 0.6335 - val_acc: 0.6761\n",
            "Epoch 34/100\n",
            "429/429 [==============================] - 0s 827us/step - loss: 0.6213 - acc: 0.6783 - val_loss: 0.6330 - val_acc: 0.6761\n",
            "Epoch 35/100\n",
            "429/429 [==============================] - 0s 817us/step - loss: 0.6081 - acc: 0.6830 - val_loss: 0.6325 - val_acc: 0.6761\n",
            "Epoch 36/100\n",
            "429/429 [==============================] - 0s 830us/step - loss: 0.6156 - acc: 0.6783 - val_loss: 0.6303 - val_acc: 0.6761\n",
            "Epoch 37/100\n",
            "429/429 [==============================] - 0s 829us/step - loss: 0.6188 - acc: 0.6807 - val_loss: 0.6316 - val_acc: 0.6761\n",
            "Epoch 38/100\n",
            "429/429 [==============================] - 0s 820us/step - loss: 0.6261 - acc: 0.6807 - val_loss: 0.6291 - val_acc: 0.6761\n",
            "Epoch 39/100\n",
            "429/429 [==============================] - 0s 830us/step - loss: 0.6399 - acc: 0.6783 - val_loss: 0.6235 - val_acc: 0.6761\n",
            "Epoch 40/100\n",
            "429/429 [==============================] - 0s 822us/step - loss: 0.6422 - acc: 0.6853 - val_loss: 0.6230 - val_acc: 0.6761\n",
            "Epoch 41/100\n",
            "429/429 [==============================] - 0s 825us/step - loss: 0.6377 - acc: 0.6760 - val_loss: 0.6209 - val_acc: 0.6761\n",
            "Epoch 42/100\n",
            "429/429 [==============================] - 0s 823us/step - loss: 0.6258 - acc: 0.6830 - val_loss: 0.6208 - val_acc: 0.6761\n",
            "Epoch 43/100\n",
            "429/429 [==============================] - 0s 828us/step - loss: 0.6201 - acc: 0.6737 - val_loss: 0.6207 - val_acc: 0.6761\n",
            "Epoch 44/100\n",
            "429/429 [==============================] - 0s 829us/step - loss: 0.6287 - acc: 0.6760 - val_loss: 0.6226 - val_acc: 0.6761\n",
            "Epoch 45/100\n",
            "429/429 [==============================] - 0s 836us/step - loss: 0.6215 - acc: 0.6783 - val_loss: 0.6264 - val_acc: 0.6761\n",
            "Epoch 46/100\n",
            "429/429 [==============================] - 0s 823us/step - loss: 0.6354 - acc: 0.6807 - val_loss: 0.6229 - val_acc: 0.6761\n",
            "Epoch 47/100\n",
            "429/429 [==============================] - 0s 827us/step - loss: 0.6168 - acc: 0.6830 - val_loss: 0.6206 - val_acc: 0.6761\n",
            "Epoch 48/100\n",
            "429/429 [==============================] - 0s 831us/step - loss: 0.6201 - acc: 0.6783 - val_loss: 0.6199 - val_acc: 0.6761\n",
            "Epoch 49/100\n",
            "429/429 [==============================] - 0s 832us/step - loss: 0.6231 - acc: 0.6760 - val_loss: 0.6222 - val_acc: 0.6761\n",
            "Epoch 50/100\n",
            "429/429 [==============================] - 0s 826us/step - loss: 0.6182 - acc: 0.6876 - val_loss: 0.6232 - val_acc: 0.6761\n",
            "Epoch 51/100\n",
            "429/429 [==============================] - 0s 843us/step - loss: 0.6140 - acc: 0.6830 - val_loss: 0.6238 - val_acc: 0.6761\n",
            "Epoch 52/100\n",
            "429/429 [==============================] - 0s 824us/step - loss: 0.6154 - acc: 0.6830 - val_loss: 0.6219 - val_acc: 0.6761\n",
            "Epoch 53/100\n",
            "429/429 [==============================] - 0s 839us/step - loss: 0.6338 - acc: 0.6807 - val_loss: 0.6189 - val_acc: 0.6761\n",
            "Epoch 54/100\n",
            "429/429 [==============================] - 0s 836us/step - loss: 0.6208 - acc: 0.6783 - val_loss: 0.6219 - val_acc: 0.6761\n",
            "Epoch 55/100\n",
            "429/429 [==============================] - 0s 831us/step - loss: 0.6178 - acc: 0.6783 - val_loss: 0.6252 - val_acc: 0.6761\n",
            "Epoch 56/100\n",
            "429/429 [==============================] - 0s 844us/step - loss: 0.6202 - acc: 0.6876 - val_loss: 0.6233 - val_acc: 0.6761\n",
            "Epoch 57/100\n",
            "429/429 [==============================] - 0s 838us/step - loss: 0.6147 - acc: 0.6853 - val_loss: 0.6220 - val_acc: 0.6761\n",
            "Epoch 58/100\n",
            "429/429 [==============================] - 0s 828us/step - loss: 0.6080 - acc: 0.6923 - val_loss: 0.6220 - val_acc: 0.6761\n",
            "Epoch 59/100\n",
            "429/429 [==============================] - 0s 834us/step - loss: 0.6181 - acc: 0.6830 - val_loss: 0.6223 - val_acc: 0.6761\n",
            "Epoch 60/100\n",
            "429/429 [==============================] - 0s 841us/step - loss: 0.6524 - acc: 0.6713 - val_loss: 0.6240 - val_acc: 0.6761\n",
            "Epoch 61/100\n",
            "429/429 [==============================] - 0s 836us/step - loss: 0.6190 - acc: 0.6853 - val_loss: 0.6203 - val_acc: 0.6761\n",
            "Epoch 62/100\n",
            "429/429 [==============================] - 0s 832us/step - loss: 0.6172 - acc: 0.6807 - val_loss: 0.6169 - val_acc: 0.6761\n",
            "Epoch 63/100\n",
            "429/429 [==============================] - 0s 838us/step - loss: 0.6258 - acc: 0.6807 - val_loss: 0.6163 - val_acc: 0.6761\n",
            "Epoch 64/100\n",
            "429/429 [==============================] - 0s 839us/step - loss: 0.6227 - acc: 0.6923 - val_loss: 0.6162 - val_acc: 0.6761\n",
            "Epoch 65/100\n",
            "429/429 [==============================] - 0s 838us/step - loss: 0.6095 - acc: 0.7016 - val_loss: 0.6127 - val_acc: 0.6761\n",
            "Epoch 66/100\n",
            "429/429 [==============================] - 0s 835us/step - loss: 0.6218 - acc: 0.6830 - val_loss: 0.6185 - val_acc: 0.6761\n",
            "Epoch 67/100\n",
            "429/429 [==============================] - 0s 840us/step - loss: 0.6171 - acc: 0.6760 - val_loss: 0.6199 - val_acc: 0.6761\n",
            "Epoch 68/100\n",
            "429/429 [==============================] - 0s 839us/step - loss: 0.6316 - acc: 0.6760 - val_loss: 0.6247 - val_acc: 0.6761\n",
            "Epoch 69/100\n",
            "429/429 [==============================] - 0s 832us/step - loss: 0.6244 - acc: 0.6783 - val_loss: 0.6267 - val_acc: 0.6761\n",
            "Epoch 70/100\n",
            "429/429 [==============================] - 0s 841us/step - loss: 0.6101 - acc: 0.6923 - val_loss: 0.6226 - val_acc: 0.6761\n",
            "Epoch 71/100\n",
            "429/429 [==============================] - 0s 851us/step - loss: 0.6036 - acc: 0.6853 - val_loss: 0.6218 - val_acc: 0.6761\n",
            "Epoch 72/100\n",
            "429/429 [==============================] - 0s 838us/step - loss: 0.6338 - acc: 0.6690 - val_loss: 0.6251 - val_acc: 0.6761\n",
            "Epoch 73/100\n",
            "429/429 [==============================] - 0s 837us/step - loss: 0.6305 - acc: 0.6713 - val_loss: 0.6288 - val_acc: 0.6761\n",
            "Epoch 74/100\n",
            "429/429 [==============================] - 0s 839us/step - loss: 0.6279 - acc: 0.6853 - val_loss: 0.6260 - val_acc: 0.6761\n",
            "Epoch 75/100\n",
            "429/429 [==============================] - 0s 839us/step - loss: 0.6217 - acc: 0.6807 - val_loss: 0.6258 - val_acc: 0.6761\n",
            "Epoch 76/100\n",
            "429/429 [==============================] - 0s 835us/step - loss: 0.6255 - acc: 0.6713 - val_loss: 0.6293 - val_acc: 0.6761\n",
            "Epoch 77/100\n",
            "429/429 [==============================] - 0s 848us/step - loss: 0.6191 - acc: 0.6783 - val_loss: 0.6258 - val_acc: 0.6761\n",
            "Epoch 78/100\n",
            "429/429 [==============================] - 0s 852us/step - loss: 0.6141 - acc: 0.6876 - val_loss: 0.6230 - val_acc: 0.6761\n",
            "Epoch 79/100\n",
            "429/429 [==============================] - 0s 843us/step - loss: 0.6186 - acc: 0.6900 - val_loss: 0.6191 - val_acc: 0.6761\n",
            "Epoch 80/100\n",
            "429/429 [==============================] - 0s 842us/step - loss: 0.6154 - acc: 0.6853 - val_loss: 0.6198 - val_acc: 0.6761\n",
            "Epoch 81/100\n",
            "429/429 [==============================] - 0s 841us/step - loss: 0.6262 - acc: 0.6807 - val_loss: 0.6204 - val_acc: 0.6761\n",
            "Epoch 82/100\n",
            "429/429 [==============================] - 0s 853us/step - loss: 0.6287 - acc: 0.6737 - val_loss: 0.6243 - val_acc: 0.6761\n",
            "Epoch 83/100\n",
            "429/429 [==============================] - 0s 834us/step - loss: 0.6170 - acc: 0.6876 - val_loss: 0.6221 - val_acc: 0.6761\n",
            "Epoch 84/100\n",
            "429/429 [==============================] - 0s 828us/step - loss: 0.6101 - acc: 0.6830 - val_loss: 0.6181 - val_acc: 0.6761\n",
            "Epoch 85/100\n",
            "429/429 [==============================] - 0s 843us/step - loss: 0.6151 - acc: 0.6876 - val_loss: 0.6176 - val_acc: 0.6761\n",
            "Epoch 86/100\n",
            "429/429 [==============================] - 0s 836us/step - loss: 0.6209 - acc: 0.6946 - val_loss: 0.6177 - val_acc: 0.6761\n",
            "Epoch 87/100\n",
            "429/429 [==============================] - 0s 837us/step - loss: 0.6279 - acc: 0.6783 - val_loss: 0.6164 - val_acc: 0.6761\n",
            "Epoch 88/100\n",
            "429/429 [==============================] - 0s 821us/step - loss: 0.6185 - acc: 0.6807 - val_loss: 0.6195 - val_acc: 0.6761\n",
            "Epoch 89/100\n",
            "429/429 [==============================] - 0s 837us/step - loss: 0.6196 - acc: 0.6807 - val_loss: 0.6200 - val_acc: 0.6761\n",
            "Epoch 90/100\n",
            "429/429 [==============================] - 0s 845us/step - loss: 0.6292 - acc: 0.6760 - val_loss: 0.6218 - val_acc: 0.6761\n",
            "Epoch 91/100\n",
            "429/429 [==============================] - 0s 846us/step - loss: 0.6236 - acc: 0.6876 - val_loss: 0.6201 - val_acc: 0.6761\n",
            "Epoch 92/100\n",
            "429/429 [==============================] - 0s 834us/step - loss: 0.6212 - acc: 0.6783 - val_loss: 0.6167 - val_acc: 0.6761\n",
            "Epoch 93/100\n",
            "429/429 [==============================] - 0s 839us/step - loss: 0.6096 - acc: 0.6853 - val_loss: 0.6151 - val_acc: 0.6761\n",
            "Epoch 94/100\n",
            "429/429 [==============================] - 0s 862us/step - loss: 0.6073 - acc: 0.6876 - val_loss: 0.6150 - val_acc: 0.6761\n",
            "Epoch 95/100\n",
            "429/429 [==============================] - 0s 841us/step - loss: 0.6242 - acc: 0.6713 - val_loss: 0.6182 - val_acc: 0.6761\n",
            "Epoch 96/100\n",
            "429/429 [==============================] - 0s 850us/step - loss: 0.6157 - acc: 0.6853 - val_loss: 0.6161 - val_acc: 0.6761\n",
            "Epoch 97/100\n",
            "429/429 [==============================] - 0s 845us/step - loss: 0.6086 - acc: 0.6853 - val_loss: 0.6131 - val_acc: 0.6761\n",
            "Epoch 98/100\n",
            "429/429 [==============================] - 0s 845us/step - loss: 0.6225 - acc: 0.6853 - val_loss: 0.6139 - val_acc: 0.6761\n",
            "Epoch 99/100\n",
            "429/429 [==============================] - 0s 830us/step - loss: 0.6364 - acc: 0.6737 - val_loss: 0.6207 - val_acc: 0.6761\n",
            "Epoch 100/100\n",
            "429/429 [==============================] - 0s 851us/step - loss: 0.6150 - acc: 0.6923 - val_loss: 0.6153 - val_acc: 0.6761\n",
            "[[ 0 23]\n",
            " [ 0 48]]\n",
            "Accuracy :  0.676056338028169\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        23\n",
            "           1       0.68      1.00      0.81        48\n",
            "\n",
            "    accuracy                           0.68        71\n",
            "   macro avg       0.34      0.50      0.40        71\n",
            "weighted avg       0.46      0.68      0.55        71\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "model_6 (Model)              (None, 2)                 9148782   \n",
            "=================================================================\n",
            "Total params: 9,148,782\n",
            "Trainable params: 8,386\n",
            "Non-trainable params: 9,140,396\n",
            "_________________________________________________________________\n",
            "Train on 429 samples, validate on 71 samples\n",
            "Epoch 1/100\n",
            "429/429 [==============================] - 3s 8ms/step - loss: 0.6333 - acc: 0.6737 - val_loss: 0.6202 - val_acc: 0.6761\n",
            "Epoch 2/100\n",
            "429/429 [==============================] - 0s 823us/step - loss: 0.6228 - acc: 0.6783 - val_loss: 0.6204 - val_acc: 0.6761\n",
            "Epoch 3/100\n",
            "429/429 [==============================] - 0s 807us/step - loss: 0.6273 - acc: 0.6807 - val_loss: 0.6176 - val_acc: 0.6761\n",
            "Epoch 4/100\n",
            "429/429 [==============================] - 0s 827us/step - loss: 0.6258 - acc: 0.6807 - val_loss: 0.6171 - val_acc: 0.6761\n",
            "Epoch 5/100\n",
            "429/429 [==============================] - 0s 816us/step - loss: 0.6176 - acc: 0.6876 - val_loss: 0.6190 - val_acc: 0.6761\n",
            "Epoch 6/100\n",
            "429/429 [==============================] - 0s 807us/step - loss: 0.6099 - acc: 0.6923 - val_loss: 0.6192 - val_acc: 0.6761\n",
            "Epoch 7/100\n",
            "429/429 [==============================] - 0s 819us/step - loss: 0.6379 - acc: 0.6900 - val_loss: 0.6185 - val_acc: 0.6761\n",
            "Epoch 8/100\n",
            "429/429 [==============================] - 0s 824us/step - loss: 0.6182 - acc: 0.6876 - val_loss: 0.6188 - val_acc: 0.6901\n",
            "Epoch 9/100\n",
            "429/429 [==============================] - 0s 818us/step - loss: 0.6257 - acc: 0.6783 - val_loss: 0.6189 - val_acc: 0.6901\n",
            "Epoch 10/100\n",
            "429/429 [==============================] - 0s 821us/step - loss: 0.6248 - acc: 0.6853 - val_loss: 0.6167 - val_acc: 0.6901\n",
            "Epoch 11/100\n",
            "429/429 [==============================] - 0s 840us/step - loss: 0.6479 - acc: 0.6830 - val_loss: 0.6147 - val_acc: 0.6901\n",
            "Epoch 12/100\n",
            "429/429 [==============================] - 0s 829us/step - loss: 0.6177 - acc: 0.6830 - val_loss: 0.6140 - val_acc: 0.6901\n",
            "Epoch 13/100\n",
            "429/429 [==============================] - 0s 824us/step - loss: 0.6247 - acc: 0.6853 - val_loss: 0.6145 - val_acc: 0.6901\n",
            "Epoch 14/100\n",
            "429/429 [==============================] - 0s 826us/step - loss: 0.6326 - acc: 0.6807 - val_loss: 0.6150 - val_acc: 0.6901\n",
            "Epoch 15/100\n",
            "429/429 [==============================] - 0s 818us/step - loss: 0.6150 - acc: 0.6923 - val_loss: 0.6143 - val_acc: 0.6901\n",
            "Epoch 16/100\n",
            "429/429 [==============================] - 0s 830us/step - loss: 0.6165 - acc: 0.6876 - val_loss: 0.6156 - val_acc: 0.6901\n",
            "Epoch 17/100\n",
            "429/429 [==============================] - 0s 813us/step - loss: 0.6245 - acc: 0.6807 - val_loss: 0.6170 - val_acc: 0.6901\n",
            "Epoch 18/100\n",
            "429/429 [==============================] - 0s 821us/step - loss: 0.6458 - acc: 0.6783 - val_loss: 0.6254 - val_acc: 0.6901\n",
            "Epoch 19/100\n",
            "429/429 [==============================] - 0s 837us/step - loss: 0.6206 - acc: 0.6830 - val_loss: 0.6197 - val_acc: 0.6901\n",
            "Epoch 20/100\n",
            "429/429 [==============================] - 0s 834us/step - loss: 0.6132 - acc: 0.6830 - val_loss: 0.6203 - val_acc: 0.6901\n",
            "Epoch 21/100\n",
            "429/429 [==============================] - 0s 823us/step - loss: 0.6208 - acc: 0.6900 - val_loss: 0.6176 - val_acc: 0.6901\n",
            "Epoch 22/100\n",
            "429/429 [==============================] - 0s 835us/step - loss: 0.6116 - acc: 0.6690 - val_loss: 0.6178 - val_acc: 0.6901\n",
            "Epoch 23/100\n",
            "429/429 [==============================] - 0s 825us/step - loss: 0.6251 - acc: 0.6807 - val_loss: 0.6201 - val_acc: 0.6901\n",
            "Epoch 24/100\n",
            "429/429 [==============================] - 0s 822us/step - loss: 0.6209 - acc: 0.6830 - val_loss: 0.6222 - val_acc: 0.6901\n",
            "Epoch 25/100\n",
            "429/429 [==============================] - 0s 838us/step - loss: 0.6209 - acc: 0.6853 - val_loss: 0.6232 - val_acc: 0.6901\n",
            "Epoch 26/100\n",
            "429/429 [==============================] - 0s 819us/step - loss: 0.6228 - acc: 0.6737 - val_loss: 0.6201 - val_acc: 0.6901\n",
            "Epoch 27/100\n",
            "429/429 [==============================] - 0s 826us/step - loss: 0.6134 - acc: 0.6946 - val_loss: 0.6159 - val_acc: 0.6901\n",
            "Epoch 28/100\n",
            "429/429 [==============================] - 0s 836us/step - loss: 0.6142 - acc: 0.6876 - val_loss: 0.6153 - val_acc: 0.6901\n",
            "Epoch 29/100\n",
            "429/429 [==============================] - 0s 823us/step - loss: 0.6243 - acc: 0.6830 - val_loss: 0.6164 - val_acc: 0.6901\n",
            "Epoch 30/100\n",
            "429/429 [==============================] - 0s 829us/step - loss: 0.6135 - acc: 0.6923 - val_loss: 0.6183 - val_acc: 0.6901\n",
            "Epoch 31/100\n",
            "429/429 [==============================] - 0s 823us/step - loss: 0.6084 - acc: 0.6946 - val_loss: 0.6173 - val_acc: 0.6901\n",
            "Epoch 32/100\n",
            "429/429 [==============================] - 0s 824us/step - loss: 0.5976 - acc: 0.6946 - val_loss: 0.6154 - val_acc: 0.6901\n",
            "Epoch 33/100\n",
            "429/429 [==============================] - 0s 823us/step - loss: 0.6273 - acc: 0.6783 - val_loss: 0.6180 - val_acc: 0.6901\n",
            "Epoch 34/100\n",
            "429/429 [==============================] - 0s 830us/step - loss: 0.6123 - acc: 0.6783 - val_loss: 0.6181 - val_acc: 0.6901\n",
            "Epoch 35/100\n",
            "429/429 [==============================] - 0s 827us/step - loss: 0.6268 - acc: 0.6876 - val_loss: 0.6143 - val_acc: 0.6901\n",
            "Epoch 36/100\n",
            "429/429 [==============================] - 0s 833us/step - loss: 0.6316 - acc: 0.6783 - val_loss: 0.6104 - val_acc: 0.6901\n",
            "Epoch 37/100\n",
            "429/429 [==============================] - 0s 832us/step - loss: 0.6260 - acc: 0.6830 - val_loss: 0.6096 - val_acc: 0.6901\n",
            "Epoch 38/100\n",
            "429/429 [==============================] - 0s 827us/step - loss: 0.6313 - acc: 0.6783 - val_loss: 0.6119 - val_acc: 0.6901\n",
            "Epoch 39/100\n",
            "429/429 [==============================] - 0s 846us/step - loss: 0.6071 - acc: 0.6830 - val_loss: 0.6118 - val_acc: 0.6901\n",
            "Epoch 40/100\n",
            "429/429 [==============================] - 0s 822us/step - loss: 0.6209 - acc: 0.6830 - val_loss: 0.6062 - val_acc: 0.6901\n",
            "Epoch 41/100\n",
            "429/429 [==============================] - 0s 829us/step - loss: 0.6341 - acc: 0.6807 - val_loss: 0.6046 - val_acc: 0.6901\n",
            "Epoch 42/100\n",
            "429/429 [==============================] - 0s 838us/step - loss: 0.6258 - acc: 0.6853 - val_loss: 0.6086 - val_acc: 0.6901\n",
            "Epoch 43/100\n",
            "429/429 [==============================] - 0s 826us/step - loss: 0.5965 - acc: 0.6993 - val_loss: 0.6158 - val_acc: 0.6901\n",
            "Epoch 44/100\n",
            "429/429 [==============================] - 0s 822us/step - loss: 0.6202 - acc: 0.6830 - val_loss: 0.6170 - val_acc: 0.6901\n",
            "Epoch 45/100\n",
            "429/429 [==============================] - 0s 835us/step - loss: 0.6308 - acc: 0.6970 - val_loss: 0.6161 - val_acc: 0.6901\n",
            "Epoch 46/100\n",
            "429/429 [==============================] - 0s 823us/step - loss: 0.6105 - acc: 0.6946 - val_loss: 0.6147 - val_acc: 0.6901\n",
            "Epoch 47/100\n",
            "429/429 [==============================] - 0s 836us/step - loss: 0.6294 - acc: 0.6807 - val_loss: 0.6135 - val_acc: 0.6901\n",
            "Epoch 48/100\n",
            "429/429 [==============================] - 0s 842us/step - loss: 0.6558 - acc: 0.6853 - val_loss: 0.6127 - val_acc: 0.6901\n",
            "Epoch 49/100\n",
            "429/429 [==============================] - 0s 824us/step - loss: 0.6121 - acc: 0.6853 - val_loss: 0.6103 - val_acc: 0.6901\n",
            "Epoch 50/100\n",
            "429/429 [==============================] - 0s 830us/step - loss: 0.6355 - acc: 0.6783 - val_loss: 0.6128 - val_acc: 0.6901\n",
            "Epoch 51/100\n",
            "429/429 [==============================] - 0s 836us/step - loss: 0.6383 - acc: 0.6760 - val_loss: 0.6192 - val_acc: 0.6901\n",
            "Epoch 52/100\n",
            "429/429 [==============================] - 0s 826us/step - loss: 0.6165 - acc: 0.6783 - val_loss: 0.6208 - val_acc: 0.6761\n",
            "Epoch 53/100\n",
            "429/429 [==============================] - 0s 832us/step - loss: 0.6149 - acc: 0.6760 - val_loss: 0.6190 - val_acc: 0.6761\n",
            "Epoch 54/100\n",
            "429/429 [==============================] - 0s 849us/step - loss: 0.6129 - acc: 0.6760 - val_loss: 0.6178 - val_acc: 0.6761\n",
            "Epoch 55/100\n",
            "429/429 [==============================] - 0s 830us/step - loss: 0.6163 - acc: 0.6830 - val_loss: 0.6187 - val_acc: 0.6761\n",
            "Epoch 56/100\n",
            "429/429 [==============================] - 0s 829us/step - loss: 0.6269 - acc: 0.6830 - val_loss: 0.6173 - val_acc: 0.6761\n",
            "Epoch 57/100\n",
            "429/429 [==============================] - 0s 830us/step - loss: 0.6400 - acc: 0.6737 - val_loss: 0.6187 - val_acc: 0.6761\n",
            "Epoch 58/100\n",
            "429/429 [==============================] - 0s 821us/step - loss: 0.6060 - acc: 0.6946 - val_loss: 0.6155 - val_acc: 0.6761\n",
            "Epoch 59/100\n",
            "429/429 [==============================] - 0s 833us/step - loss: 0.6129 - acc: 0.6807 - val_loss: 0.6139 - val_acc: 0.6761\n",
            "Epoch 60/100\n",
            "429/429 [==============================] - 0s 841us/step - loss: 0.6014 - acc: 0.6807 - val_loss: 0.6131 - val_acc: 0.6761\n",
            "Epoch 61/100\n",
            "429/429 [==============================] - 0s 847us/step - loss: 0.6098 - acc: 0.6900 - val_loss: 0.6184 - val_acc: 0.6761\n",
            "Epoch 62/100\n",
            "429/429 [==============================] - 0s 857us/step - loss: 0.6159 - acc: 0.6876 - val_loss: 0.6194 - val_acc: 0.6761\n",
            "Epoch 63/100\n",
            "429/429 [==============================] - 0s 831us/step - loss: 0.6346 - acc: 0.6807 - val_loss: 0.6140 - val_acc: 0.6761\n",
            "Epoch 64/100\n",
            "429/429 [==============================] - 0s 829us/step - loss: 0.6035 - acc: 0.6946 - val_loss: 0.6105 - val_acc: 0.6761\n",
            "Epoch 65/100\n",
            "429/429 [==============================] - 0s 845us/step - loss: 0.6080 - acc: 0.6923 - val_loss: 0.6123 - val_acc: 0.6761\n",
            "Epoch 66/100\n",
            "429/429 [==============================] - 0s 842us/step - loss: 0.5937 - acc: 0.6923 - val_loss: 0.6115 - val_acc: 0.6761\n",
            "Epoch 67/100\n",
            "429/429 [==============================] - 0s 829us/step - loss: 0.6234 - acc: 0.6876 - val_loss: 0.6124 - val_acc: 0.6761\n",
            "Epoch 68/100\n",
            "429/429 [==============================] - 0s 846us/step - loss: 0.6152 - acc: 0.6807 - val_loss: 0.6125 - val_acc: 0.6761\n",
            "Epoch 69/100\n",
            "429/429 [==============================] - 0s 864us/step - loss: 0.6068 - acc: 0.6946 - val_loss: 0.6140 - val_acc: 0.6761\n",
            "Epoch 70/100\n",
            "429/429 [==============================] - 0s 858us/step - loss: 0.6211 - acc: 0.6573 - val_loss: 0.6137 - val_acc: 0.6761\n",
            "Epoch 71/100\n",
            "429/429 [==============================] - 0s 835us/step - loss: 0.6292 - acc: 0.6876 - val_loss: 0.6214 - val_acc: 0.6761\n",
            "Epoch 72/100\n",
            "429/429 [==============================] - 0s 833us/step - loss: 0.6285 - acc: 0.6737 - val_loss: 0.6205 - val_acc: 0.6761\n",
            "Epoch 73/100\n",
            "429/429 [==============================] - 0s 837us/step - loss: 0.6121 - acc: 0.6783 - val_loss: 0.6178 - val_acc: 0.6761\n",
            "Epoch 74/100\n",
            "429/429 [==============================] - 0s 835us/step - loss: 0.6182 - acc: 0.6737 - val_loss: 0.6173 - val_acc: 0.6761\n",
            "Epoch 75/100\n",
            "429/429 [==============================] - 0s 824us/step - loss: 0.6389 - acc: 0.6737 - val_loss: 0.6170 - val_acc: 0.6761\n",
            "Epoch 76/100\n",
            "429/429 [==============================] - 0s 837us/step - loss: 0.6053 - acc: 0.6853 - val_loss: 0.6108 - val_acc: 0.6761\n",
            "Epoch 77/100\n",
            "429/429 [==============================] - 0s 839us/step - loss: 0.6200 - acc: 0.6760 - val_loss: 0.6132 - val_acc: 0.6761\n",
            "Epoch 78/100\n",
            "429/429 [==============================] - 0s 841us/step - loss: 0.6182 - acc: 0.6760 - val_loss: 0.6132 - val_acc: 0.6761\n",
            "Epoch 79/100\n",
            "429/429 [==============================] - 0s 844us/step - loss: 0.6306 - acc: 0.6760 - val_loss: 0.6179 - val_acc: 0.6761\n",
            "Epoch 80/100\n",
            "429/429 [==============================] - 0s 847us/step - loss: 0.6074 - acc: 0.6737 - val_loss: 0.6118 - val_acc: 0.6761\n",
            "Epoch 81/100\n",
            "429/429 [==============================] - 0s 835us/step - loss: 0.6223 - acc: 0.6876 - val_loss: 0.6134 - val_acc: 0.6761\n",
            "Epoch 82/100\n",
            "429/429 [==============================] - 0s 835us/step - loss: 0.6067 - acc: 0.6853 - val_loss: 0.6135 - val_acc: 0.6761\n",
            "Epoch 83/100\n",
            "429/429 [==============================] - 0s 839us/step - loss: 0.6092 - acc: 0.6830 - val_loss: 0.6130 - val_acc: 0.6761\n",
            "Epoch 84/100\n",
            "429/429 [==============================] - 0s 844us/step - loss: 0.6132 - acc: 0.6876 - val_loss: 0.6132 - val_acc: 0.6761\n",
            "Epoch 85/100\n",
            "429/429 [==============================] - 0s 849us/step - loss: 0.6156 - acc: 0.6713 - val_loss: 0.6145 - val_acc: 0.6901\n",
            "Epoch 86/100\n",
            "429/429 [==============================] - 0s 832us/step - loss: 0.6203 - acc: 0.6760 - val_loss: 0.6172 - val_acc: 0.6901\n",
            "Epoch 87/100\n",
            "429/429 [==============================] - 0s 847us/step - loss: 0.6114 - acc: 0.6783 - val_loss: 0.6153 - val_acc: 0.6901\n",
            "Epoch 88/100\n",
            "429/429 [==============================] - 0s 850us/step - loss: 0.6170 - acc: 0.6807 - val_loss: 0.6106 - val_acc: 0.6901\n",
            "Epoch 89/100\n",
            "429/429 [==============================] - 0s 845us/step - loss: 0.6186 - acc: 0.6876 - val_loss: 0.6136 - val_acc: 0.6901\n",
            "Epoch 90/100\n",
            "429/429 [==============================] - 0s 839us/step - loss: 0.6117 - acc: 0.6713 - val_loss: 0.6132 - val_acc: 0.6901\n",
            "Epoch 91/100\n",
            "429/429 [==============================] - 0s 838us/step - loss: 0.6141 - acc: 0.6970 - val_loss: 0.6181 - val_acc: 0.6901\n",
            "Epoch 92/100\n",
            "429/429 [==============================] - 0s 839us/step - loss: 0.6134 - acc: 0.6713 - val_loss: 0.6159 - val_acc: 0.6901\n",
            "Epoch 93/100\n",
            "429/429 [==============================] - 0s 847us/step - loss: 0.6153 - acc: 0.6830 - val_loss: 0.6155 - val_acc: 0.6901\n",
            "Epoch 94/100\n",
            "429/429 [==============================] - 0s 845us/step - loss: 0.6163 - acc: 0.6807 - val_loss: 0.6175 - val_acc: 0.6901\n",
            "Epoch 95/100\n",
            "429/429 [==============================] - 0s 835us/step - loss: 0.6098 - acc: 0.6830 - val_loss: 0.6188 - val_acc: 0.6901\n",
            "Epoch 96/100\n",
            "429/429 [==============================] - 0s 846us/step - loss: 0.6123 - acc: 0.6760 - val_loss: 0.6209 - val_acc: 0.6901\n",
            "Epoch 97/100\n",
            "429/429 [==============================] - 0s 850us/step - loss: 0.6028 - acc: 0.6853 - val_loss: 0.6215 - val_acc: 0.6901\n",
            "Epoch 98/100\n",
            "429/429 [==============================] - 0s 846us/step - loss: 0.5941 - acc: 0.6946 - val_loss: 0.6220 - val_acc: 0.6901\n",
            "Epoch 99/100\n",
            "429/429 [==============================] - 0s 865us/step - loss: 0.6156 - acc: 0.6830 - val_loss: 0.6218 - val_acc: 0.6901\n",
            "Epoch 100/100\n",
            "429/429 [==============================] - 0s 843us/step - loss: 0.6106 - acc: 0.6876 - val_loss: 0.6240 - val_acc: 0.6901\n",
            "[[ 1 22]\n",
            " [ 0 48]]\n",
            "Accuracy :  0.6901408450704225\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.04      0.08        23\n",
            "           1       0.69      1.00      0.81        48\n",
            "\n",
            "    accuracy                           0.69        71\n",
            "   macro avg       0.84      0.52      0.45        71\n",
            "weighted avg       0.79      0.69      0.58        71\n",
            "\n",
            "\n",
            "\n",
            "Competence\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "model_4 (Model)              (None, 2)                 9148782   \n",
            "=================================================================\n",
            "Total params: 9,148,782\n",
            "Trainable params: 8,386\n",
            "Non-trainable params: 9,140,396\n",
            "_________________________________________________________________\n",
            "Train on 427 samples, validate on 73 samples\n",
            "Epoch 1/100\n",
            "427/427 [==============================] - 4s 8ms/step - loss: 1.5167 - acc: 0.8431 - val_loss: 0.9436 - val_acc: 0.9315\n",
            "Epoch 2/100\n",
            "427/427 [==============================] - 0s 832us/step - loss: 0.6725 - acc: 0.9415 - val_loss: 0.9790 - val_acc: 0.9315\n",
            "Epoch 3/100\n",
            "427/427 [==============================] - 0s 825us/step - loss: 0.5710 - acc: 0.9415 - val_loss: 0.9025 - val_acc: 0.9315\n",
            "Epoch 4/100\n",
            "427/427 [==============================] - 0s 834us/step - loss: 0.4162 - acc: 0.9415 - val_loss: 0.8446 - val_acc: 0.9315\n",
            "Epoch 5/100\n",
            "427/427 [==============================] - 0s 834us/step - loss: 0.3885 - acc: 0.9415 - val_loss: 0.8640 - val_acc: 0.9315\n",
            "Epoch 6/100\n",
            "427/427 [==============================] - 0s 824us/step - loss: 0.5469 - acc: 0.9415 - val_loss: 0.8236 - val_acc: 0.9315\n",
            "Epoch 7/100\n",
            "427/427 [==============================] - 0s 830us/step - loss: 0.5399 - acc: 0.9391 - val_loss: 0.7084 - val_acc: 0.9315\n",
            "Epoch 8/100\n",
            "427/427 [==============================] - 0s 823us/step - loss: 0.3709 - acc: 0.9415 - val_loss: 0.5509 - val_acc: 0.9315\n",
            "Epoch 9/100\n",
            "427/427 [==============================] - 0s 832us/step - loss: 0.3312 - acc: 0.9321 - val_loss: 0.5023 - val_acc: 0.9315\n",
            "Epoch 10/100\n",
            "427/427 [==============================] - 0s 826us/step - loss: 0.2789 - acc: 0.9415 - val_loss: 0.9892 - val_acc: 0.9315\n",
            "Epoch 11/100\n",
            "427/427 [==============================] - 0s 827us/step - loss: 0.6175 - acc: 0.9368 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 12/100\n",
            "427/427 [==============================] - 0s 828us/step - loss: 0.6533 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 13/100\n",
            "427/427 [==============================] - 0s 825us/step - loss: 0.6304 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 14/100\n",
            "427/427 [==============================] - 0s 824us/step - loss: 0.5448 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 15/100\n",
            "427/427 [==============================] - 0s 839us/step - loss: 0.6275 - acc: 0.9391 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 16/100\n",
            "427/427 [==============================] - 0s 826us/step - loss: 0.5922 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 17/100\n",
            "427/427 [==============================] - 0s 824us/step - loss: 0.7513 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 18/100\n",
            "427/427 [==============================] - 0s 831us/step - loss: 0.4743 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 19/100\n",
            "427/427 [==============================] - 0s 826us/step - loss: 0.5315 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 20/100\n",
            "427/427 [==============================] - 0s 828us/step - loss: 0.5005 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 21/100\n",
            "427/427 [==============================] - 0s 830us/step - loss: 0.7234 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 22/100\n",
            "427/427 [==============================] - 0s 834us/step - loss: 0.5632 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 23/100\n",
            "427/427 [==============================] - 0s 827us/step - loss: 0.6216 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 24/100\n",
            "427/427 [==============================] - 0s 828us/step - loss: 0.7819 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 25/100\n",
            "427/427 [==============================] - 0s 830us/step - loss: 0.7400 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 26/100\n",
            "427/427 [==============================] - 0s 829us/step - loss: 0.6509 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 27/100\n",
            "427/427 [==============================] - 0s 832us/step - loss: 0.4713 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 28/100\n",
            "427/427 [==============================] - 0s 828us/step - loss: 0.6579 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 29/100\n",
            "427/427 [==============================] - 0s 828us/step - loss: 0.6898 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 30/100\n",
            "427/427 [==============================] - 0s 845us/step - loss: 0.5056 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 31/100\n",
            "427/427 [==============================] - 0s 834us/step - loss: 0.5949 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 32/100\n",
            "427/427 [==============================] - 0s 823us/step - loss: 0.6225 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 33/100\n",
            "427/427 [==============================] - 0s 836us/step - loss: 0.5431 - acc: 0.9391 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 34/100\n",
            "427/427 [==============================] - 0s 837us/step - loss: 0.6281 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 35/100\n",
            "427/427 [==============================] - 0s 837us/step - loss: 0.5955 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 36/100\n",
            "427/427 [==============================] - 0s 835us/step - loss: 0.5330 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 37/100\n",
            "427/427 [==============================] - 0s 839us/step - loss: 0.6577 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 38/100\n",
            "427/427 [==============================] - 0s 851us/step - loss: 0.5643 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 39/100\n",
            "427/427 [==============================] - 0s 834us/step - loss: 0.5695 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 40/100\n",
            "427/427 [==============================] - 0s 822us/step - loss: 0.5647 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 41/100\n",
            "427/427 [==============================] - 0s 841us/step - loss: 0.6065 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 42/100\n",
            "427/427 [==============================] - 0s 836us/step - loss: 0.4852 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 43/100\n",
            "427/427 [==============================] - 0s 837us/step - loss: 0.7184 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 44/100\n",
            "427/427 [==============================] - 0s 829us/step - loss: 0.5344 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 45/100\n",
            "427/427 [==============================] - 0s 835us/step - loss: 0.5016 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 46/100\n",
            "427/427 [==============================] - 0s 828us/step - loss: 0.7650 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 47/100\n",
            "427/427 [==============================] - 0s 840us/step - loss: 0.6646 - acc: 0.9391 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 48/100\n",
            "427/427 [==============================] - 0s 834us/step - loss: 0.5983 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 49/100\n",
            "427/427 [==============================] - 0s 836us/step - loss: 0.6390 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 50/100\n",
            "427/427 [==============================] - 0s 844us/step - loss: 0.6254 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 51/100\n",
            "427/427 [==============================] - 0s 834us/step - loss: 0.5047 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 52/100\n",
            "427/427 [==============================] - 0s 838us/step - loss: 0.5644 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 53/100\n",
            "427/427 [==============================] - 0s 840us/step - loss: 0.6964 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 54/100\n",
            "427/427 [==============================] - 0s 840us/step - loss: 0.5341 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 55/100\n",
            "427/427 [==============================] - 0s 833us/step - loss: 0.4692 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 56/100\n",
            "427/427 [==============================] - 0s 843us/step - loss: 0.6293 - acc: 0.9391 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 57/100\n",
            "427/427 [==============================] - 0s 832us/step - loss: 0.6356 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 58/100\n",
            "427/427 [==============================] - 0s 848us/step - loss: 0.5991 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 59/100\n",
            "427/427 [==============================] - 0s 833us/step - loss: 0.7559 - acc: 0.9391 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 60/100\n",
            "427/427 [==============================] - 0s 841us/step - loss: 0.5951 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 61/100\n",
            "427/427 [==============================] - 0s 837us/step - loss: 0.5872 - acc: 0.9438 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 62/100\n",
            "427/427 [==============================] - 0s 832us/step - loss: 0.4693 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 63/100\n",
            "427/427 [==============================] - 0s 837us/step - loss: 0.6933 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 64/100\n",
            "427/427 [==============================] - 0s 852us/step - loss: 0.4735 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 65/100\n",
            "427/427 [==============================] - 0s 841us/step - loss: 0.5672 - acc: 0.9391 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 66/100\n",
            "427/427 [==============================] - 0s 836us/step - loss: 0.5012 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 67/100\n",
            "427/427 [==============================] - 0s 849us/step - loss: 0.4980 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 68/100\n",
            "427/427 [==============================] - 0s 838us/step - loss: 0.4684 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 69/100\n",
            "427/427 [==============================] - 0s 836us/step - loss: 0.5970 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 70/100\n",
            "427/427 [==============================] - 0s 852us/step - loss: 0.5929 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 71/100\n",
            "427/427 [==============================] - 0s 838us/step - loss: 0.6596 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 72/100\n",
            "427/427 [==============================] - 0s 839us/step - loss: 0.6548 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 73/100\n",
            "427/427 [==============================] - 0s 869us/step - loss: 0.7502 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 74/100\n",
            "427/427 [==============================] - 0s 845us/step - loss: 0.5923 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 75/100\n",
            "427/427 [==============================] - 0s 842us/step - loss: 0.8342 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 76/100\n",
            "427/427 [==============================] - 0s 831us/step - loss: 0.7675 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 77/100\n",
            "427/427 [==============================] - 0s 845us/step - loss: 0.7667 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 78/100\n",
            "427/427 [==============================] - 0s 870us/step - loss: 0.7363 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 79/100\n",
            "427/427 [==============================] - 0s 833us/step - loss: 0.8298 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 80/100\n",
            "427/427 [==============================] - 0s 848us/step - loss: 0.8528 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 81/100\n",
            "427/427 [==============================] - 0s 852us/step - loss: 0.8831 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 82/100\n",
            "427/427 [==============================] - 0s 844us/step - loss: 0.8521 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 83/100\n",
            "427/427 [==============================] - 0s 839us/step - loss: 0.8223 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 84/100\n",
            "427/427 [==============================] - 0s 855us/step - loss: 0.8216 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 85/100\n",
            "427/427 [==============================] - 0s 846us/step - loss: 0.7822 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 86/100\n",
            "427/427 [==============================] - 0s 843us/step - loss: 0.8395 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 87/100\n",
            "427/427 [==============================] - 0s 843us/step - loss: 0.8584 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 88/100\n",
            "427/427 [==============================] - 0s 839us/step - loss: 0.7317 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 89/100\n",
            "427/427 [==============================] - 0s 844us/step - loss: 0.9153 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 90/100\n",
            "427/427 [==============================] - 0s 855us/step - loss: 0.7672 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 91/100\n",
            "427/427 [==============================] - 0s 845us/step - loss: 0.8296 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 92/100\n",
            "427/427 [==============================] - 0s 836us/step - loss: 0.7972 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 93/100\n",
            "427/427 [==============================] - 0s 854us/step - loss: 0.7967 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 94/100\n",
            "427/427 [==============================] - 0s 839us/step - loss: 0.7675 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 95/100\n",
            "427/427 [==============================] - 0s 858us/step - loss: 0.8333 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 96/100\n",
            "427/427 [==============================] - 0s 839us/step - loss: 0.7958 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 97/100\n",
            "427/427 [==============================] - 0s 844us/step - loss: 0.5536 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 98/100\n",
            "427/427 [==============================] - 0s 860us/step - loss: 0.6455 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 99/100\n",
            "427/427 [==============================] - 0s 843us/step - loss: 0.6115 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "Epoch 100/100\n",
            "427/427 [==============================] - 0s 842us/step - loss: 0.7700 - acc: 0.9415 - val_loss: 1.0980 - val_acc: 0.9315\n",
            "[[ 0  5]\n",
            " [ 0 68]]\n",
            "Accuracy :  0.9315068493150684\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         5\n",
            "           1       0.93      1.00      0.96        68\n",
            "\n",
            "    accuracy                           0.93        73\n",
            "   macro avg       0.47      0.50      0.48        73\n",
            "weighted avg       0.87      0.93      0.90        73\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "model_4 (Model)              (None, 2)                 9148782   \n",
            "=================================================================\n",
            "Total params: 9,148,782\n",
            "Trainable params: 8,386\n",
            "Non-trainable params: 9,140,396\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 428 samples, validate on 72 samples\n",
            "Epoch 1/100\n",
            "428/428 [==============================] - 3s 8ms/step - loss: 0.8587 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 2/100\n",
            "428/428 [==============================] - 0s 816us/step - loss: 0.8536 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 3/100\n",
            "428/428 [==============================] - 0s 818us/step - loss: 0.6899 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 4/100\n",
            "428/428 [==============================] - 0s 830us/step - loss: 0.6936 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 5/100\n",
            "428/428 [==============================] - 0s 816us/step - loss: 0.6285 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 6/100\n",
            "428/428 [==============================] - 0s 812us/step - loss: 0.7668 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 7/100\n",
            "428/428 [==============================] - 0s 832us/step - loss: 0.7624 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 8/100\n",
            "428/428 [==============================] - 0s 817us/step - loss: 0.8780 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 9/100\n",
            "428/428 [==============================] - 0s 821us/step - loss: 0.9093 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 10/100\n",
            "428/428 [==============================] - 0s 828us/step - loss: 0.9255 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 11/100\n",
            "428/428 [==============================] - 0s 830us/step - loss: 0.8506 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 12/100\n",
            "428/428 [==============================] - 0s 824us/step - loss: 0.7763 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 13/100\n",
            "428/428 [==============================] - 0s 835us/step - loss: 0.7592 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 14/100\n",
            "428/428 [==============================] - 0s 834us/step - loss: 0.8285 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 15/100\n",
            "428/428 [==============================] - 0s 825us/step - loss: 0.8283 - acc: 0.9393 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 16/100\n",
            "428/428 [==============================] - 0s 833us/step - loss: 0.9099 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 17/100\n",
            "428/428 [==============================] - 0s 826us/step - loss: 0.9411 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 18/100\n",
            "428/428 [==============================] - 0s 825us/step - loss: 0.9224 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 19/100\n",
            "428/428 [==============================] - 0s 830us/step - loss: 0.9404 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 20/100\n",
            "428/428 [==============================] - 0s 822us/step - loss: 0.9409 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 21/100\n",
            "428/428 [==============================] - 0s 819us/step - loss: 0.9385 - acc: 0.9393 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 22/100\n",
            "428/428 [==============================] - 0s 831us/step - loss: 0.9088 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 23/100\n",
            "428/428 [==============================] - 0s 829us/step - loss: 0.9388 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 24/100\n",
            "428/428 [==============================] - 0s 825us/step - loss: 0.9080 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 25/100\n",
            "428/428 [==============================] - 0s 829us/step - loss: 0.9081 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 26/100\n",
            "428/428 [==============================] - 0s 823us/step - loss: 0.9380 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 27/100\n",
            "428/428 [==============================] - 0s 831us/step - loss: 0.8778 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 28/100\n",
            "428/428 [==============================] - 0s 836us/step - loss: 0.8354 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 29/100\n",
            "428/428 [==============================] - 0s 828us/step - loss: 0.9068 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 30/100\n",
            "428/428 [==============================] - 0s 831us/step - loss: 0.9075 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 31/100\n",
            "428/428 [==============================] - 0s 824us/step - loss: 0.8752 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 32/100\n",
            "428/428 [==============================] - 0s 822us/step - loss: 0.9375 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 33/100\n",
            "428/428 [==============================] - 0s 832us/step - loss: 0.8749 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 34/100\n",
            "428/428 [==============================] - 0s 826us/step - loss: 0.9063 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 35/100\n",
            "428/428 [==============================] - 0s 829us/step - loss: 0.9047 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 36/100\n",
            "428/428 [==============================] - 0s 828us/step - loss: 0.9068 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 37/100\n",
            "428/428 [==============================] - 0s 837us/step - loss: 0.9375 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 38/100\n",
            "428/428 [==============================] - 0s 827us/step - loss: 0.9196 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 39/100\n",
            "428/428 [==============================] - 0s 844us/step - loss: 0.9078 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 40/100\n",
            "428/428 [==============================] - 0s 830us/step - loss: 0.9078 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 41/100\n",
            "428/428 [==============================] - 0s 840us/step - loss: 0.9382 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 42/100\n",
            "428/428 [==============================] - 0s 862us/step - loss: 0.9378 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 43/100\n",
            "428/428 [==============================] - 0s 836us/step - loss: 0.9068 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 44/100\n",
            "428/428 [==============================] - 0s 840us/step - loss: 0.9385 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 45/100\n",
            "428/428 [==============================] - 0s 842us/step - loss: 0.9377 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 46/100\n",
            "428/428 [==============================] - 0s 848us/step - loss: 0.9373 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 47/100\n",
            "428/428 [==============================] - 0s 835us/step - loss: 0.9071 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 48/100\n",
            "428/428 [==============================] - 0s 855us/step - loss: 0.9359 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 49/100\n",
            "428/428 [==============================] - 0s 836us/step - loss: 0.9408 - acc: 0.9393 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 50/100\n",
            "428/428 [==============================] - 0s 837us/step - loss: 0.8800 - acc: 0.9393 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 51/100\n",
            "428/428 [==============================] - 0s 832us/step - loss: 0.9069 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 52/100\n",
            "428/428 [==============================] - 0s 827us/step - loss: 0.9081 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 53/100\n",
            "428/428 [==============================] - 0s 838us/step - loss: 0.9377 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 54/100\n",
            "428/428 [==============================] - 0s 839us/step - loss: 0.8751 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 55/100\n",
            "428/428 [==============================] - 0s 832us/step - loss: 0.9070 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 56/100\n",
            "428/428 [==============================] - 0s 848us/step - loss: 0.9066 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 57/100\n",
            "428/428 [==============================] - 0s 844us/step - loss: 0.9380 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 58/100\n",
            "428/428 [==============================] - 0s 835us/step - loss: 0.9069 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 59/100\n",
            "428/428 [==============================] - 0s 836us/step - loss: 0.9073 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 60/100\n",
            "428/428 [==============================] - 0s 835us/step - loss: 0.9063 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 61/100\n",
            "428/428 [==============================] - 0s 851us/step - loss: 0.9375 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 62/100\n",
            "428/428 [==============================] - 0s 849us/step - loss: 0.9385 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 63/100\n",
            "428/428 [==============================] - 0s 841us/step - loss: 0.9379 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 64/100\n",
            "428/428 [==============================] - 0s 846us/step - loss: 0.9105 - acc: 0.9393 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 65/100\n",
            "428/428 [==============================] - 0s 846us/step - loss: 0.9376 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 66/100\n",
            "428/428 [==============================] - 0s 845us/step - loss: 0.8776 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 67/100\n",
            "428/428 [==============================] - 0s 834us/step - loss: 0.9379 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 68/100\n",
            "428/428 [==============================] - 0s 848us/step - loss: 0.9380 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 69/100\n",
            "428/428 [==============================] - 0s 845us/step - loss: 0.9379 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 70/100\n",
            "428/428 [==============================] - 0s 840us/step - loss: 0.9073 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 71/100\n",
            "428/428 [==============================] - 0s 850us/step - loss: 0.9380 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 72/100\n",
            "428/428 [==============================] - 0s 849us/step - loss: 0.9380 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 73/100\n",
            "428/428 [==============================] - 0s 857us/step - loss: 0.9376 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 74/100\n",
            "428/428 [==============================] - 0s 844us/step - loss: 0.9082 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 75/100\n",
            "428/428 [==============================] - 0s 848us/step - loss: 0.8478 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 76/100\n",
            "428/428 [==============================] - 0s 839us/step - loss: 0.8771 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 77/100\n",
            "428/428 [==============================] - 0s 840us/step - loss: 0.8778 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 78/100\n",
            "428/428 [==============================] - 0s 832us/step - loss: 0.9478 - acc: 0.9393 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 79/100\n",
            "428/428 [==============================] - 0s 844us/step - loss: 0.9075 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 80/100\n",
            "428/428 [==============================] - 0s 846us/step - loss: 0.9379 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 81/100\n",
            "428/428 [==============================] - 0s 845us/step - loss: 0.9373 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 82/100\n",
            "428/428 [==============================] - 0s 856us/step - loss: 0.9383 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 83/100\n",
            "428/428 [==============================] - 0s 842us/step - loss: 0.9381 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 84/100\n",
            "428/428 [==============================] - 0s 856us/step - loss: 0.9072 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 85/100\n",
            "428/428 [==============================] - 0s 843us/step - loss: 0.9074 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 86/100\n",
            "428/428 [==============================] - 0s 840us/step - loss: 0.8767 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 87/100\n",
            "428/428 [==============================] - 0s 840us/step - loss: 0.8769 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 88/100\n",
            "428/428 [==============================] - 0s 858us/step - loss: 0.9378 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 89/100\n",
            "428/428 [==============================] - 0s 856us/step - loss: 0.9369 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 90/100\n",
            "428/428 [==============================] - 0s 860us/step - loss: 0.8157 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 91/100\n",
            "428/428 [==============================] - 0s 842us/step - loss: 0.8964 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 92/100\n",
            "428/428 [==============================] - 0s 843us/step - loss: 0.8149 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 93/100\n",
            "428/428 [==============================] - 0s 849us/step - loss: 0.9379 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 94/100\n",
            "428/428 [==============================] - 0s 838us/step - loss: 0.9088 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 95/100\n",
            "428/428 [==============================] - 0s 842us/step - loss: 0.9080 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 96/100\n",
            "428/428 [==============================] - 0s 852us/step - loss: 0.9376 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 97/100\n",
            "428/428 [==============================] - 0s 844us/step - loss: 0.9075 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 98/100\n",
            "428/428 [==============================] - 0s 844us/step - loss: 0.9372 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 99/100\n",
            "428/428 [==============================] - 0s 845us/step - loss: 0.9380 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "Epoch 100/100\n",
            "428/428 [==============================] - 0s 850us/step - loss: 0.9380 - acc: 0.9416 - val_loss: 1.1132 - val_acc: 0.9306\n",
            "[[ 0  5]\n",
            " [ 0 67]]\n",
            "Accuracy :  0.9305555555555556\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         5\n",
            "           1       0.93      1.00      0.96        67\n",
            "\n",
            "    accuracy                           0.93        72\n",
            "   macro avg       0.47      0.50      0.48        72\n",
            "weighted avg       0.87      0.93      0.90        72\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "model_4 (Model)              (None, 2)                 9148782   \n",
            "=================================================================\n",
            "Total params: 9,148,782\n",
            "Trainable params: 8,386\n",
            "Non-trainable params: 9,140,396\n",
            "_________________________________________________________________\n",
            "Train on 429 samples, validate on 71 samples\n",
            "Epoch 1/100\n",
            "429/429 [==============================] - 4s 9ms/step - loss: 0.9724 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 2/100\n",
            "429/429 [==============================] - 0s 825us/step - loss: 0.9724 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 3/100\n",
            "429/429 [==============================] - 0s 835us/step - loss: 0.9731 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 4/100\n",
            "429/429 [==============================] - 0s 828us/step - loss: 0.9730 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 5/100\n",
            "429/429 [==============================] - 0s 835us/step - loss: 0.9436 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 6/100\n",
            "429/429 [==============================] - 0s 818us/step - loss: 0.9435 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 7/100\n",
            "429/429 [==============================] - 0s 829us/step - loss: 0.9724 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 8/100\n",
            "429/429 [==============================] - 0s 854us/step - loss: 0.9139 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 9/100\n",
            "429/429 [==============================] - 0s 827us/step - loss: 0.9727 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 10/100\n",
            "429/429 [==============================] - 0s 836us/step - loss: 0.9436 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 11/100\n",
            "429/429 [==============================] - 0s 829us/step - loss: 0.9432 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 12/100\n",
            "429/429 [==============================] - 0s 831us/step - loss: 0.9723 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 13/100\n",
            "429/429 [==============================] - 0s 836us/step - loss: 0.9426 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 14/100\n",
            "429/429 [==============================] - 0s 829us/step - loss: 0.9723 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 15/100\n",
            "429/429 [==============================] - 0s 824us/step - loss: 0.9424 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 16/100\n",
            "429/429 [==============================] - 0s 829us/step - loss: 0.9723 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 17/100\n",
            "429/429 [==============================] - 0s 828us/step - loss: 0.9424 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 18/100\n",
            "429/429 [==============================] - 0s 833us/step - loss: 0.9724 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 19/100\n",
            "429/429 [==============================] - 0s 840us/step - loss: 0.9723 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 20/100\n",
            "429/429 [==============================] - 0s 825us/step - loss: 0.9127 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 21/100\n",
            "429/429 [==============================] - 0s 819us/step - loss: 0.9719 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 22/100\n",
            "429/429 [==============================] - 0s 821us/step - loss: 0.9121 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 23/100\n",
            "429/429 [==============================] - 0s 824us/step - loss: 0.9725 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 24/100\n",
            "429/429 [==============================] - 0s 840us/step - loss: 0.9720 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 25/100\n",
            "429/429 [==============================] - 0s 852us/step - loss: 0.9724 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 26/100\n",
            "429/429 [==============================] - 0s 839us/step - loss: 0.9733 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 27/100\n",
            "429/429 [==============================] - 0s 835us/step - loss: 0.9722 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 28/100\n",
            "429/429 [==============================] - 0s 842us/step - loss: 0.9420 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 29/100\n",
            "429/429 [==============================] - 0s 826us/step - loss: 0.9118 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 30/100\n",
            "429/429 [==============================] - 0s 835us/step - loss: 0.9105 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 31/100\n",
            "429/429 [==============================] - 0s 845us/step - loss: 0.9729 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 32/100\n",
            "429/429 [==============================] - 0s 829us/step - loss: 0.9413 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 33/100\n",
            "429/429 [==============================] - 0s 837us/step - loss: 0.9728 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 34/100\n",
            "429/429 [==============================] - 0s 831us/step - loss: 0.9718 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 35/100\n",
            "429/429 [==============================] - 0s 837us/step - loss: 0.9719 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 36/100\n",
            "429/429 [==============================] - 0s 836us/step - loss: 0.9718 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 37/100\n",
            "429/429 [==============================] - 0s 827us/step - loss: 0.9724 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 38/100\n",
            "429/429 [==============================] - 0s 835us/step - loss: 0.9380 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 39/100\n",
            "429/429 [==============================] - 0s 835us/step - loss: 0.9417 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 40/100\n",
            "429/429 [==============================] - 0s 830us/step - loss: 0.9411 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 41/100\n",
            "429/429 [==============================] - 0s 842us/step - loss: 0.9725 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 42/100\n",
            "429/429 [==============================] - 0s 852us/step - loss: 0.9718 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 43/100\n",
            "429/429 [==============================] - 0s 833us/step - loss: 0.9409 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 44/100\n",
            "429/429 [==============================] - 0s 842us/step - loss: 0.9345 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 45/100\n",
            "429/429 [==============================] - 0s 843us/step - loss: 0.9414 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 46/100\n",
            "429/429 [==============================] - 0s 844us/step - loss: 0.9728 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 47/100\n",
            "429/429 [==============================] - 0s 857us/step - loss: 0.9726 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 48/100\n",
            "429/429 [==============================] - 0s 852us/step - loss: 0.9406 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 49/100\n",
            "429/429 [==============================] - 0s 860us/step - loss: 0.9732 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 50/100\n",
            "429/429 [==============================] - 0s 860us/step - loss: 0.9725 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 51/100\n",
            "429/429 [==============================] - 0s 828us/step - loss: 0.9721 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 52/100\n",
            "429/429 [==============================] - 0s 833us/step - loss: 0.9732 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 53/100\n",
            "429/429 [==============================] - 0s 836us/step - loss: 0.9727 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 54/100\n",
            "429/429 [==============================] - 0s 832us/step - loss: 0.9726 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 55/100\n",
            "429/429 [==============================] - 0s 831us/step - loss: 0.9722 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 56/100\n",
            "429/429 [==============================] - 0s 843us/step - loss: 0.9417 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 57/100\n",
            "429/429 [==============================] - 0s 833us/step - loss: 0.9725 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 58/100\n",
            "429/429 [==============================] - 0s 842us/step - loss: 0.9721 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 59/100\n",
            "429/429 [==============================] - 0s 848us/step - loss: 0.9724 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 60/100\n",
            "429/429 [==============================] - 0s 835us/step - loss: 0.9721 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 61/100\n",
            "429/429 [==============================] - 0s 829us/step - loss: 0.9723 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 62/100\n",
            "429/429 [==============================] - 0s 847us/step - loss: 0.9727 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 63/100\n",
            "429/429 [==============================] - 0s 826us/step - loss: 0.9110 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 64/100\n",
            "429/429 [==============================] - 0s 833us/step - loss: 0.9105 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 65/100\n",
            "429/429 [==============================] - 0s 849us/step - loss: 0.9416 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 66/100\n",
            "429/429 [==============================] - 0s 838us/step - loss: 0.9413 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 67/100\n",
            "429/429 [==============================] - 0s 842us/step - loss: 0.9401 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 68/100\n",
            "429/429 [==============================] - 0s 847us/step - loss: 0.9724 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 69/100\n",
            "429/429 [==============================] - 0s 833us/step - loss: 0.9719 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 70/100\n",
            "429/429 [==============================] - 0s 849us/step - loss: 0.9406 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 71/100\n",
            "429/429 [==============================] - 0s 855us/step - loss: 0.9728 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 72/100\n",
            "429/429 [==============================] - 0s 834us/step - loss: 0.9727 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 73/100\n",
            "429/429 [==============================] - 0s 839us/step - loss: 0.9721 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 74/100\n",
            "429/429 [==============================] - 0s 830us/step - loss: 0.9410 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 75/100\n",
            "429/429 [==============================] - 0s 841us/step - loss: 0.9723 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 76/100\n",
            "429/429 [==============================] - 0s 837us/step - loss: 0.9099 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 77/100\n",
            "429/429 [==============================] - 0s 857us/step - loss: 0.9725 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 78/100\n",
            "429/429 [==============================] - 0s 846us/step - loss: 0.9731 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 79/100\n",
            "429/429 [==============================] - 0s 844us/step - loss: 0.9727 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 80/100\n",
            "429/429 [==============================] - 0s 846us/step - loss: 0.9719 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 81/100\n",
            "429/429 [==============================] - 0s 834us/step - loss: 0.9408 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 82/100\n",
            "429/429 [==============================] - 0s 841us/step - loss: 0.9403 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 83/100\n",
            "429/429 [==============================] - 0s 831us/step - loss: 0.9718 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 84/100\n",
            "429/429 [==============================] - 0s 835us/step - loss: 0.9724 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 85/100\n",
            "429/429 [==============================] - 0s 833us/step - loss: 0.9402 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 86/100\n",
            "429/429 [==============================] - 0s 842us/step - loss: 0.9722 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 87/100\n",
            "429/429 [==============================] - 0s 848us/step - loss: 0.9405 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 88/100\n",
            "429/429 [==============================] - 0s 846us/step - loss: 0.9726 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 89/100\n",
            "429/429 [==============================] - 0s 852us/step - loss: 0.9722 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 90/100\n",
            "429/429 [==============================] - 0s 839us/step - loss: 0.9730 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 91/100\n",
            "429/429 [==============================] - 0s 833us/step - loss: 0.9722 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 92/100\n",
            "429/429 [==============================] - 0s 851us/step - loss: 0.9725 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 93/100\n",
            "429/429 [==============================] - 0s 859us/step - loss: 0.9401 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 94/100\n",
            "429/429 [==============================] - 0s 841us/step - loss: 0.9729 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 95/100\n",
            "429/429 [==============================] - 0s 834us/step - loss: 0.9723 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 96/100\n",
            "429/429 [==============================] - 0s 853us/step - loss: 0.9726 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 97/100\n",
            "429/429 [==============================] - 0s 842us/step - loss: 0.9719 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 98/100\n",
            "429/429 [==============================] - 0s 853us/step - loss: 0.8780 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 99/100\n",
            "429/429 [==============================] - 0s 853us/step - loss: 0.9722 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 100/100\n",
            "429/429 [==============================] - 0s 852us/step - loss: 0.9724 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "[[ 0  4]\n",
            " [ 0 67]]\n",
            "Accuracy :  0.9436619718309859\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         4\n",
            "           1       0.94      1.00      0.97        67\n",
            "\n",
            "    accuracy                           0.94        71\n",
            "   macro avg       0.47      0.50      0.49        71\n",
            "weighted avg       0.89      0.94      0.92        71\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "model_4 (Model)              (None, 2)                 9148782   \n",
            "=================================================================\n",
            "Total params: 9,148,782\n",
            "Trainable params: 8,386\n",
            "Non-trainable params: 9,140,396\n",
            "_________________________________________________________________\n",
            "Train on 429 samples, validate on 71 samples\n",
            "Epoch 1/100\n",
            "429/429 [==============================] - 4s 9ms/step - loss: 0.9730 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 2/100\n",
            "429/429 [==============================] - 0s 824us/step - loss: 0.9720 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 3/100\n",
            "429/429 [==============================] - 0s 815us/step - loss: 0.9720 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 4/100\n",
            "429/429 [==============================] - 0s 827us/step - loss: 0.9411 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 5/100\n",
            "429/429 [==============================] - 0s 821us/step - loss: 0.9725 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 6/100\n",
            "429/429 [==============================] - 0s 821us/step - loss: 0.9725 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 7/100\n",
            "429/429 [==============================] - 0s 833us/step - loss: 0.9720 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 8/100\n",
            "429/429 [==============================] - 0s 818us/step - loss: 0.9724 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 9/100\n",
            "429/429 [==============================] - 0s 822us/step - loss: 0.9718 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 10/100\n",
            "429/429 [==============================] - 0s 823us/step - loss: 0.9719 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 11/100\n",
            "429/429 [==============================] - 0s 815us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 12/100\n",
            "429/429 [==============================] - 0s 822us/step - loss: 0.9416 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 13/100\n",
            "429/429 [==============================] - 0s 830us/step - loss: 0.9415 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 14/100\n",
            "429/429 [==============================] - 0s 824us/step - loss: 0.9718 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 15/100\n",
            "429/429 [==============================] - 0s 825us/step - loss: 0.9720 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 16/100\n",
            "429/429 [==============================] - 0s 859us/step - loss: 0.9720 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 17/100\n",
            "429/429 [==============================] - 0s 822us/step - loss: 0.9719 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 18/100\n",
            "429/429 [==============================] - 0s 816us/step - loss: 0.9721 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 19/100\n",
            "429/429 [==============================] - 0s 847us/step - loss: 0.9411 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 20/100\n",
            "429/429 [==============================] - 0s 830us/step - loss: 0.9720 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 21/100\n",
            "429/429 [==============================] - 0s 826us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 22/100\n",
            "429/429 [==============================] - 0s 839us/step - loss: 0.9783 - acc: 0.9371 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 23/100\n",
            "429/429 [==============================] - 0s 826us/step - loss: 0.9720 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 24/100\n",
            "429/429 [==============================] - 0s 816us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 25/100\n",
            "429/429 [==============================] - 0s 839us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 26/100\n",
            "429/429 [==============================] - 0s 821us/step - loss: 0.9719 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 27/100\n",
            "429/429 [==============================] - 0s 834us/step - loss: 0.9419 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 28/100\n",
            "429/429 [==============================] - 0s 820us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 29/100\n",
            "429/429 [==============================] - 0s 827us/step - loss: 0.9719 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 30/100\n",
            "429/429 [==============================] - 0s 825us/step - loss: 0.9721 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 31/100\n",
            "429/429 [==============================] - 0s 821us/step - loss: 0.9720 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 32/100\n",
            "429/429 [==============================] - 0s 817us/step - loss: 0.9720 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 33/100\n",
            "429/429 [==============================] - 0s 831us/step - loss: 0.9719 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 34/100\n",
            "429/429 [==============================] - 0s 841us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 35/100\n",
            "429/429 [==============================] - 0s 838us/step - loss: 0.9719 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 36/100\n",
            "429/429 [==============================] - 0s 828us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 37/100\n",
            "429/429 [==============================] - 0s 836us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 38/100\n",
            "429/429 [==============================] - 0s 825us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 39/100\n",
            "429/429 [==============================] - 0s 854us/step - loss: 0.9718 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 40/100\n",
            "429/429 [==============================] - 0s 823us/step - loss: 0.9718 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 41/100\n",
            "429/429 [==============================] - 0s 823us/step - loss: 0.9719 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 42/100\n",
            "429/429 [==============================] - 0s 853us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 43/100\n",
            "429/429 [==============================] - 0s 858us/step - loss: 0.9423 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 44/100\n",
            "429/429 [==============================] - 0s 831us/step - loss: 0.9720 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 45/100\n",
            "429/429 [==============================] - 0s 851us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 46/100\n",
            "429/429 [==============================] - 0s 838us/step - loss: 0.9719 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 47/100\n",
            "429/429 [==============================] - 0s 828us/step - loss: 0.9420 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 48/100\n",
            "429/429 [==============================] - 0s 849us/step - loss: 0.9419 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 49/100\n",
            "429/429 [==============================] - 0s 837us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 50/100\n",
            "429/429 [==============================] - 0s 828us/step - loss: 0.9720 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 51/100\n",
            "429/429 [==============================] - 0s 852us/step - loss: 0.9718 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 52/100\n",
            "429/429 [==============================] - 0s 841us/step - loss: 0.9718 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 53/100\n",
            "429/429 [==============================] - 0s 848us/step - loss: 0.9718 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 54/100\n",
            "429/429 [==============================] - 0s 836us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 55/100\n",
            "429/429 [==============================] - 0s 842us/step - loss: 0.9718 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 56/100\n",
            "429/429 [==============================] - 0s 837us/step - loss: 0.9719 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 57/100\n",
            "429/429 [==============================] - 0s 836us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 58/100\n",
            "429/429 [==============================] - 0s 839us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 59/100\n",
            "429/429 [==============================] - 0s 834us/step - loss: 0.9718 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 60/100\n",
            "429/429 [==============================] - 0s 833us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 61/100\n",
            "429/429 [==============================] - 0s 845us/step - loss: 0.9420 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 62/100\n",
            "429/429 [==============================] - 0s 834us/step - loss: 0.9719 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 63/100\n",
            "429/429 [==============================] - 0s 840us/step - loss: 0.9718 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 64/100\n",
            "429/429 [==============================] - 0s 839us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 65/100\n",
            "429/429 [==============================] - 0s 853us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 66/100\n",
            "429/429 [==============================] - 0s 836us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 67/100\n",
            "429/429 [==============================] - 0s 833us/step - loss: 0.9720 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 68/100\n",
            "429/429 [==============================] - 0s 853us/step - loss: 0.9421 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 69/100\n",
            "429/429 [==============================] - 0s 843us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 70/100\n",
            "429/429 [==============================] - 0s 857us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 71/100\n",
            "429/429 [==============================] - 0s 830us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 72/100\n",
            "429/429 [==============================] - 0s 837us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 73/100\n",
            "429/429 [==============================] - 0s 840us/step - loss: 0.9105 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 74/100\n",
            "429/429 [==============================] - 0s 837us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 75/100\n",
            "429/429 [==============================] - 0s 828us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 76/100\n",
            "429/429 [==============================] - 0s 836us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 77/100\n",
            "429/429 [==============================] - 0s 852us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 78/100\n",
            "429/429 [==============================] - 0s 839us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 79/100\n",
            "429/429 [==============================] - 0s 859us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 80/100\n",
            "429/429 [==============================] - 0s 854us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 81/100\n",
            "429/429 [==============================] - 0s 835us/step - loss: 0.9718 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 82/100\n",
            "429/429 [==============================] - 0s 855us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 83/100\n",
            "429/429 [==============================] - 0s 841us/step - loss: 0.9408 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 84/100\n",
            "429/429 [==============================] - 0s 843us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 85/100\n",
            "429/429 [==============================] - 0s 843us/step - loss: 0.9719 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 86/100\n",
            "429/429 [==============================] - 0s 845us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 87/100\n",
            "429/429 [==============================] - 0s 844us/step - loss: 0.9720 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 88/100\n",
            "429/429 [==============================] - 0s 830us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 89/100\n",
            "429/429 [==============================] - 0s 844us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 90/100\n",
            "429/429 [==============================] - 0s 844us/step - loss: 0.9718 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 91/100\n",
            "429/429 [==============================] - 0s 835us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 92/100\n",
            "429/429 [==============================] - 0s 849us/step - loss: 0.9720 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 93/100\n",
            "429/429 [==============================] - 0s 849us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 94/100\n",
            "429/429 [==============================] - 0s 835us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 95/100\n",
            "429/429 [==============================] - 0s 843us/step - loss: 0.9409 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 96/100\n",
            "429/429 [==============================] - 0s 854us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 97/100\n",
            "429/429 [==============================] - 0s 839us/step - loss: 0.9722 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 98/100\n",
            "429/429 [==============================] - 0s 840us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 99/100\n",
            "429/429 [==============================] - 0s 839us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 100/100\n",
            "429/429 [==============================] - 0s 851us/step - loss: 0.9723 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "[[ 0  4]\n",
            " [ 0 67]]\n",
            "Accuracy :  0.9436619718309859\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         4\n",
            "           1       0.94      1.00      0.97        67\n",
            "\n",
            "    accuracy                           0.94        71\n",
            "   macro avg       0.47      0.50      0.49        71\n",
            "weighted avg       0.89      0.94      0.92        71\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "model_4 (Model)              (None, 2)                 9148782   \n",
            "=================================================================\n",
            "Total params: 9,148,782\n",
            "Trainable params: 8,386\n",
            "Non-trainable params: 9,140,396\n",
            "_________________________________________________________________\n",
            "Train on 429 samples, validate on 71 samples\n",
            "Epoch 1/100\n",
            "429/429 [==============================] - 4s 9ms/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 2/100\n",
            "429/429 [==============================] - 0s 823us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 3/100\n",
            "429/429 [==============================] - 0s 829us/step - loss: 0.9719 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 4/100\n",
            "429/429 [==============================] - 0s 820us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 5/100\n",
            "429/429 [==============================] - 0s 816us/step - loss: 0.9414 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 6/100\n",
            "429/429 [==============================] - 0s 820us/step - loss: 0.9720 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 7/100\n",
            "429/429 [==============================] - 0s 826us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 8/100\n",
            "429/429 [==============================] - 0s 818us/step - loss: 0.9720 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 9/100\n",
            "429/429 [==============================] - 0s 825us/step - loss: 0.9718 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 10/100\n",
            "429/429 [==============================] - 0s 825us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 11/100\n",
            "429/429 [==============================] - 0s 833us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 12/100\n",
            "429/429 [==============================] - 0s 829us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 13/100\n",
            "429/429 [==============================] - 0s 823us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 14/100\n",
            "429/429 [==============================] - 0s 821us/step - loss: 0.9719 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 15/100\n",
            "429/429 [==============================] - 0s 823us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 16/100\n",
            "429/429 [==============================] - 0s 828us/step - loss: 0.9718 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 17/100\n",
            "429/429 [==============================] - 0s 826us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 18/100\n",
            "429/429 [==============================] - 0s 848us/step - loss: 0.9417 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 19/100\n",
            "429/429 [==============================] - 0s 834us/step - loss: 0.9113 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 20/100\n",
            "429/429 [==============================] - 0s 826us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 21/100\n",
            "429/429 [==============================] - 0s 826us/step - loss: 0.9718 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 22/100\n",
            "429/429 [==============================] - 0s 825us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 23/100\n",
            "429/429 [==============================] - 0s 819us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 24/100\n",
            "429/429 [==============================] - 0s 837us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 25/100\n",
            "429/429 [==============================] - 0s 831us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 26/100\n",
            "429/429 [==============================] - 0s 837us/step - loss: 0.9718 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 27/100\n",
            "429/429 [==============================] - 0s 823us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 28/100\n",
            "429/429 [==============================] - 0s 832us/step - loss: 0.9412 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 29/100\n",
            "429/429 [==============================] - 0s 836us/step - loss: 0.9718 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 30/100\n",
            "429/429 [==============================] - 0s 825us/step - loss: 0.9719 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 31/100\n",
            "429/429 [==============================] - 0s 841us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 32/100\n",
            "429/429 [==============================] - 0s 829us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 33/100\n",
            "429/429 [==============================] - 0s 825us/step - loss: 0.9718 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 34/100\n",
            "429/429 [==============================] - 0s 822us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 35/100\n",
            "429/429 [==============================] - 0s 830us/step - loss: 0.9718 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 36/100\n",
            "429/429 [==============================] - 0s 834us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 37/100\n",
            "429/429 [==============================] - 0s 821us/step - loss: 0.9718 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 38/100\n",
            "429/429 [==============================] - 0s 828us/step - loss: 0.9718 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 39/100\n",
            "429/429 [==============================] - 0s 824us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 40/100\n",
            "429/429 [==============================] - 0s 824us/step - loss: 0.9718 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 41/100\n",
            "429/429 [==============================] - 0s 835us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 42/100\n",
            "429/429 [==============================] - 0s 835us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 43/100\n",
            "429/429 [==============================] - 0s 824us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 44/100\n",
            "429/429 [==============================] - 0s 834us/step - loss: 0.9718 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 45/100\n",
            "429/429 [==============================] - 0s 831us/step - loss: 0.9722 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 46/100\n",
            "429/429 [==============================] - 0s 827us/step - loss: 0.9719 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 47/100\n",
            "429/429 [==============================] - 0s 830us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 48/100\n",
            "429/429 [==============================] - 0s 820us/step - loss: 0.9412 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 49/100\n",
            "429/429 [==============================] - 0s 833us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 50/100\n",
            "429/429 [==============================] - 0s 830us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 51/100\n",
            "429/429 [==============================] - 0s 830us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 52/100\n",
            "429/429 [==============================] - 0s 827us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 53/100\n",
            "429/429 [==============================] - 0s 831us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 54/100\n",
            "429/429 [==============================] - 0s 832us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 55/100\n",
            "429/429 [==============================] - 0s 848us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 56/100\n",
            "429/429 [==============================] - 0s 833us/step - loss: 0.9718 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 57/100\n",
            "429/429 [==============================] - 0s 841us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 58/100\n",
            "429/429 [==============================] - 0s 850us/step - loss: 0.9718 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 59/100\n",
            "429/429 [==============================] - 0s 843us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 60/100\n",
            "429/429 [==============================] - 0s 830us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 61/100\n",
            "429/429 [==============================] - 0s 840us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 62/100\n",
            "429/429 [==============================] - 0s 848us/step - loss: 0.9721 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 63/100\n",
            "429/429 [==============================] - 0s 847us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 64/100\n",
            "429/429 [==============================] - 0s 848us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 65/100\n",
            "429/429 [==============================] - 0s 825us/step - loss: 0.9718 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 66/100\n",
            "429/429 [==============================] - 0s 831us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 67/100\n",
            "429/429 [==============================] - 0s 840us/step - loss: 0.9719 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 68/100\n",
            "429/429 [==============================] - 0s 834us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 69/100\n",
            "429/429 [==============================] - 0s 843us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 70/100\n",
            "429/429 [==============================] - 0s 831us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 71/100\n",
            "429/429 [==============================] - 0s 829us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 72/100\n",
            "429/429 [==============================] - 0s 847us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 73/100\n",
            "429/429 [==============================] - 0s 833us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 74/100\n",
            "429/429 [==============================] - 0s 847us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 75/100\n",
            "429/429 [==============================] - 0s 839us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 76/100\n",
            "429/429 [==============================] - 0s 838us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 77/100\n",
            "429/429 [==============================] - 0s 836us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 78/100\n",
            "429/429 [==============================] - 0s 847us/step - loss: 0.9718 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 79/100\n",
            "429/429 [==============================] - 0s 830us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 80/100\n",
            "429/429 [==============================] - 0s 843us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 81/100\n",
            "429/429 [==============================] - 0s 836us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 82/100\n",
            "429/429 [==============================] - 0s 834us/step - loss: 0.9720 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 83/100\n",
            "429/429 [==============================] - 0s 838us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 84/100\n",
            "429/429 [==============================] - 0s 839us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 85/100\n",
            "429/429 [==============================] - 0s 841us/step - loss: 0.9718 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 86/100\n",
            "429/429 [==============================] - 0s 844us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 87/100\n",
            "429/429 [==============================] - 0s 839us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 88/100\n",
            "429/429 [==============================] - 0s 832us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 89/100\n",
            "429/429 [==============================] - 0s 841us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 90/100\n",
            "429/429 [==============================] - 0s 837us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 91/100\n",
            "429/429 [==============================] - 0s 843us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 92/100\n",
            "429/429 [==============================] - 0s 857us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 93/100\n",
            "429/429 [==============================] - 0s 832us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 94/100\n",
            "429/429 [==============================] - 0s 842us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 95/100\n",
            "429/429 [==============================] - 0s 854us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 96/100\n",
            "429/429 [==============================] - 0s 846us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 97/100\n",
            "429/429 [==============================] - 0s 840us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 98/100\n",
            "429/429 [==============================] - 0s 852us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 99/100\n",
            "429/429 [==============================] - 0s 834us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 100/100\n",
            "429/429 [==============================] - 0s 842us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "[[ 0  4]\n",
            " [ 0 67]]\n",
            "Accuracy :  0.9436619718309859\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         4\n",
            "           1       0.94      1.00      0.97        67\n",
            "\n",
            "    accuracy                           0.94        71\n",
            "   macro avg       0.47      0.50      0.49        71\n",
            "weighted avg       0.89      0.94      0.92        71\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "model_4 (Model)              (None, 2)                 9148782   \n",
            "=================================================================\n",
            "Total params: 9,148,782\n",
            "Trainable params: 8,386\n",
            "Non-trainable params: 9,140,396\n",
            "_________________________________________________________________\n",
            "Train on 429 samples, validate on 71 samples\n",
            "Epoch 1/100\n",
            "429/429 [==============================] - 4s 9ms/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 2/100\n",
            "429/429 [==============================] - 0s 819us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 3/100\n",
            "429/429 [==============================] - 0s 829us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 4/100\n",
            "429/429 [==============================] - 0s 822us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 5/100\n",
            "429/429 [==============================] - 0s 820us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 6/100\n",
            "429/429 [==============================] - 0s 821us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 7/100\n",
            "429/429 [==============================] - 0s 819us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 8/100\n",
            "429/429 [==============================] - 0s 826us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 9/100\n",
            "429/429 [==============================] - 0s 831us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 10/100\n",
            "429/429 [==============================] - 0s 820us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 11/100\n",
            "429/429 [==============================] - 0s 832us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 12/100\n",
            "429/429 [==============================] - 0s 823us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 13/100\n",
            "429/429 [==============================] - 0s 817us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 14/100\n",
            "429/429 [==============================] - 0s 823us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 15/100\n",
            "429/429 [==============================] - 0s 821us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 16/100\n",
            "429/429 [==============================] - 0s 818us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 17/100\n",
            "429/429 [==============================] - 0s 823us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 18/100\n",
            "429/429 [==============================] - 0s 825us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 19/100\n",
            "429/429 [==============================] - 0s 842us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 20/100\n",
            "429/429 [==============================] - 0s 837us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 21/100\n",
            "429/429 [==============================] - 0s 822us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 22/100\n",
            "429/429 [==============================] - 0s 822us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 23/100\n",
            "429/429 [==============================] - 0s 827us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 24/100\n",
            "429/429 [==============================] - 0s 821us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 25/100\n",
            "429/429 [==============================] - 0s 822us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 26/100\n",
            "429/429 [==============================] - 0s 819us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 27/100\n",
            "429/429 [==============================] - 0s 822us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 28/100\n",
            "429/429 [==============================] - 0s 827us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 29/100\n",
            "429/429 [==============================] - 0s 828us/step - loss: 0.9442 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 30/100\n",
            "429/429 [==============================] - 0s 823us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 31/100\n",
            "429/429 [==============================] - 0s 829us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 32/100\n",
            "429/429 [==============================] - 0s 846us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 33/100\n",
            "429/429 [==============================] - 0s 829us/step - loss: 0.9435 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 34/100\n",
            "429/429 [==============================] - 0s 839us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 35/100\n",
            "429/429 [==============================] - 0s 827us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 36/100\n",
            "429/429 [==============================] - 0s 831us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 37/100\n",
            "429/429 [==============================] - 0s 837us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 38/100\n",
            "429/429 [==============================] - 0s 828us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 39/100\n",
            "429/429 [==============================] - 0s 828us/step - loss: 0.9431 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 40/100\n",
            "429/429 [==============================] - 0s 839us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 41/100\n",
            "429/429 [==============================] - 0s 829us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 42/100\n",
            "429/429 [==============================] - 0s 825us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 43/100\n",
            "429/429 [==============================] - 0s 831us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 44/100\n",
            "429/429 [==============================] - 0s 824us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 45/100\n",
            "429/429 [==============================] - 0s 830us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 46/100\n",
            "429/429 [==============================] - 0s 830us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 47/100\n",
            "429/429 [==============================] - 0s 829us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 48/100\n",
            "429/429 [==============================] - 0s 830us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 49/100\n",
            "429/429 [==============================] - 0s 836us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 50/100\n",
            "429/429 [==============================] - 0s 819us/step - loss: 0.9426 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 51/100\n",
            "429/429 [==============================] - 0s 828us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 52/100\n",
            "429/429 [==============================] - 0s 839us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 53/100\n",
            "429/429 [==============================] - 0s 830us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 54/100\n",
            "429/429 [==============================] - 0s 828us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 55/100\n",
            "429/429 [==============================] - 0s 828us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 56/100\n",
            "429/429 [==============================] - 0s 842us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 57/100\n",
            "429/429 [==============================] - 0s 833us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 58/100\n",
            "429/429 [==============================] - 0s 833us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 59/100\n",
            "429/429 [==============================] - 0s 832us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 60/100\n",
            "429/429 [==============================] - 0s 848us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 61/100\n",
            "429/429 [==============================] - 0s 834us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 62/100\n",
            "429/429 [==============================] - 0s 838us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 63/100\n",
            "429/429 [==============================] - 0s 838us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 64/100\n",
            "429/429 [==============================] - 0s 832us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 65/100\n",
            "429/429 [==============================] - 0s 837us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 66/100\n",
            "429/429 [==============================] - 0s 845us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 67/100\n",
            "429/429 [==============================] - 0s 827us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 68/100\n",
            "429/429 [==============================] - 0s 836us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 69/100\n",
            "429/429 [==============================] - 0s 841us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 70/100\n",
            "429/429 [==============================] - 0s 827us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 71/100\n",
            "429/429 [==============================] - 0s 845us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 72/100\n",
            "429/429 [==============================] - 0s 830us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 73/100\n",
            "429/429 [==============================] - 0s 832us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 74/100\n",
            "429/429 [==============================] - 0s 853us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 75/100\n",
            "429/429 [==============================] - 0s 846us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 76/100\n",
            "429/429 [==============================] - 0s 834us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 77/100\n",
            "429/429 [==============================] - 0s 841us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 78/100\n",
            "429/429 [==============================] - 0s 843us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 79/100\n",
            "429/429 [==============================] - 0s 837us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 80/100\n",
            "429/429 [==============================] - 0s 843us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 81/100\n",
            "429/429 [==============================] - 0s 842us/step - loss: 0.9426 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 82/100\n",
            "429/429 [==============================] - 0s 861us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 83/100\n",
            "429/429 [==============================] - 0s 836us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 84/100\n",
            "429/429 [==============================] - 0s 831us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 85/100\n",
            "429/429 [==============================] - 0s 836us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 86/100\n",
            "429/429 [==============================] - 0s 835us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 87/100\n",
            "429/429 [==============================] - 0s 847us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 88/100\n",
            "429/429 [==============================] - 0s 842us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 89/100\n",
            "429/429 [==============================] - 0s 847us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 90/100\n",
            "429/429 [==============================] - 0s 834us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 91/100\n",
            "429/429 [==============================] - 0s 839us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 92/100\n",
            "429/429 [==============================] - 0s 836us/step - loss: 0.9422 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 93/100\n",
            "429/429 [==============================] - 0s 831us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 94/100\n",
            "429/429 [==============================] - 0s 859us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 95/100\n",
            "429/429 [==============================] - 0s 853us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 96/100\n",
            "429/429 [==============================] - 0s 839us/step - loss: 0.9419 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 97/100\n",
            "429/429 [==============================] - 0s 843us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 98/100\n",
            "429/429 [==============================] - 0s 858us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 99/100\n",
            "429/429 [==============================] - 0s 845us/step - loss: 0.9718 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 100/100\n",
            "429/429 [==============================] - 0s 854us/step - loss: 0.9718 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "[[ 0  4]\n",
            " [ 0 67]]\n",
            "Accuracy :  0.9436619718309859\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         4\n",
            "           1       0.94      1.00      0.97        67\n",
            "\n",
            "    accuracy                           0.94        71\n",
            "   macro avg       0.47      0.50      0.49        71\n",
            "weighted avg       0.89      0.94      0.92        71\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "model_4 (Model)              (None, 2)                 9148782   \n",
            "=================================================================\n",
            "Total params: 9,148,782\n",
            "Trainable params: 8,386\n",
            "Non-trainable params: 9,140,396\n",
            "_________________________________________________________________\n",
            "Train on 429 samples, validate on 71 samples\n",
            "Epoch 1/100\n",
            "429/429 [==============================] - 4s 9ms/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 2/100\n",
            "429/429 [==============================] - 0s 816us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 3/100\n",
            "429/429 [==============================] - 0s 821us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 4/100\n",
            "429/429 [==============================] - 0s 831us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 5/100\n",
            "429/429 [==============================] - 0s 817us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 6/100\n",
            "429/429 [==============================] - 0s 818us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 7/100\n",
            "429/429 [==============================] - 0s 828us/step - loss: 0.9718 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 8/100\n",
            "429/429 [==============================] - 0s 813us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 9/100\n",
            "429/429 [==============================] - 0s 825us/step - loss: 0.9718 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 10/100\n",
            "429/429 [==============================] - 0s 833us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 11/100\n",
            "429/429 [==============================] - 0s 821us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 12/100\n",
            "429/429 [==============================] - 0s 821us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 13/100\n",
            "429/429 [==============================] - 0s 836us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 14/100\n",
            "429/429 [==============================] - 0s 817us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 15/100\n",
            "429/429 [==============================] - 0s 823us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 16/100\n",
            "429/429 [==============================] - 0s 835us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 17/100\n",
            "429/429 [==============================] - 0s 822us/step - loss: 0.9428 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 18/100\n",
            "429/429 [==============================] - 0s 828us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 19/100\n",
            "429/429 [==============================] - 0s 832us/step - loss: 0.9718 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 20/100\n",
            "429/429 [==============================] - 0s 846us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 21/100\n",
            "429/429 [==============================] - 0s 830us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 22/100\n",
            "429/429 [==============================] - 0s 832us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 23/100\n",
            "429/429 [==============================] - 0s 825us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 24/100\n",
            "429/429 [==============================] - 0s 825us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 25/100\n",
            "429/429 [==============================] - 0s 827us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 26/100\n",
            "429/429 [==============================] - 0s 822us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 27/100\n",
            "429/429 [==============================] - 0s 829us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 28/100\n",
            "429/429 [==============================] - 0s 840us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 29/100\n",
            "429/429 [==============================] - 0s 833us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 30/100\n",
            "429/429 [==============================] - 0s 827us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 31/100\n",
            "429/429 [==============================] - 0s 830us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 32/100\n",
            "429/429 [==============================] - 0s 833us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 33/100\n",
            "429/429 [==============================] - 0s 833us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 34/100\n",
            "429/429 [==============================] - 0s 830us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 35/100\n",
            "429/429 [==============================] - 0s 831us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 36/100\n",
            "429/429 [==============================] - 0s 837us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 37/100\n",
            "429/429 [==============================] - 0s 838us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 38/100\n",
            "429/429 [==============================] - 0s 826us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 39/100\n",
            "429/429 [==============================] - 0s 838us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 40/100\n",
            "429/429 [==============================] - 0s 829us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 41/100\n",
            "429/429 [==============================] - 0s 827us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 42/100\n",
            "429/429 [==============================] - 0s 829us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 43/100\n",
            "429/429 [==============================] - 0s 824us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 44/100\n",
            "429/429 [==============================] - 0s 833us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 45/100\n",
            "429/429 [==============================] - 0s 835us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 46/100\n",
            "429/429 [==============================] - 0s 837us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 47/100\n",
            "429/429 [==============================] - 0s 845us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 48/100\n",
            "429/429 [==============================] - 0s 847us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 49/100\n",
            "429/429 [==============================] - 0s 825us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 50/100\n",
            "429/429 [==============================] - 0s 833us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 51/100\n",
            "429/429 [==============================] - 0s 841us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 52/100\n",
            "429/429 [==============================] - 0s 839us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 53/100\n",
            "429/429 [==============================] - 0s 843us/step - loss: 0.9531 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 54/100\n",
            "429/429 [==============================] - 0s 835us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 55/100\n",
            "429/429 [==============================] - 0s 844us/step - loss: 0.9422 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 56/100\n",
            "429/429 [==============================] - 0s 843us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 57/100\n",
            "429/429 [==============================] - 0s 845us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 58/100\n",
            "429/429 [==============================] - 0s 840us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 59/100\n",
            "429/429 [==============================] - 0s 838us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 60/100\n",
            "429/429 [==============================] - 0s 844us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 61/100\n",
            "429/429 [==============================] - 0s 860us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 62/100\n",
            "429/429 [==============================] - 0s 845us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 63/100\n",
            "429/429 [==============================] - 0s 841us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 64/100\n",
            "429/429 [==============================] - 0s 845us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 65/100\n",
            "429/429 [==============================] - 0s 840us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 66/100\n",
            "429/429 [==============================] - 0s 837us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 67/100\n",
            "429/429 [==============================] - 0s 833us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 68/100\n",
            "429/429 [==============================] - 0s 839us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 69/100\n",
            "429/429 [==============================] - 0s 847us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 70/100\n",
            "429/429 [==============================] - 0s 845us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 71/100\n",
            "429/429 [==============================] - 0s 840us/step - loss: 0.9720 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 72/100\n",
            "429/429 [==============================] - 0s 841us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 73/100\n",
            "429/429 [==============================] - 0s 847us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 74/100\n",
            "429/429 [==============================] - 0s 831us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 75/100\n",
            "429/429 [==============================] - 0s 835us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 76/100\n",
            "429/429 [==============================] - 0s 842us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 77/100\n",
            "429/429 [==============================] - 0s 854us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 78/100\n",
            "429/429 [==============================] - 0s 853us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 79/100\n",
            "429/429 [==============================] - 0s 842us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 80/100\n",
            "429/429 [==============================] - 0s 838us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 81/100\n",
            "429/429 [==============================] - 0s 850us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 82/100\n",
            "429/429 [==============================] - 0s 842us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 83/100\n",
            "429/429 [==============================] - 0s 857us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 84/100\n",
            "429/429 [==============================] - 0s 837us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 85/100\n",
            "429/429 [==============================] - 0s 840us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 86/100\n",
            "429/429 [==============================] - 0s 852us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 87/100\n",
            "429/429 [==============================] - 0s 857us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 88/100\n",
            "429/429 [==============================] - 0s 843us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 89/100\n",
            "429/429 [==============================] - 0s 838us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 90/100\n",
            "429/429 [==============================] - 0s 839us/step - loss: 0.9423 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 91/100\n",
            "429/429 [==============================] - 0s 842us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 92/100\n",
            "429/429 [==============================] - 0s 854us/step - loss: 0.9716 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 93/100\n",
            "429/429 [==============================] - 0s 860us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 94/100\n",
            "429/429 [==============================] - 0s 846us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 95/100\n",
            "429/429 [==============================] - 0s 852us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 96/100\n",
            "429/429 [==============================] - 0s 848us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 97/100\n",
            "429/429 [==============================] - 0s 840us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 98/100\n",
            "429/429 [==============================] - 0s 841us/step - loss: 0.9717 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 99/100\n",
            "429/429 [==============================] - 0s 838us/step - loss: 0.9718 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "Epoch 100/100\n",
            "429/429 [==============================] - 0s 839us/step - loss: 0.9715 - acc: 0.9394 - val_loss: 0.9031 - val_acc: 0.9437\n",
            "[[ 0  4]\n",
            " [ 0 67]]\n",
            "Accuracy :  0.9436619718309859\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         4\n",
            "           1       0.94      1.00      0.97        67\n",
            "\n",
            "    accuracy                           0.94        71\n",
            "   macro avg       0.47      0.50      0.49        71\n",
            "weighted avg       0.89      0.94      0.92        71\n",
            "\n",
            "\n",
            "\n",
            "Ruggedness\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:257: UserWarning: After over-sampling, the number of samples (500) in class 1 will be larger than the number of samples in the majority class (class #0 -> 265)\n",
            "  n_samples_majority))\n",
            "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:257: UserWarning: After over-sampling, the number of samples (500) in class 0 will be larger than the number of samples in the majority class (class #0 -> 265)\n",
            "  n_samples_majority))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "model_2 (Model)              (None, 2)                 9148782   \n",
            "=================================================================\n",
            "Total params: 9,148,782\n",
            "Trainable params: 8,386\n",
            "Non-trainable params: 9,140,396\n",
            "_________________________________________________________________\n",
            "Train on 1000 samples, validate on 73 samples\n",
            "Epoch 1/100\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 5.4578 - acc: 0.5210 - val_loss: 6.6140 - val_acc: 0.5753\n",
            "Epoch 2/100\n",
            "1000/1000 [==============================] - 1s 766us/step - loss: 5.4281 - acc: 0.5010 - val_loss: 4.9529 - val_acc: 0.6027\n",
            "Epoch 3/100\n",
            "1000/1000 [==============================] - 1s 769us/step - loss: 4.7632 - acc: 0.5310 - val_loss: 6.0335 - val_acc: 0.5205\n",
            "Epoch 4/100\n",
            "1000/1000 [==============================] - 1s 770us/step - loss: 4.4327 - acc: 0.5270 - val_loss: 4.7060 - val_acc: 0.5342\n",
            "Epoch 5/100\n",
            "1000/1000 [==============================] - 1s 772us/step - loss: 3.8937 - acc: 0.5250 - val_loss: 4.5262 - val_acc: 0.5753\n",
            "Epoch 6/100\n",
            "1000/1000 [==============================] - 1s 776us/step - loss: 3.1950 - acc: 0.5390 - val_loss: 4.0239 - val_acc: 0.5890\n",
            "Epoch 7/100\n",
            "1000/1000 [==============================] - 1s 774us/step - loss: 3.0161 - acc: 0.5060 - val_loss: 3.7498 - val_acc: 0.6027\n",
            "Epoch 8/100\n",
            "1000/1000 [==============================] - 1s 765us/step - loss: 2.5246 - acc: 0.4940 - val_loss: 2.8892 - val_acc: 0.6164\n",
            "Epoch 9/100\n",
            "1000/1000 [==============================] - 1s 766us/step - loss: 1.8714 - acc: 0.4810 - val_loss: 2.8868 - val_acc: 0.6164\n",
            "Epoch 10/100\n",
            "1000/1000 [==============================] - 1s 769us/step - loss: 1.7230 - acc: 0.5030 - val_loss: 2.6126 - val_acc: 0.6164\n",
            "Epoch 11/100\n",
            "1000/1000 [==============================] - 1s 767us/step - loss: 1.5754 - acc: 0.4980 - val_loss: 1.9320 - val_acc: 0.6027\n",
            "Epoch 12/100\n",
            "1000/1000 [==============================] - 1s 768us/step - loss: 1.1611 - acc: 0.4970 - val_loss: 1.6131 - val_acc: 0.3973\n",
            "Epoch 13/100\n",
            "1000/1000 [==============================] - 1s 774us/step - loss: 1.0350 - acc: 0.4860 - val_loss: 1.4837 - val_acc: 0.4110\n",
            "Epoch 14/100\n",
            "1000/1000 [==============================] - 1s 774us/step - loss: 1.0155 - acc: 0.4740 - val_loss: 1.6962 - val_acc: 0.3836\n",
            "Epoch 15/100\n",
            "1000/1000 [==============================] - 1s 775us/step - loss: 0.9679 - acc: 0.4790 - val_loss: 0.8757 - val_acc: 0.6027\n",
            "Epoch 16/100\n",
            "1000/1000 [==============================] - 1s 775us/step - loss: 0.7600 - acc: 0.4900 - val_loss: 0.6914 - val_acc: 0.6027\n",
            "Epoch 17/100\n",
            "1000/1000 [==============================] - 1s 773us/step - loss: 0.7224 - acc: 0.4820 - val_loss: 0.6956 - val_acc: 0.3836\n",
            "Epoch 18/100\n",
            "1000/1000 [==============================] - 1s 780us/step - loss: 0.7375 - acc: 0.4780 - val_loss: 0.6898 - val_acc: 0.6027\n",
            "Epoch 19/100\n",
            "1000/1000 [==============================] - 1s 777us/step - loss: 0.7223 - acc: 0.4830 - val_loss: 0.6976 - val_acc: 0.3836\n",
            "Epoch 20/100\n",
            "1000/1000 [==============================] - 1s 779us/step - loss: 0.7069 - acc: 0.4840 - val_loss: 0.6963 - val_acc: 0.3836\n",
            "Epoch 21/100\n",
            "1000/1000 [==============================] - 1s 771us/step - loss: 0.7537 - acc: 0.5000 - val_loss: 0.6979 - val_acc: 0.3836\n",
            "Epoch 22/100\n",
            "1000/1000 [==============================] - 1s 778us/step - loss: 0.7222 - acc: 0.4780 - val_loss: 0.6947 - val_acc: 0.6027\n",
            "Epoch 23/100\n",
            "1000/1000 [==============================] - 1s 774us/step - loss: 0.7307 - acc: 0.4930 - val_loss: 0.6973 - val_acc: 0.3836\n",
            "Epoch 24/100\n",
            "1000/1000 [==============================] - 1s 776us/step - loss: 0.7130 - acc: 0.5000 - val_loss: 0.6938 - val_acc: 0.3836\n",
            "Epoch 25/100\n",
            "1000/1000 [==============================] - 1s 773us/step - loss: 0.7063 - acc: 0.4680 - val_loss: 0.6954 - val_acc: 0.3836\n",
            "Epoch 26/100\n",
            "1000/1000 [==============================] - 1s 777us/step - loss: 0.7231 - acc: 0.4950 - val_loss: 0.6922 - val_acc: 0.6164\n",
            "Epoch 27/100\n",
            "1000/1000 [==============================] - 1s 780us/step - loss: 0.7227 - acc: 0.4810 - val_loss: 0.6924 - val_acc: 0.6164\n",
            "Epoch 28/100\n",
            "1000/1000 [==============================] - 1s 782us/step - loss: 0.7361 - acc: 0.4870 - val_loss: 0.6740 - val_acc: 0.6164\n",
            "Epoch 29/100\n",
            "1000/1000 [==============================] - 1s 773us/step - loss: 0.7691 - acc: 0.4870 - val_loss: 0.6815 - val_acc: 0.6164\n",
            "Epoch 30/100\n",
            "1000/1000 [==============================] - 1s 779us/step - loss: 0.7118 - acc: 0.4840 - val_loss: 0.6898 - val_acc: 0.6164\n",
            "Epoch 31/100\n",
            "1000/1000 [==============================] - 1s 783us/step - loss: 0.6939 - acc: 0.4840 - val_loss: 0.6933 - val_acc: 0.3836\n",
            "Epoch 32/100\n",
            "1000/1000 [==============================] - 1s 784us/step - loss: 0.6931 - acc: 0.4690 - val_loss: 0.6931 - val_acc: 0.6164\n",
            "Epoch 33/100\n",
            "1000/1000 [==============================] - 1s 775us/step - loss: 0.6953 - acc: 0.4610 - val_loss: 0.6921 - val_acc: 0.6164\n",
            "Epoch 34/100\n",
            "1000/1000 [==============================] - 1s 787us/step - loss: 0.6934 - acc: 0.4750 - val_loss: 0.6950 - val_acc: 0.3836\n",
            "Epoch 35/100\n",
            "1000/1000 [==============================] - 1s 784us/step - loss: 0.7154 - acc: 0.4950 - val_loss: 0.6936 - val_acc: 0.3836\n",
            "Epoch 36/100\n",
            "1000/1000 [==============================] - 1s 787us/step - loss: 0.6950 - acc: 0.5000 - val_loss: 0.6917 - val_acc: 0.6164\n",
            "Epoch 37/100\n",
            "1000/1000 [==============================] - 1s 788us/step - loss: 0.6946 - acc: 0.5000 - val_loss: 0.6917 - val_acc: 0.6164\n",
            "Epoch 38/100\n",
            "1000/1000 [==============================] - 1s 785us/step - loss: 0.6934 - acc: 0.5010 - val_loss: 0.6920 - val_acc: 0.6164\n",
            "Epoch 39/100\n",
            "1000/1000 [==============================] - 1s 790us/step - loss: 0.7082 - acc: 0.4990 - val_loss: 0.6972 - val_acc: 0.3836\n",
            "Epoch 40/100\n",
            "1000/1000 [==============================] - 1s 780us/step - loss: 0.6933 - acc: 0.4880 - val_loss: 0.6933 - val_acc: 0.3836\n",
            "Epoch 41/100\n",
            "1000/1000 [==============================] - 1s 783us/step - loss: 0.6945 - acc: 0.5000 - val_loss: 0.6940 - val_acc: 0.3836\n",
            "Epoch 42/100\n",
            "1000/1000 [==============================] - 1s 786us/step - loss: 0.6922 - acc: 0.4810 - val_loss: 0.6925 - val_acc: 0.6164\n",
            "Epoch 43/100\n",
            "1000/1000 [==============================] - 1s 790us/step - loss: 0.6930 - acc: 0.4960 - val_loss: 0.6947 - val_acc: 0.3836\n",
            "Epoch 44/100\n",
            "1000/1000 [==============================] - 1s 787us/step - loss: 0.7232 - acc: 0.4960 - val_loss: 0.6914 - val_acc: 0.6164\n",
            "Epoch 45/100\n",
            "1000/1000 [==============================] - 1s 797us/step - loss: 0.6973 - acc: 0.4990 - val_loss: 0.6900 - val_acc: 0.6164\n",
            "Epoch 46/100\n",
            "1000/1000 [==============================] - 1s 785us/step - loss: 0.6931 - acc: 0.4880 - val_loss: 0.6947 - val_acc: 0.3836\n",
            "Epoch 47/100\n",
            "1000/1000 [==============================] - 1s 781us/step - loss: 0.7086 - acc: 0.5130 - val_loss: 0.6884 - val_acc: 0.6164\n",
            "Epoch 48/100\n",
            "1000/1000 [==============================] - 1s 781us/step - loss: 0.7075 - acc: 0.5020 - val_loss: 0.6902 - val_acc: 0.6164\n",
            "Epoch 49/100\n",
            "1000/1000 [==============================] - 1s 780us/step - loss: 0.6937 - acc: 0.4990 - val_loss: 0.6981 - val_acc: 0.3836\n",
            "Epoch 50/100\n",
            "1000/1000 [==============================] - 1s 784us/step - loss: 0.6919 - acc: 0.4900 - val_loss: 0.6905 - val_acc: 0.6164\n",
            "Epoch 51/100\n",
            "1000/1000 [==============================] - 1s 782us/step - loss: 0.7535 - acc: 0.4800 - val_loss: 0.6931 - val_acc: 0.6164\n",
            "Epoch 52/100\n",
            "1000/1000 [==============================] - 1s 780us/step - loss: 0.7261 - acc: 0.4790 - val_loss: 0.6919 - val_acc: 0.6164\n",
            "Epoch 53/100\n",
            "1000/1000 [==============================] - 1s 784us/step - loss: 0.7093 - acc: 0.5000 - val_loss: 0.6926 - val_acc: 0.6164\n",
            "Epoch 54/100\n",
            "1000/1000 [==============================] - 1s 785us/step - loss: 0.6934 - acc: 0.4970 - val_loss: 0.6947 - val_acc: 0.3836\n",
            "Epoch 55/100\n",
            "1000/1000 [==============================] - 1s 785us/step - loss: 0.7082 - acc: 0.4940 - val_loss: 0.6925 - val_acc: 0.6164\n",
            "Epoch 56/100\n",
            "1000/1000 [==============================] - 1s 779us/step - loss: 0.7235 - acc: 0.4800 - val_loss: 0.6925 - val_acc: 0.6164\n",
            "Epoch 57/100\n",
            "1000/1000 [==============================] - 1s 779us/step - loss: 0.7229 - acc: 0.4770 - val_loss: 0.6932 - val_acc: 0.3836\n",
            "Epoch 58/100\n",
            "1000/1000 [==============================] - 1s 777us/step - loss: 0.7521 - acc: 0.4800 - val_loss: 0.6943 - val_acc: 0.3836\n",
            "Epoch 59/100\n",
            "1000/1000 [==============================] - 1s 784us/step - loss: 0.7792 - acc: 0.4770 - val_loss: 0.6927 - val_acc: 0.6164\n",
            "Epoch 60/100\n",
            "1000/1000 [==============================] - 1s 780us/step - loss: 0.7235 - acc: 0.4800 - val_loss: 0.6923 - val_acc: 0.6164\n",
            "Epoch 61/100\n",
            "1000/1000 [==============================] - 1s 779us/step - loss: 0.6949 - acc: 0.4710 - val_loss: 0.6913 - val_acc: 0.6164\n",
            "Epoch 62/100\n",
            "1000/1000 [==============================] - 1s 773us/step - loss: 0.7085 - acc: 0.4600 - val_loss: 0.6926 - val_acc: 0.6164\n",
            "Epoch 63/100\n",
            "1000/1000 [==============================] - 1s 781us/step - loss: 0.7284 - acc: 0.5000 - val_loss: 0.6929 - val_acc: 0.6164\n",
            "Epoch 64/100\n",
            "1000/1000 [==============================] - 1s 778us/step - loss: 0.6937 - acc: 0.4660 - val_loss: 0.6928 - val_acc: 0.6164\n",
            "Epoch 65/100\n",
            "1000/1000 [==============================] - 1s 783us/step - loss: 0.6936 - acc: 0.4830 - val_loss: 0.6983 - val_acc: 0.3836\n",
            "Epoch 66/100\n",
            "1000/1000 [==============================] - 1s 774us/step - loss: 0.6938 - acc: 0.4850 - val_loss: 0.6938 - val_acc: 0.3836\n",
            "Epoch 67/100\n",
            "1000/1000 [==============================] - 1s 775us/step - loss: 0.6943 - acc: 0.4680 - val_loss: 0.6986 - val_acc: 0.3836\n",
            "Epoch 68/100\n",
            "1000/1000 [==============================] - 1s 780us/step - loss: 0.6938 - acc: 0.4750 - val_loss: 0.6932 - val_acc: 0.3836\n",
            "Epoch 69/100\n",
            "1000/1000 [==============================] - 1s 775us/step - loss: 0.6928 - acc: 0.4810 - val_loss: 0.6916 - val_acc: 0.6164\n",
            "Epoch 70/100\n",
            "1000/1000 [==============================] - 1s 778us/step - loss: 0.6945 - acc: 0.4840 - val_loss: 0.6951 - val_acc: 0.3836\n",
            "Epoch 71/100\n",
            "1000/1000 [==============================] - 1s 770us/step - loss: 0.6952 - acc: 0.4870 - val_loss: 0.6912 - val_acc: 0.6164\n",
            "Epoch 72/100\n",
            "1000/1000 [==============================] - 1s 777us/step - loss: 0.6934 - acc: 0.4780 - val_loss: 0.6959 - val_acc: 0.3836\n",
            "Epoch 73/100\n",
            "1000/1000 [==============================] - 1s 773us/step - loss: 0.7306 - acc: 0.4860 - val_loss: 0.6934 - val_acc: 0.3836\n",
            "Epoch 74/100\n",
            "1000/1000 [==============================] - 1s 777us/step - loss: 0.6935 - acc: 0.4900 - val_loss: 0.6920 - val_acc: 0.6164\n",
            "Epoch 75/100\n",
            "1000/1000 [==============================] - 1s 776us/step - loss: 0.6925 - acc: 0.4690 - val_loss: 0.6912 - val_acc: 0.6164\n",
            "Epoch 76/100\n",
            "1000/1000 [==============================] - 1s 781us/step - loss: 0.7083 - acc: 0.5010 - val_loss: 0.6977 - val_acc: 0.3836\n",
            "Epoch 77/100\n",
            "1000/1000 [==============================] - 1s 774us/step - loss: 0.7380 - acc: 0.4770 - val_loss: 0.6935 - val_acc: 0.3836\n",
            "Epoch 78/100\n",
            "1000/1000 [==============================] - 1s 779us/step - loss: 0.7084 - acc: 0.4890 - val_loss: 0.6910 - val_acc: 0.6164\n",
            "Epoch 79/100\n",
            "1000/1000 [==============================] - 1s 772us/step - loss: 0.6935 - acc: 0.5000 - val_loss: 0.6910 - val_acc: 0.6164\n",
            "Epoch 80/100\n",
            "1000/1000 [==============================] - 1s 776us/step - loss: 0.6934 - acc: 0.4950 - val_loss: 0.6911 - val_acc: 0.6164\n",
            "Epoch 81/100\n",
            "1000/1000 [==============================] - 1s 778us/step - loss: 0.6935 - acc: 0.4940 - val_loss: 0.6943 - val_acc: 0.3836\n",
            "Epoch 82/100\n",
            "1000/1000 [==============================] - 1s 775us/step - loss: 0.6938 - acc: 0.5030 - val_loss: 0.6912 - val_acc: 0.6164\n",
            "Epoch 83/100\n",
            "1000/1000 [==============================] - 1s 771us/step - loss: 0.7090 - acc: 0.4760 - val_loss: 0.6909 - val_acc: 0.6164\n",
            "Epoch 84/100\n",
            "1000/1000 [==============================] - 1s 766us/step - loss: 0.6938 - acc: 0.5000 - val_loss: 0.6919 - val_acc: 0.6164\n",
            "Epoch 85/100\n",
            "1000/1000 [==============================] - 1s 783us/step - loss: 0.6934 - acc: 0.4860 - val_loss: 0.6943 - val_acc: 0.3836\n",
            "Epoch 86/100\n",
            "1000/1000 [==============================] - 1s 772us/step - loss: 0.6938 - acc: 0.5000 - val_loss: 0.6946 - val_acc: 0.3836\n",
            "Epoch 87/100\n",
            "1000/1000 [==============================] - 1s 768us/step - loss: 0.6943 - acc: 0.4940 - val_loss: 0.6918 - val_acc: 0.6164\n",
            "Epoch 88/100\n",
            "1000/1000 [==============================] - 1s 771us/step - loss: 0.7082 - acc: 0.4760 - val_loss: 0.6923 - val_acc: 0.6164\n",
            "Epoch 89/100\n",
            "1000/1000 [==============================] - 1s 773us/step - loss: 0.6941 - acc: 0.4900 - val_loss: 0.6934 - val_acc: 0.3836\n",
            "Epoch 90/100\n",
            "1000/1000 [==============================] - 1s 769us/step - loss: 0.6934 - acc: 0.4860 - val_loss: 0.6931 - val_acc: 0.6164\n",
            "Epoch 91/100\n",
            "1000/1000 [==============================] - 1s 771us/step - loss: 0.6934 - acc: 0.4790 - val_loss: 0.6930 - val_acc: 0.6164\n",
            "Epoch 92/100\n",
            "1000/1000 [==============================] - 1s 774us/step - loss: 0.6936 - acc: 0.5030 - val_loss: 0.6937 - val_acc: 0.3836\n",
            "Epoch 93/100\n",
            "1000/1000 [==============================] - 1s 779us/step - loss: 0.6935 - acc: 0.5030 - val_loss: 0.6914 - val_acc: 0.6164\n",
            "Epoch 94/100\n",
            "1000/1000 [==============================] - 1s 771us/step - loss: 0.6958 - acc: 0.4860 - val_loss: 0.6943 - val_acc: 0.3836\n",
            "Epoch 95/100\n",
            "1000/1000 [==============================] - 1s 769us/step - loss: 0.6937 - acc: 0.5000 - val_loss: 0.6960 - val_acc: 0.3836\n",
            "Epoch 96/100\n",
            "1000/1000 [==============================] - 1s 768us/step - loss: 0.7072 - acc: 0.5060 - val_loss: 0.6904 - val_acc: 0.6164\n",
            "Epoch 97/100\n",
            "1000/1000 [==============================] - 1s 766us/step - loss: 0.6929 - acc: 0.4740 - val_loss: 0.6918 - val_acc: 0.6164\n",
            "Epoch 98/100\n",
            "1000/1000 [==============================] - 1s 771us/step - loss: 0.6938 - acc: 0.4770 - val_loss: 0.6884 - val_acc: 0.6164\n",
            "Epoch 99/100\n",
            "1000/1000 [==============================] - 1s 774us/step - loss: 0.6933 - acc: 0.5000 - val_loss: 0.6927 - val_acc: 0.6164\n",
            "Epoch 100/100\n",
            "1000/1000 [==============================] - 1s 777us/step - loss: 0.6938 - acc: 0.4830 - val_loss: 0.6931 - val_acc: 0.6164\n",
            "[[45  0]\n",
            " [28  0]]\n",
            "Accuracy :  0.6164383561643836\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      1.00      0.76        45\n",
            "           1       0.00      0.00      0.00        28\n",
            "\n",
            "    accuracy                           0.62        73\n",
            "   macro avg       0.31      0.50      0.38        73\n",
            "weighted avg       0.38      0.62      0.47        73\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:257: UserWarning: After over-sampling, the number of samples (500) in class 1 will be larger than the number of samples in the majority class (class #0 -> 265)\n",
            "  n_samples_majority))\n",
            "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:257: UserWarning: After over-sampling, the number of samples (500) in class 0 will be larger than the number of samples in the majority class (class #0 -> 265)\n",
            "  n_samples_majority))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "model_2 (Model)              (None, 2)                 9148782   \n",
            "=================================================================\n",
            "Total params: 9,148,782\n",
            "Trainable params: 8,386\n",
            "Non-trainable params: 9,140,396\n",
            "_________________________________________________________________\n",
            "Train on 1000 samples, validate on 72 samples\n",
            "Epoch 1/100\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.6940 - acc: 0.4950 - val_loss: 0.6954 - val_acc: 0.3750\n",
            "Epoch 2/100\n",
            "1000/1000 [==============================] - 1s 758us/step - loss: 0.6937 - acc: 0.4820 - val_loss: 0.6920 - val_acc: 0.6250\n",
            "Epoch 3/100\n",
            "1000/1000 [==============================] - 1s 775us/step - loss: 0.6936 - acc: 0.4820 - val_loss: 0.6947 - val_acc: 0.3750\n",
            "Epoch 4/100\n",
            "1000/1000 [==============================] - 1s 764us/step - loss: 0.6940 - acc: 0.4820 - val_loss: 0.6984 - val_acc: 0.3750\n",
            "Epoch 5/100\n",
            "1000/1000 [==============================] - 1s 764us/step - loss: 0.6935 - acc: 0.4830 - val_loss: 0.6935 - val_acc: 0.3750\n",
            "Epoch 6/100\n",
            "1000/1000 [==============================] - 1s 769us/step - loss: 0.6938 - acc: 0.4800 - val_loss: 0.6994 - val_acc: 0.3750\n",
            "Epoch 7/100\n",
            "1000/1000 [==============================] - 1s 763us/step - loss: 0.6939 - acc: 0.4890 - val_loss: 0.6919 - val_acc: 0.6250\n",
            "Epoch 8/100\n",
            "1000/1000 [==============================] - 1s 768us/step - loss: 0.6936 - acc: 0.5000 - val_loss: 0.6919 - val_acc: 0.6250\n",
            "Epoch 9/100\n",
            "1000/1000 [==============================] - 1s 769us/step - loss: 0.6932 - acc: 0.4690 - val_loss: 0.6982 - val_acc: 0.3750\n",
            "Epoch 10/100\n",
            "1000/1000 [==============================] - 1s 769us/step - loss: 0.6935 - acc: 0.4780 - val_loss: 0.6961 - val_acc: 0.3750\n",
            "Epoch 11/100\n",
            "1000/1000 [==============================] - 1s 768us/step - loss: 0.6939 - acc: 0.4760 - val_loss: 0.6958 - val_acc: 0.3750\n",
            "Epoch 12/100\n",
            "1000/1000 [==============================] - 1s 764us/step - loss: 0.6935 - acc: 0.4870 - val_loss: 0.6941 - val_acc: 0.3750\n",
            "Epoch 13/100\n",
            "1000/1000 [==============================] - 1s 769us/step - loss: 0.6937 - acc: 0.4900 - val_loss: 0.6932 - val_acc: 0.3750\n",
            "Epoch 14/100\n",
            "1000/1000 [==============================] - 1s 772us/step - loss: 0.6926 - acc: 0.4800 - val_loss: 0.6964 - val_acc: 0.3750\n",
            "Epoch 15/100\n",
            "1000/1000 [==============================] - 1s 778us/step - loss: 0.7412 - acc: 0.4970 - val_loss: 0.6938 - val_acc: 0.3750\n",
            "Epoch 16/100\n",
            "1000/1000 [==============================] - 1s 767us/step - loss: 0.7089 - acc: 0.4780 - val_loss: 0.6939 - val_acc: 0.3750\n",
            "Epoch 17/100\n",
            "1000/1000 [==============================] - 1s 780us/step - loss: 0.6937 - acc: 0.4720 - val_loss: 0.6904 - val_acc: 0.6250\n",
            "Epoch 18/100\n",
            "1000/1000 [==============================] - 1s 769us/step - loss: 0.7092 - acc: 0.4860 - val_loss: 0.6947 - val_acc: 0.3750\n",
            "Epoch 19/100\n",
            "1000/1000 [==============================] - 1s 776us/step - loss: 0.6938 - acc: 0.4870 - val_loss: 0.6932 - val_acc: 0.3750\n",
            "Epoch 20/100\n",
            "1000/1000 [==============================] - 1s 778us/step - loss: 0.6936 - acc: 0.4830 - val_loss: 0.6955 - val_acc: 0.3750\n",
            "Epoch 21/100\n",
            "1000/1000 [==============================] - 1s 770us/step - loss: 0.6936 - acc: 0.4810 - val_loss: 0.6892 - val_acc: 0.6250\n",
            "Epoch 22/100\n",
            "1000/1000 [==============================] - 1s 769us/step - loss: 0.6940 - acc: 0.4830 - val_loss: 0.6949 - val_acc: 0.3750\n",
            "Epoch 23/100\n",
            "1000/1000 [==============================] - 1s 776us/step - loss: 0.7363 - acc: 0.4900 - val_loss: 0.6935 - val_acc: 0.3750\n",
            "Epoch 24/100\n",
            "1000/1000 [==============================] - 1s 773us/step - loss: 0.7213 - acc: 0.5040 - val_loss: 0.6903 - val_acc: 0.6250\n",
            "Epoch 25/100\n",
            "1000/1000 [==============================] - 1s 774us/step - loss: 0.6935 - acc: 0.5100 - val_loss: 0.6991 - val_acc: 0.3750\n",
            "Epoch 26/100\n",
            "1000/1000 [==============================] - 1s 774us/step - loss: 0.6938 - acc: 0.4800 - val_loss: 0.6921 - val_acc: 0.6250\n",
            "Epoch 27/100\n",
            "1000/1000 [==============================] - 1s 777us/step - loss: 0.6934 - acc: 0.4880 - val_loss: 0.6921 - val_acc: 0.6250\n",
            "Epoch 28/100\n",
            "1000/1000 [==============================] - 1s 778us/step - loss: 0.6934 - acc: 0.4920 - val_loss: 0.6934 - val_acc: 0.3750\n",
            "Epoch 29/100\n",
            "1000/1000 [==============================] - 1s 779us/step - loss: 0.6929 - acc: 0.4770 - val_loss: 0.6948 - val_acc: 0.3750\n",
            "Epoch 30/100\n",
            "1000/1000 [==============================] - 1s 774us/step - loss: 0.6935 - acc: 0.5000 - val_loss: 0.6960 - val_acc: 0.3750\n",
            "Epoch 31/100\n",
            "1000/1000 [==============================] - 1s 780us/step - loss: 0.6938 - acc: 0.4780 - val_loss: 0.6961 - val_acc: 0.3750\n",
            "Epoch 32/100\n",
            "1000/1000 [==============================] - 1s 776us/step - loss: 0.6935 - acc: 0.4880 - val_loss: 0.6941 - val_acc: 0.3750\n",
            "Epoch 33/100\n",
            "1000/1000 [==============================] - 1s 779us/step - loss: 0.7081 - acc: 0.5000 - val_loss: 0.6941 - val_acc: 0.3889\n",
            "Epoch 34/100\n",
            "1000/1000 [==============================] - 1s 784us/step - loss: 0.7092 - acc: 0.4860 - val_loss: 0.6895 - val_acc: 0.6250\n",
            "Epoch 35/100\n",
            "1000/1000 [==============================] - 1s 776us/step - loss: 0.6944 - acc: 0.4860 - val_loss: 0.6932 - val_acc: 0.3889\n",
            "Epoch 36/100\n",
            "1000/1000 [==============================] - 1s 783us/step - loss: 0.6930 - acc: 0.5000 - val_loss: 0.6855 - val_acc: 0.6250\n",
            "Epoch 37/100\n",
            "1000/1000 [==============================] - 1s 786us/step - loss: 0.7033 - acc: 0.4960 - val_loss: 0.6967 - val_acc: 0.3750\n",
            "Epoch 38/100\n",
            "1000/1000 [==============================] - 1s 779us/step - loss: 0.6927 - acc: 0.5010 - val_loss: 0.6946 - val_acc: 0.3750\n",
            "Epoch 39/100\n",
            "1000/1000 [==============================] - 1s 780us/step - loss: 0.6943 - acc: 0.5000 - val_loss: 0.6972 - val_acc: 0.3750\n",
            "Epoch 40/100\n",
            "1000/1000 [==============================] - 1s 782us/step - loss: 0.6935 - acc: 0.4920 - val_loss: 0.6919 - val_acc: 0.6250\n",
            "Epoch 41/100\n",
            "1000/1000 [==============================] - 1s 782us/step - loss: 0.6941 - acc: 0.4800 - val_loss: 0.6946 - val_acc: 0.3750\n",
            "Epoch 42/100\n",
            "1000/1000 [==============================] - 1s 785us/step - loss: 0.6932 - acc: 0.4860 - val_loss: 0.6923 - val_acc: 0.6250\n",
            "Epoch 43/100\n",
            "1000/1000 [==============================] - 1s 777us/step - loss: 0.7241 - acc: 0.5080 - val_loss: 0.6970 - val_acc: 0.3750\n",
            "Epoch 44/100\n",
            "1000/1000 [==============================] - 1s 784us/step - loss: 0.6939 - acc: 0.4670 - val_loss: 0.6950 - val_acc: 0.3750\n",
            "Epoch 45/100\n",
            "1000/1000 [==============================] - 1s 784us/step - loss: 0.6935 - acc: 0.5000 - val_loss: 0.6963 - val_acc: 0.3750\n",
            "Epoch 46/100\n",
            "1000/1000 [==============================] - 1s 788us/step - loss: 0.6934 - acc: 0.5000 - val_loss: 0.6941 - val_acc: 0.3750\n",
            "Epoch 47/100\n",
            "1000/1000 [==============================] - 1s 779us/step - loss: 0.6949 - acc: 0.4900 - val_loss: 0.6925 - val_acc: 0.6250\n",
            "Epoch 48/100\n",
            "1000/1000 [==============================] - 1s 788us/step - loss: 0.6935 - acc: 0.4920 - val_loss: 0.6927 - val_acc: 0.6250\n",
            "Epoch 49/100\n",
            "1000/1000 [==============================] - 1s 781us/step - loss: 0.6933 - acc: 0.4730 - val_loss: 0.6931 - val_acc: 0.6250\n",
            "Epoch 50/100\n",
            "1000/1000 [==============================] - 1s 792us/step - loss: 0.7222 - acc: 0.4830 - val_loss: 0.7973 - val_acc: 0.6250\n",
            "Epoch 51/100\n",
            "1000/1000 [==============================] - 1s 779us/step - loss: 0.7925 - acc: 0.4900 - val_loss: 0.6939 - val_acc: 0.3750\n",
            "Epoch 52/100\n",
            "1000/1000 [==============================] - 1s 784us/step - loss: 0.6940 - acc: 0.5000 - val_loss: 0.6950 - val_acc: 0.3750\n",
            "Epoch 53/100\n",
            "1000/1000 [==============================] - 1s 781us/step - loss: 0.7091 - acc: 0.4920 - val_loss: 0.6889 - val_acc: 0.6250\n",
            "Epoch 54/100\n",
            "1000/1000 [==============================] - 1s 781us/step - loss: 0.7085 - acc: 0.4750 - val_loss: 0.6902 - val_acc: 0.6250\n",
            "Epoch 55/100\n",
            "1000/1000 [==============================] - 1s 780us/step - loss: 0.6935 - acc: 0.4850 - val_loss: 0.6957 - val_acc: 0.3750\n",
            "Epoch 56/100\n",
            "1000/1000 [==============================] - 1s 778us/step - loss: 0.7089 - acc: 0.4990 - val_loss: 0.6906 - val_acc: 0.6250\n",
            "Epoch 57/100\n",
            "1000/1000 [==============================] - 1s 777us/step - loss: 0.6936 - acc: 0.4840 - val_loss: 0.6963 - val_acc: 0.3750\n",
            "Epoch 58/100\n",
            "1000/1000 [==============================] - 1s 783us/step - loss: 0.6933 - acc: 0.4950 - val_loss: 0.6920 - val_acc: 0.6250\n",
            "Epoch 59/100\n",
            "1000/1000 [==============================] - 1s 784us/step - loss: 0.6939 - acc: 0.4790 - val_loss: 0.6888 - val_acc: 0.6250\n",
            "Epoch 60/100\n",
            "1000/1000 [==============================] - 1s 772us/step - loss: 0.6937 - acc: 0.5000 - val_loss: 0.6945 - val_acc: 0.3750\n",
            "Epoch 61/100\n",
            "1000/1000 [==============================] - 1s 784us/step - loss: 0.6939 - acc: 0.4890 - val_loss: 0.6919 - val_acc: 0.6250\n",
            "Epoch 62/100\n",
            "1000/1000 [==============================] - 1s 778us/step - loss: 0.6938 - acc: 0.4780 - val_loss: 0.6940 - val_acc: 0.3750\n",
            "Epoch 63/100\n",
            "1000/1000 [==============================] - 1s 783us/step - loss: 0.6933 - acc: 0.4960 - val_loss: 0.6907 - val_acc: 0.6250\n",
            "Epoch 64/100\n",
            "1000/1000 [==============================] - 1s 781us/step - loss: 0.6938 - acc: 0.4810 - val_loss: 0.6945 - val_acc: 0.3750\n",
            "Epoch 65/100\n",
            "1000/1000 [==============================] - 1s 777us/step - loss: 0.6934 - acc: 0.4890 - val_loss: 0.6930 - val_acc: 0.6250\n",
            "Epoch 66/100\n",
            "1000/1000 [==============================] - 1s 784us/step - loss: 0.6936 - acc: 0.4800 - val_loss: 0.6919 - val_acc: 0.6250\n",
            "Epoch 67/100\n",
            "1000/1000 [==============================] - 1s 777us/step - loss: 0.6935 - acc: 0.4820 - val_loss: 0.6923 - val_acc: 0.6250\n",
            "Epoch 68/100\n",
            "1000/1000 [==============================] - 1s 780us/step - loss: 0.6935 - acc: 0.4910 - val_loss: 0.6937 - val_acc: 0.3750\n",
            "Epoch 69/100\n",
            "1000/1000 [==============================] - 1s 772us/step - loss: 0.6936 - acc: 0.5000 - val_loss: 0.6952 - val_acc: 0.3750\n",
            "Epoch 70/100\n",
            "1000/1000 [==============================] - 1s 783us/step - loss: 0.6936 - acc: 0.4690 - val_loss: 0.6931 - val_acc: 0.6250\n",
            "Epoch 71/100\n",
            "1000/1000 [==============================] - 1s 777us/step - loss: 0.6936 - acc: 0.4840 - val_loss: 0.6890 - val_acc: 0.6250\n",
            "Epoch 72/100\n",
            "1000/1000 [==============================] - 1s 774us/step - loss: 0.6932 - acc: 0.4960 - val_loss: 0.6947 - val_acc: 0.3750\n",
            "Epoch 73/100\n",
            "1000/1000 [==============================] - 1s 781us/step - loss: 0.6934 - acc: 0.4760 - val_loss: 0.6965 - val_acc: 0.3750\n",
            "Epoch 74/100\n",
            "1000/1000 [==============================] - 1s 775us/step - loss: 0.6933 - acc: 0.5000 - val_loss: 0.6928 - val_acc: 0.6250\n",
            "Epoch 75/100\n",
            "1000/1000 [==============================] - 1s 782us/step - loss: 0.6938 - acc: 0.5000 - val_loss: 0.6889 - val_acc: 0.6250\n",
            "Epoch 76/100\n",
            "1000/1000 [==============================] - 1s 775us/step - loss: 0.6994 - acc: 0.4610 - val_loss: 0.6971 - val_acc: 0.3750\n",
            "Epoch 77/100\n",
            "1000/1000 [==============================] - 1s 777us/step - loss: 0.6936 - acc: 0.4780 - val_loss: 0.6954 - val_acc: 0.3750\n",
            "Epoch 78/100\n",
            "1000/1000 [==============================] - 1s 775us/step - loss: 0.6935 - acc: 0.4850 - val_loss: 0.6897 - val_acc: 0.6250\n",
            "Epoch 79/100\n",
            "1000/1000 [==============================] - 1s 774us/step - loss: 0.6937 - acc: 0.4980 - val_loss: 0.6981 - val_acc: 0.3750\n",
            "Epoch 80/100\n",
            "1000/1000 [==============================] - 1s 781us/step - loss: 0.6933 - acc: 0.5000 - val_loss: 0.6940 - val_acc: 0.3750\n",
            "Epoch 81/100\n",
            "1000/1000 [==============================] - 1s 773us/step - loss: 0.7124 - acc: 0.4980 - val_loss: 0.6924 - val_acc: 0.6250\n",
            "Epoch 82/100\n",
            "1000/1000 [==============================] - 1s 774us/step - loss: 0.6944 - acc: 0.4810 - val_loss: 0.6949 - val_acc: 0.3750\n",
            "Epoch 83/100\n",
            "1000/1000 [==============================] - 1s 773us/step - loss: 0.6926 - acc: 0.5130 - val_loss: 0.6912 - val_acc: 0.6250\n",
            "Epoch 84/100\n",
            "1000/1000 [==============================] - 1s 778us/step - loss: 0.6935 - acc: 0.5000 - val_loss: 0.6928 - val_acc: 0.6250\n",
            "Epoch 85/100\n",
            "1000/1000 [==============================] - 1s 774us/step - loss: 0.7022 - acc: 0.4780 - val_loss: 0.6954 - val_acc: 0.3750\n",
            "Epoch 86/100\n",
            "1000/1000 [==============================] - 1s 777us/step - loss: 0.6935 - acc: 0.5000 - val_loss: 0.6963 - val_acc: 0.3750\n",
            "Epoch 87/100\n",
            "1000/1000 [==============================] - 1s 771us/step - loss: 0.6937 - acc: 0.5000 - val_loss: 0.6945 - val_acc: 0.3750\n",
            "Epoch 88/100\n",
            "1000/1000 [==============================] - 1s 765us/step - loss: 0.6940 - acc: 0.4950 - val_loss: 0.6933 - val_acc: 0.3750\n",
            "Epoch 89/100\n",
            "1000/1000 [==============================] - 1s 770us/step - loss: 0.7100 - acc: 0.5000 - val_loss: 0.6938 - val_acc: 0.3750\n",
            "Epoch 90/100\n",
            "1000/1000 [==============================] - 1s 768us/step - loss: 0.7088 - acc: 0.4900 - val_loss: 0.6930 - val_acc: 0.6250\n",
            "Epoch 91/100\n",
            "1000/1000 [==============================] - 1s 770us/step - loss: 0.6937 - acc: 0.4930 - val_loss: 0.6937 - val_acc: 0.3750\n",
            "Epoch 92/100\n",
            "1000/1000 [==============================] - 1s 767us/step - loss: 0.6938 - acc: 0.4890 - val_loss: 0.6904 - val_acc: 0.6250\n",
            "Epoch 93/100\n",
            "1000/1000 [==============================] - 1s 775us/step - loss: 0.7088 - acc: 0.4940 - val_loss: 0.6943 - val_acc: 0.3750\n",
            "Epoch 94/100\n",
            "1000/1000 [==============================] - 1s 768us/step - loss: 0.6935 - acc: 0.5000 - val_loss: 0.6950 - val_acc: 0.3750\n",
            "Epoch 95/100\n",
            "1000/1000 [==============================] - 1s 769us/step - loss: 0.6932 - acc: 0.4870 - val_loss: 0.6901 - val_acc: 0.6250\n",
            "Epoch 96/100\n",
            "1000/1000 [==============================] - 1s 767us/step - loss: 0.7089 - acc: 0.4730 - val_loss: 0.6913 - val_acc: 0.6250\n",
            "Epoch 97/100\n",
            "1000/1000 [==============================] - 1s 768us/step - loss: 0.6935 - acc: 0.4800 - val_loss: 0.6897 - val_acc: 0.6250\n",
            "Epoch 98/100\n",
            "1000/1000 [==============================] - 1s 777us/step - loss: 0.6936 - acc: 0.5000 - val_loss: 0.6907 - val_acc: 0.6250\n",
            "Epoch 99/100\n",
            "1000/1000 [==============================] - 1s 770us/step - loss: 0.6935 - acc: 0.4740 - val_loss: 0.6931 - val_acc: 0.6250\n",
            "Epoch 100/100\n",
            "1000/1000 [==============================] - 1s 769us/step - loss: 0.7096 - acc: 0.4800 - val_loss: 0.6900 - val_acc: 0.6250\n",
            "[[45  0]\n",
            " [27  0]]\n",
            "Accuracy :  0.625\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      1.00      0.77        45\n",
            "           1       0.00      0.00      0.00        27\n",
            "\n",
            "    accuracy                           0.62        72\n",
            "   macro avg       0.31      0.50      0.38        72\n",
            "weighted avg       0.39      0.62      0.48        72\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:257: UserWarning: After over-sampling, the number of samples (500) in class 1 will be larger than the number of samples in the majority class (class #0 -> 266)\n",
            "  n_samples_majority))\n",
            "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:257: UserWarning: After over-sampling, the number of samples (500) in class 0 will be larger than the number of samples in the majority class (class #0 -> 266)\n",
            "  n_samples_majority))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "model_2 (Model)              (None, 2)                 9148782   \n",
            "=================================================================\n",
            "Total params: 9,148,782\n",
            "Trainable params: 8,386\n",
            "Non-trainable params: 9,140,396\n",
            "_________________________________________________________________\n",
            "Train on 1000 samples, validate on 71 samples\n",
            "Epoch 1/100\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.6937 - acc: 0.4910 - val_loss: 0.6943 - val_acc: 0.3803\n",
            "Epoch 2/100\n",
            "1000/1000 [==============================] - 1s 764us/step - loss: 0.6936 - acc: 0.4940 - val_loss: 0.6931 - val_acc: 0.6197\n",
            "Epoch 3/100\n",
            "1000/1000 [==============================] - 1s 764us/step - loss: 0.7090 - acc: 0.4860 - val_loss: 0.6921 - val_acc: 0.6197\n",
            "Epoch 4/100\n",
            "1000/1000 [==============================] - 1s 768us/step - loss: 0.6938 - acc: 0.4820 - val_loss: 0.6890 - val_acc: 0.6197\n",
            "Epoch 5/100\n",
            "1000/1000 [==============================] - 1s 765us/step - loss: 0.6945 - acc: 0.5000 - val_loss: 0.6913 - val_acc: 0.6197\n",
            "Epoch 6/100\n",
            "1000/1000 [==============================] - 1s 765us/step - loss: 0.6941 - acc: 0.4990 - val_loss: 0.6984 - val_acc: 0.3803\n",
            "Epoch 7/100\n",
            "1000/1000 [==============================] - 1s 766us/step - loss: 0.6927 - acc: 0.5040 - val_loss: 0.6914 - val_acc: 0.6197\n",
            "Epoch 8/100\n",
            "1000/1000 [==============================] - 1s 764us/step - loss: 0.6937 - acc: 0.4760 - val_loss: 0.6931 - val_acc: 0.6197\n",
            "Epoch 9/100\n",
            "1000/1000 [==============================] - 1s 770us/step - loss: 0.6937 - acc: 0.4810 - val_loss: 0.6938 - val_acc: 0.3803\n",
            "Epoch 10/100\n",
            "1000/1000 [==============================] - 1s 766us/step - loss: 0.6934 - acc: 0.4930 - val_loss: 0.6924 - val_acc: 0.6197\n",
            "Epoch 11/100\n",
            "1000/1000 [==============================] - 1s 768us/step - loss: 0.7095 - acc: 0.4840 - val_loss: 0.6936 - val_acc: 0.3803\n",
            "Epoch 12/100\n",
            "1000/1000 [==============================] - 1s 774us/step - loss: 0.6939 - acc: 0.4910 - val_loss: 0.6908 - val_acc: 0.6197\n",
            "Epoch 13/100\n",
            "1000/1000 [==============================] - 1s 768us/step - loss: 0.7090 - acc: 0.4910 - val_loss: 0.6937 - val_acc: 0.3803\n",
            "Epoch 14/100\n",
            "1000/1000 [==============================] - 1s 769us/step - loss: 0.6937 - acc: 0.4790 - val_loss: 0.6971 - val_acc: 0.3803\n",
            "Epoch 15/100\n",
            "1000/1000 [==============================] - 1s 771us/step - loss: 1.1221 - acc: 0.5160 - val_loss: 0.6879 - val_acc: 0.6197\n",
            "Epoch 16/100\n",
            "1000/1000 [==============================] - 1s 771us/step - loss: 0.6940 - acc: 0.5000 - val_loss: 0.6880 - val_acc: 0.6197\n",
            "Epoch 17/100\n",
            "1000/1000 [==============================] - 1s 775us/step - loss: 0.6936 - acc: 0.4760 - val_loss: 0.6921 - val_acc: 0.6197\n",
            "Epoch 18/100\n",
            "1000/1000 [==============================] - 1s 775us/step - loss: 0.6943 - acc: 0.5080 - val_loss: 0.6955 - val_acc: 0.3803\n",
            "Epoch 19/100\n",
            "1000/1000 [==============================] - 1s 785us/step - loss: 0.6949 - acc: 0.5000 - val_loss: 0.6953 - val_acc: 0.3803\n",
            "Epoch 20/100\n",
            "1000/1000 [==============================] - 1s 771us/step - loss: 0.6943 - acc: 0.4960 - val_loss: 0.6909 - val_acc: 0.6197\n",
            "Epoch 21/100\n",
            "1000/1000 [==============================] - 1s 780us/step - loss: 0.6926 - acc: 0.4810 - val_loss: 0.6977 - val_acc: 0.3803\n",
            "Epoch 22/100\n",
            "1000/1000 [==============================] - 1s 775us/step - loss: 0.6934 - acc: 0.4910 - val_loss: 0.6917 - val_acc: 0.6197\n",
            "Epoch 23/100\n",
            "1000/1000 [==============================] - 1s 772us/step - loss: 0.6935 - acc: 0.5000 - val_loss: 0.6949 - val_acc: 0.3803\n",
            "Epoch 24/100\n",
            "1000/1000 [==============================] - 1s 768us/step - loss: 0.6938 - acc: 0.5000 - val_loss: 0.6927 - val_acc: 0.6197\n",
            "Epoch 25/100\n",
            "1000/1000 [==============================] - 1s 770us/step - loss: 0.7091 - acc: 0.4690 - val_loss: 0.6879 - val_acc: 0.6197\n",
            "Epoch 26/100\n",
            "1000/1000 [==============================] - 1s 779us/step - loss: 0.6934 - acc: 0.5000 - val_loss: 0.6929 - val_acc: 0.6197\n",
            "Epoch 27/100\n",
            "1000/1000 [==============================] - 1s 771us/step - loss: 0.6942 - acc: 0.4990 - val_loss: 0.6931 - val_acc: 0.6197\n",
            "Epoch 28/100\n",
            "1000/1000 [==============================] - 1s 772us/step - loss: 0.6939 - acc: 0.4950 - val_loss: 0.6940 - val_acc: 0.3803\n",
            "Epoch 29/100\n",
            "1000/1000 [==============================] - 1s 775us/step - loss: 0.6945 - acc: 0.4680 - val_loss: 0.6975 - val_acc: 0.3803\n",
            "Epoch 30/100\n",
            "1000/1000 [==============================] - 1s 778us/step - loss: 0.6930 - acc: 0.5060 - val_loss: 0.6905 - val_acc: 0.6197\n",
            "Epoch 31/100\n",
            "1000/1000 [==============================] - 1s 783us/step - loss: 0.6943 - acc: 0.4840 - val_loss: 0.6893 - val_acc: 0.6197\n",
            "Epoch 32/100\n",
            "1000/1000 [==============================] - 1s 778us/step - loss: 0.6937 - acc: 0.4770 - val_loss: 0.6887 - val_acc: 0.6197\n",
            "Epoch 33/100\n",
            "1000/1000 [==============================] - 1s 776us/step - loss: 0.6938 - acc: 0.5000 - val_loss: 0.6890 - val_acc: 0.6197\n",
            "Epoch 34/100\n",
            "1000/1000 [==============================] - 1s 782us/step - loss: 0.6932 - acc: 0.5030 - val_loss: 0.6956 - val_acc: 0.3803\n",
            "Epoch 35/100\n",
            "1000/1000 [==============================] - 1s 782us/step - loss: 0.6935 - acc: 0.5000 - val_loss: 0.6950 - val_acc: 0.3803\n",
            "Epoch 36/100\n",
            "1000/1000 [==============================] - 1s 784us/step - loss: 0.6939 - acc: 0.4820 - val_loss: 0.6954 - val_acc: 0.3803\n",
            "Epoch 37/100\n",
            "1000/1000 [==============================] - 1s 778us/step - loss: 0.6935 - acc: 0.5000 - val_loss: 0.6934 - val_acc: 0.3803\n",
            "Epoch 38/100\n",
            "1000/1000 [==============================] - 1s 782us/step - loss: 0.6935 - acc: 0.4940 - val_loss: 0.6946 - val_acc: 0.3803\n",
            "Epoch 39/100\n",
            "1000/1000 [==============================] - 1s 781us/step - loss: 0.6942 - acc: 0.4870 - val_loss: 0.6941 - val_acc: 0.3803\n",
            "Epoch 40/100\n",
            "1000/1000 [==============================] - 1s 786us/step - loss: 0.6934 - acc: 0.5000 - val_loss: 0.6973 - val_acc: 0.3803\n",
            "Epoch 41/100\n",
            "1000/1000 [==============================] - 1s 775us/step - loss: 0.6938 - acc: 0.4890 - val_loss: 0.6932 - val_acc: 0.3803\n",
            "Epoch 42/100\n",
            "1000/1000 [==============================] - 1s 782us/step - loss: 0.6933 - acc: 0.5000 - val_loss: 0.6942 - val_acc: 0.3803\n",
            "Epoch 43/100\n",
            "1000/1000 [==============================] - 1s 780us/step - loss: 0.6939 - acc: 0.4820 - val_loss: 0.6936 - val_acc: 0.3803\n",
            "Epoch 44/100\n",
            "1000/1000 [==============================] - 1s 781us/step - loss: 1.4799 - acc: 0.5090 - val_loss: 6.0960 - val_acc: 0.6197\n",
            "Epoch 45/100\n",
            "1000/1000 [==============================] - 1s 776us/step - loss: 3.3489 - acc: 0.5120 - val_loss: 0.6941 - val_acc: 0.3803\n",
            "Epoch 46/100\n",
            "1000/1000 [==============================] - 1s 781us/step - loss: 0.7671 - acc: 0.4960 - val_loss: 0.6923 - val_acc: 0.6197\n",
            "Epoch 47/100\n",
            "1000/1000 [==============================] - 1s 779us/step - loss: 0.8400 - acc: 0.4940 - val_loss: 0.6950 - val_acc: 0.3803\n",
            "Epoch 48/100\n",
            "1000/1000 [==============================] - 1s 782us/step - loss: 1.0140 - acc: 0.4780 - val_loss: 1.2557 - val_acc: 0.4085\n",
            "Epoch 49/100\n",
            "1000/1000 [==============================] - 1s 781us/step - loss: 1.0826 - acc: 0.4910 - val_loss: 0.6821 - val_acc: 0.6197\n",
            "Epoch 50/100\n",
            "1000/1000 [==============================] - 1s 781us/step - loss: 0.7112 - acc: 0.4950 - val_loss: 0.6935 - val_acc: 0.3803\n",
            "Epoch 51/100\n",
            "1000/1000 [==============================] - 1s 779us/step - loss: 0.6940 - acc: 0.5000 - val_loss: 0.6938 - val_acc: 0.3803\n",
            "Epoch 52/100\n",
            "1000/1000 [==============================] - 1s 777us/step - loss: 0.6936 - acc: 0.5070 - val_loss: 0.6904 - val_acc: 0.6197\n",
            "Epoch 53/100\n",
            "1000/1000 [==============================] - 1s 779us/step - loss: 0.6934 - acc: 0.5070 - val_loss: 0.6943 - val_acc: 0.3803\n",
            "Epoch 54/100\n",
            "1000/1000 [==============================] - 1s 777us/step - loss: 0.6938 - acc: 0.5010 - val_loss: 0.6953 - val_acc: 0.3803\n",
            "Epoch 55/100\n",
            "1000/1000 [==============================] - 1s 785us/step - loss: 0.6934 - acc: 0.4850 - val_loss: 0.6927 - val_acc: 0.6197\n",
            "Epoch 56/100\n",
            "1000/1000 [==============================] - 1s 780us/step - loss: 0.6946 - acc: 0.4990 - val_loss: 0.6884 - val_acc: 0.6197\n",
            "Epoch 57/100\n",
            "1000/1000 [==============================] - 1s 777us/step - loss: 0.6932 - acc: 0.4820 - val_loss: 0.6971 - val_acc: 0.3803\n",
            "Epoch 58/100\n",
            "1000/1000 [==============================] - 1s 777us/step - loss: 0.6935 - acc: 0.5000 - val_loss: 0.6942 - val_acc: 0.3803\n",
            "Epoch 59/100\n",
            "1000/1000 [==============================] - 1s 785us/step - loss: 0.6934 - acc: 0.4800 - val_loss: 0.6912 - val_acc: 0.6197\n",
            "Epoch 60/100\n",
            "1000/1000 [==============================] - 1s 783us/step - loss: 0.6937 - acc: 0.5000 - val_loss: 0.6936 - val_acc: 0.3803\n",
            "Epoch 61/100\n",
            "1000/1000 [==============================] - 1s 779us/step - loss: 0.6939 - acc: 0.4750 - val_loss: 0.6942 - val_acc: 0.3803\n",
            "Epoch 62/100\n",
            "1000/1000 [==============================] - 1s 778us/step - loss: 0.6938 - acc: 0.5000 - val_loss: 0.6952 - val_acc: 0.3803\n",
            "Epoch 63/100\n",
            "1000/1000 [==============================] - 1s 780us/step - loss: 0.6936 - acc: 0.4940 - val_loss: 0.6916 - val_acc: 0.6197\n",
            "Epoch 64/100\n",
            "1000/1000 [==============================] - 1s 779us/step - loss: 0.6938 - acc: 0.5000 - val_loss: 0.6874 - val_acc: 0.6197\n",
            "Epoch 65/100\n",
            "1000/1000 [==============================] - 1s 774us/step - loss: 0.7090 - acc: 0.4970 - val_loss: 0.6942 - val_acc: 0.3803\n",
            "Epoch 66/100\n",
            "1000/1000 [==============================] - 1s 778us/step - loss: 0.6940 - acc: 0.4940 - val_loss: 0.6911 - val_acc: 0.6197\n",
            "Epoch 67/100\n",
            "1000/1000 [==============================] - 1s 781us/step - loss: 0.6942 - acc: 0.5000 - val_loss: 0.6922 - val_acc: 0.6197\n",
            "Epoch 68/100\n",
            "1000/1000 [==============================] - 1s 783us/step - loss: 0.6936 - acc: 0.4850 - val_loss: 0.6929 - val_acc: 0.6197\n",
            "Epoch 69/100\n",
            "1000/1000 [==============================] - 1s 771us/step - loss: 0.6942 - acc: 0.4660 - val_loss: 0.6989 - val_acc: 0.3803\n",
            "Epoch 70/100\n",
            "1000/1000 [==============================] - 1s 774us/step - loss: 0.6936 - acc: 0.4970 - val_loss: 0.6913 - val_acc: 0.6197\n",
            "Epoch 71/100\n",
            "1000/1000 [==============================] - 1s 776us/step - loss: 0.6933 - acc: 0.4880 - val_loss: 0.6911 - val_acc: 0.6197\n",
            "Epoch 72/100\n",
            "1000/1000 [==============================] - 1s 778us/step - loss: 0.6937 - acc: 0.4620 - val_loss: 0.6942 - val_acc: 0.3803\n",
            "Epoch 73/100\n",
            "1000/1000 [==============================] - 1s 780us/step - loss: 0.6936 - acc: 0.4970 - val_loss: 0.6930 - val_acc: 0.6197\n",
            "Epoch 74/100\n",
            "1000/1000 [==============================] - 1s 776us/step - loss: 0.6943 - acc: 0.4750 - val_loss: 0.6903 - val_acc: 0.6197\n",
            "Epoch 75/100\n",
            "1000/1000 [==============================] - 1s 777us/step - loss: 0.6934 - acc: 0.5020 - val_loss: 0.6959 - val_acc: 0.3803\n",
            "Epoch 76/100\n",
            "1000/1000 [==============================] - 1s 783us/step - loss: 0.7083 - acc: 0.5000 - val_loss: 0.6926 - val_acc: 0.6197\n",
            "Epoch 77/100\n",
            "1000/1000 [==============================] - 1s 777us/step - loss: 0.6938 - acc: 0.5000 - val_loss: 0.6898 - val_acc: 0.6197\n",
            "Epoch 78/100\n",
            "1000/1000 [==============================] - 1s 771us/step - loss: 0.6948 - acc: 0.4770 - val_loss: 0.6927 - val_acc: 0.6197\n",
            "Epoch 79/100\n",
            "1000/1000 [==============================] - 1s 778us/step - loss: 0.6935 - acc: 0.5000 - val_loss: 0.6923 - val_acc: 0.6197\n",
            "Epoch 80/100\n",
            "1000/1000 [==============================] - 1s 775us/step - loss: 0.6934 - acc: 0.4820 - val_loss: 0.6947 - val_acc: 0.3803\n",
            "Epoch 81/100\n",
            "1000/1000 [==============================] - 1s 784us/step - loss: 0.6935 - acc: 0.4750 - val_loss: 0.6935 - val_acc: 0.3803\n",
            "Epoch 82/100\n",
            "1000/1000 [==============================] - 1s 776us/step - loss: 0.6939 - acc: 0.4770 - val_loss: 0.6947 - val_acc: 0.3803\n",
            "Epoch 83/100\n",
            "1000/1000 [==============================] - 1s 775us/step - loss: 0.6936 - acc: 0.4930 - val_loss: 0.6968 - val_acc: 0.3803\n",
            "Epoch 84/100\n",
            "1000/1000 [==============================] - 1s 783us/step - loss: 0.6933 - acc: 0.5000 - val_loss: 0.6938 - val_acc: 0.3803\n",
            "Epoch 85/100\n",
            "1000/1000 [==============================] - 1s 781us/step - loss: 0.6935 - acc: 0.4800 - val_loss: 0.6931 - val_acc: 0.6197\n",
            "Epoch 86/100\n",
            "1000/1000 [==============================] - 1s 778us/step - loss: 0.6935 - acc: 0.4890 - val_loss: 0.6928 - val_acc: 0.6197\n",
            "Epoch 87/100\n",
            "1000/1000 [==============================] - 1s 775us/step - loss: 0.6935 - acc: 0.4930 - val_loss: 0.6966 - val_acc: 0.3803\n",
            "Epoch 88/100\n",
            "1000/1000 [==============================] - 1s 773us/step - loss: 0.6933 - acc: 0.5000 - val_loss: 0.6911 - val_acc: 0.6197\n",
            "Epoch 89/100\n",
            "1000/1000 [==============================] - 1s 768us/step - loss: 0.6934 - acc: 0.4840 - val_loss: 0.6923 - val_acc: 0.6197\n",
            "Epoch 90/100\n",
            "1000/1000 [==============================] - 1s 768us/step - loss: 0.6935 - acc: 0.4740 - val_loss: 0.6910 - val_acc: 0.6197\n",
            "Epoch 91/100\n",
            "1000/1000 [==============================] - 1s 782us/step - loss: 0.6936 - acc: 0.4770 - val_loss: 0.6910 - val_acc: 0.6197\n",
            "Epoch 92/100\n",
            "1000/1000 [==============================] - 1s 781us/step - loss: 0.6933 - acc: 0.5000 - val_loss: 0.6932 - val_acc: 0.3803\n",
            "Epoch 93/100\n",
            "1000/1000 [==============================] - 1s 777us/step - loss: 0.6937 - acc: 0.4910 - val_loss: 0.6928 - val_acc: 0.6197\n",
            "Epoch 94/100\n",
            "1000/1000 [==============================] - 1s 784us/step - loss: 0.6938 - acc: 0.4970 - val_loss: 0.6966 - val_acc: 0.3803\n",
            "Epoch 95/100\n",
            "1000/1000 [==============================] - 1s 775us/step - loss: 0.6934 - acc: 0.4820 - val_loss: 0.6929 - val_acc: 0.6197\n",
            "Epoch 96/100\n",
            "1000/1000 [==============================] - 1s 780us/step - loss: 0.6933 - acc: 0.4830 - val_loss: 0.6928 - val_acc: 0.6197\n",
            "Epoch 97/100\n",
            "1000/1000 [==============================] - 1s 775us/step - loss: 0.6937 - acc: 0.4720 - val_loss: 0.6952 - val_acc: 0.3803\n",
            "Epoch 98/100\n",
            "1000/1000 [==============================] - 1s 783us/step - loss: 0.6933 - acc: 0.4780 - val_loss: 0.6933 - val_acc: 0.3803\n",
            "Epoch 99/100\n",
            "1000/1000 [==============================] - 1s 775us/step - loss: 0.6932 - acc: 0.5030 - val_loss: 0.6908 - val_acc: 0.6197\n",
            "Epoch 100/100\n",
            "1000/1000 [==============================] - 1s 782us/step - loss: 0.6935 - acc: 0.4890 - val_loss: 0.6940 - val_acc: 0.3803\n",
            "[[ 0 44]\n",
            " [ 0 27]]\n",
            "Accuracy :  0.38028169014084506\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        44\n",
            "           1       0.38      1.00      0.55        27\n",
            "\n",
            "    accuracy                           0.38        71\n",
            "   macro avg       0.19      0.50      0.28        71\n",
            "weighted avg       0.14      0.38      0.21        71\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:257: UserWarning: After over-sampling, the number of samples (500) in class 1 will be larger than the number of samples in the majority class (class #0 -> 266)\n",
            "  n_samples_majority))\n",
            "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:257: UserWarning: After over-sampling, the number of samples (500) in class 0 will be larger than the number of samples in the majority class (class #0 -> 266)\n",
            "  n_samples_majority))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "model_2 (Model)              (None, 2)                 9148782   \n",
            "=================================================================\n",
            "Total params: 9,148,782\n",
            "Trainable params: 8,386\n",
            "Non-trainable params: 9,140,396\n",
            "_________________________________________________________________\n",
            "Train on 1000 samples, validate on 71 samples\n",
            "Epoch 1/100\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.6932 - acc: 0.5030 - val_loss: 0.6943 - val_acc: 0.3803\n",
            "Epoch 2/100\n",
            "1000/1000 [==============================] - 1s 763us/step - loss: 0.6938 - acc: 0.5000 - val_loss: 0.6955 - val_acc: 0.3803\n",
            "Epoch 3/100\n",
            "1000/1000 [==============================] - 1s 765us/step - loss: 0.6937 - acc: 0.4730 - val_loss: 0.6954 - val_acc: 0.3803\n",
            "Epoch 4/100\n",
            "1000/1000 [==============================] - 1s 762us/step - loss: 0.6939 - acc: 0.4800 - val_loss: 0.6980 - val_acc: 0.3803\n",
            "Epoch 5/100\n",
            "1000/1000 [==============================] - 1s 768us/step - loss: 0.6939 - acc: 0.4800 - val_loss: 0.6930 - val_acc: 0.6197\n",
            "Epoch 6/100\n",
            "1000/1000 [==============================] - 1s 761us/step - loss: 0.6935 - acc: 0.4950 - val_loss: 0.6974 - val_acc: 0.3803\n",
            "Epoch 7/100\n",
            "1000/1000 [==============================] - 1s 764us/step - loss: 0.6934 - acc: 0.4930 - val_loss: 0.6922 - val_acc: 0.6197\n",
            "Epoch 8/100\n",
            "1000/1000 [==============================] - 1s 765us/step - loss: 0.6935 - acc: 0.4760 - val_loss: 0.6925 - val_acc: 0.6197\n",
            "Epoch 9/100\n",
            "1000/1000 [==============================] - 1s 764us/step - loss: 0.6933 - acc: 0.5040 - val_loss: 0.6939 - val_acc: 0.3803\n",
            "Epoch 10/100\n",
            "1000/1000 [==============================] - 1s 765us/step - loss: 0.6935 - acc: 0.5000 - val_loss: 0.6950 - val_acc: 0.3803\n",
            "Epoch 11/100\n",
            "1000/1000 [==============================] - 1s 766us/step - loss: 0.6935 - acc: 0.4830 - val_loss: 0.6937 - val_acc: 0.3803\n",
            "Epoch 12/100\n",
            "1000/1000 [==============================] - 1s 774us/step - loss: 0.6935 - acc: 0.4920 - val_loss: 0.6909 - val_acc: 0.6197\n",
            "Epoch 13/100\n",
            "1000/1000 [==============================] - 1s 768us/step - loss: 0.6934 - acc: 0.5020 - val_loss: 0.6965 - val_acc: 0.3803\n",
            "Epoch 14/100\n",
            "1000/1000 [==============================] - 1s 770us/step - loss: 0.6951 - acc: 0.4880 - val_loss: 0.6886 - val_acc: 0.6197\n",
            "Epoch 15/100\n",
            "1000/1000 [==============================] - 1s 765us/step - loss: 0.6949 - acc: 0.4940 - val_loss: 0.6967 - val_acc: 0.3803\n",
            "Epoch 16/100\n",
            "1000/1000 [==============================] - 1s 770us/step - loss: 0.6934 - acc: 0.4920 - val_loss: 0.6896 - val_acc: 0.6197\n",
            "Epoch 17/100\n",
            "1000/1000 [==============================] - 1s 767us/step - loss: 0.6937 - acc: 0.5000 - val_loss: 0.6909 - val_acc: 0.6197\n",
            "Epoch 18/100\n",
            "1000/1000 [==============================] - 1s 774us/step - loss: 0.6933 - acc: 0.5080 - val_loss: 0.6959 - val_acc: 0.3803\n",
            "Epoch 19/100\n",
            "1000/1000 [==============================] - 1s 774us/step - loss: 0.6943 - acc: 0.4730 - val_loss: 0.6912 - val_acc: 0.6197\n",
            "Epoch 20/100\n",
            "1000/1000 [==============================] - 1s 771us/step - loss: 0.6944 - acc: 0.4640 - val_loss: 0.6915 - val_acc: 0.6197\n",
            "Epoch 21/100\n",
            "1000/1000 [==============================] - 1s 769us/step - loss: 0.6935 - acc: 0.4950 - val_loss: 0.6981 - val_acc: 0.3803\n",
            "Epoch 22/100\n",
            "1000/1000 [==============================] - 1s 775us/step - loss: 0.6939 - acc: 0.4760 - val_loss: 0.6956 - val_acc: 0.3803\n",
            "Epoch 23/100\n",
            "1000/1000 [==============================] - 1s 777us/step - loss: 0.6936 - acc: 0.4870 - val_loss: 0.6916 - val_acc: 0.6197\n",
            "Epoch 24/100\n",
            "1000/1000 [==============================] - 1s 772us/step - loss: 0.6952 - acc: 0.4690 - val_loss: 0.6883 - val_acc: 0.6197\n",
            "Epoch 25/100\n",
            "1000/1000 [==============================] - 1s 794us/step - loss: 0.6939 - acc: 0.4930 - val_loss: 0.6928 - val_acc: 0.6197\n",
            "Epoch 26/100\n",
            "1000/1000 [==============================] - 1s 780us/step - loss: 0.6940 - acc: 0.5000 - val_loss: 0.6911 - val_acc: 0.6197\n",
            "Epoch 27/100\n",
            "1000/1000 [==============================] - 1s 773us/step - loss: 0.6942 - acc: 0.4640 - val_loss: 0.6940 - val_acc: 0.3803\n",
            "Epoch 28/100\n",
            "1000/1000 [==============================] - 1s 773us/step - loss: 0.6934 - acc: 0.4870 - val_loss: 0.6931 - val_acc: 0.6197\n",
            "Epoch 29/100\n",
            "1000/1000 [==============================] - 1s 771us/step - loss: 0.6934 - acc: 0.4850 - val_loss: 0.6924 - val_acc: 0.6197\n",
            "Epoch 30/100\n",
            "1000/1000 [==============================] - 1s 781us/step - loss: 0.6948 - acc: 0.4770 - val_loss: 0.6894 - val_acc: 0.6197\n",
            "Epoch 31/100\n",
            "1000/1000 [==============================] - 1s 774us/step - loss: 0.6940 - acc: 0.4890 - val_loss: 0.6964 - val_acc: 0.3803\n",
            "Epoch 32/100\n",
            "1000/1000 [==============================] - 1s 783us/step - loss: 0.6936 - acc: 0.4800 - val_loss: 0.6957 - val_acc: 0.3803\n",
            "Epoch 33/100\n",
            "1000/1000 [==============================] - 1s 791us/step - loss: 0.6935 - acc: 0.4670 - val_loss: 0.6950 - val_acc: 0.3803\n",
            "Epoch 34/100\n",
            "1000/1000 [==============================] - 1s 777us/step - loss: 0.6936 - acc: 0.4840 - val_loss: 0.6919 - val_acc: 0.6197\n",
            "Epoch 35/100\n",
            "1000/1000 [==============================] - 1s 774us/step - loss: 0.6935 - acc: 0.4950 - val_loss: 0.6969 - val_acc: 0.3803\n",
            "Epoch 36/100\n",
            "1000/1000 [==============================] - 1s 773us/step - loss: 0.6934 - acc: 0.4690 - val_loss: 0.6923 - val_acc: 0.6197\n",
            "Epoch 37/100\n",
            "1000/1000 [==============================] - 1s 782us/step - loss: 0.6930 - acc: 0.4930 - val_loss: 0.6930 - val_acc: 0.6197\n",
            "Epoch 38/100\n",
            "1000/1000 [==============================] - 1s 773us/step - loss: 0.6934 - acc: 0.5000 - val_loss: 0.6899 - val_acc: 0.6197\n",
            "Epoch 39/100\n",
            "1000/1000 [==============================] - 1s 779us/step - loss: 0.6934 - acc: 0.4790 - val_loss: 0.6935 - val_acc: 0.3803\n",
            "Epoch 40/100\n",
            "1000/1000 [==============================] - 1s 782us/step - loss: 0.6933 - acc: 0.5000 - val_loss: 0.6932 - val_acc: 0.3803\n",
            "Epoch 41/100\n",
            "1000/1000 [==============================] - 1s 783us/step - loss: 0.6937 - acc: 0.4870 - val_loss: 0.6966 - val_acc: 0.3803\n",
            "Epoch 42/100\n",
            "1000/1000 [==============================] - 1s 784us/step - loss: 0.6934 - acc: 0.5000 - val_loss: 0.6931 - val_acc: 0.6197\n",
            "Epoch 43/100\n",
            "1000/1000 [==============================] - 1s 779us/step - loss: 0.6939 - acc: 0.4620 - val_loss: 0.6906 - val_acc: 0.6197\n",
            "Epoch 44/100\n",
            "1000/1000 [==============================] - 1s 781us/step - loss: 0.6938 - acc: 0.4730 - val_loss: 0.6916 - val_acc: 0.6197\n",
            "Epoch 45/100\n",
            "1000/1000 [==============================] - 1s 785us/step - loss: 0.6937 - acc: 0.5000 - val_loss: 0.6922 - val_acc: 0.6197\n",
            "Epoch 46/100\n",
            "1000/1000 [==============================] - 1s 782us/step - loss: 0.6935 - acc: 0.4940 - val_loss: 0.6967 - val_acc: 0.3803\n",
            "Epoch 47/100\n",
            "1000/1000 [==============================] - 1s 780us/step - loss: 0.6931 - acc: 0.4770 - val_loss: 0.6944 - val_acc: 0.3803\n",
            "Epoch 48/100\n",
            "1000/1000 [==============================] - 1s 781us/step - loss: 0.6935 - acc: 0.4910 - val_loss: 0.6923 - val_acc: 0.6197\n",
            "Epoch 49/100\n",
            "1000/1000 [==============================] - 1s 781us/step - loss: 0.6938 - acc: 0.4890 - val_loss: 0.6946 - val_acc: 0.3803\n",
            "Epoch 50/100\n",
            "1000/1000 [==============================] - 1s 781us/step - loss: 0.6945 - acc: 0.4650 - val_loss: 0.6985 - val_acc: 0.3803\n",
            "Epoch 51/100\n",
            "1000/1000 [==============================] - 1s 778us/step - loss: 0.6948 - acc: 0.4610 - val_loss: 0.6953 - val_acc: 0.3803\n",
            "Epoch 52/100\n",
            "1000/1000 [==============================] - 1s 792us/step - loss: 0.6935 - acc: 0.5000 - val_loss: 0.6949 - val_acc: 0.3803\n",
            "Epoch 53/100\n",
            "1000/1000 [==============================] - 1s 782us/step - loss: 0.6934 - acc: 0.4940 - val_loss: 0.6910 - val_acc: 0.6197\n",
            "Epoch 54/100\n",
            "1000/1000 [==============================] - 1s 785us/step - loss: 0.6982 - acc: 0.4930 - val_loss: 0.6947 - val_acc: 0.3803\n",
            "Epoch 55/100\n",
            "1000/1000 [==============================] - 1s 784us/step - loss: 0.6944 - acc: 0.4690 - val_loss: 0.6957 - val_acc: 0.3803\n",
            "Epoch 56/100\n",
            "1000/1000 [==============================] - 1s 781us/step - loss: 0.6948 - acc: 0.5030 - val_loss: 0.6917 - val_acc: 0.6197\n",
            "Epoch 57/100\n",
            "1000/1000 [==============================] - 1s 779us/step - loss: 0.6937 - acc: 0.5000 - val_loss: 0.6884 - val_acc: 0.6197\n",
            "Epoch 58/100\n",
            "1000/1000 [==============================] - 1s 787us/step - loss: 0.6937 - acc: 0.4840 - val_loss: 0.6940 - val_acc: 0.3803\n",
            "Epoch 59/100\n",
            "1000/1000 [==============================] - 1s 777us/step - loss: 0.6936 - acc: 0.4720 - val_loss: 0.6940 - val_acc: 0.3803\n",
            "Epoch 60/100\n",
            "1000/1000 [==============================] - 1s 782us/step - loss: 0.6937 - acc: 0.4900 - val_loss: 0.6905 - val_acc: 0.6197\n",
            "Epoch 61/100\n",
            "1000/1000 [==============================] - 1s 782us/step - loss: 0.6939 - acc: 0.4870 - val_loss: 0.6950 - val_acc: 0.3803\n",
            "Epoch 62/100\n",
            "1000/1000 [==============================] - 1s 783us/step - loss: 0.6933 - acc: 0.5000 - val_loss: 0.6902 - val_acc: 0.6197\n",
            "Epoch 63/100\n",
            "1000/1000 [==============================] - 1s 781us/step - loss: 0.6936 - acc: 0.4840 - val_loss: 0.6931 - val_acc: 0.6197\n",
            "Epoch 64/100\n",
            "1000/1000 [==============================] - 1s 777us/step - loss: 0.6936 - acc: 0.4860 - val_loss: 0.6941 - val_acc: 0.3803\n",
            "Epoch 65/100\n",
            "1000/1000 [==============================] - 1s 785us/step - loss: 0.6936 - acc: 0.5010 - val_loss: 0.6931 - val_acc: 0.6197\n",
            "Epoch 66/100\n",
            "1000/1000 [==============================] - 1s 781us/step - loss: 0.7393 - acc: 0.4990 - val_loss: 0.6929 - val_acc: 0.6197\n",
            "Epoch 67/100\n",
            "1000/1000 [==============================] - 1s 781us/step - loss: 0.6934 - acc: 0.4910 - val_loss: 0.6941 - val_acc: 0.3803\n",
            "Epoch 68/100\n",
            "1000/1000 [==============================] - 1s 784us/step - loss: 0.6940 - acc: 0.4650 - val_loss: 0.6944 - val_acc: 0.3803\n",
            "Epoch 69/100\n",
            "1000/1000 [==============================] - 1s 785us/step - loss: 0.6937 - acc: 0.4670 - val_loss: 0.6990 - val_acc: 0.3803\n",
            "Epoch 70/100\n",
            "1000/1000 [==============================] - 1s 785us/step - loss: 0.6935 - acc: 0.5000 - val_loss: 0.6951 - val_acc: 0.3803\n",
            "Epoch 71/100\n",
            "1000/1000 [==============================] - 1s 779us/step - loss: 0.6938 - acc: 0.4900 - val_loss: 0.6903 - val_acc: 0.6197\n",
            "Epoch 72/100\n",
            "1000/1000 [==============================] - 1s 780us/step - loss: 0.6934 - acc: 0.4950 - val_loss: 0.6938 - val_acc: 0.3803\n",
            "Epoch 73/100\n",
            "1000/1000 [==============================] - 1s 779us/step - loss: 0.6938 - acc: 0.4880 - val_loss: 0.6935 - val_acc: 0.3803\n",
            "Epoch 74/100\n",
            "1000/1000 [==============================] - 1s 778us/step - loss: 0.6934 - acc: 0.4760 - val_loss: 0.6943 - val_acc: 0.3803\n",
            "Epoch 75/100\n",
            "1000/1000 [==============================] - 1s 778us/step - loss: 0.6928 - acc: 0.5010 - val_loss: 0.6948 - val_acc: 0.3803\n",
            "Epoch 76/100\n",
            "1000/1000 [==============================] - 1s 778us/step - loss: 0.6942 - acc: 0.4760 - val_loss: 0.6915 - val_acc: 0.6197\n",
            "Epoch 77/100\n",
            "1000/1000 [==============================] - 1s 784us/step - loss: 0.6934 - acc: 0.4920 - val_loss: 0.6962 - val_acc: 0.3803\n",
            "Epoch 78/100\n",
            "1000/1000 [==============================] - 1s 774us/step - loss: 0.6941 - acc: 0.4860 - val_loss: 0.6915 - val_acc: 0.6197\n",
            "Epoch 79/100\n",
            "1000/1000 [==============================] - 1s 772us/step - loss: 0.6940 - acc: 0.4850 - val_loss: 0.6957 - val_acc: 0.3803\n",
            "Epoch 80/100\n",
            "1000/1000 [==============================] - 1s 774us/step - loss: 0.6943 - acc: 0.5010 - val_loss: 0.6877 - val_acc: 0.6197\n",
            "Epoch 81/100\n",
            "1000/1000 [==============================] - 1s 771us/step - loss: 0.6933 - acc: 0.4940 - val_loss: 0.6935 - val_acc: 0.3803\n",
            "Epoch 82/100\n",
            "1000/1000 [==============================] - 1s 783us/step - loss: 0.6936 - acc: 0.5000 - val_loss: 0.6977 - val_acc: 0.3803\n",
            "Epoch 83/100\n",
            "1000/1000 [==============================] - 1s 775us/step - loss: 0.6936 - acc: 0.4700 - val_loss: 0.6939 - val_acc: 0.3803\n",
            "Epoch 84/100\n",
            "1000/1000 [==============================] - 1s 770us/step - loss: 0.6934 - acc: 0.4960 - val_loss: 0.6927 - val_acc: 0.6197\n",
            "Epoch 85/100\n",
            "1000/1000 [==============================] - 1s 776us/step - loss: 0.6934 - acc: 0.4880 - val_loss: 0.6945 - val_acc: 0.3803\n",
            "Epoch 86/100\n",
            "1000/1000 [==============================] - 1s 775us/step - loss: 0.6935 - acc: 0.4850 - val_loss: 0.6926 - val_acc: 0.6197\n",
            "Epoch 87/100\n",
            "1000/1000 [==============================] - 1s 773us/step - loss: 0.6934 - acc: 0.4800 - val_loss: 0.6939 - val_acc: 0.3803\n",
            "Epoch 88/100\n",
            "1000/1000 [==============================] - 1s 769us/step - loss: 0.6934 - acc: 0.4770 - val_loss: 0.6939 - val_acc: 0.3803\n",
            "Epoch 89/100\n",
            "1000/1000 [==============================] - 1s 770us/step - loss: 0.6938 - acc: 0.4700 - val_loss: 0.6911 - val_acc: 0.6197\n",
            "Epoch 90/100\n",
            "1000/1000 [==============================] - 1s 769us/step - loss: 0.6934 - acc: 0.5010 - val_loss: 0.6969 - val_acc: 0.3803\n",
            "Epoch 91/100\n",
            "1000/1000 [==============================] - 1s 770us/step - loss: 0.6938 - acc: 0.4810 - val_loss: 0.6940 - val_acc: 0.3803\n",
            "Epoch 92/100\n",
            "1000/1000 [==============================] - 1s 767us/step - loss: 0.6939 - acc: 0.4790 - val_loss: 0.6947 - val_acc: 0.3803\n",
            "Epoch 93/100\n",
            "1000/1000 [==============================] - 1s 771us/step - loss: 0.6935 - acc: 0.5000 - val_loss: 0.6953 - val_acc: 0.3803\n",
            "Epoch 94/100\n",
            "1000/1000 [==============================] - 1s 771us/step - loss: 0.6936 - acc: 0.5000 - val_loss: 0.6945 - val_acc: 0.3803\n",
            "Epoch 95/100\n",
            "1000/1000 [==============================] - 1s 770us/step - loss: 0.6937 - acc: 0.4920 - val_loss: 0.6901 - val_acc: 0.6197\n",
            "Epoch 96/100\n",
            "1000/1000 [==============================] - 1s 766us/step - loss: 0.6935 - acc: 0.4850 - val_loss: 0.6928 - val_acc: 0.6197\n",
            "Epoch 97/100\n",
            "1000/1000 [==============================] - 1s 773us/step - loss: 0.6935 - acc: 0.4930 - val_loss: 0.6917 - val_acc: 0.6197\n",
            "Epoch 98/100\n",
            "1000/1000 [==============================] - 1s 771us/step - loss: 0.6937 - acc: 0.4950 - val_loss: 0.6941 - val_acc: 0.3803\n",
            "Epoch 99/100\n",
            "1000/1000 [==============================] - 1s 772us/step - loss: 0.6928 - acc: 0.4790 - val_loss: 0.6946 - val_acc: 0.3803\n",
            "Epoch 100/100\n",
            "1000/1000 [==============================] - 1s 772us/step - loss: 0.6935 - acc: 0.4740 - val_loss: 0.6950 - val_acc: 0.3803\n",
            "[[ 0 44]\n",
            " [ 0 27]]\n",
            "Accuracy :  0.38028169014084506\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        44\n",
            "           1       0.38      1.00      0.55        27\n",
            "\n",
            "    accuracy                           0.38        71\n",
            "   macro avg       0.19      0.50      0.28        71\n",
            "weighted avg       0.14      0.38      0.21        71\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:257: UserWarning: After over-sampling, the number of samples (500) in class 1 will be larger than the number of samples in the majority class (class #0 -> 266)\n",
            "  n_samples_majority))\n",
            "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:257: UserWarning: After over-sampling, the number of samples (500) in class 0 will be larger than the number of samples in the majority class (class #0 -> 266)\n",
            "  n_samples_majority))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "model_2 (Model)              (None, 2)                 9148782   \n",
            "=================================================================\n",
            "Total params: 9,148,782\n",
            "Trainable params: 8,386\n",
            "Non-trainable params: 9,140,396\n",
            "_________________________________________________________________\n",
            "Train on 1000 samples, validate on 71 samples\n",
            "Epoch 1/100\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.6935 - acc: 0.5000 - val_loss: 0.6941 - val_acc: 0.3803\n",
            "Epoch 2/100\n",
            "1000/1000 [==============================] - 1s 765us/step - loss: 0.6933 - acc: 0.4810 - val_loss: 0.6927 - val_acc: 0.6197\n",
            "Epoch 3/100\n",
            "1000/1000 [==============================] - 1s 762us/step - loss: 0.6933 - acc: 0.4770 - val_loss: 0.6931 - val_acc: 0.6197\n",
            "Epoch 4/100\n",
            "1000/1000 [==============================] - 1s 764us/step - loss: 0.6935 - acc: 0.4970 - val_loss: 0.6928 - val_acc: 0.6197\n",
            "Epoch 5/100\n",
            "1000/1000 [==============================] - 1s 759us/step - loss: 0.6935 - acc: 0.5010 - val_loss: 0.6908 - val_acc: 0.6197\n",
            "Epoch 6/100\n",
            "1000/1000 [==============================] - 1s 761us/step - loss: 0.6938 - acc: 0.4920 - val_loss: 0.6952 - val_acc: 0.3803\n",
            "Epoch 7/100\n",
            "1000/1000 [==============================] - 1s 765us/step - loss: 0.7284 - acc: 0.4930 - val_loss: 0.6922 - val_acc: 0.6197\n",
            "Epoch 8/100\n",
            "1000/1000 [==============================] - 1s 763us/step - loss: 0.6940 - acc: 0.4860 - val_loss: 0.6908 - val_acc: 0.6197\n",
            "Epoch 9/100\n",
            "1000/1000 [==============================] - 1s 763us/step - loss: 0.6941 - acc: 0.4810 - val_loss: 0.6935 - val_acc: 0.3803\n",
            "Epoch 10/100\n",
            "1000/1000 [==============================] - 1s 766us/step - loss: 0.6940 - acc: 0.4900 - val_loss: 0.6929 - val_acc: 0.6197\n",
            "Epoch 11/100\n",
            "1000/1000 [==============================] - 1s 768us/step - loss: 0.6946 - acc: 0.4850 - val_loss: 0.6925 - val_acc: 0.6197\n",
            "Epoch 12/100\n",
            "1000/1000 [==============================] - 1s 763us/step - loss: 0.6937 - acc: 0.4700 - val_loss: 0.6990 - val_acc: 0.3803\n",
            "Epoch 13/100\n",
            "1000/1000 [==============================] - 1s 765us/step - loss: 0.6935 - acc: 0.5000 - val_loss: 0.6952 - val_acc: 0.3803\n",
            "Epoch 14/100\n",
            "1000/1000 [==============================] - 1s 769us/step - loss: 0.6943 - acc: 0.4870 - val_loss: 0.6924 - val_acc: 0.6197\n",
            "Epoch 15/100\n",
            "1000/1000 [==============================] - 1s 767us/step - loss: 0.6936 - acc: 0.4870 - val_loss: 0.6953 - val_acc: 0.3803\n",
            "Epoch 16/100\n",
            "1000/1000 [==============================] - 1s 768us/step - loss: 0.6931 - acc: 0.4770 - val_loss: 0.6940 - val_acc: 0.3803\n",
            "Epoch 17/100\n",
            "1000/1000 [==============================] - 1s 769us/step - loss: 0.6938 - acc: 0.4880 - val_loss: 0.6923 - val_acc: 0.6197\n",
            "Epoch 18/100\n",
            "1000/1000 [==============================] - 1s 768us/step - loss: 0.6935 - acc: 0.4900 - val_loss: 0.6947 - val_acc: 0.3803\n",
            "Epoch 19/100\n",
            "1000/1000 [==============================] - 1s 770us/step - loss: 0.7234 - acc: 0.4860 - val_loss: 0.6928 - val_acc: 0.6197\n",
            "Epoch 20/100\n",
            "1000/1000 [==============================] - 1s 764us/step - loss: 0.7077 - acc: 0.4760 - val_loss: 0.6949 - val_acc: 0.3803\n",
            "Epoch 21/100\n",
            "1000/1000 [==============================] - 1s 767us/step - loss: 0.6935 - acc: 0.4820 - val_loss: 0.6939 - val_acc: 0.3803\n",
            "Epoch 22/100\n",
            "1000/1000 [==============================] - 1s 772us/step - loss: 0.6942 - acc: 0.4880 - val_loss: 0.6947 - val_acc: 0.3803\n",
            "Epoch 23/100\n",
            "1000/1000 [==============================] - 1s 769us/step - loss: 0.6942 - acc: 0.4900 - val_loss: 0.6946 - val_acc: 0.3803\n",
            "Epoch 24/100\n",
            "1000/1000 [==============================] - 1s 770us/step - loss: 0.6934 - acc: 0.5000 - val_loss: 0.6948 - val_acc: 0.3803\n",
            "Epoch 25/100\n",
            "1000/1000 [==============================] - 1s 772us/step - loss: 0.6934 - acc: 0.4900 - val_loss: 0.6937 - val_acc: 0.3803\n",
            "Epoch 26/100\n",
            "1000/1000 [==============================] - 1s 778us/step - loss: 0.6934 - acc: 0.4830 - val_loss: 0.6930 - val_acc: 0.6197\n",
            "Epoch 27/100\n",
            "1000/1000 [==============================] - 1s 778us/step - loss: 0.6936 - acc: 0.4650 - val_loss: 0.6908 - val_acc: 0.6197\n",
            "Epoch 28/100\n",
            "1000/1000 [==============================] - 1s 773us/step - loss: 0.6939 - acc: 0.4800 - val_loss: 0.6930 - val_acc: 0.6197\n",
            "Epoch 29/100\n",
            "1000/1000 [==============================] - 1s 778us/step - loss: 0.6934 - acc: 0.4720 - val_loss: 0.6915 - val_acc: 0.6197\n",
            "Epoch 30/100\n",
            "1000/1000 [==============================] - 1s 776us/step - loss: 0.6935 - acc: 0.5000 - val_loss: 0.6921 - val_acc: 0.6197\n",
            "Epoch 31/100\n",
            "1000/1000 [==============================] - 1s 775us/step - loss: 0.6940 - acc: 0.4950 - val_loss: 0.6942 - val_acc: 0.3803\n",
            "Epoch 32/100\n",
            "1000/1000 [==============================] - 1s 781us/step - loss: 0.6931 - acc: 0.5010 - val_loss: 0.6956 - val_acc: 0.3803\n",
            "Epoch 33/100\n",
            "1000/1000 [==============================] - 1s 773us/step - loss: 0.6938 - acc: 0.4860 - val_loss: 0.6927 - val_acc: 0.6197\n",
            "Epoch 34/100\n",
            "1000/1000 [==============================] - 1s 776us/step - loss: 0.6936 - acc: 0.4730 - val_loss: 0.6929 - val_acc: 0.6197\n",
            "Epoch 35/100\n",
            "1000/1000 [==============================] - 1s 783us/step - loss: 0.6935 - acc: 0.4780 - val_loss: 0.6934 - val_acc: 0.3803\n",
            "Epoch 36/100\n",
            "1000/1000 [==============================] - 1s 785us/step - loss: 0.6933 - acc: 0.4850 - val_loss: 0.6924 - val_acc: 0.6197\n",
            "Epoch 37/100\n",
            "1000/1000 [==============================] - 1s 774us/step - loss: 0.6938 - acc: 0.5000 - val_loss: 0.6914 - val_acc: 0.6197\n",
            "Epoch 38/100\n",
            "1000/1000 [==============================] - 1s 778us/step - loss: 0.6936 - acc: 0.4980 - val_loss: 0.6962 - val_acc: 0.3803\n",
            "Epoch 39/100\n",
            "1000/1000 [==============================] - 1s 777us/step - loss: 0.6935 - acc: 0.4740 - val_loss: 0.6954 - val_acc: 0.3803\n",
            "Epoch 40/100\n",
            "1000/1000 [==============================] - 1s 782us/step - loss: 0.6939 - acc: 0.4680 - val_loss: 0.6958 - val_acc: 0.3803\n",
            "Epoch 41/100\n",
            "1000/1000 [==============================] - 1s 787us/step - loss: 0.6939 - acc: 0.4840 - val_loss: 0.6901 - val_acc: 0.6197\n",
            "Epoch 42/100\n",
            "1000/1000 [==============================] - 1s 776us/step - loss: 0.6946 - acc: 0.4800 - val_loss: 0.6905 - val_acc: 0.6197\n",
            "Epoch 43/100\n",
            "1000/1000 [==============================] - 1s 792us/step - loss: 0.6931 - acc: 0.4890 - val_loss: 0.6895 - val_acc: 0.6197\n",
            "Epoch 44/100\n",
            "1000/1000 [==============================] - 1s 780us/step - loss: 0.6938 - acc: 0.4830 - val_loss: 0.6912 - val_acc: 0.6197\n",
            "Epoch 45/100\n",
            "1000/1000 [==============================] - 1s 778us/step - loss: 0.6937 - acc: 0.4970 - val_loss: 0.6940 - val_acc: 0.3803\n",
            "Epoch 46/100\n",
            "1000/1000 [==============================] - 1s 777us/step - loss: 0.6937 - acc: 0.4880 - val_loss: 0.6927 - val_acc: 0.6197\n",
            "Epoch 47/100\n",
            "1000/1000 [==============================] - 1s 785us/step - loss: 0.6934 - acc: 0.4960 - val_loss: 0.6953 - val_acc: 0.3803\n",
            "Epoch 48/100\n",
            "1000/1000 [==============================] - 1s 786us/step - loss: 0.6939 - acc: 0.4960 - val_loss: 0.6898 - val_acc: 0.6197\n",
            "Epoch 49/100\n",
            "1000/1000 [==============================] - 1s 784us/step - loss: 0.6938 - acc: 0.4840 - val_loss: 0.6956 - val_acc: 0.3803\n",
            "Epoch 50/100\n",
            "1000/1000 [==============================] - 1s 782us/step - loss: 0.6936 - acc: 0.4890 - val_loss: 0.6893 - val_acc: 0.6197\n",
            "Epoch 51/100\n",
            "1000/1000 [==============================] - 1s 781us/step - loss: 0.6935 - acc: 0.4800 - val_loss: 0.6918 - val_acc: 0.6197\n",
            "Epoch 52/100\n",
            "1000/1000 [==============================] - 1s 776us/step - loss: 0.6934 - acc: 0.4850 - val_loss: 0.6957 - val_acc: 0.3803\n",
            "Epoch 53/100\n",
            "1000/1000 [==============================] - 1s 778us/step - loss: 0.7088 - acc: 0.4780 - val_loss: 0.6947 - val_acc: 0.3803\n",
            "Epoch 54/100\n",
            "1000/1000 [==============================] - 1s 785us/step - loss: 0.6935 - acc: 0.4920 - val_loss: 0.6953 - val_acc: 0.3803\n",
            "Epoch 55/100\n",
            "1000/1000 [==============================] - 1s 780us/step - loss: 0.6935 - acc: 0.4780 - val_loss: 0.6916 - val_acc: 0.6197\n",
            "Epoch 56/100\n",
            "1000/1000 [==============================] - 1s 780us/step - loss: 0.6971 - acc: 0.5000 - val_loss: 0.6913 - val_acc: 0.6197\n",
            "Epoch 57/100\n",
            "1000/1000 [==============================] - 1s 789us/step - loss: 0.7090 - acc: 0.4880 - val_loss: 0.6970 - val_acc: 0.3803\n",
            "Epoch 58/100\n",
            "1000/1000 [==============================] - 1s 776us/step - loss: 0.7011 - acc: 0.4930 - val_loss: 0.6910 - val_acc: 0.6197\n",
            "Epoch 59/100\n",
            "1000/1000 [==============================] - 1s 782us/step - loss: 0.6936 - acc: 0.4850 - val_loss: 0.6958 - val_acc: 0.3803\n",
            "Epoch 60/100\n",
            "1000/1000 [==============================] - 1s 776us/step - loss: 0.6939 - acc: 0.5020 - val_loss: 0.6908 - val_acc: 0.6197\n",
            "Epoch 61/100\n",
            "1000/1000 [==============================] - 1s 788us/step - loss: 0.6937 - acc: 0.4770 - val_loss: 0.6944 - val_acc: 0.3803\n",
            "Epoch 62/100\n",
            "1000/1000 [==============================] - 1s 778us/step - loss: 0.6937 - acc: 0.4910 - val_loss: 0.6902 - val_acc: 0.6197\n",
            "Epoch 63/100\n",
            "1000/1000 [==============================] - 1s 782us/step - loss: 0.6938 - acc: 0.4920 - val_loss: 0.6947 - val_acc: 0.3803\n",
            "Epoch 64/100\n",
            "1000/1000 [==============================] - 1s 780us/step - loss: 0.6931 - acc: 0.4960 - val_loss: 0.6887 - val_acc: 0.6197\n",
            "Epoch 65/100\n",
            "1000/1000 [==============================] - 1s 779us/step - loss: 0.6936 - acc: 0.4730 - val_loss: 0.6924 - val_acc: 0.6197\n",
            "Epoch 66/100\n",
            "1000/1000 [==============================] - 1s 779us/step - loss: 0.6934 - acc: 0.4850 - val_loss: 0.6919 - val_acc: 0.6197\n",
            "Epoch 67/100\n",
            "1000/1000 [==============================] - 1s 789us/step - loss: 0.6937 - acc: 0.5000 - val_loss: 0.6929 - val_acc: 0.6197\n",
            "Epoch 68/100\n",
            "1000/1000 [==============================] - 1s 782us/step - loss: 0.7097 - acc: 0.5000 - val_loss: 0.6959 - val_acc: 0.3803\n",
            "Epoch 69/100\n",
            "1000/1000 [==============================] - 1s 781us/step - loss: 0.6938 - acc: 0.4910 - val_loss: 0.6920 - val_acc: 0.6197\n",
            "Epoch 70/100\n",
            "1000/1000 [==============================] - 1s 773us/step - loss: 0.6933 - acc: 0.4960 - val_loss: 0.6952 - val_acc: 0.3803\n",
            "Epoch 71/100\n",
            "1000/1000 [==============================] - 1s 778us/step - loss: 0.6935 - acc: 0.4640 - val_loss: 0.6914 - val_acc: 0.6197\n",
            "Epoch 72/100\n",
            "1000/1000 [==============================] - 1s 782us/step - loss: 0.6932 - acc: 0.4820 - val_loss: 0.6960 - val_acc: 0.3803\n",
            "Epoch 73/100\n",
            "1000/1000 [==============================] - 1s 778us/step - loss: 0.6935 - acc: 0.5000 - val_loss: 0.6932 - val_acc: 0.3803\n",
            "Epoch 74/100\n",
            "1000/1000 [==============================] - 1s 773us/step - loss: 0.6934 - acc: 0.4820 - val_loss: 0.6928 - val_acc: 0.6197\n",
            "Epoch 75/100\n",
            "1000/1000 [==============================] - 1s 775us/step - loss: 0.6936 - acc: 0.4820 - val_loss: 0.6925 - val_acc: 0.6197\n",
            "Epoch 76/100\n",
            "1000/1000 [==============================] - 1s 775us/step - loss: 0.6928 - acc: 0.4850 - val_loss: 0.6914 - val_acc: 0.6197\n",
            "Epoch 77/100\n",
            "1000/1000 [==============================] - 1s 771us/step - loss: 0.6934 - acc: 0.4840 - val_loss: 0.6920 - val_acc: 0.6197\n",
            "Epoch 78/100\n",
            "1000/1000 [==============================] - 1s 769us/step - loss: 0.6964 - acc: 0.5000 - val_loss: 0.6915 - val_acc: 0.6197\n",
            "Epoch 79/100\n",
            "1000/1000 [==============================] - 1s 777us/step - loss: 0.6934 - acc: 0.4800 - val_loss: 0.6948 - val_acc: 0.3803\n",
            "Epoch 80/100\n",
            "1000/1000 [==============================] - 1s 777us/step - loss: 0.6928 - acc: 0.5010 - val_loss: 0.6958 - val_acc: 0.3803\n",
            "Epoch 81/100\n",
            "1000/1000 [==============================] - 1s 777us/step - loss: 0.6931 - acc: 0.4920 - val_loss: 0.6932 - val_acc: 0.3803\n",
            "Epoch 82/100\n",
            "1000/1000 [==============================] - 1s 768us/step - loss: 0.6935 - acc: 0.4860 - val_loss: 0.6929 - val_acc: 0.6197\n",
            "Epoch 83/100\n",
            "1000/1000 [==============================] - 1s 779us/step - loss: 0.6935 - acc: 0.4880 - val_loss: 0.6974 - val_acc: 0.3803\n",
            "Epoch 84/100\n",
            "1000/1000 [==============================] - 1s 775us/step - loss: 0.6936 - acc: 0.4800 - val_loss: 0.6967 - val_acc: 0.3803\n",
            "Epoch 85/100\n",
            "1000/1000 [==============================] - 1s 773us/step - loss: 0.6935 - acc: 0.4880 - val_loss: 0.6939 - val_acc: 0.3803\n",
            "Epoch 86/100\n",
            "1000/1000 [==============================] - 1s 770us/step - loss: 0.6933 - acc: 0.5000 - val_loss: 0.6938 - val_acc: 0.3803\n",
            "Epoch 87/100\n",
            "1000/1000 [==============================] - 1s 770us/step - loss: 0.6934 - acc: 0.4980 - val_loss: 0.6929 - val_acc: 0.6197\n",
            "Epoch 88/100\n",
            "1000/1000 [==============================] - 1s 775us/step - loss: 0.6936 - acc: 0.4680 - val_loss: 0.6933 - val_acc: 0.3803\n",
            "Epoch 89/100\n",
            "1000/1000 [==============================] - 1s 767us/step - loss: 0.7079 - acc: 0.4700 - val_loss: 0.6922 - val_acc: 0.6197\n",
            "Epoch 90/100\n",
            "1000/1000 [==============================] - 1s 775us/step - loss: 0.6934 - acc: 0.4770 - val_loss: 0.6928 - val_acc: 0.6197\n",
            "Epoch 91/100\n",
            "1000/1000 [==============================] - 1s 765us/step - loss: 0.6937 - acc: 0.4580 - val_loss: 0.6933 - val_acc: 0.3803\n",
            "Epoch 92/100\n",
            "1000/1000 [==============================] - 1s 774us/step - loss: 0.6935 - acc: 0.4620 - val_loss: 0.6907 - val_acc: 0.6197\n",
            "Epoch 93/100\n",
            "1000/1000 [==============================] - 1s 768us/step - loss: 0.6934 - acc: 0.4950 - val_loss: 0.6945 - val_acc: 0.3803\n",
            "Epoch 94/100\n",
            "1000/1000 [==============================] - 1s 767us/step - loss: 0.6936 - acc: 0.5000 - val_loss: 0.6931 - val_acc: 0.6197\n",
            "Epoch 95/100\n",
            "1000/1000 [==============================] - 1s 772us/step - loss: 0.6936 - acc: 0.5000 - val_loss: 0.6899 - val_acc: 0.6197\n",
            "Epoch 96/100\n",
            "1000/1000 [==============================] - 1s 772us/step - loss: 0.6934 - acc: 0.5050 - val_loss: 0.6938 - val_acc: 0.3803\n",
            "Epoch 97/100\n",
            "1000/1000 [==============================] - 1s 769us/step - loss: 0.6934 - acc: 0.5000 - val_loss: 0.6938 - val_acc: 0.3803\n",
            "Epoch 98/100\n",
            "1000/1000 [==============================] - 1s 771us/step - loss: 0.6934 - acc: 0.4860 - val_loss: 0.6935 - val_acc: 0.3803\n",
            "Epoch 99/100\n",
            "1000/1000 [==============================] - 1s 765us/step - loss: 0.6934 - acc: 0.4710 - val_loss: 0.6946 - val_acc: 0.3803\n",
            "Epoch 100/100\n",
            "1000/1000 [==============================] - 1s 768us/step - loss: 0.7083 - acc: 0.5000 - val_loss: 0.6941 - val_acc: 0.3803\n",
            "[[ 0 44]\n",
            " [ 0 27]]\n",
            "Accuracy :  0.38028169014084506\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        44\n",
            "           1       0.38      1.00      0.55        27\n",
            "\n",
            "    accuracy                           0.38        71\n",
            "   macro avg       0.19      0.50      0.28        71\n",
            "weighted avg       0.14      0.38      0.21        71\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:257: UserWarning: After over-sampling, the number of samples (500) in class 1 will be larger than the number of samples in the majority class (class #0 -> 266)\n",
            "  n_samples_majority))\n",
            "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:257: UserWarning: After over-sampling, the number of samples (500) in class 0 will be larger than the number of samples in the majority class (class #0 -> 266)\n",
            "  n_samples_majority))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "model_2 (Model)              (None, 2)                 9148782   \n",
            "=================================================================\n",
            "Total params: 9,148,782\n",
            "Trainable params: 8,386\n",
            "Non-trainable params: 9,140,396\n",
            "_________________________________________________________________\n",
            "Train on 1000 samples, validate on 71 samples\n",
            "Epoch 1/100\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.6961 - acc: 0.4830 - val_loss: 0.6930 - val_acc: 0.6197\n",
            "Epoch 2/100\n",
            "1000/1000 [==============================] - 1s 761us/step - loss: 0.6934 - acc: 0.4970 - val_loss: 0.6926 - val_acc: 0.6197\n",
            "Epoch 3/100\n",
            "1000/1000 [==============================] - 1s 762us/step - loss: 0.6934 - acc: 0.4880 - val_loss: 0.6939 - val_acc: 0.3803\n",
            "Epoch 4/100\n",
            "1000/1000 [==============================] - 1s 763us/step - loss: 0.6938 - acc: 0.5000 - val_loss: 0.6947 - val_acc: 0.3803\n",
            "Epoch 5/100\n",
            "1000/1000 [==============================] - 1s 764us/step - loss: 0.7091 - acc: 0.5020 - val_loss: 0.6925 - val_acc: 0.6197\n",
            "Epoch 6/100\n",
            "1000/1000 [==============================] - 1s 762us/step - loss: 0.6941 - acc: 0.4790 - val_loss: 0.6901 - val_acc: 0.6197\n",
            "Epoch 7/100\n",
            "1000/1000 [==============================] - 1s 765us/step - loss: 0.6944 - acc: 0.4970 - val_loss: 0.6954 - val_acc: 0.3803\n",
            "Epoch 8/100\n",
            "1000/1000 [==============================] - 1s 766us/step - loss: 0.6938 - acc: 0.4730 - val_loss: 0.6967 - val_acc: 0.3803\n",
            "Epoch 9/100\n",
            "1000/1000 [==============================] - 1s 766us/step - loss: 0.6944 - acc: 0.4940 - val_loss: 0.6875 - val_acc: 0.6197\n",
            "Epoch 10/100\n",
            "1000/1000 [==============================] - 1s 769us/step - loss: 0.6937 - acc: 0.4990 - val_loss: 0.6952 - val_acc: 0.3803\n",
            "Epoch 11/100\n",
            "1000/1000 [==============================] - 1s 771us/step - loss: 0.6937 - acc: 0.4860 - val_loss: 0.6963 - val_acc: 0.3803\n",
            "Epoch 12/100\n",
            "1000/1000 [==============================] - 1s 766us/step - loss: 0.6934 - acc: 0.5030 - val_loss: 0.6919 - val_acc: 0.6197\n",
            "Epoch 13/100\n",
            "1000/1000 [==============================] - 1s 773us/step - loss: 0.6935 - acc: 0.4960 - val_loss: 0.6950 - val_acc: 0.3803\n",
            "Epoch 14/100\n",
            "1000/1000 [==============================] - 1s 763us/step - loss: 0.6944 - acc: 0.4860 - val_loss: 0.6907 - val_acc: 0.6197\n",
            "Epoch 15/100\n",
            "1000/1000 [==============================] - 1s 768us/step - loss: 0.6935 - acc: 0.4800 - val_loss: 0.6941 - val_acc: 0.3803\n",
            "Epoch 16/100\n",
            "1000/1000 [==============================] - 1s 766us/step - loss: 0.6934 - acc: 0.5000 - val_loss: 0.6969 - val_acc: 0.3803\n",
            "Epoch 17/100\n",
            "1000/1000 [==============================] - 1s 770us/step - loss: 0.6936 - acc: 0.4740 - val_loss: 0.6944 - val_acc: 0.3803\n",
            "Epoch 18/100\n",
            "1000/1000 [==============================] - 1s 770us/step - loss: 0.6935 - acc: 0.5020 - val_loss: 0.6896 - val_acc: 0.6197\n",
            "Epoch 19/100\n",
            "1000/1000 [==============================] - 1s 773us/step - loss: 0.6936 - acc: 0.4810 - val_loss: 0.6924 - val_acc: 0.6197\n",
            "Epoch 20/100\n",
            "1000/1000 [==============================] - 1s 769us/step - loss: 0.6949 - acc: 0.5000 - val_loss: 0.6912 - val_acc: 0.6197\n",
            "Epoch 21/100\n",
            "1000/1000 [==============================] - 1s 770us/step - loss: 0.6938 - acc: 0.4770 - val_loss: 0.6964 - val_acc: 0.3803\n",
            "Epoch 22/100\n",
            "1000/1000 [==============================] - 1s 768us/step - loss: 0.6939 - acc: 0.4870 - val_loss: 0.6925 - val_acc: 0.6197\n",
            "Epoch 23/100\n",
            "1000/1000 [==============================] - 1s 768us/step - loss: 0.6935 - acc: 0.4890 - val_loss: 0.6963 - val_acc: 0.3803\n",
            "Epoch 24/100\n",
            "1000/1000 [==============================] - 1s 772us/step - loss: 0.6935 - acc: 0.4830 - val_loss: 0.6922 - val_acc: 0.6197\n",
            "Epoch 25/100\n",
            "1000/1000 [==============================] - 1s 774us/step - loss: 0.6936 - acc: 0.4800 - val_loss: 0.6926 - val_acc: 0.6197\n",
            "Epoch 26/100\n",
            "1000/1000 [==============================] - 1s 779us/step - loss: 0.6933 - acc: 0.4910 - val_loss: 0.6953 - val_acc: 0.3803\n",
            "Epoch 27/100\n",
            "1000/1000 [==============================] - 1s 774us/step - loss: 0.6947 - acc: 0.4870 - val_loss: 0.6961 - val_acc: 0.3803\n",
            "Epoch 28/100\n",
            "1000/1000 [==============================] - 1s 778us/step - loss: 0.6938 - acc: 0.5000 - val_loss: 0.6980 - val_acc: 0.3803\n",
            "Epoch 29/100\n",
            "1000/1000 [==============================] - 1s 777us/step - loss: 0.6934 - acc: 0.4910 - val_loss: 0.6927 - val_acc: 0.6197\n",
            "Epoch 30/100\n",
            "1000/1000 [==============================] - 1s 776us/step - loss: 0.6933 - acc: 0.4970 - val_loss: 0.6927 - val_acc: 0.6197\n",
            "Epoch 31/100\n",
            "1000/1000 [==============================] - 1s 782us/step - loss: 0.6936 - acc: 0.4710 - val_loss: 0.6936 - val_acc: 0.3803\n",
            "Epoch 32/100\n",
            "1000/1000 [==============================] - 1s 777us/step - loss: 0.6934 - acc: 0.4880 - val_loss: 0.6948 - val_acc: 0.3803\n",
            "Epoch 33/100\n",
            "1000/1000 [==============================] - 1s 776us/step - loss: 0.6937 - acc: 0.4990 - val_loss: 0.6906 - val_acc: 0.6197\n",
            "Epoch 34/100\n",
            "1000/1000 [==============================] - 1s 777us/step - loss: 0.6932 - acc: 0.5010 - val_loss: 0.6965 - val_acc: 0.3803\n",
            "Epoch 35/100\n",
            "1000/1000 [==============================] - 1s 782us/step - loss: 0.6938 - acc: 0.4860 - val_loss: 0.6955 - val_acc: 0.3803\n",
            "Epoch 36/100\n",
            "1000/1000 [==============================] - 1s 787us/step - loss: 0.6936 - acc: 0.4720 - val_loss: 0.6974 - val_acc: 0.3803\n",
            "Epoch 37/100\n",
            "1000/1000 [==============================] - 1s 781us/step - loss: 0.6947 - acc: 0.4780 - val_loss: 0.6928 - val_acc: 0.6197\n",
            "Epoch 38/100\n",
            "1000/1000 [==============================] - 1s 788us/step - loss: 0.6936 - acc: 0.5070 - val_loss: 0.6973 - val_acc: 0.3803\n",
            "Epoch 39/100\n",
            "1000/1000 [==============================] - 1s 783us/step - loss: 0.6936 - acc: 0.4850 - val_loss: 0.6924 - val_acc: 0.6197\n",
            "Epoch 40/100\n",
            "1000/1000 [==============================] - 1s 781us/step - loss: 0.6938 - acc: 0.4690 - val_loss: 0.6905 - val_acc: 0.6197\n",
            "Epoch 41/100\n",
            "1000/1000 [==============================] - 1s 784us/step - loss: 0.6938 - acc: 0.4800 - val_loss: 0.6968 - val_acc: 0.3803\n",
            "Epoch 42/100\n",
            "1000/1000 [==============================] - 1s 780us/step - loss: 0.6935 - acc: 0.4780 - val_loss: 0.6923 - val_acc: 0.6197\n",
            "Epoch 43/100\n",
            "1000/1000 [==============================] - 1s 783us/step - loss: 0.6938 - acc: 0.4890 - val_loss: 0.6928 - val_acc: 0.6197\n",
            "Epoch 44/100\n",
            "1000/1000 [==============================] - 1s 785us/step - loss: 0.6940 - acc: 0.4840 - val_loss: 0.6961 - val_acc: 0.3803\n",
            "Epoch 45/100\n",
            "1000/1000 [==============================] - 1s 778us/step - loss: 0.6933 - acc: 0.5060 - val_loss: 0.6920 - val_acc: 0.6197\n",
            "Epoch 46/100\n",
            "1000/1000 [==============================] - 1s 784us/step - loss: 0.6951 - acc: 0.5120 - val_loss: 0.6948 - val_acc: 0.3803\n",
            "Epoch 47/100\n",
            "1000/1000 [==============================] - 1s 781us/step - loss: 0.6934 - acc: 0.5010 - val_loss: 0.6981 - val_acc: 0.3803\n",
            "Epoch 48/100\n",
            "1000/1000 [==============================] - 1s 784us/step - loss: 0.6934 - acc: 0.4940 - val_loss: 0.6914 - val_acc: 0.6197\n",
            "Epoch 49/100\n",
            "1000/1000 [==============================] - 1s 782us/step - loss: 0.6935 - acc: 0.4960 - val_loss: 0.6946 - val_acc: 0.3803\n",
            "Epoch 50/100\n",
            "1000/1000 [==============================] - 1s 782us/step - loss: 0.7057 - acc: 0.4990 - val_loss: 0.6932 - val_acc: 0.3803\n",
            "Epoch 51/100\n",
            "1000/1000 [==============================] - 1s 787us/step - loss: 0.6940 - acc: 0.5010 - val_loss: 0.6908 - val_acc: 0.6197\n",
            "Epoch 52/100\n",
            "1000/1000 [==============================] - 1s 775us/step - loss: 0.6934 - acc: 0.4980 - val_loss: 0.6957 - val_acc: 0.3803\n",
            "Epoch 53/100\n",
            "1000/1000 [==============================] - 1s 787us/step - loss: 0.6938 - acc: 0.4990 - val_loss: 0.6925 - val_acc: 0.6197\n",
            "Epoch 54/100\n",
            "1000/1000 [==============================] - 1s 777us/step - loss: 0.6937 - acc: 0.5000 - val_loss: 0.6923 - val_acc: 0.6197\n",
            "Epoch 55/100\n",
            "1000/1000 [==============================] - 1s 784us/step - loss: 0.6934 - acc: 0.4880 - val_loss: 0.6945 - val_acc: 0.3803\n",
            "Epoch 56/100\n",
            "1000/1000 [==============================] - 1s 793us/step - loss: 0.6936 - acc: 0.4970 - val_loss: 0.6909 - val_acc: 0.6197\n",
            "Epoch 57/100\n",
            "1000/1000 [==============================] - 1s 787us/step - loss: 0.6935 - acc: 0.4880 - val_loss: 0.6927 - val_acc: 0.6197\n",
            "Epoch 58/100\n",
            "1000/1000 [==============================] - 1s 780us/step - loss: 0.6938 - acc: 0.5010 - val_loss: 0.6935 - val_acc: 0.3803\n",
            "Epoch 59/100\n",
            "1000/1000 [==============================] - 1s 784us/step - loss: 0.6934 - acc: 0.4820 - val_loss: 0.6972 - val_acc: 0.3803\n",
            "Epoch 60/100\n",
            "1000/1000 [==============================] - 1s 780us/step - loss: 0.6934 - acc: 0.4930 - val_loss: 0.6928 - val_acc: 0.6197\n",
            "Epoch 61/100\n",
            "1000/1000 [==============================] - 1s 782us/step - loss: 0.6935 - acc: 0.5000 - val_loss: 0.6934 - val_acc: 0.3803\n",
            "Epoch 62/100\n",
            "1000/1000 [==============================] - 1s 779us/step - loss: 0.6936 - acc: 0.4710 - val_loss: 0.6951 - val_acc: 0.3803\n",
            "Epoch 63/100\n",
            "1000/1000 [==============================] - 1s 781us/step - loss: 0.6942 - acc: 0.4990 - val_loss: 0.6926 - val_acc: 0.6197\n",
            "Epoch 64/100\n",
            "1000/1000 [==============================] - 1s 782us/step - loss: 0.6937 - acc: 0.4930 - val_loss: 0.6941 - val_acc: 0.3803\n",
            "Epoch 65/100\n",
            "1000/1000 [==============================] - 1s 790us/step - loss: 0.6938 - acc: 0.4660 - val_loss: 0.6926 - val_acc: 0.6197\n",
            "Epoch 66/100\n",
            "1000/1000 [==============================] - 1s 794us/step - loss: 0.6934 - acc: 0.4870 - val_loss: 0.6910 - val_acc: 0.6197\n",
            "Epoch 67/100\n",
            "1000/1000 [==============================] - 1s 778us/step - loss: 0.6933 - acc: 0.4850 - val_loss: 0.6944 - val_acc: 0.3803\n",
            "Epoch 68/100\n",
            "1000/1000 [==============================] - 1s 780us/step - loss: 0.6939 - acc: 0.5000 - val_loss: 0.6928 - val_acc: 0.6197\n",
            "Epoch 69/100\n",
            "1000/1000 [==============================] - 1s 779us/step - loss: 0.7090 - acc: 0.5000 - val_loss: 0.6927 - val_acc: 0.6197\n",
            "Epoch 70/100\n",
            "1000/1000 [==============================] - 1s 781us/step - loss: 0.6941 - acc: 0.4900 - val_loss: 0.6959 - val_acc: 0.3803\n",
            "Epoch 71/100\n",
            "1000/1000 [==============================] - 1s 785us/step - loss: 0.6934 - acc: 0.5000 - val_loss: 0.6955 - val_acc: 0.3803\n",
            "Epoch 72/100\n",
            "1000/1000 [==============================] - 1s 787us/step - loss: 0.6933 - acc: 0.5000 - val_loss: 0.6936 - val_acc: 0.3803\n",
            "Epoch 73/100\n",
            "1000/1000 [==============================] - 1s 780us/step - loss: 0.6935 - acc: 0.4730 - val_loss: 0.6936 - val_acc: 0.3803\n",
            "Epoch 74/100\n",
            "1000/1000 [==============================] - 1s 785us/step - loss: 0.6933 - acc: 0.4860 - val_loss: 0.6925 - val_acc: 0.6197\n",
            "Epoch 75/100\n",
            "1000/1000 [==============================] - 1s 781us/step - loss: 0.6936 - acc: 0.4770 - val_loss: 0.6910 - val_acc: 0.6197\n",
            "Epoch 76/100\n",
            "1000/1000 [==============================] - 1s 787us/step - loss: 0.6937 - acc: 0.4880 - val_loss: 0.6932 - val_acc: 0.3803\n",
            "Epoch 77/100\n",
            "1000/1000 [==============================] - 1s 784us/step - loss: 0.6936 - acc: 0.4950 - val_loss: 0.6937 - val_acc: 0.3803\n",
            "Epoch 78/100\n",
            "1000/1000 [==============================] - 1s 784us/step - loss: 0.6935 - acc: 0.4650 - val_loss: 0.6913 - val_acc: 0.6197\n",
            "Epoch 79/100\n",
            "1000/1000 [==============================] - 1s 780us/step - loss: 0.6934 - acc: 0.5000 - val_loss: 0.6924 - val_acc: 0.6197\n",
            "Epoch 80/100\n",
            "1000/1000 [==============================] - 1s 790us/step - loss: 0.6938 - acc: 0.4650 - val_loss: 0.6949 - val_acc: 0.3803\n",
            "Epoch 81/100\n",
            "1000/1000 [==============================] - 1s 778us/step - loss: 0.6937 - acc: 0.4700 - val_loss: 0.6939 - val_acc: 0.3803\n",
            "Epoch 82/100\n",
            "1000/1000 [==============================] - 1s 787us/step - loss: 0.6935 - acc: 0.4890 - val_loss: 0.6917 - val_acc: 0.6197\n",
            "Epoch 83/100\n",
            "1000/1000 [==============================] - 1s 780us/step - loss: 0.6935 - acc: 0.4900 - val_loss: 0.6937 - val_acc: 0.3803\n",
            "Epoch 84/100\n",
            "1000/1000 [==============================] - 1s 780us/step - loss: 0.6936 - acc: 0.4870 - val_loss: 0.6946 - val_acc: 0.3803\n",
            "Epoch 85/100\n",
            "1000/1000 [==============================] - 1s 784us/step - loss: 0.6937 - acc: 0.4750 - val_loss: 0.6938 - val_acc: 0.3803\n",
            "Epoch 86/100\n",
            "1000/1000 [==============================] - 1s 778us/step - loss: 0.6933 - acc: 0.4720 - val_loss: 0.6928 - val_acc: 0.6197\n",
            "Epoch 87/100\n",
            "1000/1000 [==============================] - 1s 775us/step - loss: 0.6939 - acc: 0.4830 - val_loss: 0.6912 - val_acc: 0.6197\n",
            "Epoch 88/100\n",
            "1000/1000 [==============================] - 1s 777us/step - loss: 0.6938 - acc: 0.4900 - val_loss: 0.6971 - val_acc: 0.3803\n",
            "Epoch 89/100\n",
            "1000/1000 [==============================] - 1s 778us/step - loss: 0.6936 - acc: 0.4760 - val_loss: 0.6948 - val_acc: 0.3803\n",
            "Epoch 90/100\n",
            "1000/1000 [==============================] - 1s 777us/step - loss: 0.6935 - acc: 0.4980 - val_loss: 0.6926 - val_acc: 0.6197\n",
            "Epoch 91/100\n",
            "1000/1000 [==============================] - 1s 772us/step - loss: 0.6939 - acc: 0.4890 - val_loss: 0.6938 - val_acc: 0.3803\n",
            "Epoch 92/100\n",
            "1000/1000 [==============================] - 1s 769us/step - loss: 0.6934 - acc: 0.4750 - val_loss: 0.6902 - val_acc: 0.6197\n",
            "Epoch 93/100\n",
            "1000/1000 [==============================] - 1s 772us/step - loss: 0.6936 - acc: 0.5000 - val_loss: 0.6891 - val_acc: 0.6197\n",
            "Epoch 94/100\n",
            "1000/1000 [==============================] - 1s 769us/step - loss: 0.6927 - acc: 0.4870 - val_loss: 0.6929 - val_acc: 0.6197\n",
            "Epoch 95/100\n",
            "1000/1000 [==============================] - 1s 766us/step - loss: 0.6937 - acc: 0.4970 - val_loss: 0.6932 - val_acc: 0.3803\n",
            "Epoch 96/100\n",
            "1000/1000 [==============================] - 1s 773us/step - loss: 0.6938 - acc: 0.4810 - val_loss: 0.6942 - val_acc: 0.3803\n",
            "Epoch 97/100\n",
            "1000/1000 [==============================] - 1s 771us/step - loss: 0.6927 - acc: 0.4850 - val_loss: 0.6906 - val_acc: 0.6197\n",
            "Epoch 98/100\n",
            "1000/1000 [==============================] - 1s 772us/step - loss: 0.6941 - acc: 0.4730 - val_loss: 0.6912 - val_acc: 0.6197\n",
            "Epoch 99/100\n",
            "1000/1000 [==============================] - 1s 764us/step - loss: 0.6937 - acc: 0.4810 - val_loss: 0.6929 - val_acc: 0.6197\n",
            "Epoch 100/100\n",
            "1000/1000 [==============================] - 1s 777us/step - loss: 0.6936 - acc: 0.4850 - val_loss: 0.6948 - val_acc: 0.3803\n",
            "[[ 0 44]\n",
            " [ 0 27]]\n",
            "Accuracy :  0.38028169014084506\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        44\n",
            "           1       0.38      1.00      0.55        27\n",
            "\n",
            "    accuracy                           0.38        71\n",
            "   macro avg       0.19      0.50      0.28        71\n",
            "weighted avg       0.14      0.38      0.21        71\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:257: UserWarning: After over-sampling, the number of samples (500) in class 1 will be larger than the number of samples in the majority class (class #0 -> 266)\n",
            "  n_samples_majority))\n",
            "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:257: UserWarning: After over-sampling, the number of samples (500) in class 0 will be larger than the number of samples in the majority class (class #0 -> 266)\n",
            "  n_samples_majority))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "model_2 (Model)              (None, 2)                 9148782   \n",
            "=================================================================\n",
            "Total params: 9,148,782\n",
            "Trainable params: 8,386\n",
            "Non-trainable params: 9,140,396\n",
            "_________________________________________________________________\n",
            "Train on 1000 samples, validate on 71 samples\n",
            "Epoch 1/100\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.6941 - acc: 0.4980 - val_loss: 0.6888 - val_acc: 0.6197\n",
            "Epoch 2/100\n",
            "1000/1000 [==============================] - 1s 759us/step - loss: 0.6941 - acc: 0.4620 - val_loss: 0.6897 - val_acc: 0.6197\n",
            "Epoch 3/100\n",
            "1000/1000 [==============================] - 1s 769us/step - loss: 0.6936 - acc: 0.5010 - val_loss: 0.6938 - val_acc: 0.3803\n",
            "Epoch 4/100\n",
            "1000/1000 [==============================] - 1s 769us/step - loss: 0.6935 - acc: 0.4860 - val_loss: 0.6922 - val_acc: 0.6197\n",
            "Epoch 5/100\n",
            "1000/1000 [==============================] - 1s 769us/step - loss: 0.6937 - acc: 0.4930 - val_loss: 0.6944 - val_acc: 0.3803\n",
            "Epoch 6/100\n",
            "1000/1000 [==============================] - 1s 767us/step - loss: 0.6945 - acc: 0.5000 - val_loss: 0.6970 - val_acc: 0.3803\n",
            "Epoch 7/100\n",
            "1000/1000 [==============================] - 1s 764us/step - loss: 0.6941 - acc: 0.4880 - val_loss: 0.6925 - val_acc: 0.6197\n",
            "Epoch 8/100\n",
            "1000/1000 [==============================] - 1s 773us/step - loss: 0.6940 - acc: 0.5000 - val_loss: 0.6910 - val_acc: 0.6197\n",
            "Epoch 9/100\n",
            "1000/1000 [==============================] - 1s 772us/step - loss: 0.6945 - acc: 0.4880 - val_loss: 0.6919 - val_acc: 0.6197\n",
            "Epoch 10/100\n",
            "1000/1000 [==============================] - 1s 768us/step - loss: 0.6935 - acc: 0.5000 - val_loss: 0.6890 - val_acc: 0.6197\n",
            "Epoch 11/100\n",
            "1000/1000 [==============================] - 1s 771us/step - loss: 0.7102 - acc: 0.4630 - val_loss: 0.6890 - val_acc: 0.6197\n",
            "Epoch 12/100\n",
            "1000/1000 [==============================] - 1s 766us/step - loss: 0.6936 - acc: 0.4820 - val_loss: 0.6920 - val_acc: 0.6197\n",
            "Epoch 13/100\n",
            "1000/1000 [==============================] - 1s 767us/step - loss: 0.6938 - acc: 0.4790 - val_loss: 0.6910 - val_acc: 0.6197\n",
            "Epoch 14/100\n",
            "1000/1000 [==============================] - 1s 773us/step - loss: 0.6936 - acc: 0.4810 - val_loss: 0.6932 - val_acc: 0.3803\n",
            "Epoch 15/100\n",
            "1000/1000 [==============================] - 1s 776us/step - loss: 0.6938 - acc: 0.4960 - val_loss: 0.6938 - val_acc: 0.3803\n",
            "Epoch 16/100\n",
            "1000/1000 [==============================] - 1s 773us/step - loss: 0.6937 - acc: 0.4850 - val_loss: 0.6925 - val_acc: 0.6197\n",
            "Epoch 17/100\n",
            "1000/1000 [==============================] - 1s 769us/step - loss: 0.6935 - acc: 0.5060 - val_loss: 0.6961 - val_acc: 0.3803\n",
            "Epoch 18/100\n",
            "1000/1000 [==============================] - 1s 768us/step - loss: 0.6937 - acc: 0.4910 - val_loss: 0.6926 - val_acc: 0.6197\n",
            "Epoch 19/100\n",
            "1000/1000 [==============================] - 1s 772us/step - loss: 0.6935 - acc: 0.5000 - val_loss: 0.6928 - val_acc: 0.6197\n",
            "Epoch 20/100\n",
            "1000/1000 [==============================] - 1s 769us/step - loss: 0.6939 - acc: 0.4930 - val_loss: 0.6969 - val_acc: 0.3803\n",
            "Epoch 21/100\n",
            "1000/1000 [==============================] - 1s 772us/step - loss: 0.6936 - acc: 0.4930 - val_loss: 0.6892 - val_acc: 0.6197\n",
            "Epoch 22/100\n",
            "1000/1000 [==============================] - 1s 768us/step - loss: 0.6928 - acc: 0.4950 - val_loss: 0.6948 - val_acc: 0.3803\n",
            "Epoch 23/100\n",
            "1000/1000 [==============================] - 1s 770us/step - loss: 0.7087 - acc: 0.4950 - val_loss: 0.6919 - val_acc: 0.6197\n",
            "Epoch 24/100\n",
            "1000/1000 [==============================] - 1s 774us/step - loss: 0.7085 - acc: 0.5000 - val_loss: 0.6911 - val_acc: 0.6197\n",
            "Epoch 25/100\n",
            "1000/1000 [==============================] - 1s 774us/step - loss: 0.7238 - acc: 0.4880 - val_loss: 0.6983 - val_acc: 0.3803\n",
            "Epoch 26/100\n",
            "1000/1000 [==============================] - 1s 779us/step - loss: 0.7083 - acc: 0.4770 - val_loss: 0.6949 - val_acc: 0.3803\n",
            "Epoch 27/100\n",
            "1000/1000 [==============================] - 1s 772us/step - loss: 0.7247 - acc: 0.4850 - val_loss: 0.6898 - val_acc: 0.6197\n",
            "Epoch 28/100\n",
            "1000/1000 [==============================] - 1s 780us/step - loss: 0.6929 - acc: 0.4850 - val_loss: 0.6941 - val_acc: 0.3803\n",
            "Epoch 29/100\n",
            "1000/1000 [==============================] - 1s 775us/step - loss: 0.6936 - acc: 0.4880 - val_loss: 0.6919 - val_acc: 0.6197\n",
            "Epoch 30/100\n",
            "1000/1000 [==============================] - 1s 775us/step - loss: 0.7076 - acc: 0.4770 - val_loss: 0.6926 - val_acc: 0.6197\n",
            "Epoch 31/100\n",
            "1000/1000 [==============================] - 1s 774us/step - loss: 0.7391 - acc: 0.4860 - val_loss: 0.6960 - val_acc: 0.3803\n",
            "Epoch 32/100\n",
            "1000/1000 [==============================] - 1s 778us/step - loss: 0.6967 - acc: 0.5000 - val_loss: 0.6930 - val_acc: 0.6197\n",
            "Epoch 33/100\n",
            "1000/1000 [==============================] - 1s 781us/step - loss: 0.6934 - acc: 0.4840 - val_loss: 0.6917 - val_acc: 0.6197\n",
            "Epoch 34/100\n",
            "1000/1000 [==============================] - 1s 776us/step - loss: 0.6938 - acc: 0.4830 - val_loss: 0.6898 - val_acc: 0.6197\n",
            "Epoch 35/100\n",
            "1000/1000 [==============================] - 1s 780us/step - loss: 0.6936 - acc: 0.5000 - val_loss: 0.6937 - val_acc: 0.3803\n",
            "Epoch 36/100\n",
            "1000/1000 [==============================] - 1s 775us/step - loss: 0.6937 - acc: 0.5000 - val_loss: 0.6942 - val_acc: 0.3803\n",
            "Epoch 37/100\n",
            "1000/1000 [==============================] - 1s 782us/step - loss: 0.6933 - acc: 0.4970 - val_loss: 0.6913 - val_acc: 0.6197\n",
            "Epoch 38/100\n",
            "1000/1000 [==============================] - 1s 783us/step - loss: 0.6937 - acc: 0.4970 - val_loss: 0.6942 - val_acc: 0.3803\n",
            "Epoch 39/100\n",
            "1000/1000 [==============================] - 1s 780us/step - loss: 0.6937 - acc: 0.4810 - val_loss: 0.6939 - val_acc: 0.3803\n",
            "Epoch 40/100\n",
            "1000/1000 [==============================] - 1s 780us/step - loss: 0.6937 - acc: 0.4930 - val_loss: 0.6927 - val_acc: 0.6197\n",
            "Epoch 41/100\n",
            "1000/1000 [==============================] - 1s 777us/step - loss: 0.6936 - acc: 0.5000 - val_loss: 0.6904 - val_acc: 0.6197\n",
            "Epoch 42/100\n",
            "1000/1000 [==============================] - 1s 783us/step - loss: 0.6945 - acc: 0.4830 - val_loss: 0.6919 - val_acc: 0.6197\n",
            "Epoch 43/100\n",
            "1000/1000 [==============================] - 1s 781us/step - loss: 0.6939 - acc: 0.5000 - val_loss: 0.6920 - val_acc: 0.6197\n",
            "Epoch 44/100\n",
            "1000/1000 [==============================] - 1s 781us/step - loss: 0.6934 - acc: 0.4570 - val_loss: 0.6939 - val_acc: 0.3803\n",
            "Epoch 45/100\n",
            "1000/1000 [==============================] - 1s 788us/step - loss: 0.6936 - acc: 0.4920 - val_loss: 0.6973 - val_acc: 0.3803\n",
            "Epoch 46/100\n",
            "1000/1000 [==============================] - 1s 784us/step - loss: 0.6938 - acc: 0.4950 - val_loss: 0.6922 - val_acc: 0.6197\n",
            "Epoch 47/100\n",
            "1000/1000 [==============================] - 1s 783us/step - loss: 0.6948 - acc: 0.4830 - val_loss: 0.6937 - val_acc: 0.3803\n",
            "Epoch 48/100\n",
            "1000/1000 [==============================] - 1s 784us/step - loss: 0.6942 - acc: 0.4720 - val_loss: 0.6938 - val_acc: 0.3803\n",
            "Epoch 49/100\n",
            "1000/1000 [==============================] - 1s 782us/step - loss: 0.6935 - acc: 0.4990 - val_loss: 0.6909 - val_acc: 0.6197\n",
            "Epoch 50/100\n",
            "1000/1000 [==============================] - 1s 783us/step - loss: 0.6934 - acc: 0.4860 - val_loss: 0.6920 - val_acc: 0.6197\n",
            "Epoch 51/100\n",
            "1000/1000 [==============================] - 1s 783us/step - loss: 0.6935 - acc: 0.4970 - val_loss: 0.6933 - val_acc: 0.3803\n",
            "Epoch 52/100\n",
            "1000/1000 [==============================] - 1s 779us/step - loss: 0.6935 - acc: 0.4960 - val_loss: 0.6896 - val_acc: 0.6197\n",
            "Epoch 53/100\n",
            "1000/1000 [==============================] - 1s 780us/step - loss: 0.6936 - acc: 0.5000 - val_loss: 0.6931 - val_acc: 0.6197\n",
            "Epoch 54/100\n",
            "1000/1000 [==============================] - 1s 780us/step - loss: 0.6938 - acc: 0.4950 - val_loss: 0.6943 - val_acc: 0.3803\n",
            "Epoch 55/100\n",
            "1000/1000 [==============================] - 1s 780us/step - loss: 0.6933 - acc: 0.4930 - val_loss: 0.6927 - val_acc: 0.6197\n",
            "Epoch 56/100\n",
            "1000/1000 [==============================] - 1s 782us/step - loss: 0.6941 - acc: 0.4910 - val_loss: 0.6975 - val_acc: 0.3803\n",
            "Epoch 57/100\n",
            "1000/1000 [==============================] - 1s 786us/step - loss: 0.6943 - acc: 0.4800 - val_loss: 0.6911 - val_acc: 0.6197\n",
            "Epoch 58/100\n",
            "1000/1000 [==============================] - 1s 789us/step - loss: 0.6937 - acc: 0.4720 - val_loss: 0.6946 - val_acc: 0.3803\n",
            "Epoch 59/100\n",
            "1000/1000 [==============================] - 1s 798us/step - loss: 0.6939 - acc: 0.4960 - val_loss: 0.6913 - val_acc: 0.6197\n",
            "Epoch 60/100\n",
            "1000/1000 [==============================] - 1s 789us/step - loss: 0.6946 - acc: 0.4670 - val_loss: 0.6889 - val_acc: 0.6197\n",
            "Epoch 61/100\n",
            "1000/1000 [==============================] - 1s 787us/step - loss: 0.6940 - acc: 0.4880 - val_loss: 0.6957 - val_acc: 0.3803\n",
            "Epoch 62/100\n",
            "1000/1000 [==============================] - 1s 782us/step - loss: 0.6934 - acc: 0.4890 - val_loss: 0.6918 - val_acc: 0.6197\n",
            "Epoch 63/100\n",
            "1000/1000 [==============================] - 1s 782us/step - loss: 0.6935 - acc: 0.4680 - val_loss: 0.6931 - val_acc: 0.6197\n",
            "Epoch 64/100\n",
            "1000/1000 [==============================] - 1s 782us/step - loss: 0.6937 - acc: 0.4910 - val_loss: 0.6922 - val_acc: 0.6197\n",
            "Epoch 65/100\n",
            "1000/1000 [==============================] - 1s 779us/step - loss: 0.6937 - acc: 0.4950 - val_loss: 0.6947 - val_acc: 0.3803\n",
            "Epoch 66/100\n",
            "1000/1000 [==============================] - 1s 779us/step - loss: 0.6935 - acc: 0.5000 - val_loss: 0.6947 - val_acc: 0.3803\n",
            "Epoch 67/100\n",
            "1000/1000 [==============================] - 1s 780us/step - loss: 0.6934 - acc: 0.4920 - val_loss: 0.6910 - val_acc: 0.6197\n",
            "Epoch 68/100\n",
            "1000/1000 [==============================] - 1s 775us/step - loss: 0.6933 - acc: 0.4970 - val_loss: 0.6934 - val_acc: 0.3803\n",
            "Epoch 69/100\n",
            "1000/1000 [==============================] - 1s 784us/step - loss: 0.6936 - acc: 0.4840 - val_loss: 0.6911 - val_acc: 0.6197\n",
            "Epoch 70/100\n",
            "1000/1000 [==============================] - 1s 799us/step - loss: 0.6942 - acc: 0.5000 - val_loss: 0.6951 - val_acc: 0.3803\n",
            "Epoch 71/100\n",
            "1000/1000 [==============================] - 1s 775us/step - loss: 0.6937 - acc: 0.5000 - val_loss: 0.6964 - val_acc: 0.3803\n",
            "Epoch 72/100\n",
            "1000/1000 [==============================] - 1s 774us/step - loss: 0.6935 - acc: 0.5000 - val_loss: 0.6948 - val_acc: 0.3803\n",
            "Epoch 73/100\n",
            "1000/1000 [==============================] - 1s 777us/step - loss: 0.6935 - acc: 0.4950 - val_loss: 0.6923 - val_acc: 0.6197\n",
            "Epoch 74/100\n",
            "1000/1000 [==============================] - 1s 778us/step - loss: 0.6935 - acc: 0.5000 - val_loss: 0.6922 - val_acc: 0.6197\n",
            "Epoch 75/100\n",
            "1000/1000 [==============================] - 1s 777us/step - loss: 0.6935 - acc: 0.5000 - val_loss: 0.6939 - val_acc: 0.3803\n",
            "Epoch 76/100\n",
            "1000/1000 [==============================] - 1s 775us/step - loss: 0.6936 - acc: 0.5000 - val_loss: 0.6963 - val_acc: 0.3803\n",
            "Epoch 77/100\n",
            "1000/1000 [==============================] - 1s 773us/step - loss: 0.6934 - acc: 0.4950 - val_loss: 0.6907 - val_acc: 0.6197\n",
            "Epoch 78/100\n",
            "1000/1000 [==============================] - 1s 784us/step - loss: 0.6934 - acc: 0.5000 - val_loss: 0.6920 - val_acc: 0.6197\n",
            "Epoch 79/100\n",
            "1000/1000 [==============================] - 1s 773us/step - loss: 0.6936 - acc: 0.4660 - val_loss: 0.6959 - val_acc: 0.3803\n",
            "Epoch 80/100\n",
            "1000/1000 [==============================] - 1s 772us/step - loss: 0.6938 - acc: 0.4980 - val_loss: 0.6897 - val_acc: 0.6197\n",
            "Epoch 81/100\n",
            "1000/1000 [==============================] - 1s 769us/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6960 - val_acc: 0.3803\n",
            "Epoch 82/100\n",
            "1000/1000 [==============================] - 1s 778us/step - loss: 0.6937 - acc: 0.4810 - val_loss: 0.6945 - val_acc: 0.3803\n",
            "Epoch 83/100\n",
            "1000/1000 [==============================] - 1s 783us/step - loss: 0.6937 - acc: 0.4740 - val_loss: 0.6934 - val_acc: 0.3803\n",
            "Epoch 84/100\n",
            "1000/1000 [==============================] - 1s 785us/step - loss: 0.6933 - acc: 0.4680 - val_loss: 0.6933 - val_acc: 0.3803\n",
            "Epoch 85/100\n",
            "1000/1000 [==============================] - 1s 777us/step - loss: 0.6936 - acc: 0.5000 - val_loss: 0.6930 - val_acc: 0.6197\n",
            "Epoch 86/100\n",
            "1000/1000 [==============================] - 1s 779us/step - loss: 0.6939 - acc: 0.5010 - val_loss: 0.6945 - val_acc: 0.3803\n",
            "Epoch 87/100\n",
            "1000/1000 [==============================] - 1s 775us/step - loss: 0.6936 - acc: 0.4780 - val_loss: 0.6968 - val_acc: 0.3803\n",
            "Epoch 88/100\n",
            "1000/1000 [==============================] - 1s 782us/step - loss: 0.6934 - acc: 0.5000 - val_loss: 0.6961 - val_acc: 0.3803\n",
            "Epoch 89/100\n",
            "1000/1000 [==============================] - 1s 775us/step - loss: 0.6938 - acc: 0.4820 - val_loss: 0.6919 - val_acc: 0.6197\n",
            "Epoch 90/100\n",
            "1000/1000 [==============================] - 1s 774us/step - loss: 0.6933 - acc: 0.4770 - val_loss: 0.6919 - val_acc: 0.6197\n",
            "Epoch 91/100\n",
            "1000/1000 [==============================] - 1s 783us/step - loss: 0.6935 - acc: 0.4750 - val_loss: 0.6924 - val_acc: 0.6197\n",
            "Epoch 92/100\n",
            "1000/1000 [==============================] - 1s 783us/step - loss: 0.6942 - acc: 0.4820 - val_loss: 0.6946 - val_acc: 0.3803\n",
            "Epoch 93/100\n",
            "1000/1000 [==============================] - 1s 781us/step - loss: 0.6939 - acc: 0.4890 - val_loss: 0.6866 - val_acc: 0.6197\n",
            "Epoch 94/100\n",
            "1000/1000 [==============================] - 1s 779us/step - loss: 0.6933 - acc: 0.4930 - val_loss: 0.6930 - val_acc: 0.6197\n",
            "Epoch 95/100\n",
            "1000/1000 [==============================] - 1s 779us/step - loss: 0.6933 - acc: 0.4960 - val_loss: 0.6949 - val_acc: 0.3803\n",
            "Epoch 96/100\n",
            "1000/1000 [==============================] - 1s 777us/step - loss: 0.6937 - acc: 0.4840 - val_loss: 0.6919 - val_acc: 0.6197\n",
            "Epoch 97/100\n",
            "1000/1000 [==============================] - 1s 775us/step - loss: 0.6934 - acc: 0.4970 - val_loss: 0.6952 - val_acc: 0.3803\n",
            "Epoch 98/100\n",
            "1000/1000 [==============================] - 1s 785us/step - loss: 0.6934 - acc: 0.4920 - val_loss: 0.6931 - val_acc: 0.6197\n",
            "Epoch 99/100\n",
            "1000/1000 [==============================] - 1s 776us/step - loss: 0.6933 - acc: 0.4950 - val_loss: 0.6943 - val_acc: 0.3803\n",
            "Epoch 100/100\n",
            "1000/1000 [==============================] - 1s 783us/step - loss: 0.6934 - acc: 0.4930 - val_loss: 0.6934 - val_acc: 0.3803\n",
            "[[ 0 44]\n",
            " [ 0 27]]\n",
            "Accuracy :  0.38028169014084506\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        44\n",
            "           1       0.38      1.00      0.55        27\n",
            "\n",
            "    accuracy                           0.38        71\n",
            "   macro avg       0.19      0.50      0.28        71\n",
            "weighted avg       0.14      0.38      0.21        71\n",
            "\n",
            "\n",
            "\n",
            "Sophistication\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "model_2 (Model)              (None, 2)                 9148782   \n",
            "=================================================================\n",
            "Total params: 9,148,782\n",
            "Trainable params: 8,386\n",
            "Non-trainable params: 9,140,396\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 428 samples, validate on 72 samples\n",
            "Epoch 1/100\n",
            "428/428 [==============================] - 5s 11ms/step - loss: 1.2146 - acc: 0.5444 - val_loss: 0.6647 - val_acc: 0.5556\n",
            "Epoch 2/100\n",
            "428/428 [==============================] - 0s 825us/step - loss: 0.6797 - acc: 0.5537 - val_loss: 0.6712 - val_acc: 0.5556\n",
            "Epoch 3/100\n",
            "428/428 [==============================] - 0s 836us/step - loss: 0.6942 - acc: 0.5514 - val_loss: 0.6728 - val_acc: 0.5556\n",
            "Epoch 4/100\n",
            "428/428 [==============================] - 0s 830us/step - loss: 0.6895 - acc: 0.5140 - val_loss: 0.6755 - val_acc: 0.5556\n",
            "Epoch 5/100\n",
            "428/428 [==============================] - 0s 824us/step - loss: 0.6825 - acc: 0.5514 - val_loss: 0.6698 - val_acc: 0.5556\n",
            "Epoch 6/100\n",
            "428/428 [==============================] - 0s 822us/step - loss: 0.6798 - acc: 0.5514 - val_loss: 0.6700 - val_acc: 0.5556\n",
            "Epoch 7/100\n",
            "428/428 [==============================] - 0s 823us/step - loss: 0.6770 - acc: 0.5514 - val_loss: 0.6725 - val_acc: 0.5556\n",
            "Epoch 8/100\n",
            "428/428 [==============================] - 0s 828us/step - loss: 0.6747 - acc: 0.5678 - val_loss: 0.6657 - val_acc: 0.6111\n",
            "Epoch 9/100\n",
            "428/428 [==============================] - 0s 824us/step - loss: 0.6816 - acc: 0.5187 - val_loss: 0.6674 - val_acc: 0.5972\n",
            "Epoch 10/100\n",
            "428/428 [==============================] - 0s 825us/step - loss: 0.6757 - acc: 0.5257 - val_loss: 0.6723 - val_acc: 0.5833\n",
            "Epoch 11/100\n",
            "428/428 [==============================] - 0s 829us/step - loss: 0.6762 - acc: 0.5514 - val_loss: 0.6731 - val_acc: 0.5694\n",
            "Epoch 12/100\n",
            "428/428 [==============================] - 0s 824us/step - loss: 0.6794 - acc: 0.5257 - val_loss: 0.6742 - val_acc: 0.5694\n",
            "Epoch 13/100\n",
            "428/428 [==============================] - 0s 825us/step - loss: 0.6918 - acc: 0.5070 - val_loss: 0.6743 - val_acc: 0.5278\n",
            "Epoch 14/100\n",
            "428/428 [==============================] - 0s 827us/step - loss: 0.6805 - acc: 0.5607 - val_loss: 0.6717 - val_acc: 0.5556\n",
            "Epoch 15/100\n",
            "428/428 [==============================] - 0s 819us/step - loss: 0.6608 - acc: 0.5514 - val_loss: 0.6669 - val_acc: 0.5556\n",
            "Epoch 16/100\n",
            "428/428 [==============================] - 0s 824us/step - loss: 0.6907 - acc: 0.5584 - val_loss: 0.6750 - val_acc: 0.5833\n",
            "Epoch 17/100\n",
            "428/428 [==============================] - 0s 827us/step - loss: 0.6832 - acc: 0.5070 - val_loss: 0.6661 - val_acc: 0.5556\n",
            "Epoch 18/100\n",
            "428/428 [==============================] - 0s 829us/step - loss: 0.6825 - acc: 0.5631 - val_loss: 0.6691 - val_acc: 0.5972\n",
            "Epoch 19/100\n",
            "428/428 [==============================] - 0s 825us/step - loss: 0.6753 - acc: 0.6051 - val_loss: 0.6645 - val_acc: 0.5694\n",
            "Epoch 20/100\n",
            "428/428 [==============================] - 0s 835us/step - loss: 0.6815 - acc: 0.5654 - val_loss: 0.6684 - val_acc: 0.5556\n",
            "Epoch 21/100\n",
            "428/428 [==============================] - 0s 817us/step - loss: 0.6889 - acc: 0.5164 - val_loss: 0.6637 - val_acc: 0.5556\n",
            "Epoch 22/100\n",
            "428/428 [==============================] - 0s 823us/step - loss: 0.6919 - acc: 0.5140 - val_loss: 0.6615 - val_acc: 0.5556\n",
            "Epoch 23/100\n",
            "428/428 [==============================] - 0s 847us/step - loss: 0.6760 - acc: 0.5514 - val_loss: 0.6637 - val_acc: 0.5417\n",
            "Epoch 24/100\n",
            "428/428 [==============================] - 0s 827us/step - loss: 0.6599 - acc: 0.5561 - val_loss: 0.6602 - val_acc: 0.5556\n",
            "Epoch 25/100\n",
            "428/428 [==============================] - 0s 827us/step - loss: 0.6712 - acc: 0.5514 - val_loss: 0.6664 - val_acc: 0.5417\n",
            "Epoch 26/100\n",
            "428/428 [==============================] - 0s 827us/step - loss: 0.6707 - acc: 0.5280 - val_loss: 0.6670 - val_acc: 0.5000\n",
            "Epoch 27/100\n",
            "428/428 [==============================] - 0s 834us/step - loss: 0.6726 - acc: 0.5654 - val_loss: 0.6642 - val_acc: 0.5139\n",
            "Epoch 28/100\n",
            "428/428 [==============================] - 0s 829us/step - loss: 0.6830 - acc: 0.5607 - val_loss: 0.6634 - val_acc: 0.5139\n",
            "Epoch 29/100\n",
            "428/428 [==============================] - 0s 828us/step - loss: 0.6686 - acc: 0.5537 - val_loss: 0.6604 - val_acc: 0.5694\n",
            "Epoch 30/100\n",
            "428/428 [==============================] - 0s 814us/step - loss: 0.6772 - acc: 0.5584 - val_loss: 0.6581 - val_acc: 0.5417\n",
            "Epoch 31/100\n",
            "428/428 [==============================] - 0s 829us/step - loss: 0.6825 - acc: 0.5164 - val_loss: 0.6572 - val_acc: 0.5139\n",
            "Epoch 32/100\n",
            "428/428 [==============================] - 0s 827us/step - loss: 0.6841 - acc: 0.5117 - val_loss: 0.6557 - val_acc: 0.5139\n",
            "Epoch 33/100\n",
            "428/428 [==============================] - 0s 820us/step - loss: 0.6790 - acc: 0.5350 - val_loss: 0.6635 - val_acc: 0.5556\n",
            "Epoch 34/100\n",
            "428/428 [==============================] - 0s 829us/step - loss: 0.6624 - acc: 0.5701 - val_loss: 0.6711 - val_acc: 0.5417\n",
            "Epoch 35/100\n",
            "428/428 [==============================] - 0s 829us/step - loss: 0.6651 - acc: 0.6051 - val_loss: 0.6696 - val_acc: 0.6111\n",
            "Epoch 36/100\n",
            "428/428 [==============================] - 0s 834us/step - loss: 0.6610 - acc: 0.5935 - val_loss: 0.6666 - val_acc: 0.6111\n",
            "Epoch 37/100\n",
            "428/428 [==============================] - 0s 844us/step - loss: 0.6700 - acc: 0.5421 - val_loss: 0.6633 - val_acc: 0.6111\n",
            "Epoch 38/100\n",
            "428/428 [==============================] - 0s 824us/step - loss: 0.6714 - acc: 0.5864 - val_loss: 0.6570 - val_acc: 0.5694\n",
            "Epoch 39/100\n",
            "428/428 [==============================] - 0s 823us/step - loss: 0.6689 - acc: 0.5794 - val_loss: 0.6555 - val_acc: 0.5833\n",
            "Epoch 40/100\n",
            "428/428 [==============================] - 0s 836us/step - loss: 0.6772 - acc: 0.5537 - val_loss: 0.6525 - val_acc: 0.5556\n",
            "Epoch 41/100\n",
            "428/428 [==============================] - 0s 826us/step - loss: 0.6643 - acc: 0.5678 - val_loss: 0.6504 - val_acc: 0.5417\n",
            "Epoch 42/100\n",
            "428/428 [==============================] - 0s 828us/step - loss: 0.6506 - acc: 0.6262 - val_loss: 0.6558 - val_acc: 0.5694\n",
            "Epoch 43/100\n",
            "428/428 [==============================] - 0s 833us/step - loss: 0.6726 - acc: 0.5958 - val_loss: 0.6574 - val_acc: 0.5833\n",
            "Epoch 44/100\n",
            "428/428 [==============================] - 0s 826us/step - loss: 0.6570 - acc: 0.5888 - val_loss: 0.6561 - val_acc: 0.5972\n",
            "Epoch 45/100\n",
            "428/428 [==============================] - 0s 827us/step - loss: 0.6578 - acc: 0.5958 - val_loss: 0.6599 - val_acc: 0.5694\n",
            "Epoch 46/100\n",
            "428/428 [==============================] - 0s 849us/step - loss: 0.6626 - acc: 0.5841 - val_loss: 0.6631 - val_acc: 0.5833\n",
            "Epoch 47/100\n",
            "428/428 [==============================] - 0s 840us/step - loss: 0.6656 - acc: 0.5584 - val_loss: 0.6589 - val_acc: 0.5694\n",
            "Epoch 48/100\n",
            "428/428 [==============================] - 0s 834us/step - loss: 0.6668 - acc: 0.5841 - val_loss: 0.6567 - val_acc: 0.5417\n",
            "Epoch 49/100\n",
            "428/428 [==============================] - 0s 849us/step - loss: 0.6520 - acc: 0.5678 - val_loss: 0.6528 - val_acc: 0.5694\n",
            "Epoch 50/100\n",
            "428/428 [==============================] - 0s 839us/step - loss: 0.6915 - acc: 0.5537 - val_loss: 0.6573 - val_acc: 0.5000\n",
            "Epoch 51/100\n",
            "428/428 [==============================] - 0s 829us/step - loss: 0.6720 - acc: 0.5911 - val_loss: 0.6691 - val_acc: 0.5139\n",
            "Epoch 52/100\n",
            "428/428 [==============================] - 0s 852us/step - loss: 0.6628 - acc: 0.5771 - val_loss: 0.6721 - val_acc: 0.4722\n",
            "Epoch 53/100\n",
            "428/428 [==============================] - 0s 833us/step - loss: 0.6696 - acc: 0.5467 - val_loss: 0.6767 - val_acc: 0.4722\n",
            "Epoch 54/100\n",
            "428/428 [==============================] - 0s 829us/step - loss: 0.6683 - acc: 0.5864 - val_loss: 0.6637 - val_acc: 0.5278\n",
            "Epoch 55/100\n",
            "428/428 [==============================] - 0s 841us/step - loss: 0.6846 - acc: 0.5280 - val_loss: 0.6630 - val_acc: 0.5000\n",
            "Epoch 56/100\n",
            "428/428 [==============================] - 0s 825us/step - loss: 0.6621 - acc: 0.5537 - val_loss: 0.6709 - val_acc: 0.4722\n",
            "Epoch 57/100\n",
            "428/428 [==============================] - 0s 846us/step - loss: 0.6580 - acc: 0.5935 - val_loss: 0.6575 - val_acc: 0.5139\n",
            "Epoch 58/100\n",
            "428/428 [==============================] - 0s 853us/step - loss: 0.6877 - acc: 0.5818 - val_loss: 0.6605 - val_acc: 0.5417\n",
            "Epoch 59/100\n",
            "428/428 [==============================] - 0s 843us/step - loss: 0.6754 - acc: 0.5561 - val_loss: 0.6637 - val_acc: 0.5278\n",
            "Epoch 60/100\n",
            "428/428 [==============================] - 0s 844us/step - loss: 0.6597 - acc: 0.5864 - val_loss: 0.6645 - val_acc: 0.4861\n",
            "Epoch 61/100\n",
            "428/428 [==============================] - 0s 835us/step - loss: 0.6713 - acc: 0.5537 - val_loss: 0.6640 - val_acc: 0.4722\n",
            "Epoch 62/100\n",
            "428/428 [==============================] - 0s 837us/step - loss: 0.6806 - acc: 0.5397 - val_loss: 0.6639 - val_acc: 0.5000\n",
            "Epoch 63/100\n",
            "428/428 [==============================] - 0s 851us/step - loss: 0.6707 - acc: 0.5537 - val_loss: 0.6614 - val_acc: 0.5139\n",
            "Epoch 64/100\n",
            "428/428 [==============================] - 0s 835us/step - loss: 0.6666 - acc: 0.5911 - val_loss: 0.6640 - val_acc: 0.4861\n",
            "Epoch 65/100\n",
            "428/428 [==============================] - 0s 836us/step - loss: 0.6648 - acc: 0.5631 - val_loss: 0.6633 - val_acc: 0.4722\n",
            "Epoch 66/100\n",
            "428/428 [==============================] - 0s 829us/step - loss: 0.6839 - acc: 0.5631 - val_loss: 0.6636 - val_acc: 0.5000\n",
            "Epoch 67/100\n",
            "428/428 [==============================] - 0s 838us/step - loss: 0.6637 - acc: 0.5794 - val_loss: 0.6629 - val_acc: 0.5000\n",
            "Epoch 68/100\n",
            "428/428 [==============================] - 0s 833us/step - loss: 0.6543 - acc: 0.6005 - val_loss: 0.6630 - val_acc: 0.5417\n",
            "Epoch 69/100\n",
            "428/428 [==============================] - 0s 848us/step - loss: 0.6717 - acc: 0.5701 - val_loss: 0.6606 - val_acc: 0.5694\n",
            "Epoch 70/100\n",
            "428/428 [==============================] - 0s 832us/step - loss: 0.6729 - acc: 0.5888 - val_loss: 0.6599 - val_acc: 0.5000\n",
            "Epoch 71/100\n",
            "428/428 [==============================] - 0s 840us/step - loss: 0.6635 - acc: 0.5327 - val_loss: 0.6633 - val_acc: 0.5556\n",
            "Epoch 72/100\n",
            "428/428 [==============================] - 0s 841us/step - loss: 0.6619 - acc: 0.5888 - val_loss: 0.6632 - val_acc: 0.5000\n",
            "Epoch 73/100\n",
            "428/428 [==============================] - 0s 839us/step - loss: 0.6686 - acc: 0.5748 - val_loss: 0.6614 - val_acc: 0.5139\n",
            "Epoch 74/100\n",
            "428/428 [==============================] - 0s 831us/step - loss: 0.6757 - acc: 0.5654 - val_loss: 0.6657 - val_acc: 0.5417\n",
            "Epoch 75/100\n",
            "428/428 [==============================] - 0s 851us/step - loss: 0.6935 - acc: 0.5327 - val_loss: 0.6673 - val_acc: 0.5000\n",
            "Epoch 76/100\n",
            "428/428 [==============================] - 0s 836us/step - loss: 0.6837 - acc: 0.5327 - val_loss: 0.6658 - val_acc: 0.5556\n",
            "Epoch 77/100\n",
            "428/428 [==============================] - 0s 844us/step - loss: 0.6724 - acc: 0.5514 - val_loss: 0.6603 - val_acc: 0.5556\n",
            "Epoch 78/100\n",
            "428/428 [==============================] - 0s 827us/step - loss: 0.6768 - acc: 0.5514 - val_loss: 0.6594 - val_acc: 0.5556\n",
            "Epoch 79/100\n",
            "428/428 [==============================] - 0s 841us/step - loss: 0.6602 - acc: 0.5514 - val_loss: 0.6589 - val_acc: 0.5556\n",
            "Epoch 80/100\n",
            "428/428 [==============================] - 0s 843us/step - loss: 0.6710 - acc: 0.5257 - val_loss: 0.6582 - val_acc: 0.5000\n",
            "Epoch 81/100\n",
            "428/428 [==============================] - 0s 842us/step - loss: 0.6739 - acc: 0.5911 - val_loss: 0.6554 - val_acc: 0.5278\n",
            "Epoch 82/100\n",
            "428/428 [==============================] - 0s 839us/step - loss: 0.6609 - acc: 0.5654 - val_loss: 0.6532 - val_acc: 0.5694\n",
            "Epoch 83/100\n",
            "428/428 [==============================] - 0s 840us/step - loss: 0.6792 - acc: 0.5678 - val_loss: 0.6564 - val_acc: 0.5556\n",
            "Epoch 84/100\n",
            "428/428 [==============================] - 0s 843us/step - loss: 0.6721 - acc: 0.5841 - val_loss: 0.6597 - val_acc: 0.5417\n",
            "Epoch 85/100\n",
            "428/428 [==============================] - 0s 838us/step - loss: 0.6775 - acc: 0.5537 - val_loss: 0.6517 - val_acc: 0.5278\n",
            "Epoch 86/100\n",
            "428/428 [==============================] - 0s 842us/step - loss: 0.6720 - acc: 0.5444 - val_loss: 0.6545 - val_acc: 0.5417\n",
            "Epoch 87/100\n",
            "428/428 [==============================] - 0s 841us/step - loss: 0.6847 - acc: 0.5327 - val_loss: 0.6546 - val_acc: 0.5417\n",
            "Epoch 88/100\n",
            "428/428 [==============================] - 0s 840us/step - loss: 0.6749 - acc: 0.5164 - val_loss: 0.6528 - val_acc: 0.5556\n",
            "Epoch 89/100\n",
            "428/428 [==============================] - 0s 837us/step - loss: 0.6672 - acc: 0.5958 - val_loss: 0.6507 - val_acc: 0.5556\n",
            "Epoch 90/100\n",
            "428/428 [==============================] - 0s 839us/step - loss: 0.6785 - acc: 0.5678 - val_loss: 0.6486 - val_acc: 0.5278\n",
            "Epoch 91/100\n",
            "428/428 [==============================] - 0s 840us/step - loss: 0.6656 - acc: 0.5701 - val_loss: 0.6450 - val_acc: 0.5556\n",
            "Epoch 92/100\n",
            "428/428 [==============================] - 0s 848us/step - loss: 0.6677 - acc: 0.5584 - val_loss: 0.6430 - val_acc: 0.5417\n",
            "Epoch 93/100\n",
            "428/428 [==============================] - 0s 850us/step - loss: 0.6686 - acc: 0.5467 - val_loss: 0.6481 - val_acc: 0.5694\n",
            "Epoch 94/100\n",
            "428/428 [==============================] - 0s 852us/step - loss: 0.6698 - acc: 0.5537 - val_loss: 0.6475 - val_acc: 0.5556\n",
            "Epoch 95/100\n",
            "428/428 [==============================] - 0s 849us/step - loss: 0.6549 - acc: 0.5514 - val_loss: 0.6547 - val_acc: 0.5556\n",
            "Epoch 96/100\n",
            "428/428 [==============================] - 0s 844us/step - loss: 0.6695 - acc: 0.5537 - val_loss: 0.6476 - val_acc: 0.5000\n",
            "Epoch 97/100\n",
            "428/428 [==============================] - 0s 854us/step - loss: 0.6773 - acc: 0.5561 - val_loss: 0.6444 - val_acc: 0.5000\n",
            "Epoch 98/100\n",
            "428/428 [==============================] - 0s 834us/step - loss: 0.6670 - acc: 0.5911 - val_loss: 0.6452 - val_acc: 0.5139\n",
            "Epoch 99/100\n",
            "428/428 [==============================] - 0s 847us/step - loss: 0.6798 - acc: 0.5864 - val_loss: 0.6462 - val_acc: 0.5000\n",
            "Epoch 100/100\n",
            "428/428 [==============================] - 0s 851us/step - loss: 0.6681 - acc: 0.5654 - val_loss: 0.6488 - val_acc: 0.5556\n",
            "[[13 19]\n",
            " [13 27]]\n",
            "Accuracy :  0.5555555555555556\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.41      0.45        32\n",
            "           1       0.59      0.68      0.63        40\n",
            "\n",
            "    accuracy                           0.56        72\n",
            "   macro avg       0.54      0.54      0.54        72\n",
            "weighted avg       0.55      0.56      0.55        72\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "model_2 (Model)              (None, 2)                 9148782   \n",
            "=================================================================\n",
            "Total params: 9,148,782\n",
            "Trainable params: 8,386\n",
            "Non-trainable params: 9,140,396\n",
            "_________________________________________________________________\n",
            "Train on 428 samples, validate on 72 samples\n",
            "Epoch 1/100\n",
            "428/428 [==============================] - 5s 11ms/step - loss: 0.6588 - acc: 0.5958 - val_loss: 0.7177 - val_acc: 0.4028\n",
            "Epoch 2/100\n",
            "428/428 [==============================] - 0s 829us/step - loss: 0.6562 - acc: 0.6121 - val_loss: 0.7310 - val_acc: 0.4306\n",
            "Epoch 3/100\n",
            "428/428 [==============================] - 0s 828us/step - loss: 0.6539 - acc: 0.6075 - val_loss: 0.7434 - val_acc: 0.4028\n",
            "Epoch 4/100\n",
            "428/428 [==============================] - 0s 845us/step - loss: 0.6712 - acc: 0.5537 - val_loss: 0.7316 - val_acc: 0.4028\n",
            "Epoch 5/100\n",
            "428/428 [==============================] - 0s 820us/step - loss: 0.6724 - acc: 0.5631 - val_loss: 0.7264 - val_acc: 0.4167\n",
            "Epoch 6/100\n",
            "428/428 [==============================] - 0s 825us/step - loss: 0.6726 - acc: 0.5514 - val_loss: 0.7270 - val_acc: 0.4306\n",
            "Epoch 7/100\n",
            "428/428 [==============================] - 0s 840us/step - loss: 0.6733 - acc: 0.5421 - val_loss: 0.7200 - val_acc: 0.4306\n",
            "Epoch 8/100\n",
            "428/428 [==============================] - 0s 828us/step - loss: 0.6722 - acc: 0.5888 - val_loss: 0.7236 - val_acc: 0.4722\n",
            "Epoch 9/100\n",
            "428/428 [==============================] - 0s 826us/step - loss: 0.6779 - acc: 0.5724 - val_loss: 0.7188 - val_acc: 0.4722\n",
            "Epoch 10/100\n",
            "428/428 [==============================] - 0s 842us/step - loss: 0.6468 - acc: 0.6215 - val_loss: 0.7123 - val_acc: 0.4444\n",
            "Epoch 11/100\n",
            "428/428 [==============================] - 0s 825us/step - loss: 0.6753 - acc: 0.5514 - val_loss: 0.7225 - val_acc: 0.4306\n",
            "Epoch 12/100\n",
            "428/428 [==============================] - 0s 825us/step - loss: 0.6759 - acc: 0.5374 - val_loss: 0.7189 - val_acc: 0.4722\n",
            "Epoch 13/100\n",
            "428/428 [==============================] - 0s 849us/step - loss: 0.6734 - acc: 0.5818 - val_loss: 0.7249 - val_acc: 0.4583\n",
            "Epoch 14/100\n",
            "428/428 [==============================] - 0s 825us/step - loss: 0.6561 - acc: 0.5841 - val_loss: 0.7523 - val_acc: 0.4583\n",
            "Epoch 15/100\n",
            "428/428 [==============================] - 0s 827us/step - loss: 0.7073 - acc: 0.6145 - val_loss: 0.7210 - val_acc: 0.4306\n",
            "Epoch 16/100\n",
            "428/428 [==============================] - 0s 832us/step - loss: 0.6802 - acc: 0.5374 - val_loss: 0.7219 - val_acc: 0.4444\n",
            "Epoch 17/100\n",
            "428/428 [==============================] - 0s 828us/step - loss: 0.6915 - acc: 0.5257 - val_loss: 0.7128 - val_acc: 0.4167\n",
            "Epoch 18/100\n",
            "428/428 [==============================] - 0s 832us/step - loss: 0.6478 - acc: 0.5818 - val_loss: 0.7266 - val_acc: 0.5417\n",
            "Epoch 19/100\n",
            "428/428 [==============================] - 0s 844us/step - loss: 0.6796 - acc: 0.5607 - val_loss: 0.7230 - val_acc: 0.4306\n",
            "Epoch 20/100\n",
            "428/428 [==============================] - 0s 850us/step - loss: 0.6684 - acc: 0.5561 - val_loss: 0.7153 - val_acc: 0.5139\n",
            "Epoch 21/100\n",
            "428/428 [==============================] - 0s 825us/step - loss: 0.6604 - acc: 0.5467 - val_loss: 0.7246 - val_acc: 0.5694\n",
            "Epoch 22/100\n",
            "428/428 [==============================] - 0s 849us/step - loss: 0.6651 - acc: 0.5794 - val_loss: 0.7236 - val_acc: 0.4167\n",
            "Epoch 23/100\n",
            "428/428 [==============================] - 0s 835us/step - loss: 0.6917 - acc: 0.5234 - val_loss: 0.7267 - val_acc: 0.4583\n",
            "Epoch 24/100\n",
            "428/428 [==============================] - 0s 834us/step - loss: 0.6821 - acc: 0.5584 - val_loss: 0.7131 - val_acc: 0.5556\n",
            "Epoch 25/100\n",
            "428/428 [==============================] - 0s 849us/step - loss: 0.6754 - acc: 0.5537 - val_loss: 0.7116 - val_acc: 0.5556\n",
            "Epoch 26/100\n",
            "428/428 [==============================] - 0s 828us/step - loss: 0.6767 - acc: 0.5257 - val_loss: 0.7134 - val_acc: 0.5139\n",
            "Epoch 27/100\n",
            "428/428 [==============================] - 0s 845us/step - loss: 0.6832 - acc: 0.5467 - val_loss: 0.7239 - val_acc: 0.5556\n",
            "Epoch 28/100\n",
            "428/428 [==============================] - 0s 824us/step - loss: 0.6646 - acc: 0.5514 - val_loss: 0.7132 - val_acc: 0.5556\n",
            "Epoch 29/100\n",
            "428/428 [==============================] - 0s 833us/step - loss: 0.6648 - acc: 0.5561 - val_loss: 0.7160 - val_acc: 0.5556\n",
            "Epoch 30/100\n",
            "428/428 [==============================] - 0s 857us/step - loss: 0.6534 - acc: 0.5561 - val_loss: 0.7188 - val_acc: 0.5000\n",
            "Epoch 31/100\n",
            "428/428 [==============================] - 0s 845us/step - loss: 0.6827 - acc: 0.5724 - val_loss: 0.7204 - val_acc: 0.4861\n",
            "Epoch 32/100\n",
            "428/428 [==============================] - 0s 835us/step - loss: 0.6646 - acc: 0.5981 - val_loss: 0.7250 - val_acc: 0.5278\n",
            "Epoch 33/100\n",
            "428/428 [==============================] - 0s 853us/step - loss: 0.6693 - acc: 0.5818 - val_loss: 0.7269 - val_acc: 0.5417\n",
            "Epoch 34/100\n",
            "428/428 [==============================] - 0s 843us/step - loss: 0.6748 - acc: 0.5584 - val_loss: 0.7399 - val_acc: 0.5000\n",
            "Epoch 35/100\n",
            "428/428 [==============================] - 0s 829us/step - loss: 0.6697 - acc: 0.6028 - val_loss: 0.7479 - val_acc: 0.5417\n",
            "Epoch 36/100\n",
            "428/428 [==============================] - 0s 845us/step - loss: 0.6636 - acc: 0.6051 - val_loss: 0.7474 - val_acc: 0.5139\n",
            "Epoch 37/100\n",
            "428/428 [==============================] - 0s 831us/step - loss: 0.6664 - acc: 0.5724 - val_loss: 0.7445 - val_acc: 0.5000\n",
            "Epoch 38/100\n",
            "428/428 [==============================] - 0s 842us/step - loss: 0.6671 - acc: 0.5537 - val_loss: 0.7402 - val_acc: 0.5000\n",
            "Epoch 39/100\n",
            "428/428 [==============================] - 0s 838us/step - loss: 0.6811 - acc: 0.5911 - val_loss: 0.7499 - val_acc: 0.4444\n",
            "Epoch 40/100\n",
            "428/428 [==============================] - 0s 837us/step - loss: 0.6766 - acc: 0.5631 - val_loss: 0.7523 - val_acc: 0.4306\n",
            "Epoch 41/100\n",
            "428/428 [==============================] - 0s 836us/step - loss: 0.6516 - acc: 0.5911 - val_loss: 0.7575 - val_acc: 0.4583\n",
            "Epoch 42/100\n",
            "428/428 [==============================] - 0s 837us/step - loss: 0.6926 - acc: 0.5491 - val_loss: 0.7308 - val_acc: 0.5000\n",
            "Epoch 43/100\n",
            "428/428 [==============================] - 0s 834us/step - loss: 0.6463 - acc: 0.6075 - val_loss: 0.7511 - val_acc: 0.5000\n",
            "Epoch 44/100\n",
            "428/428 [==============================] - 0s 848us/step - loss: 0.6693 - acc: 0.5818 - val_loss: 0.7635 - val_acc: 0.4306\n",
            "Epoch 45/100\n",
            "428/428 [==============================] - 0s 840us/step - loss: 0.6822 - acc: 0.6028 - val_loss: 0.8060 - val_acc: 0.4583\n",
            "Epoch 46/100\n",
            "428/428 [==============================] - 0s 835us/step - loss: 0.6746 - acc: 0.5514 - val_loss: 0.7361 - val_acc: 0.3889\n",
            "Epoch 47/100\n",
            "428/428 [==============================] - 0s 845us/step - loss: 0.6557 - acc: 0.5794 - val_loss: 0.7353 - val_acc: 0.3889\n",
            "Epoch 48/100\n",
            "428/428 [==============================] - 0s 846us/step - loss: 0.6515 - acc: 0.6051 - val_loss: 0.7419 - val_acc: 0.4167\n",
            "Epoch 49/100\n",
            "428/428 [==============================] - 0s 830us/step - loss: 0.6739 - acc: 0.5888 - val_loss: 0.7477 - val_acc: 0.4306\n",
            "Epoch 50/100\n",
            "428/428 [==============================] - 0s 850us/step - loss: 0.6727 - acc: 0.6121 - val_loss: 0.7390 - val_acc: 0.4167\n",
            "Epoch 51/100\n",
            "428/428 [==============================] - 0s 835us/step - loss: 0.6562 - acc: 0.6098 - val_loss: 0.7489 - val_acc: 0.3750\n",
            "Epoch 52/100\n",
            "428/428 [==============================] - 0s 842us/step - loss: 0.6582 - acc: 0.6121 - val_loss: 0.7553 - val_acc: 0.4306\n",
            "Epoch 53/100\n",
            "428/428 [==============================] - 0s 853us/step - loss: 0.6420 - acc: 0.6332 - val_loss: 0.7668 - val_acc: 0.4306\n",
            "Epoch 54/100\n",
            "428/428 [==============================] - 0s 851us/step - loss: 0.6835 - acc: 0.5280 - val_loss: 0.7455 - val_acc: 0.4583\n",
            "Epoch 55/100\n",
            "428/428 [==============================] - 0s 836us/step - loss: 0.6591 - acc: 0.5888 - val_loss: 0.7280 - val_acc: 0.5000\n",
            "Epoch 56/100\n",
            "428/428 [==============================] - 0s 840us/step - loss: 0.6744 - acc: 0.5818 - val_loss: 0.7186 - val_acc: 0.4583\n",
            "Epoch 57/100\n",
            "428/428 [==============================] - 0s 841us/step - loss: 0.6748 - acc: 0.5584 - val_loss: 0.7064 - val_acc: 0.4444\n",
            "Epoch 58/100\n",
            "428/428 [==============================] - 0s 840us/step - loss: 0.6782 - acc: 0.5888 - val_loss: 0.6992 - val_acc: 0.5694\n",
            "Epoch 59/100\n",
            "428/428 [==============================] - 0s 838us/step - loss: 0.6796 - acc: 0.5537 - val_loss: 0.7100 - val_acc: 0.5000\n",
            "Epoch 60/100\n",
            "428/428 [==============================] - 0s 842us/step - loss: 0.6801 - acc: 0.5584 - val_loss: 0.7164 - val_acc: 0.5000\n",
            "Epoch 61/100\n",
            "428/428 [==============================] - 0s 840us/step - loss: 0.6674 - acc: 0.5724 - val_loss: 0.7168 - val_acc: 0.4583\n",
            "Epoch 62/100\n",
            "428/428 [==============================] - 0s 836us/step - loss: 0.6625 - acc: 0.5771 - val_loss: 0.7208 - val_acc: 0.4722\n",
            "Epoch 63/100\n",
            "428/428 [==============================] - 0s 846us/step - loss: 0.6636 - acc: 0.5864 - val_loss: 0.7380 - val_acc: 0.4583\n",
            "Epoch 64/100\n",
            "428/428 [==============================] - 0s 845us/step - loss: 0.6437 - acc: 0.5327 - val_loss: 0.7389 - val_acc: 0.5694\n",
            "Epoch 65/100\n",
            "428/428 [==============================] - 0s 842us/step - loss: 0.6854 - acc: 0.5234 - val_loss: 0.7350 - val_acc: 0.4306\n",
            "Epoch 66/100\n",
            "428/428 [==============================] - 0s 849us/step - loss: 0.6633 - acc: 0.5771 - val_loss: 0.7212 - val_acc: 0.4167\n",
            "Epoch 67/100\n",
            "428/428 [==============================] - 0s 850us/step - loss: 0.6711 - acc: 0.5724 - val_loss: 0.7246 - val_acc: 0.4444\n",
            "Epoch 68/100\n",
            "428/428 [==============================] - 0s 842us/step - loss: 0.6615 - acc: 0.5864 - val_loss: 0.7273 - val_acc: 0.4167\n",
            "Epoch 69/100\n",
            "428/428 [==============================] - 0s 841us/step - loss: 0.6731 - acc: 0.5584 - val_loss: 0.7147 - val_acc: 0.4722\n",
            "Epoch 70/100\n",
            "428/428 [==============================] - 0s 849us/step - loss: 0.6665 - acc: 0.5794 - val_loss: 0.7156 - val_acc: 0.5556\n",
            "Epoch 71/100\n",
            "428/428 [==============================] - 0s 843us/step - loss: 0.6653 - acc: 0.5678 - val_loss: 0.7328 - val_acc: 0.5556\n",
            "Epoch 72/100\n",
            "428/428 [==============================] - 0s 850us/step - loss: 0.6831 - acc: 0.5234 - val_loss: 0.7315 - val_acc: 0.5556\n",
            "Epoch 73/100\n",
            "428/428 [==============================] - 0s 841us/step - loss: 0.6782 - acc: 0.5374 - val_loss: 0.7386 - val_acc: 0.5556\n",
            "Epoch 74/100\n",
            "428/428 [==============================] - 0s 844us/step - loss: 0.6812 - acc: 0.5584 - val_loss: 0.7428 - val_acc: 0.5694\n",
            "Epoch 75/100\n",
            "428/428 [==============================] - 0s 848us/step - loss: 0.6587 - acc: 0.5771 - val_loss: 0.7448 - val_acc: 0.5556\n",
            "Epoch 76/100\n",
            "428/428 [==============================] - 0s 845us/step - loss: 0.6734 - acc: 0.5607 - val_loss: 0.7430 - val_acc: 0.5417\n",
            "Epoch 77/100\n",
            "428/428 [==============================] - 0s 847us/step - loss: 0.6547 - acc: 0.5958 - val_loss: 0.7569 - val_acc: 0.4444\n",
            "Epoch 78/100\n",
            "428/428 [==============================] - 0s 855us/step - loss: 0.6578 - acc: 0.6005 - val_loss: 0.7759 - val_acc: 0.4583\n",
            "Epoch 79/100\n",
            "428/428 [==============================] - 0s 857us/step - loss: 0.6575 - acc: 0.5888 - val_loss: 0.7899 - val_acc: 0.4583\n",
            "Epoch 80/100\n",
            "428/428 [==============================] - 0s 842us/step - loss: 0.6814 - acc: 0.5537 - val_loss: 0.7925 - val_acc: 0.5139\n",
            "Epoch 81/100\n",
            "428/428 [==============================] - 0s 847us/step - loss: 0.6595 - acc: 0.6098 - val_loss: 0.7579 - val_acc: 0.5000\n",
            "Epoch 82/100\n",
            "428/428 [==============================] - 0s 841us/step - loss: 0.6477 - acc: 0.6051 - val_loss: 0.7492 - val_acc: 0.4583\n",
            "Epoch 83/100\n",
            "428/428 [==============================] - 0s 841us/step - loss: 0.6373 - acc: 0.6145 - val_loss: 0.7700 - val_acc: 0.4306\n",
            "Epoch 84/100\n",
            "428/428 [==============================] - 0s 857us/step - loss: 0.6678 - acc: 0.5607 - val_loss: 0.7971 - val_acc: 0.4306\n",
            "Epoch 85/100\n",
            "428/428 [==============================] - 0s 843us/step - loss: 0.6600 - acc: 0.5701 - val_loss: 0.8061 - val_acc: 0.4028\n",
            "Epoch 86/100\n",
            "428/428 [==============================] - 0s 839us/step - loss: 0.6742 - acc: 0.5561 - val_loss: 0.8098 - val_acc: 0.4444\n",
            "Epoch 87/100\n",
            "428/428 [==============================] - 0s 854us/step - loss: 0.6776 - acc: 0.5467 - val_loss: 0.7542 - val_acc: 0.4583\n",
            "Epoch 88/100\n",
            "428/428 [==============================] - 0s 838us/step - loss: 0.6522 - acc: 0.5794 - val_loss: 0.7400 - val_acc: 0.4583\n",
            "Epoch 89/100\n",
            "428/428 [==============================] - 0s 843us/step - loss: 0.6681 - acc: 0.5841 - val_loss: 0.7426 - val_acc: 0.4444\n",
            "Epoch 90/100\n",
            "428/428 [==============================] - 0s 846us/step - loss: 0.6698 - acc: 0.5771 - val_loss: 0.7416 - val_acc: 0.4444\n",
            "Epoch 91/100\n",
            "428/428 [==============================] - 0s 857us/step - loss: 0.6689 - acc: 0.5748 - val_loss: 0.7430 - val_acc: 0.4583\n",
            "Epoch 92/100\n",
            "428/428 [==============================] - 0s 846us/step - loss: 0.6482 - acc: 0.6028 - val_loss: 0.7569 - val_acc: 0.4583\n",
            "Epoch 93/100\n",
            "428/428 [==============================] - 0s 849us/step - loss: 0.6767 - acc: 0.5514 - val_loss: 0.7677 - val_acc: 0.4722\n",
            "Epoch 94/100\n",
            "428/428 [==============================] - 0s 846us/step - loss: 0.6727 - acc: 0.5958 - val_loss: 0.7802 - val_acc: 0.4028\n",
            "Epoch 95/100\n",
            "428/428 [==============================] - 0s 837us/step - loss: 0.6801 - acc: 0.5654 - val_loss: 0.7496 - val_acc: 0.4722\n",
            "Epoch 96/100\n",
            "428/428 [==============================] - 0s 852us/step - loss: 0.6678 - acc: 0.5794 - val_loss: 0.7450 - val_acc: 0.4583\n",
            "Epoch 97/100\n",
            "428/428 [==============================] - 0s 846us/step - loss: 0.6803 - acc: 0.5864 - val_loss: 0.7400 - val_acc: 0.4444\n",
            "Epoch 98/100\n",
            "428/428 [==============================] - 0s 842us/step - loss: 0.6797 - acc: 0.5421 - val_loss: 0.7318 - val_acc: 0.4722\n",
            "Epoch 99/100\n",
            "428/428 [==============================] - 0s 845us/step - loss: 0.6560 - acc: 0.5654 - val_loss: 0.7412 - val_acc: 0.5417\n",
            "Epoch 100/100\n",
            "428/428 [==============================] - 0s 839us/step - loss: 0.6624 - acc: 0.5561 - val_loss: 0.7449 - val_acc: 0.5694\n",
            "[[ 5 27]\n",
            " [ 4 36]]\n",
            "Accuracy :  0.5694444444444444\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.16      0.24        32\n",
            "           1       0.57      0.90      0.70        40\n",
            "\n",
            "    accuracy                           0.57        72\n",
            "   macro avg       0.56      0.53      0.47        72\n",
            "weighted avg       0.56      0.57      0.50        72\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "model_2 (Model)              (None, 2)                 9148782   \n",
            "=================================================================\n",
            "Total params: 9,148,782\n",
            "Trainable params: 8,386\n",
            "Non-trainable params: 9,140,396\n",
            "_________________________________________________________________\n",
            "Train on 428 samples, validate on 72 samples\n",
            "Epoch 1/100\n",
            "428/428 [==============================] - 5s 11ms/step - loss: 0.6594 - acc: 0.5678 - val_loss: 0.7364 - val_acc: 0.4444\n",
            "Epoch 2/100\n",
            "428/428 [==============================] - 0s 817us/step - loss: 0.6650 - acc: 0.6145 - val_loss: 0.7500 - val_acc: 0.4444\n",
            "Epoch 3/100\n",
            "428/428 [==============================] - 0s 824us/step - loss: 0.6589 - acc: 0.5864 - val_loss: 0.7640 - val_acc: 0.4167\n",
            "Epoch 4/100\n",
            "428/428 [==============================] - 0s 832us/step - loss: 0.6685 - acc: 0.5935 - val_loss: 0.7768 - val_acc: 0.4583\n",
            "Epoch 5/100\n",
            "428/428 [==============================] - 0s 829us/step - loss: 0.6627 - acc: 0.5911 - val_loss: 0.7504 - val_acc: 0.4583\n",
            "Epoch 6/100\n",
            "428/428 [==============================] - 0s 827us/step - loss: 0.6482 - acc: 0.6145 - val_loss: 0.7559 - val_acc: 0.5000\n",
            "Epoch 7/100\n",
            "428/428 [==============================] - 0s 834us/step - loss: 0.6734 - acc: 0.5584 - val_loss: 0.7657 - val_acc: 0.4583\n",
            "Epoch 8/100\n",
            "428/428 [==============================] - 0s 821us/step - loss: 0.6708 - acc: 0.5397 - val_loss: 0.7422 - val_acc: 0.4583\n",
            "Epoch 9/100\n",
            "428/428 [==============================] - 0s 826us/step - loss: 0.6560 - acc: 0.5911 - val_loss: 0.7310 - val_acc: 0.4444\n",
            "Epoch 10/100\n",
            "428/428 [==============================] - 0s 827us/step - loss: 0.6674 - acc: 0.5864 - val_loss: 0.7222 - val_acc: 0.4583\n",
            "Epoch 11/100\n",
            "428/428 [==============================] - 0s 834us/step - loss: 0.6598 - acc: 0.5958 - val_loss: 0.7200 - val_acc: 0.4306\n",
            "Epoch 12/100\n",
            "428/428 [==============================] - 0s 834us/step - loss: 0.6575 - acc: 0.5794 - val_loss: 0.7306 - val_acc: 0.4306\n",
            "Epoch 13/100\n",
            "428/428 [==============================] - 0s 832us/step - loss: 0.6700 - acc: 0.5374 - val_loss: 0.7338 - val_acc: 0.4306\n",
            "Epoch 14/100\n",
            "428/428 [==============================] - 0s 825us/step - loss: 0.6454 - acc: 0.5841 - val_loss: 0.7394 - val_acc: 0.4722\n",
            "Epoch 15/100\n",
            "428/428 [==============================] - 0s 832us/step - loss: 0.6499 - acc: 0.5374 - val_loss: 0.7537 - val_acc: 0.4028\n",
            "Epoch 16/100\n",
            "428/428 [==============================] - 0s 829us/step - loss: 0.6843 - acc: 0.5841 - val_loss: 0.7626 - val_acc: 0.4722\n",
            "Epoch 17/100\n",
            "428/428 [==============================] - 0s 827us/step - loss: 0.6645 - acc: 0.5678 - val_loss: 0.7754 - val_acc: 0.5000\n",
            "Epoch 18/100\n",
            "428/428 [==============================] - 0s 837us/step - loss: 0.6735 - acc: 0.5561 - val_loss: 0.7774 - val_acc: 0.5972\n",
            "Epoch 19/100\n",
            "428/428 [==============================] - 0s 829us/step - loss: 0.6587 - acc: 0.5678 - val_loss: 0.7708 - val_acc: 0.5139\n",
            "Epoch 20/100\n",
            "428/428 [==============================] - 0s 832us/step - loss: 0.6716 - acc: 0.5561 - val_loss: 0.7424 - val_acc: 0.4028\n",
            "Epoch 21/100\n",
            "428/428 [==============================] - 0s 855us/step - loss: 0.6562 - acc: 0.5864 - val_loss: 0.7290 - val_acc: 0.4444\n",
            "Epoch 22/100\n",
            "428/428 [==============================] - 0s 827us/step - loss: 0.6922 - acc: 0.5421 - val_loss: 0.7277 - val_acc: 0.4167\n",
            "Epoch 23/100\n",
            "428/428 [==============================] - 0s 832us/step - loss: 0.6667 - acc: 0.5514 - val_loss: 0.7477 - val_acc: 0.4583\n",
            "Epoch 24/100\n",
            "428/428 [==============================] - 0s 836us/step - loss: 0.6645 - acc: 0.5350 - val_loss: 0.7479 - val_acc: 0.5000\n",
            "Epoch 25/100\n",
            "428/428 [==============================] - 0s 833us/step - loss: 0.6603 - acc: 0.5794 - val_loss: 0.7429 - val_acc: 0.4861\n",
            "Epoch 26/100\n",
            "428/428 [==============================] - 0s 844us/step - loss: 0.6521 - acc: 0.6051 - val_loss: 0.7425 - val_acc: 0.4028\n",
            "Epoch 27/100\n",
            "428/428 [==============================] - 0s 829us/step - loss: 0.6604 - acc: 0.5981 - val_loss: 0.7621 - val_acc: 0.4306\n",
            "Epoch 28/100\n",
            "428/428 [==============================] - 0s 825us/step - loss: 0.6741 - acc: 0.6192 - val_loss: 0.7645 - val_acc: 0.4167\n",
            "Epoch 29/100\n",
            "428/428 [==============================] - 0s 832us/step - loss: 0.6904 - acc: 0.5771 - val_loss: 0.7331 - val_acc: 0.4167\n",
            "Epoch 30/100\n",
            "428/428 [==============================] - 0s 832us/step - loss: 0.6815 - acc: 0.5841 - val_loss: 0.7277 - val_acc: 0.4167\n",
            "Epoch 31/100\n",
            "428/428 [==============================] - 0s 836us/step - loss: 0.6517 - acc: 0.6145 - val_loss: 0.7336 - val_acc: 0.4167\n",
            "Epoch 32/100\n",
            "428/428 [==============================] - 0s 844us/step - loss: 0.6713 - acc: 0.5748 - val_loss: 0.7479 - val_acc: 0.4028\n",
            "Epoch 33/100\n",
            "428/428 [==============================] - 0s 833us/step - loss: 0.6607 - acc: 0.5818 - val_loss: 0.7883 - val_acc: 0.4444\n",
            "Epoch 34/100\n",
            "428/428 [==============================] - 0s 832us/step - loss: 0.6878 - acc: 0.5701 - val_loss: 0.7582 - val_acc: 0.4167\n",
            "Epoch 35/100\n",
            "428/428 [==============================] - 0s 843us/step - loss: 0.6572 - acc: 0.6402 - val_loss: 0.7533 - val_acc: 0.4722\n",
            "Epoch 36/100\n",
            "428/428 [==============================] - 0s 834us/step - loss: 0.6727 - acc: 0.6051 - val_loss: 0.7620 - val_acc: 0.4861\n",
            "Epoch 37/100\n",
            "428/428 [==============================] - 0s 839us/step - loss: 0.6617 - acc: 0.5678 - val_loss: 0.7684 - val_acc: 0.5000\n",
            "Epoch 38/100\n",
            "428/428 [==============================] - 0s 850us/step - loss: 0.6519 - acc: 0.6145 - val_loss: 0.7706 - val_acc: 0.4444\n",
            "Epoch 39/100\n",
            "428/428 [==============================] - 0s 834us/step - loss: 0.6416 - acc: 0.6051 - val_loss: 0.7649 - val_acc: 0.4306\n",
            "Epoch 40/100\n",
            "428/428 [==============================] - 0s 829us/step - loss: 0.6663 - acc: 0.6098 - val_loss: 0.7873 - val_acc: 0.4444\n",
            "Epoch 41/100\n",
            "428/428 [==============================] - 0s 875us/step - loss: 0.6658 - acc: 0.5888 - val_loss: 0.8056 - val_acc: 0.4444\n",
            "Epoch 42/100\n",
            "428/428 [==============================] - 0s 850us/step - loss: 0.6917 - acc: 0.5841 - val_loss: 0.7580 - val_acc: 0.4306\n",
            "Epoch 43/100\n",
            "428/428 [==============================] - 0s 841us/step - loss: 0.6403 - acc: 0.6402 - val_loss: 0.7564 - val_acc: 0.4167\n",
            "Epoch 44/100\n",
            "428/428 [==============================] - 0s 852us/step - loss: 0.6672 - acc: 0.5724 - val_loss: 0.7374 - val_acc: 0.4444\n",
            "Epoch 45/100\n",
            "428/428 [==============================] - 0s 839us/step - loss: 0.6656 - acc: 0.6005 - val_loss: 0.7366 - val_acc: 0.4444\n",
            "Epoch 46/100\n",
            "428/428 [==============================] - 0s 857us/step - loss: 0.6458 - acc: 0.5958 - val_loss: 0.7440 - val_acc: 0.4306\n",
            "Epoch 47/100\n",
            "428/428 [==============================] - 0s 840us/step - loss: 0.6588 - acc: 0.5935 - val_loss: 0.7416 - val_acc: 0.4306\n",
            "Epoch 48/100\n",
            "428/428 [==============================] - 0s 841us/step - loss: 0.6628 - acc: 0.5958 - val_loss: 0.7404 - val_acc: 0.4167\n",
            "Epoch 49/100\n",
            "428/428 [==============================] - 0s 855us/step - loss: 0.6575 - acc: 0.5794 - val_loss: 0.7676 - val_acc: 0.4167\n",
            "Epoch 50/100\n",
            "428/428 [==============================] - 0s 843us/step - loss: 0.6829 - acc: 0.5981 - val_loss: 0.7461 - val_acc: 0.4028\n",
            "Epoch 51/100\n",
            "428/428 [==============================] - 0s 850us/step - loss: 0.6765 - acc: 0.5561 - val_loss: 0.7411 - val_acc: 0.4167\n",
            "Epoch 52/100\n",
            "428/428 [==============================] - 0s 861us/step - loss: 0.6698 - acc: 0.5724 - val_loss: 0.7564 - val_acc: 0.4306\n",
            "Epoch 53/100\n",
            "428/428 [==============================] - 0s 845us/step - loss: 0.6628 - acc: 0.5654 - val_loss: 0.7495 - val_acc: 0.4167\n",
            "Epoch 54/100\n",
            "428/428 [==============================] - 0s 844us/step - loss: 0.6614 - acc: 0.5818 - val_loss: 0.7486 - val_acc: 0.4583\n",
            "Epoch 55/100\n",
            "428/428 [==============================] - 0s 851us/step - loss: 0.6642 - acc: 0.5724 - val_loss: 0.7461 - val_acc: 0.4444\n",
            "Epoch 56/100\n",
            "428/428 [==============================] - 0s 837us/step - loss: 0.6981 - acc: 0.5701 - val_loss: 0.7714 - val_acc: 0.4444\n",
            "Epoch 57/100\n",
            "428/428 [==============================] - 0s 849us/step - loss: 0.6630 - acc: 0.5935 - val_loss: 0.7599 - val_acc: 0.4444\n",
            "Epoch 58/100\n",
            "428/428 [==============================] - 0s 871us/step - loss: 0.6676 - acc: 0.5607 - val_loss: 0.7374 - val_acc: 0.4583\n",
            "Epoch 59/100\n",
            "428/428 [==============================] - 0s 849us/step - loss: 0.6696 - acc: 0.5771 - val_loss: 0.7266 - val_acc: 0.4861\n",
            "Epoch 60/100\n",
            "428/428 [==============================] - 0s 858us/step - loss: 0.6722 - acc: 0.5818 - val_loss: 0.7271 - val_acc: 0.4444\n",
            "Epoch 61/100\n",
            "428/428 [==============================] - 0s 843us/step - loss: 0.6660 - acc: 0.5701 - val_loss: 0.7235 - val_acc: 0.4444\n",
            "Epoch 62/100\n",
            "428/428 [==============================] - 0s 854us/step - loss: 0.6729 - acc: 0.5981 - val_loss: 0.7289 - val_acc: 0.4444\n",
            "Epoch 63/100\n",
            "428/428 [==============================] - 0s 868us/step - loss: 0.6692 - acc: 0.5771 - val_loss: 0.7269 - val_acc: 0.4444\n",
            "Epoch 64/100\n",
            "428/428 [==============================] - 0s 856us/step - loss: 0.6727 - acc: 0.5561 - val_loss: 0.7186 - val_acc: 0.4306\n",
            "Epoch 65/100\n",
            "428/428 [==============================] - 0s 859us/step - loss: 0.6550 - acc: 0.5678 - val_loss: 0.7187 - val_acc: 0.4167\n",
            "Epoch 66/100\n",
            "428/428 [==============================] - 0s 855us/step - loss: 0.6479 - acc: 0.5958 - val_loss: 0.7309 - val_acc: 0.4444\n",
            "Epoch 67/100\n",
            "428/428 [==============================] - 0s 856us/step - loss: 0.6726 - acc: 0.5864 - val_loss: 0.7339 - val_acc: 0.4028\n",
            "Epoch 68/100\n",
            "428/428 [==============================] - 0s 859us/step - loss: 0.6648 - acc: 0.5841 - val_loss: 0.7372 - val_acc: 0.4028\n",
            "Epoch 69/100\n",
            "428/428 [==============================] - 0s 871us/step - loss: 0.6532 - acc: 0.5701 - val_loss: 0.7529 - val_acc: 0.4306\n",
            "Epoch 70/100\n",
            "428/428 [==============================] - 0s 841us/step - loss: 0.6398 - acc: 0.6121 - val_loss: 0.8023 - val_acc: 0.4722\n",
            "Epoch 71/100\n",
            "428/428 [==============================] - 0s 848us/step - loss: 0.6617 - acc: 0.6215 - val_loss: 0.7710 - val_acc: 0.4028\n",
            "Epoch 72/100\n",
            "428/428 [==============================] - 0s 862us/step - loss: 0.6632 - acc: 0.5911 - val_loss: 0.7775 - val_acc: 0.4167\n",
            "Epoch 73/100\n",
            "428/428 [==============================] - 0s 852us/step - loss: 0.6527 - acc: 0.5981 - val_loss: 0.7781 - val_acc: 0.4167\n",
            "Epoch 74/100\n",
            "428/428 [==============================] - 0s 873us/step - loss: 0.6505 - acc: 0.6145 - val_loss: 0.7701 - val_acc: 0.4306\n",
            "Epoch 75/100\n",
            "428/428 [==============================] - 0s 853us/step - loss: 0.6659 - acc: 0.5748 - val_loss: 0.7525 - val_acc: 0.4028\n",
            "Epoch 76/100\n",
            "428/428 [==============================] - 0s 845us/step - loss: 0.6843 - acc: 0.5187 - val_loss: 0.7506 - val_acc: 0.4028\n",
            "Epoch 77/100\n",
            "428/428 [==============================] - 0s 851us/step - loss: 0.6733 - acc: 0.5444 - val_loss: 0.7572 - val_acc: 0.5694\n",
            "Epoch 78/100\n",
            "428/428 [==============================] - 0s 853us/step - loss: 0.6629 - acc: 0.5724 - val_loss: 0.7489 - val_acc: 0.5556\n",
            "Epoch 79/100\n",
            "428/428 [==============================] - 0s 844us/step - loss: 0.6608 - acc: 0.5561 - val_loss: 0.7573 - val_acc: 0.4306\n",
            "Epoch 80/100\n",
            "428/428 [==============================] - 0s 838us/step - loss: 0.6642 - acc: 0.5701 - val_loss: 0.7689 - val_acc: 0.4028\n",
            "Epoch 81/100\n",
            "428/428 [==============================] - 0s 854us/step - loss: 0.6785 - acc: 0.5701 - val_loss: 0.7706 - val_acc: 0.4167\n",
            "Epoch 82/100\n",
            "428/428 [==============================] - 0s 843us/step - loss: 0.6766 - acc: 0.5421 - val_loss: 0.7700 - val_acc: 0.4722\n",
            "Epoch 83/100\n",
            "428/428 [==============================] - 0s 840us/step - loss: 0.6625 - acc: 0.5724 - val_loss: 0.7809 - val_acc: 0.5417\n",
            "Epoch 84/100\n",
            "428/428 [==============================] - 0s 845us/step - loss: 0.6642 - acc: 0.5841 - val_loss: 0.8017 - val_acc: 0.4583\n",
            "Epoch 85/100\n",
            "428/428 [==============================] - 0s 849us/step - loss: 0.6606 - acc: 0.5818 - val_loss: 0.8353 - val_acc: 0.4861\n",
            "Epoch 86/100\n",
            "428/428 [==============================] - 0s 861us/step - loss: 0.6538 - acc: 0.5794 - val_loss: 0.8376 - val_acc: 0.5417\n",
            "Epoch 87/100\n",
            "428/428 [==============================] - 0s 848us/step - loss: 0.6777 - acc: 0.5514 - val_loss: 0.7999 - val_acc: 0.5000\n",
            "Epoch 88/100\n",
            "428/428 [==============================] - 0s 836us/step - loss: 0.6649 - acc: 0.5631 - val_loss: 0.7740 - val_acc: 0.4722\n",
            "Epoch 89/100\n",
            "428/428 [==============================] - 0s 839us/step - loss: 0.6832 - acc: 0.5631 - val_loss: 0.7663 - val_acc: 0.5556\n",
            "Epoch 90/100\n",
            "428/428 [==============================] - 0s 855us/step - loss: 0.6586 - acc: 0.5654 - val_loss: 0.7987 - val_acc: 0.5139\n",
            "Epoch 91/100\n",
            "428/428 [==============================] - 0s 843us/step - loss: 0.6353 - acc: 0.5678 - val_loss: 0.7961 - val_acc: 0.4722\n",
            "Epoch 92/100\n",
            "428/428 [==============================] - 0s 844us/step - loss: 0.6529 - acc: 0.5724 - val_loss: 0.7816 - val_acc: 0.4444\n",
            "Epoch 93/100\n",
            "428/428 [==============================] - 0s 835us/step - loss: 0.6428 - acc: 0.6075 - val_loss: 0.7940 - val_acc: 0.4444\n",
            "Epoch 94/100\n",
            "428/428 [==============================] - 0s 854us/step - loss: 0.6631 - acc: 0.6192 - val_loss: 0.7857 - val_acc: 0.4306\n",
            "Epoch 95/100\n",
            "428/428 [==============================] - 0s 846us/step - loss: 0.6636 - acc: 0.5864 - val_loss: 0.7906 - val_acc: 0.4167\n",
            "Epoch 96/100\n",
            "428/428 [==============================] - 0s 842us/step - loss: 0.6713 - acc: 0.5678 - val_loss: 0.7772 - val_acc: 0.4167\n",
            "Epoch 97/100\n",
            "428/428 [==============================] - 0s 853us/step - loss: 0.6565 - acc: 0.6121 - val_loss: 0.7613 - val_acc: 0.4306\n",
            "Epoch 98/100\n",
            "428/428 [==============================] - 0s 839us/step - loss: 0.6785 - acc: 0.5678 - val_loss: 0.7624 - val_acc: 0.4583\n",
            "Epoch 99/100\n",
            "428/428 [==============================] - 0s 851us/step - loss: 0.6666 - acc: 0.5678 - val_loss: 0.7685 - val_acc: 0.5278\n",
            "Epoch 100/100\n",
            "428/428 [==============================] - 0s 862us/step - loss: 0.6595 - acc: 0.5794 - val_loss: 0.7669 - val_acc: 0.4444\n",
            "[[14 18]\n",
            " [22 18]]\n",
            "Accuracy :  0.4444444444444444\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.39      0.44      0.41        32\n",
            "           1       0.50      0.45      0.47        40\n",
            "\n",
            "    accuracy                           0.44        72\n",
            "   macro avg       0.44      0.44      0.44        72\n",
            "weighted avg       0.45      0.44      0.45        72\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "model_2 (Model)              (None, 2)                 9148782   \n",
            "=================================================================\n",
            "Total params: 9,148,782\n",
            "Trainable params: 8,386\n",
            "Non-trainable params: 9,140,396\n",
            "_________________________________________________________________\n",
            "Train on 429 samples, validate on 71 samples\n",
            "Epoch 1/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.6697 - acc: 0.5408 - val_loss: 0.8455 - val_acc: 0.3944\n",
            "Epoch 2/100\n",
            "429/429 [==============================] - 0s 838us/step - loss: 0.6690 - acc: 0.5618 - val_loss: 0.8107 - val_acc: 0.3803\n",
            "Epoch 3/100\n",
            "429/429 [==============================] - 0s 836us/step - loss: 0.6708 - acc: 0.5734 - val_loss: 0.8028 - val_acc: 0.3662\n",
            "Epoch 4/100\n",
            "429/429 [==============================] - 0s 848us/step - loss: 0.6621 - acc: 0.6014 - val_loss: 0.8207 - val_acc: 0.5634\n",
            "Epoch 5/100\n",
            "429/429 [==============================] - 0s 840us/step - loss: 0.6745 - acc: 0.5944 - val_loss: 0.8004 - val_acc: 0.4366\n",
            "Epoch 6/100\n",
            "429/429 [==============================] - 0s 845us/step - loss: 0.6668 - acc: 0.5781 - val_loss: 0.8123 - val_acc: 0.4366\n",
            "Epoch 7/100\n",
            "429/429 [==============================] - 0s 846us/step - loss: 0.6681 - acc: 0.5734 - val_loss: 0.8114 - val_acc: 0.4085\n",
            "Epoch 8/100\n",
            "429/429 [==============================] - 0s 838us/step - loss: 0.6743 - acc: 0.5828 - val_loss: 0.8230 - val_acc: 0.5352\n",
            "Epoch 9/100\n",
            "429/429 [==============================] - 0s 843us/step - loss: 0.6665 - acc: 0.5571 - val_loss: 0.8142 - val_acc: 0.5634\n",
            "Epoch 10/100\n",
            "429/429 [==============================] - 0s 846us/step - loss: 0.6690 - acc: 0.5664 - val_loss: 0.8069 - val_acc: 0.5915\n",
            "Epoch 11/100\n",
            "429/429 [==============================] - 0s 850us/step - loss: 0.6656 - acc: 0.5641 - val_loss: 0.8095 - val_acc: 0.5634\n",
            "Epoch 12/100\n",
            "429/429 [==============================] - 0s 850us/step - loss: 0.6820 - acc: 0.5711 - val_loss: 0.7722 - val_acc: 0.3662\n",
            "Epoch 13/100\n",
            "429/429 [==============================] - 0s 858us/step - loss: 0.6624 - acc: 0.6270 - val_loss: 0.7981 - val_acc: 0.3944\n",
            "Epoch 14/100\n",
            "429/429 [==============================] - 0s 836us/step - loss: 0.6674 - acc: 0.5781 - val_loss: 0.8158 - val_acc: 0.4366\n",
            "Epoch 15/100\n",
            "429/429 [==============================] - 0s 832us/step - loss: 0.6512 - acc: 0.6014 - val_loss: 0.8119 - val_acc: 0.4225\n",
            "Epoch 16/100\n",
            "429/429 [==============================] - 0s 839us/step - loss: 0.6749 - acc: 0.5828 - val_loss: 0.8045 - val_acc: 0.4085\n",
            "Epoch 17/100\n",
            "429/429 [==============================] - 0s 848us/step - loss: 0.6606 - acc: 0.5804 - val_loss: 0.8148 - val_acc: 0.4366\n",
            "Epoch 18/100\n",
            "429/429 [==============================] - 0s 839us/step - loss: 0.6643 - acc: 0.5991 - val_loss: 0.8084 - val_acc: 0.4085\n",
            "Epoch 19/100\n",
            "429/429 [==============================] - 0s 844us/step - loss: 0.6632 - acc: 0.5571 - val_loss: 0.8429 - val_acc: 0.3944\n",
            "Epoch 20/100\n",
            "429/429 [==============================] - 0s 839us/step - loss: 0.6561 - acc: 0.5828 - val_loss: 0.9000 - val_acc: 0.4507\n",
            "Epoch 21/100\n",
            "429/429 [==============================] - 0s 840us/step - loss: 0.6578 - acc: 0.5758 - val_loss: 0.8959 - val_acc: 0.5493\n",
            "Epoch 22/100\n",
            "429/429 [==============================] - 0s 859us/step - loss: 0.6501 - acc: 0.5874 - val_loss: 0.9092 - val_acc: 0.4648\n",
            "Epoch 23/100\n",
            "429/429 [==============================] - 0s 844us/step - loss: 0.6776 - acc: 0.5804 - val_loss: 0.8765 - val_acc: 0.4366\n",
            "Epoch 24/100\n",
            "429/429 [==============================] - 0s 837us/step - loss: 0.6838 - acc: 0.5268 - val_loss: 0.8048 - val_acc: 0.5493\n",
            "Epoch 25/100\n",
            "429/429 [==============================] - 0s 835us/step - loss: 0.6569 - acc: 0.5897 - val_loss: 0.8295 - val_acc: 0.5915\n",
            "Epoch 26/100\n",
            "429/429 [==============================] - 0s 843us/step - loss: 0.6590 - acc: 0.5897 - val_loss: 0.8946 - val_acc: 0.5070\n",
            "Epoch 27/100\n",
            "429/429 [==============================] - 0s 855us/step - loss: 0.6579 - acc: 0.5828 - val_loss: 0.9067 - val_acc: 0.4930\n",
            "Epoch 28/100\n",
            "429/429 [==============================] - 0s 844us/step - loss: 0.6614 - acc: 0.6084 - val_loss: 0.8297 - val_acc: 0.4085\n",
            "Epoch 29/100\n",
            "429/429 [==============================] - 0s 836us/step - loss: 0.6683 - acc: 0.5991 - val_loss: 0.8312 - val_acc: 0.3944\n",
            "Epoch 30/100\n",
            "429/429 [==============================] - 0s 844us/step - loss: 0.6561 - acc: 0.5711 - val_loss: 0.8322 - val_acc: 0.4789\n",
            "Epoch 31/100\n",
            "429/429 [==============================] - 0s 863us/step - loss: 0.6623 - acc: 0.5851 - val_loss: 0.8020 - val_acc: 0.5211\n",
            "Epoch 32/100\n",
            "429/429 [==============================] - 0s 844us/step - loss: 0.6812 - acc: 0.5641 - val_loss: 0.7899 - val_acc: 0.5352\n",
            "Epoch 33/100\n",
            "429/429 [==============================] - 0s 856us/step - loss: 0.6556 - acc: 0.5571 - val_loss: 0.7793 - val_acc: 0.5352\n",
            "Epoch 34/100\n",
            "429/429 [==============================] - 0s 843us/step - loss: 0.6610 - acc: 0.5874 - val_loss: 0.7589 - val_acc: 0.3803\n",
            "Epoch 35/100\n",
            "429/429 [==============================] - 0s 837us/step - loss: 0.6652 - acc: 0.5711 - val_loss: 0.7682 - val_acc: 0.3662\n",
            "Epoch 36/100\n",
            "429/429 [==============================] - 0s 837us/step - loss: 0.6794 - acc: 0.5781 - val_loss: 0.7710 - val_acc: 0.3380\n",
            "Epoch 37/100\n",
            "429/429 [==============================] - 0s 845us/step - loss: 0.6730 - acc: 0.5268 - val_loss: 0.7526 - val_acc: 0.3803\n",
            "Epoch 38/100\n",
            "429/429 [==============================] - 0s 839us/step - loss: 0.6591 - acc: 0.5664 - val_loss: 0.7736 - val_acc: 0.5634\n",
            "Epoch 39/100\n",
            "429/429 [==============================] - 0s 842us/step - loss: 0.6769 - acc: 0.5734 - val_loss: 0.7782 - val_acc: 0.3944\n",
            "Epoch 40/100\n",
            "429/429 [==============================] - 0s 829us/step - loss: 0.6656 - acc: 0.5688 - val_loss: 0.7735 - val_acc: 0.5634\n",
            "Epoch 41/100\n",
            "429/429 [==============================] - 0s 831us/step - loss: 0.6651 - acc: 0.5688 - val_loss: 0.8302 - val_acc: 0.5493\n",
            "Epoch 42/100\n",
            "429/429 [==============================] - 0s 851us/step - loss: 0.6601 - acc: 0.5804 - val_loss: 0.7969 - val_acc: 0.5211\n",
            "Epoch 43/100\n",
            "429/429 [==============================] - 0s 830us/step - loss: 0.6665 - acc: 0.5641 - val_loss: 0.8162 - val_acc: 0.3803\n",
            "Epoch 44/100\n",
            "429/429 [==============================] - 0s 836us/step - loss: 0.6457 - acc: 0.6434 - val_loss: 0.8437 - val_acc: 0.4085\n",
            "Epoch 45/100\n",
            "429/429 [==============================] - 0s 845us/step - loss: 0.6574 - acc: 0.6037 - val_loss: 0.8314 - val_acc: 0.4366\n",
            "Epoch 46/100\n",
            "429/429 [==============================] - 0s 833us/step - loss: 0.6582 - acc: 0.6037 - val_loss: 0.8392 - val_acc: 0.4225\n",
            "Epoch 47/100\n",
            "429/429 [==============================] - 0s 844us/step - loss: 0.6623 - acc: 0.5851 - val_loss: 0.8440 - val_acc: 0.3944\n",
            "Epoch 48/100\n",
            "429/429 [==============================] - 0s 847us/step - loss: 0.6519 - acc: 0.5874 - val_loss: 0.8309 - val_acc: 0.4366\n",
            "Epoch 49/100\n",
            "429/429 [==============================] - 0s 838us/step - loss: 0.6529 - acc: 0.6014 - val_loss: 0.8344 - val_acc: 0.4366\n",
            "Epoch 50/100\n",
            "429/429 [==============================] - 0s 833us/step - loss: 0.6620 - acc: 0.5524 - val_loss: 0.8262 - val_acc: 0.4366\n",
            "Epoch 51/100\n",
            "429/429 [==============================] - 0s 854us/step - loss: 0.6760 - acc: 0.5991 - val_loss: 0.8197 - val_acc: 0.4930\n",
            "Epoch 52/100\n",
            "429/429 [==============================] - 0s 833us/step - loss: 0.6469 - acc: 0.5431 - val_loss: 0.8235 - val_acc: 0.4648\n",
            "Epoch 53/100\n",
            "429/429 [==============================] - 0s 833us/step - loss: 0.6500 - acc: 0.6434 - val_loss: 0.8371 - val_acc: 0.4648\n",
            "Epoch 54/100\n",
            "429/429 [==============================] - 0s 854us/step - loss: 0.6681 - acc: 0.5664 - val_loss: 0.8109 - val_acc: 0.3662\n",
            "Epoch 55/100\n",
            "429/429 [==============================] - 0s 841us/step - loss: 0.6764 - acc: 0.5594 - val_loss: 0.8146 - val_acc: 0.3803\n",
            "Epoch 56/100\n",
            "429/429 [==============================] - 0s 834us/step - loss: 0.6671 - acc: 0.5828 - val_loss: 0.8280 - val_acc: 0.4085\n",
            "Epoch 57/100\n",
            "429/429 [==============================] - 0s 846us/step - loss: 0.6460 - acc: 0.6200 - val_loss: 0.8191 - val_acc: 0.4225\n",
            "Epoch 58/100\n",
            "429/429 [==============================] - 0s 844us/step - loss: 0.6739 - acc: 0.5804 - val_loss: 0.8368 - val_acc: 0.4225\n",
            "Epoch 59/100\n",
            "429/429 [==============================] - 0s 840us/step - loss: 0.6563 - acc: 0.6014 - val_loss: 0.8474 - val_acc: 0.4225\n",
            "Epoch 60/100\n",
            "429/429 [==============================] - 0s 835us/step - loss: 0.6395 - acc: 0.5897 - val_loss: 0.8782 - val_acc: 0.5634\n",
            "Epoch 61/100\n",
            "429/429 [==============================] - 0s 844us/step - loss: 0.6584 - acc: 0.5781 - val_loss: 0.8918 - val_acc: 0.5211\n",
            "Epoch 62/100\n",
            "429/429 [==============================] - 0s 856us/step - loss: 0.6626 - acc: 0.5758 - val_loss: 0.8848 - val_acc: 0.5915\n",
            "Epoch 63/100\n",
            "429/429 [==============================] - 0s 837us/step - loss: 0.6611 - acc: 0.5524 - val_loss: 0.9220 - val_acc: 0.4648\n",
            "Epoch 64/100\n",
            "429/429 [==============================] - 0s 840us/step - loss: 0.6632 - acc: 0.5688 - val_loss: 0.9187 - val_acc: 0.5775\n",
            "Epoch 65/100\n",
            "429/429 [==============================] - 0s 854us/step - loss: 0.6725 - acc: 0.5594 - val_loss: 0.8637 - val_acc: 0.5775\n",
            "Epoch 66/100\n",
            "429/429 [==============================] - 0s 839us/step - loss: 0.6634 - acc: 0.5618 - val_loss: 0.8393 - val_acc: 0.3944\n",
            "Epoch 67/100\n",
            "429/429 [==============================] - 0s 847us/step - loss: 0.6855 - acc: 0.5594 - val_loss: 0.8012 - val_acc: 0.4085\n",
            "Epoch 68/100\n",
            "429/429 [==============================] - 0s 836us/step - loss: 0.6503 - acc: 0.5991 - val_loss: 0.8335 - val_acc: 0.4225\n",
            "Epoch 69/100\n",
            "429/429 [==============================] - 0s 837us/step - loss: 0.6680 - acc: 0.6177 - val_loss: 0.8515 - val_acc: 0.4085\n",
            "Epoch 70/100\n",
            "429/429 [==============================] - 0s 838us/step - loss: 0.6611 - acc: 0.5874 - val_loss: 0.8248 - val_acc: 0.4225\n",
            "Epoch 71/100\n",
            "429/429 [==============================] - 0s 838us/step - loss: 0.6765 - acc: 0.5641 - val_loss: 0.8376 - val_acc: 0.4789\n",
            "Epoch 72/100\n",
            "429/429 [==============================] - 0s 836us/step - loss: 0.6531 - acc: 0.6014 - val_loss: 0.8563 - val_acc: 0.4507\n",
            "Epoch 73/100\n",
            "429/429 [==============================] - 0s 844us/step - loss: 0.6693 - acc: 0.5758 - val_loss: 0.8485 - val_acc: 0.3803\n",
            "Epoch 74/100\n",
            "429/429 [==============================] - 0s 838us/step - loss: 0.6553 - acc: 0.5851 - val_loss: 0.8649 - val_acc: 0.3803\n",
            "Epoch 75/100\n",
            "429/429 [==============================] - 0s 835us/step - loss: 0.6786 - acc: 0.5921 - val_loss: 0.8619 - val_acc: 0.3944\n",
            "Epoch 76/100\n",
            "429/429 [==============================] - 0s 850us/step - loss: 0.6598 - acc: 0.6084 - val_loss: 0.8470 - val_acc: 0.3803\n",
            "Epoch 77/100\n",
            "429/429 [==============================] - 0s 850us/step - loss: 0.6651 - acc: 0.5967 - val_loss: 0.8618 - val_acc: 0.4085\n",
            "Epoch 78/100\n",
            "429/429 [==============================] - 0s 841us/step - loss: 0.6640 - acc: 0.6247 - val_loss: 0.8882 - val_acc: 0.3944\n",
            "Epoch 79/100\n",
            "429/429 [==============================] - 0s 852us/step - loss: 0.6490 - acc: 0.6131 - val_loss: 0.8904 - val_acc: 0.4648\n",
            "Epoch 80/100\n",
            "429/429 [==============================] - 0s 847us/step - loss: 0.6694 - acc: 0.5944 - val_loss: 0.8582 - val_acc: 0.3944\n",
            "Epoch 81/100\n",
            "429/429 [==============================] - 0s 844us/step - loss: 0.6439 - acc: 0.6131 - val_loss: 0.8858 - val_acc: 0.4085\n",
            "Epoch 82/100\n",
            "429/429 [==============================] - 0s 853us/step - loss: 0.6396 - acc: 0.5921 - val_loss: 0.9160 - val_acc: 0.3803\n",
            "Epoch 83/100\n",
            "429/429 [==============================] - 0s 844us/step - loss: 0.6445 - acc: 0.6410 - val_loss: 0.8993 - val_acc: 0.3803\n",
            "Epoch 84/100\n",
            "429/429 [==============================] - 0s 842us/step - loss: 0.6683 - acc: 0.6037 - val_loss: 0.8773 - val_acc: 0.3521\n",
            "Epoch 85/100\n",
            "429/429 [==============================] - 0s 859us/step - loss: 0.6763 - acc: 0.5664 - val_loss: 0.8392 - val_acc: 0.4225\n",
            "Epoch 86/100\n",
            "429/429 [==============================] - 0s 853us/step - loss: 0.6890 - acc: 0.5408 - val_loss: 0.8570 - val_acc: 0.3803\n",
            "Epoch 87/100\n",
            "429/429 [==============================] - 0s 851us/step - loss: 0.6572 - acc: 0.5851 - val_loss: 0.8447 - val_acc: 0.4930\n",
            "Epoch 88/100\n",
            "429/429 [==============================] - 0s 841us/step - loss: 0.6538 - acc: 0.5594 - val_loss: 0.8286 - val_acc: 0.3944\n",
            "Epoch 89/100\n",
            "429/429 [==============================] - 0s 849us/step - loss: 0.6519 - acc: 0.5641 - val_loss: 0.9060 - val_acc: 0.4930\n",
            "Epoch 90/100\n",
            "429/429 [==============================] - 0s 835us/step - loss: 0.6621 - acc: 0.5641 - val_loss: 0.9126 - val_acc: 0.3944\n",
            "Epoch 91/100\n",
            "429/429 [==============================] - 0s 851us/step - loss: 0.6648 - acc: 0.5781 - val_loss: 0.9065 - val_acc: 0.5352\n",
            "Epoch 92/100\n",
            "429/429 [==============================] - 0s 849us/step - loss: 0.6687 - acc: 0.5851 - val_loss: 0.9206 - val_acc: 0.4789\n",
            "Epoch 93/100\n",
            "429/429 [==============================] - 0s 852us/step - loss: 0.6597 - acc: 0.5618 - val_loss: 0.9039 - val_acc: 0.4789\n",
            "Epoch 94/100\n",
            "429/429 [==============================] - 0s 849us/step - loss: 0.6532 - acc: 0.5944 - val_loss: 0.8777 - val_acc: 0.5070\n",
            "Epoch 95/100\n",
            "429/429 [==============================] - 0s 851us/step - loss: 0.6475 - acc: 0.5618 - val_loss: 0.8501 - val_acc: 0.3803\n",
            "Epoch 96/100\n",
            "429/429 [==============================] - 0s 852us/step - loss: 0.6681 - acc: 0.6014 - val_loss: 0.8085 - val_acc: 0.3803\n",
            "Epoch 97/100\n",
            "429/429 [==============================] - 0s 841us/step - loss: 0.6608 - acc: 0.5594 - val_loss: 0.8022 - val_acc: 0.3662\n",
            "Epoch 98/100\n",
            "429/429 [==============================] - 0s 848us/step - loss: 0.6717 - acc: 0.5711 - val_loss: 0.8234 - val_acc: 0.4085\n",
            "Epoch 99/100\n",
            "429/429 [==============================] - 0s 851us/step - loss: 0.6494 - acc: 0.6014 - val_loss: 0.8460 - val_acc: 0.4930\n",
            "Epoch 100/100\n",
            "429/429 [==============================] - 0s 843us/step - loss: 0.6417 - acc: 0.5781 - val_loss: 0.8747 - val_acc: 0.4225\n",
            "[[ 9 23]\n",
            " [18 21]]\n",
            "Accuracy :  0.4225352112676056\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.33      0.28      0.31        32\n",
            "           1       0.48      0.54      0.51        39\n",
            "\n",
            "    accuracy                           0.42        71\n",
            "   macro avg       0.41      0.41      0.41        71\n",
            "weighted avg       0.41      0.42      0.42        71\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "model_2 (Model)              (None, 2)                 9148782   \n",
            "=================================================================\n",
            "Total params: 9,148,782\n",
            "Trainable params: 8,386\n",
            "Non-trainable params: 9,140,396\n",
            "_________________________________________________________________\n",
            "Train on 429 samples, validate on 71 samples\n",
            "Epoch 1/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.6644 - acc: 0.6084 - val_loss: 0.8786 - val_acc: 0.4648\n",
            "Epoch 2/100\n",
            "429/429 [==============================] - 0s 826us/step - loss: 0.6573 - acc: 0.5804 - val_loss: 0.8774 - val_acc: 0.4085\n",
            "Epoch 3/100\n",
            "429/429 [==============================] - 0s 828us/step - loss: 0.6563 - acc: 0.5967 - val_loss: 0.8254 - val_acc: 0.4789\n",
            "Epoch 4/100\n",
            "429/429 [==============================] - 0s 825us/step - loss: 0.6468 - acc: 0.6061 - val_loss: 0.8375 - val_acc: 0.4507\n",
            "Epoch 5/100\n",
            "429/429 [==============================] - 0s 828us/step - loss: 0.6565 - acc: 0.5944 - val_loss: 0.8031 - val_acc: 0.3944\n",
            "Epoch 6/100\n",
            "429/429 [==============================] - 0s 828us/step - loss: 0.6740 - acc: 0.6061 - val_loss: 0.8233 - val_acc: 0.3944\n",
            "Epoch 7/100\n",
            "429/429 [==============================] - 0s 833us/step - loss: 0.6453 - acc: 0.6224 - val_loss: 0.8536 - val_acc: 0.3944\n",
            "Epoch 8/100\n",
            "429/429 [==============================] - 0s 833us/step - loss: 0.6537 - acc: 0.5967 - val_loss: 0.9257 - val_acc: 0.4225\n",
            "Epoch 9/100\n",
            "429/429 [==============================] - 0s 848us/step - loss: 0.6513 - acc: 0.6154 - val_loss: 0.8764 - val_acc: 0.4507\n",
            "Epoch 10/100\n",
            "429/429 [==============================] - 0s 848us/step - loss: 0.6770 - acc: 0.5618 - val_loss: 0.8456 - val_acc: 0.4507\n",
            "Epoch 11/100\n",
            "429/429 [==============================] - 0s 832us/step - loss: 0.6686 - acc: 0.6200 - val_loss: 0.8676 - val_acc: 0.5070\n",
            "Epoch 12/100\n",
            "429/429 [==============================] - 0s 833us/step - loss: 0.6735 - acc: 0.5711 - val_loss: 0.8623 - val_acc: 0.4648\n",
            "Epoch 13/100\n",
            "429/429 [==============================] - 0s 828us/step - loss: 0.6695 - acc: 0.6200 - val_loss: 0.8259 - val_acc: 0.3944\n",
            "Epoch 14/100\n",
            "429/429 [==============================] - 0s 836us/step - loss: 0.6586 - acc: 0.5991 - val_loss: 0.8123 - val_acc: 0.4648\n",
            "Epoch 15/100\n",
            "429/429 [==============================] - 0s 839us/step - loss: 0.6666 - acc: 0.5828 - val_loss: 0.7720 - val_acc: 0.3803\n",
            "Epoch 16/100\n",
            "429/429 [==============================] - 0s 840us/step - loss: 0.6601 - acc: 0.6037 - val_loss: 0.7917 - val_acc: 0.3944\n",
            "Epoch 17/100\n",
            "429/429 [==============================] - 0s 853us/step - loss: 0.6564 - acc: 0.6177 - val_loss: 0.7800 - val_acc: 0.4085\n",
            "Epoch 18/100\n",
            "429/429 [==============================] - 0s 858us/step - loss: 0.6759 - acc: 0.5664 - val_loss: 0.7960 - val_acc: 0.4366\n",
            "Epoch 19/100\n",
            "429/429 [==============================] - 0s 846us/step - loss: 0.6405 - acc: 0.6294 - val_loss: 0.7882 - val_acc: 0.4366\n",
            "Epoch 20/100\n",
            "429/429 [==============================] - 0s 841us/step - loss: 0.6715 - acc: 0.5828 - val_loss: 0.8108 - val_acc: 0.4507\n",
            "Epoch 21/100\n",
            "429/429 [==============================] - 0s 832us/step - loss: 0.6678 - acc: 0.5688 - val_loss: 0.8410 - val_acc: 0.5070\n",
            "Epoch 22/100\n",
            "429/429 [==============================] - 0s 845us/step - loss: 0.6703 - acc: 0.5431 - val_loss: 0.9124 - val_acc: 0.5915\n",
            "Epoch 23/100\n",
            "429/429 [==============================] - 0s 851us/step - loss: 0.6469 - acc: 0.5804 - val_loss: 0.9687 - val_acc: 0.4507\n",
            "Epoch 24/100\n",
            "429/429 [==============================] - 0s 853us/step - loss: 0.6525 - acc: 0.6154 - val_loss: 0.9438 - val_acc: 0.4366\n",
            "Epoch 25/100\n",
            "429/429 [==============================] - 0s 823us/step - loss: 0.6644 - acc: 0.5851 - val_loss: 0.9363 - val_acc: 0.4085\n",
            "Epoch 26/100\n",
            "429/429 [==============================] - 0s 837us/step - loss: 0.6519 - acc: 0.6014 - val_loss: 0.9340 - val_acc: 0.4225\n",
            "Epoch 27/100\n",
            "429/429 [==============================] - 0s 844us/step - loss: 0.6354 - acc: 0.6224 - val_loss: 0.9061 - val_acc: 0.4225\n",
            "Epoch 28/100\n",
            "429/429 [==============================] - 0s 848us/step - loss: 0.6635 - acc: 0.5944 - val_loss: 0.8975 - val_acc: 0.4225\n",
            "Epoch 29/100\n",
            "429/429 [==============================] - 0s 841us/step - loss: 0.6469 - acc: 0.6107 - val_loss: 0.8757 - val_acc: 0.4225\n",
            "Epoch 30/100\n",
            "429/429 [==============================] - 0s 827us/step - loss: 0.6614 - acc: 0.6084 - val_loss: 0.8868 - val_acc: 0.4085\n",
            "Epoch 31/100\n",
            "429/429 [==============================] - 0s 846us/step - loss: 0.6620 - acc: 0.5944 - val_loss: 0.8712 - val_acc: 0.4085\n",
            "Epoch 32/100\n",
            "429/429 [==============================] - 0s 856us/step - loss: 0.6760 - acc: 0.5594 - val_loss: 0.8448 - val_acc: 0.3944\n",
            "Epoch 33/100\n",
            "429/429 [==============================] - 0s 833us/step - loss: 0.6865 - acc: 0.5501 - val_loss: 0.8127 - val_acc: 0.4085\n",
            "Epoch 34/100\n",
            "429/429 [==============================] - 0s 838us/step - loss: 0.6519 - acc: 0.6224 - val_loss: 0.8125 - val_acc: 0.5211\n",
            "Epoch 35/100\n",
            "429/429 [==============================] - 0s 828us/step - loss: 0.6718 - acc: 0.5944 - val_loss: 0.8114 - val_acc: 0.5211\n",
            "Epoch 36/100\n",
            "429/429 [==============================] - 0s 834us/step - loss: 0.6570 - acc: 0.5828 - val_loss: 0.8260 - val_acc: 0.4930\n",
            "Epoch 37/100\n",
            "429/429 [==============================] - 0s 841us/step - loss: 0.6673 - acc: 0.5897 - val_loss: 0.8465 - val_acc: 0.5211\n",
            "Epoch 38/100\n",
            "429/429 [==============================] - 0s 834us/step - loss: 0.6668 - acc: 0.5385 - val_loss: 0.8424 - val_acc: 0.5493\n",
            "Epoch 39/100\n",
            "429/429 [==============================] - 0s 843us/step - loss: 0.6518 - acc: 0.5781 - val_loss: 0.8187 - val_acc: 0.4507\n",
            "Epoch 40/100\n",
            "429/429 [==============================] - 0s 850us/step - loss: 0.6590 - acc: 0.5664 - val_loss: 0.8300 - val_acc: 0.4225\n",
            "Epoch 41/100\n",
            "429/429 [==============================] - 0s 831us/step - loss: 0.6632 - acc: 0.5851 - val_loss: 0.8169 - val_acc: 0.3944\n",
            "Epoch 42/100\n",
            "429/429 [==============================] - 0s 839us/step - loss: 0.6428 - acc: 0.6224 - val_loss: 0.8424 - val_acc: 0.4507\n",
            "Epoch 43/100\n",
            "429/429 [==============================] - 0s 844us/step - loss: 0.6638 - acc: 0.5734 - val_loss: 0.8313 - val_acc: 0.4366\n",
            "Epoch 44/100\n",
            "429/429 [==============================] - 0s 840us/step - loss: 0.6553 - acc: 0.5804 - val_loss: 0.8440 - val_acc: 0.5352\n",
            "Epoch 45/100\n",
            "429/429 [==============================] - 0s 832us/step - loss: 0.6825 - acc: 0.5315 - val_loss: 0.8514 - val_acc: 0.5352\n",
            "Epoch 46/100\n",
            "429/429 [==============================] - 0s 856us/step - loss: 0.6701 - acc: 0.5781 - val_loss: 0.8597 - val_acc: 0.5493\n",
            "Epoch 47/100\n",
            "429/429 [==============================] - 0s 851us/step - loss: 0.6541 - acc: 0.5431 - val_loss: 0.8637 - val_acc: 0.5634\n",
            "Epoch 48/100\n",
            "429/429 [==============================] - 0s 871us/step - loss: 0.6499 - acc: 0.5478 - val_loss: 0.8405 - val_acc: 0.4789\n",
            "Epoch 49/100\n",
            "429/429 [==============================] - 0s 844us/step - loss: 0.6516 - acc: 0.5921 - val_loss: 0.8494 - val_acc: 0.4648\n",
            "Epoch 50/100\n",
            "429/429 [==============================] - 0s 843us/step - loss: 0.6674 - acc: 0.5921 - val_loss: 0.8290 - val_acc: 0.4366\n",
            "Epoch 51/100\n",
            "429/429 [==============================] - 0s 851us/step - loss: 0.6533 - acc: 0.5664 - val_loss: 0.7888 - val_acc: 0.4225\n",
            "Epoch 52/100\n",
            "429/429 [==============================] - 0s 840us/step - loss: 0.6364 - acc: 0.5944 - val_loss: 0.7779 - val_acc: 0.4225\n",
            "Epoch 53/100\n",
            "429/429 [==============================] - 0s 837us/step - loss: 0.6718 - acc: 0.5991 - val_loss: 0.7882 - val_acc: 0.4366\n",
            "Epoch 54/100\n",
            "429/429 [==============================] - 0s 839us/step - loss: 0.6774 - acc: 0.5734 - val_loss: 0.7858 - val_acc: 0.5070\n",
            "Epoch 55/100\n",
            "429/429 [==============================] - 0s 835us/step - loss: 0.6732 - acc: 0.5804 - val_loss: 0.7384 - val_acc: 0.4507\n",
            "Epoch 56/100\n",
            "429/429 [==============================] - 0s 834us/step - loss: 0.6694 - acc: 0.5524 - val_loss: 0.7261 - val_acc: 0.4225\n",
            "Epoch 57/100\n",
            "429/429 [==============================] - 0s 850us/step - loss: 0.6924 - acc: 0.5385 - val_loss: 0.7385 - val_acc: 0.4225\n",
            "Epoch 58/100\n",
            "429/429 [==============================] - 0s 844us/step - loss: 0.6723 - acc: 0.5641 - val_loss: 0.7556 - val_acc: 0.4507\n",
            "Epoch 59/100\n",
            "429/429 [==============================] - 0s 836us/step - loss: 0.6755 - acc: 0.5315 - val_loss: 0.7524 - val_acc: 0.4507\n",
            "Epoch 60/100\n",
            "429/429 [==============================] - 0s 842us/step - loss: 0.6720 - acc: 0.5734 - val_loss: 0.7449 - val_acc: 0.4789\n",
            "Epoch 61/100\n",
            "429/429 [==============================] - 0s 844us/step - loss: 0.6800 - acc: 0.5758 - val_loss: 0.7487 - val_acc: 0.4930\n",
            "Epoch 62/100\n",
            "429/429 [==============================] - 0s 848us/step - loss: 0.6655 - acc: 0.5874 - val_loss: 0.7367 - val_acc: 0.4648\n",
            "Epoch 63/100\n",
            "429/429 [==============================] - 0s 857us/step - loss: 0.6691 - acc: 0.5408 - val_loss: 0.7276 - val_acc: 0.4507\n",
            "Epoch 64/100\n",
            "429/429 [==============================] - 0s 861us/step - loss: 0.6637 - acc: 0.5548 - val_loss: 0.7243 - val_acc: 0.4507\n",
            "Epoch 65/100\n",
            "429/429 [==============================] - 0s 859us/step - loss: 0.6703 - acc: 0.5874 - val_loss: 0.7384 - val_acc: 0.5915\n",
            "Epoch 66/100\n",
            "429/429 [==============================] - 0s 858us/step - loss: 0.6788 - acc: 0.5711 - val_loss: 0.7311 - val_acc: 0.5775\n",
            "Epoch 67/100\n",
            "429/429 [==============================] - 0s 855us/step - loss: 0.6571 - acc: 0.6084 - val_loss: 0.7225 - val_acc: 0.5775\n",
            "Epoch 68/100\n",
            "429/429 [==============================] - 0s 839us/step - loss: 0.6632 - acc: 0.5781 - val_loss: 0.7272 - val_acc: 0.5915\n",
            "Epoch 69/100\n",
            "429/429 [==============================] - 0s 859us/step - loss: 0.6580 - acc: 0.5711 - val_loss: 0.7199 - val_acc: 0.5352\n",
            "Epoch 70/100\n",
            "429/429 [==============================] - 0s 854us/step - loss: 0.6492 - acc: 0.5711 - val_loss: 0.7461 - val_acc: 0.5775\n",
            "Epoch 71/100\n",
            "429/429 [==============================] - 0s 842us/step - loss: 0.6590 - acc: 0.5688 - val_loss: 0.7700 - val_acc: 0.5915\n",
            "Epoch 72/100\n",
            "429/429 [==============================] - 0s 850us/step - loss: 0.6609 - acc: 0.5571 - val_loss: 0.7783 - val_acc: 0.5634\n",
            "Epoch 73/100\n",
            "429/429 [==============================] - 0s 856us/step - loss: 0.6743 - acc: 0.5874 - val_loss: 0.7365 - val_acc: 0.3803\n",
            "Epoch 74/100\n",
            "429/429 [==============================] - 0s 865us/step - loss: 0.6525 - acc: 0.6061 - val_loss: 0.7284 - val_acc: 0.4085\n",
            "Epoch 75/100\n",
            "429/429 [==============================] - 0s 859us/step - loss: 0.6786 - acc: 0.5758 - val_loss: 0.7519 - val_acc: 0.4930\n",
            "Epoch 76/100\n",
            "429/429 [==============================] - 0s 853us/step - loss: 0.6587 - acc: 0.5734 - val_loss: 0.7762 - val_acc: 0.5634\n",
            "Epoch 77/100\n",
            "429/429 [==============================] - 0s 853us/step - loss: 0.6554 - acc: 0.5664 - val_loss: 0.8021 - val_acc: 0.5493\n",
            "Epoch 78/100\n",
            "429/429 [==============================] - 0s 855us/step - loss: 0.6475 - acc: 0.5781 - val_loss: 0.8258 - val_acc: 0.5352\n",
            "Epoch 79/100\n",
            "429/429 [==============================] - 0s 869us/step - loss: 0.6726 - acc: 0.5548 - val_loss: 0.8076 - val_acc: 0.5352\n",
            "Epoch 80/100\n",
            "429/429 [==============================] - 0s 848us/step - loss: 0.6596 - acc: 0.5804 - val_loss: 0.8029 - val_acc: 0.5493\n",
            "Epoch 81/100\n",
            "429/429 [==============================] - 0s 849us/step - loss: 0.6610 - acc: 0.5804 - val_loss: 0.7929 - val_acc: 0.3944\n",
            "Epoch 82/100\n",
            "429/429 [==============================] - 0s 854us/step - loss: 0.6662 - acc: 0.5268 - val_loss: 0.8007 - val_acc: 0.3944\n",
            "Epoch 83/100\n",
            "429/429 [==============================] - 0s 857us/step - loss: 0.6760 - acc: 0.5618 - val_loss: 0.8240 - val_acc: 0.5211\n",
            "Epoch 84/100\n",
            "429/429 [==============================] - 0s 861us/step - loss: 0.6494 - acc: 0.5967 - val_loss: 0.8391 - val_acc: 0.5493\n",
            "Epoch 85/100\n",
            "429/429 [==============================] - 0s 850us/step - loss: 0.6547 - acc: 0.5781 - val_loss: 0.8406 - val_acc: 0.5211\n",
            "Epoch 86/100\n",
            "429/429 [==============================] - 0s 862us/step - loss: 0.6384 - acc: 0.5781 - val_loss: 0.8250 - val_acc: 0.4085\n",
            "Epoch 87/100\n",
            "429/429 [==============================] - 0s 847us/step - loss: 0.6775 - acc: 0.6107 - val_loss: 0.8760 - val_acc: 0.4366\n",
            "Epoch 88/100\n",
            "429/429 [==============================] - 0s 850us/step - loss: 0.6621 - acc: 0.5921 - val_loss: 0.8584 - val_acc: 0.4366\n",
            "Epoch 89/100\n",
            "429/429 [==============================] - 0s 857us/step - loss: 0.6805 - acc: 0.5758 - val_loss: 0.8146 - val_acc: 0.5211\n",
            "Epoch 90/100\n",
            "429/429 [==============================] - 0s 852us/step - loss: 0.6554 - acc: 0.5781 - val_loss: 0.7720 - val_acc: 0.4789\n",
            "Epoch 91/100\n",
            "429/429 [==============================] - 0s 850us/step - loss: 0.6473 - acc: 0.6131 - val_loss: 0.7920 - val_acc: 0.3803\n",
            "Epoch 92/100\n",
            "429/429 [==============================] - 0s 851us/step - loss: 0.6559 - acc: 0.5781 - val_loss: 0.7866 - val_acc: 0.4085\n",
            "Epoch 93/100\n",
            "429/429 [==============================] - 0s 848us/step - loss: 0.6804 - acc: 0.5618 - val_loss: 0.8001 - val_acc: 0.3803\n",
            "Epoch 94/100\n",
            "429/429 [==============================] - 0s 843us/step - loss: 0.6594 - acc: 0.5688 - val_loss: 0.8471 - val_acc: 0.4789\n",
            "Epoch 95/100\n",
            "429/429 [==============================] - 0s 860us/step - loss: 0.6716 - acc: 0.5734 - val_loss: 0.7972 - val_acc: 0.4225\n",
            "Epoch 96/100\n",
            "429/429 [==============================] - 0s 867us/step - loss: 0.6791 - acc: 0.5734 - val_loss: 0.7639 - val_acc: 0.5070\n",
            "Epoch 97/100\n",
            "429/429 [==============================] - 0s 850us/step - loss: 0.6585 - acc: 0.5851 - val_loss: 0.7527 - val_acc: 0.4507\n",
            "Epoch 98/100\n",
            "429/429 [==============================] - 0s 849us/step - loss: 0.6617 - acc: 0.5781 - val_loss: 0.7756 - val_acc: 0.5634\n",
            "Epoch 99/100\n",
            "429/429 [==============================] - 0s 857us/step - loss: 0.6539 - acc: 0.5385 - val_loss: 0.7657 - val_acc: 0.4085\n",
            "Epoch 100/100\n",
            "429/429 [==============================] - 0s 873us/step - loss: 0.6510 - acc: 0.5921 - val_loss: 0.7500 - val_acc: 0.4366\n",
            "[[11 21]\n",
            " [19 20]]\n",
            "Accuracy :  0.43661971830985913\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.37      0.34      0.35        32\n",
            "           1       0.49      0.51      0.50        39\n",
            "\n",
            "    accuracy                           0.44        71\n",
            "   macro avg       0.43      0.43      0.43        71\n",
            "weighted avg       0.43      0.44      0.43        71\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "model_2 (Model)              (None, 2)                 9148782   \n",
            "=================================================================\n",
            "Total params: 9,148,782\n",
            "Trainable params: 8,386\n",
            "Non-trainable params: 9,140,396\n",
            "_________________________________________________________________\n",
            "Train on 429 samples, validate on 71 samples\n",
            "Epoch 1/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.6602 - acc: 0.5548 - val_loss: 0.7594 - val_acc: 0.5915\n",
            "Epoch 2/100\n",
            "429/429 [==============================] - 0s 833us/step - loss: 0.6587 - acc: 0.5385 - val_loss: 0.7721 - val_acc: 0.5211\n",
            "Epoch 3/100\n",
            "429/429 [==============================] - 0s 833us/step - loss: 0.6525 - acc: 0.5804 - val_loss: 0.7943 - val_acc: 0.5915\n",
            "Epoch 4/100\n",
            "429/429 [==============================] - 0s 826us/step - loss: 0.6571 - acc: 0.5664 - val_loss: 0.7664 - val_acc: 0.5493\n",
            "Epoch 5/100\n",
            "429/429 [==============================] - 0s 822us/step - loss: 0.6595 - acc: 0.5734 - val_loss: 0.7661 - val_acc: 0.5352\n",
            "Epoch 6/100\n",
            "429/429 [==============================] - 0s 838us/step - loss: 0.6721 - acc: 0.5711 - val_loss: 0.7662 - val_acc: 0.5634\n",
            "Epoch 7/100\n",
            "429/429 [==============================] - 0s 840us/step - loss: 0.6454 - acc: 0.5758 - val_loss: 0.7991 - val_acc: 0.5070\n",
            "Epoch 8/100\n",
            "429/429 [==============================] - 0s 822us/step - loss: 0.6739 - acc: 0.5035 - val_loss: 0.8364 - val_acc: 0.4930\n",
            "Epoch 9/100\n",
            "429/429 [==============================] - 0s 825us/step - loss: 0.6593 - acc: 0.6084 - val_loss: 0.7845 - val_acc: 0.5211\n",
            "Epoch 10/100\n",
            "429/429 [==============================] - 0s 826us/step - loss: 0.6993 - acc: 0.5035 - val_loss: 0.7249 - val_acc: 0.5352\n",
            "Epoch 11/100\n",
            "429/429 [==============================] - 0s 837us/step - loss: 0.6495 - acc: 0.5711 - val_loss: 0.7042 - val_acc: 0.5915\n",
            "Epoch 12/100\n",
            "429/429 [==============================] - 0s 827us/step - loss: 0.6702 - acc: 0.5734 - val_loss: 0.7039 - val_acc: 0.6056\n",
            "Epoch 13/100\n",
            "429/429 [==============================] - 0s 821us/step - loss: 0.6595 - acc: 0.5315 - val_loss: 0.7210 - val_acc: 0.5775\n",
            "Epoch 14/100\n",
            "429/429 [==============================] - 0s 836us/step - loss: 0.6612 - acc: 0.6410 - val_loss: 0.7386 - val_acc: 0.5493\n",
            "Epoch 15/100\n",
            "429/429 [==============================] - 0s 827us/step - loss: 0.6793 - acc: 0.5128 - val_loss: 0.7443 - val_acc: 0.5493\n",
            "Epoch 16/100\n",
            "429/429 [==============================] - 0s 829us/step - loss: 0.6549 - acc: 0.5874 - val_loss: 0.7418 - val_acc: 0.6338\n",
            "Epoch 17/100\n",
            "429/429 [==============================] - 0s 835us/step - loss: 0.6736 - acc: 0.5734 - val_loss: 0.7290 - val_acc: 0.6197\n",
            "Epoch 18/100\n",
            "429/429 [==============================] - 0s 831us/step - loss: 0.6661 - acc: 0.5641 - val_loss: 0.7131 - val_acc: 0.5211\n",
            "Epoch 19/100\n",
            "429/429 [==============================] - 0s 829us/step - loss: 0.6535 - acc: 0.5897 - val_loss: 0.7148 - val_acc: 0.5634\n",
            "Epoch 20/100\n",
            "429/429 [==============================] - 0s 830us/step - loss: 0.6522 - acc: 0.5501 - val_loss: 0.7031 - val_acc: 0.5352\n",
            "Epoch 21/100\n",
            "429/429 [==============================] - 0s 832us/step - loss: 0.6605 - acc: 0.6154 - val_loss: 0.6955 - val_acc: 0.5070\n",
            "Epoch 22/100\n",
            "429/429 [==============================] - 0s 825us/step - loss: 0.6583 - acc: 0.6084 - val_loss: 0.6966 - val_acc: 0.5634\n",
            "Epoch 23/100\n",
            "429/429 [==============================] - 0s 842us/step - loss: 0.6574 - acc: 0.5897 - val_loss: 0.7353 - val_acc: 0.6056\n",
            "Epoch 24/100\n",
            "429/429 [==============================] - 0s 829us/step - loss: 0.6635 - acc: 0.5664 - val_loss: 0.7500 - val_acc: 0.5915\n",
            "Epoch 25/100\n",
            "429/429 [==============================] - 0s 825us/step - loss: 0.6921 - acc: 0.5618 - val_loss: 0.7206 - val_acc: 0.5775\n",
            "Epoch 26/100\n",
            "429/429 [==============================] - 0s 852us/step - loss: 0.6488 - acc: 0.5688 - val_loss: 0.7098 - val_acc: 0.5775\n",
            "Epoch 27/100\n",
            "429/429 [==============================] - 0s 835us/step - loss: 0.6831 - acc: 0.5524 - val_loss: 0.7111 - val_acc: 0.4930\n",
            "Epoch 28/100\n",
            "429/429 [==============================] - 0s 827us/step - loss: 0.6499 - acc: 0.5921 - val_loss: 0.6924 - val_acc: 0.5493\n",
            "Epoch 29/100\n",
            "429/429 [==============================] - 0s 834us/step - loss: 0.6571 - acc: 0.6084 - val_loss: 0.7028 - val_acc: 0.5634\n",
            "Epoch 30/100\n",
            "429/429 [==============================] - 0s 835us/step - loss: 0.6715 - acc: 0.5781 - val_loss: 0.6995 - val_acc: 0.5352\n",
            "Epoch 31/100\n",
            "429/429 [==============================] - 0s 837us/step - loss: 0.6613 - acc: 0.5524 - val_loss: 0.7008 - val_acc: 0.5915\n",
            "Epoch 32/100\n",
            "429/429 [==============================] - 0s 852us/step - loss: 0.6663 - acc: 0.5688 - val_loss: 0.6978 - val_acc: 0.5634\n",
            "Epoch 33/100\n",
            "429/429 [==============================] - 0s 824us/step - loss: 0.6460 - acc: 0.6014 - val_loss: 0.7109 - val_acc: 0.5775\n",
            "Epoch 34/100\n",
            "429/429 [==============================] - 0s 844us/step - loss: 0.6358 - acc: 0.6177 - val_loss: 0.7258 - val_acc: 0.5352\n",
            "Epoch 35/100\n",
            "429/429 [==============================] - 0s 833us/step - loss: 0.6640 - acc: 0.5828 - val_loss: 0.7448 - val_acc: 0.5352\n",
            "Epoch 36/100\n",
            "429/429 [==============================] - 0s 828us/step - loss: 0.6594 - acc: 0.5781 - val_loss: 0.7474 - val_acc: 0.5915\n",
            "Epoch 37/100\n",
            "429/429 [==============================] - 0s 838us/step - loss: 0.6884 - acc: 0.5711 - val_loss: 0.7664 - val_acc: 0.5915\n",
            "Epoch 38/100\n",
            "429/429 [==============================] - 0s 833us/step - loss: 0.6786 - acc: 0.5524 - val_loss: 0.7592 - val_acc: 0.5775\n",
            "Epoch 39/100\n",
            "429/429 [==============================] - 0s 844us/step - loss: 0.6644 - acc: 0.5431 - val_loss: 0.7399 - val_acc: 0.5775\n",
            "Epoch 40/100\n",
            "429/429 [==============================] - 0s 828us/step - loss: 0.6587 - acc: 0.5758 - val_loss: 0.7275 - val_acc: 0.5775\n",
            "Epoch 41/100\n",
            "429/429 [==============================] - 0s 838us/step - loss: 0.6774 - acc: 0.5781 - val_loss: 0.7327 - val_acc: 0.5915\n",
            "Epoch 42/100\n",
            "429/429 [==============================] - 0s 851us/step - loss: 0.6524 - acc: 0.5828 - val_loss: 0.7327 - val_acc: 0.5915\n",
            "Epoch 43/100\n",
            "429/429 [==============================] - 0s 864us/step - loss: 0.6823 - acc: 0.6014 - val_loss: 0.7239 - val_acc: 0.5915\n",
            "Epoch 44/100\n",
            "429/429 [==============================] - 0s 834us/step - loss: 0.6606 - acc: 0.5734 - val_loss: 0.7271 - val_acc: 0.6056\n",
            "Epoch 45/100\n",
            "429/429 [==============================] - 0s 838us/step - loss: 0.6613 - acc: 0.6037 - val_loss: 0.7286 - val_acc: 0.5775\n",
            "Epoch 46/100\n",
            "429/429 [==============================] - 0s 851us/step - loss: 0.6725 - acc: 0.5758 - val_loss: 0.7387 - val_acc: 0.5775\n",
            "Epoch 47/100\n",
            "429/429 [==============================] - 0s 838us/step - loss: 0.6739 - acc: 0.5385 - val_loss: 0.7260 - val_acc: 0.5775\n",
            "Epoch 48/100\n",
            "429/429 [==============================] - 0s 829us/step - loss: 0.6428 - acc: 0.6084 - val_loss: 0.7184 - val_acc: 0.5493\n",
            "Epoch 49/100\n",
            "429/429 [==============================] - 0s 834us/step - loss: 0.6759 - acc: 0.5315 - val_loss: 0.7151 - val_acc: 0.5211\n",
            "Epoch 50/100\n",
            "429/429 [==============================] - 0s 831us/step - loss: 0.6524 - acc: 0.5734 - val_loss: 0.7368 - val_acc: 0.5915\n",
            "Epoch 51/100\n",
            "429/429 [==============================] - 0s 839us/step - loss: 0.6658 - acc: 0.5758 - val_loss: 0.7309 - val_acc: 0.5915\n",
            "Epoch 52/100\n",
            "429/429 [==============================] - 0s 840us/step - loss: 0.6534 - acc: 0.5758 - val_loss: 0.7244 - val_acc: 0.5775\n",
            "Epoch 53/100\n",
            "429/429 [==============================] - 0s 834us/step - loss: 0.6599 - acc: 0.5664 - val_loss: 0.7234 - val_acc: 0.5493\n",
            "Epoch 54/100\n",
            "429/429 [==============================] - 0s 852us/step - loss: 0.6626 - acc: 0.5641 - val_loss: 0.7230 - val_acc: 0.6338\n",
            "Epoch 55/100\n",
            "429/429 [==============================] - 0s 843us/step - loss: 0.6689 - acc: 0.5548 - val_loss: 0.7122 - val_acc: 0.6056\n",
            "Epoch 56/100\n",
            "429/429 [==============================] - 0s 837us/step - loss: 0.6604 - acc: 0.5688 - val_loss: 0.7176 - val_acc: 0.6056\n",
            "Epoch 57/100\n",
            "429/429 [==============================] - 0s 852us/step - loss: 0.6654 - acc: 0.5618 - val_loss: 0.7396 - val_acc: 0.5915\n",
            "Epoch 58/100\n",
            "429/429 [==============================] - 0s 854us/step - loss: 0.6677 - acc: 0.5781 - val_loss: 0.7372 - val_acc: 0.5493\n",
            "Epoch 59/100\n",
            "429/429 [==============================] - 0s 839us/step - loss: 0.6656 - acc: 0.5921 - val_loss: 0.7264 - val_acc: 0.6056\n",
            "Epoch 60/100\n",
            "429/429 [==============================] - 0s 845us/step - loss: 0.6541 - acc: 0.5781 - val_loss: 0.7344 - val_acc: 0.6197\n",
            "Epoch 61/100\n",
            "429/429 [==============================] - 0s 835us/step - loss: 0.6506 - acc: 0.5781 - val_loss: 0.7418 - val_acc: 0.6056\n",
            "Epoch 62/100\n",
            "429/429 [==============================] - 0s 839us/step - loss: 0.6636 - acc: 0.5618 - val_loss: 0.7406 - val_acc: 0.5915\n",
            "Epoch 63/100\n",
            "429/429 [==============================] - 0s 833us/step - loss: 0.6486 - acc: 0.5991 - val_loss: 0.7269 - val_acc: 0.5352\n",
            "Epoch 64/100\n",
            "429/429 [==============================] - 0s 835us/step - loss: 0.6828 - acc: 0.5408 - val_loss: 0.7162 - val_acc: 0.5352\n",
            "Epoch 65/100\n",
            "429/429 [==============================] - 0s 835us/step - loss: 0.6631 - acc: 0.5688 - val_loss: 0.7119 - val_acc: 0.5915\n",
            "Epoch 66/100\n",
            "429/429 [==============================] - 0s 842us/step - loss: 0.6522 - acc: 0.5897 - val_loss: 0.7085 - val_acc: 0.5915\n",
            "Epoch 67/100\n",
            "429/429 [==============================] - 0s 842us/step - loss: 0.6747 - acc: 0.5734 - val_loss: 0.7237 - val_acc: 0.6197\n",
            "Epoch 68/100\n",
            "429/429 [==============================] - 0s 840us/step - loss: 0.6512 - acc: 0.5711 - val_loss: 0.7499 - val_acc: 0.6056\n",
            "Epoch 69/100\n",
            "429/429 [==============================] - 0s 841us/step - loss: 0.6681 - acc: 0.5804 - val_loss: 0.7318 - val_acc: 0.5915\n",
            "Epoch 70/100\n",
            "429/429 [==============================] - 0s 840us/step - loss: 0.6519 - acc: 0.5641 - val_loss: 0.7153 - val_acc: 0.5634\n",
            "Epoch 71/100\n",
            "429/429 [==============================] - 0s 846us/step - loss: 0.6430 - acc: 0.5921 - val_loss: 0.7203 - val_acc: 0.5634\n",
            "Epoch 72/100\n",
            "429/429 [==============================] - 0s 843us/step - loss: 0.6710 - acc: 0.5758 - val_loss: 0.7357 - val_acc: 0.5915\n",
            "Epoch 73/100\n",
            "429/429 [==============================] - 0s 848us/step - loss: 0.6336 - acc: 0.6014 - val_loss: 0.7300 - val_acc: 0.5211\n",
            "Epoch 74/100\n",
            "429/429 [==============================] - 0s 877us/step - loss: 0.6999 - acc: 0.5734 - val_loss: 0.7349 - val_acc: 0.5211\n",
            "Epoch 75/100\n",
            "429/429 [==============================] - 0s 838us/step - loss: 0.6680 - acc: 0.5594 - val_loss: 0.7585 - val_acc: 0.6056\n",
            "Epoch 76/100\n",
            "429/429 [==============================] - 0s 850us/step - loss: 0.6436 - acc: 0.5618 - val_loss: 0.7764 - val_acc: 0.6056\n",
            "Epoch 77/100\n",
            "429/429 [==============================] - 0s 870us/step - loss: 0.6576 - acc: 0.5991 - val_loss: 0.7492 - val_acc: 0.5211\n",
            "Epoch 78/100\n",
            "429/429 [==============================] - 0s 847us/step - loss: 0.6489 - acc: 0.5851 - val_loss: 0.7368 - val_acc: 0.5352\n",
            "Epoch 79/100\n",
            "429/429 [==============================] - 0s 844us/step - loss: 0.6677 - acc: 0.5524 - val_loss: 0.7352 - val_acc: 0.5211\n",
            "Epoch 80/100\n",
            "429/429 [==============================] - 0s 858us/step - loss: 0.6414 - acc: 0.5991 - val_loss: 0.7146 - val_acc: 0.5775\n",
            "Epoch 81/100\n",
            "429/429 [==============================] - 0s 852us/step - loss: 0.6617 - acc: 0.5897 - val_loss: 0.7211 - val_acc: 0.5352\n",
            "Epoch 82/100\n",
            "429/429 [==============================] - 0s 850us/step - loss: 0.6512 - acc: 0.6294 - val_loss: 0.7478 - val_acc: 0.5211\n",
            "Epoch 83/100\n",
            "429/429 [==============================] - 0s 853us/step - loss: 0.6749 - acc: 0.5804 - val_loss: 0.7662 - val_acc: 0.5634\n",
            "Epoch 84/100\n",
            "429/429 [==============================] - 0s 855us/step - loss: 0.6685 - acc: 0.5967 - val_loss: 0.7318 - val_acc: 0.5634\n",
            "Epoch 85/100\n",
            "429/429 [==============================] - 0s 862us/step - loss: 0.6663 - acc: 0.5688 - val_loss: 0.7067 - val_acc: 0.5775\n",
            "Epoch 86/100\n",
            "429/429 [==============================] - 0s 850us/step - loss: 0.6611 - acc: 0.6107 - val_loss: 0.7193 - val_acc: 0.5915\n",
            "Epoch 87/100\n",
            "429/429 [==============================] - 0s 845us/step - loss: 0.6553 - acc: 0.6014 - val_loss: 0.7155 - val_acc: 0.5634\n",
            "Epoch 88/100\n",
            "429/429 [==============================] - 0s 847us/step - loss: 0.6648 - acc: 0.5804 - val_loss: 0.7093 - val_acc: 0.5634\n",
            "Epoch 89/100\n",
            "429/429 [==============================] - 0s 854us/step - loss: 0.6670 - acc: 0.5455 - val_loss: 0.7275 - val_acc: 0.5634\n",
            "Epoch 90/100\n",
            "429/429 [==============================] - 0s 839us/step - loss: 0.6562 - acc: 0.5688 - val_loss: 0.7475 - val_acc: 0.5493\n",
            "Epoch 91/100\n",
            "429/429 [==============================] - 0s 838us/step - loss: 0.6599 - acc: 0.5804 - val_loss: 0.7463 - val_acc: 0.5211\n",
            "Epoch 92/100\n",
            "429/429 [==============================] - 0s 849us/step - loss: 0.6710 - acc: 0.6014 - val_loss: 0.7638 - val_acc: 0.5352\n",
            "Epoch 93/100\n",
            "429/429 [==============================] - 0s 846us/step - loss: 0.6739 - acc: 0.5874 - val_loss: 0.7518 - val_acc: 0.5211\n",
            "Epoch 94/100\n",
            "429/429 [==============================] - 0s 863us/step - loss: 0.6631 - acc: 0.5897 - val_loss: 0.7497 - val_acc: 0.5634\n",
            "Epoch 95/100\n",
            "429/429 [==============================] - 0s 847us/step - loss: 0.6528 - acc: 0.5734 - val_loss: 0.7684 - val_acc: 0.5493\n",
            "Epoch 96/100\n",
            "429/429 [==============================] - 0s 849us/step - loss: 0.6503 - acc: 0.5804 - val_loss: 0.7599 - val_acc: 0.5634\n",
            "Epoch 97/100\n",
            "429/429 [==============================] - 0s 860us/step - loss: 0.6870 - acc: 0.5967 - val_loss: 0.7278 - val_acc: 0.5775\n",
            "Epoch 98/100\n",
            "429/429 [==============================] - 0s 844us/step - loss: 0.6513 - acc: 0.6434 - val_loss: 0.7524 - val_acc: 0.5493\n",
            "Epoch 99/100\n",
            "429/429 [==============================] - 0s 850us/step - loss: 0.6676 - acc: 0.5524 - val_loss: 0.7551 - val_acc: 0.5211\n",
            "Epoch 100/100\n",
            "429/429 [==============================] - 0s 856us/step - loss: 0.6632 - acc: 0.5828 - val_loss: 0.7510 - val_acc: 0.5211\n",
            "[[15 17]\n",
            " [17 22]]\n",
            "Accuracy :  0.5211267605633803\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.47      0.47        32\n",
            "           1       0.56      0.56      0.56        39\n",
            "\n",
            "    accuracy                           0.52        71\n",
            "   macro avg       0.52      0.52      0.52        71\n",
            "weighted avg       0.52      0.52      0.52        71\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "model_2 (Model)              (None, 2)                 9148782   \n",
            "=================================================================\n",
            "Total params: 9,148,782\n",
            "Trainable params: 8,386\n",
            "Non-trainable params: 9,140,396\n",
            "_________________________________________________________________\n",
            "Train on 429 samples, validate on 71 samples\n",
            "Epoch 1/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.6722 - acc: 0.6014 - val_loss: 0.7783 - val_acc: 0.4366\n",
            "Epoch 2/100\n",
            "429/429 [==============================] - 0s 828us/step - loss: 0.6815 - acc: 0.5478 - val_loss: 0.7609 - val_acc: 0.4930\n",
            "Epoch 3/100\n",
            "429/429 [==============================] - 0s 829us/step - loss: 0.6834 - acc: 0.5781 - val_loss: 0.7519 - val_acc: 0.4930\n",
            "Epoch 4/100\n",
            "429/429 [==============================] - 0s 836us/step - loss: 0.6658 - acc: 0.5804 - val_loss: 0.7511 - val_acc: 0.4789\n",
            "Epoch 5/100\n",
            "429/429 [==============================] - 0s 824us/step - loss: 0.6943 - acc: 0.5781 - val_loss: 0.7564 - val_acc: 0.5634\n",
            "Epoch 6/100\n",
            "429/429 [==============================] - 0s 841us/step - loss: 0.6518 - acc: 0.6014 - val_loss: 0.7821 - val_acc: 0.5493\n",
            "Epoch 7/100\n",
            "429/429 [==============================] - 0s 828us/step - loss: 0.6631 - acc: 0.5524 - val_loss: 0.8444 - val_acc: 0.5211\n",
            "Epoch 8/100\n",
            "429/429 [==============================] - 0s 821us/step - loss: 0.6453 - acc: 0.5874 - val_loss: 0.8587 - val_acc: 0.4366\n",
            "Epoch 9/100\n",
            "429/429 [==============================] - 0s 827us/step - loss: 0.6735 - acc: 0.5921 - val_loss: 0.8950 - val_acc: 0.4085\n",
            "Epoch 10/100\n",
            "429/429 [==============================] - 0s 827us/step - loss: 0.6863 - acc: 0.5198 - val_loss: 0.9128 - val_acc: 0.4225\n",
            "Epoch 11/100\n",
            "429/429 [==============================] - 0s 836us/step - loss: 0.6682 - acc: 0.5524 - val_loss: 0.8876 - val_acc: 0.4225\n",
            "Epoch 12/100\n",
            "429/429 [==============================] - 0s 825us/step - loss: 0.6469 - acc: 0.5618 - val_loss: 0.8937 - val_acc: 0.5211\n",
            "Epoch 13/100\n",
            "429/429 [==============================] - 0s 836us/step - loss: 0.6729 - acc: 0.5641 - val_loss: 0.8760 - val_acc: 0.4789\n",
            "Epoch 14/100\n",
            "429/429 [==============================] - 0s 844us/step - loss: 0.6482 - acc: 0.6177 - val_loss: 0.9189 - val_acc: 0.5634\n",
            "Epoch 15/100\n",
            "429/429 [==============================] - 0s 829us/step - loss: 0.6952 - acc: 0.5804 - val_loss: 0.9030 - val_acc: 0.5634\n",
            "Epoch 16/100\n",
            "429/429 [==============================] - 0s 816us/step - loss: 0.6752 - acc: 0.5548 - val_loss: 0.8233 - val_acc: 0.5775\n",
            "Epoch 17/100\n",
            "429/429 [==============================] - 0s 829us/step - loss: 0.6498 - acc: 0.5781 - val_loss: 0.7955 - val_acc: 0.5775\n",
            "Epoch 18/100\n",
            "429/429 [==============================] - 0s 833us/step - loss: 0.6693 - acc: 0.5897 - val_loss: 0.7946 - val_acc: 0.4366\n",
            "Epoch 19/100\n",
            "429/429 [==============================] - 0s 826us/step - loss: 0.6755 - acc: 0.5431 - val_loss: 0.8206 - val_acc: 0.5634\n",
            "Epoch 20/100\n",
            "429/429 [==============================] - 0s 837us/step - loss: 0.6561 - acc: 0.5921 - val_loss: 0.8112 - val_acc: 0.5775\n",
            "Epoch 21/100\n",
            "429/429 [==============================] - 0s 828us/step - loss: 0.6663 - acc: 0.5921 - val_loss: 0.8493 - val_acc: 0.5493\n",
            "Epoch 22/100\n",
            "429/429 [==============================] - 0s 830us/step - loss: 0.6654 - acc: 0.5781 - val_loss: 0.8666 - val_acc: 0.5634\n",
            "Epoch 23/100\n",
            "429/429 [==============================] - 0s 843us/step - loss: 0.6694 - acc: 0.5688 - val_loss: 0.8372 - val_acc: 0.5493\n",
            "Epoch 24/100\n",
            "429/429 [==============================] - 0s 830us/step - loss: 0.6590 - acc: 0.5571 - val_loss: 0.8213 - val_acc: 0.5352\n",
            "Epoch 25/100\n",
            "429/429 [==============================] - 0s 829us/step - loss: 0.6709 - acc: 0.5385 - val_loss: 0.8362 - val_acc: 0.5493\n",
            "Epoch 26/100\n",
            "429/429 [==============================] - 0s 840us/step - loss: 0.6829 - acc: 0.5711 - val_loss: 0.8283 - val_acc: 0.5211\n",
            "Epoch 27/100\n",
            "429/429 [==============================] - 0s 833us/step - loss: 0.6672 - acc: 0.5664 - val_loss: 0.7921 - val_acc: 0.5211\n",
            "Epoch 28/100\n",
            "429/429 [==============================] - 0s 832us/step - loss: 0.6459 - acc: 0.5828 - val_loss: 0.7848 - val_acc: 0.6056\n",
            "Epoch 29/100\n",
            "429/429 [==============================] - 0s 830us/step - loss: 0.6789 - acc: 0.5711 - val_loss: 0.7843 - val_acc: 0.4789\n",
            "Epoch 30/100\n",
            "429/429 [==============================] - 0s 827us/step - loss: 0.6627 - acc: 0.5804 - val_loss: 0.7937 - val_acc: 0.4085\n",
            "Epoch 31/100\n",
            "429/429 [==============================] - 0s 831us/step - loss: 0.6524 - acc: 0.5804 - val_loss: 0.8082 - val_acc: 0.5493\n",
            "Epoch 32/100\n",
            "429/429 [==============================] - 0s 836us/step - loss: 0.6780 - acc: 0.5804 - val_loss: 0.8336 - val_acc: 0.5211\n",
            "Epoch 33/100\n",
            "429/429 [==============================] - 0s 829us/step - loss: 0.6633 - acc: 0.5734 - val_loss: 0.8790 - val_acc: 0.5352\n",
            "Epoch 34/100\n",
            "429/429 [==============================] - 0s 832us/step - loss: 0.6367 - acc: 0.6131 - val_loss: 0.8702 - val_acc: 0.5070\n",
            "Epoch 35/100\n",
            "429/429 [==============================] - 0s 831us/step - loss: 0.6690 - acc: 0.5944 - val_loss: 0.8942 - val_acc: 0.5775\n",
            "Epoch 36/100\n",
            "429/429 [==============================] - 0s 827us/step - loss: 0.6622 - acc: 0.5967 - val_loss: 0.8594 - val_acc: 0.5352\n",
            "Epoch 37/100\n",
            "429/429 [==============================] - 0s 836us/step - loss: 0.6710 - acc: 0.5664 - val_loss: 0.8737 - val_acc: 0.5634\n",
            "Epoch 38/100\n",
            "429/429 [==============================] - 0s 842us/step - loss: 0.6553 - acc: 0.5594 - val_loss: 0.8853 - val_acc: 0.5634\n",
            "Epoch 39/100\n",
            "429/429 [==============================] - 0s 832us/step - loss: 0.6846 - acc: 0.5524 - val_loss: 0.8413 - val_acc: 0.3944\n",
            "Epoch 40/100\n",
            "429/429 [==============================] - 0s 852us/step - loss: 0.6626 - acc: 0.5851 - val_loss: 0.8356 - val_acc: 0.5211\n",
            "Epoch 41/100\n",
            "429/429 [==============================] - 0s 852us/step - loss: 0.6685 - acc: 0.5758 - val_loss: 0.8174 - val_acc: 0.5493\n",
            "Epoch 42/100\n",
            "429/429 [==============================] - 0s 823us/step - loss: 0.6539 - acc: 0.5641 - val_loss: 0.8205 - val_acc: 0.5634\n",
            "Epoch 43/100\n",
            "429/429 [==============================] - 0s 833us/step - loss: 0.6767 - acc: 0.5664 - val_loss: 0.8552 - val_acc: 0.5634\n",
            "Epoch 44/100\n",
            "429/429 [==============================] - 0s 836us/step - loss: 0.6497 - acc: 0.5851 - val_loss: 0.8991 - val_acc: 0.5352\n",
            "Epoch 45/100\n",
            "429/429 [==============================] - 0s 844us/step - loss: 0.6488 - acc: 0.5734 - val_loss: 0.8663 - val_acc: 0.3944\n",
            "Epoch 46/100\n",
            "429/429 [==============================] - 0s 846us/step - loss: 0.6680 - acc: 0.5408 - val_loss: 0.9024 - val_acc: 0.4225\n",
            "Epoch 47/100\n",
            "429/429 [==============================] - 0s 845us/step - loss: 0.6661 - acc: 0.5501 - val_loss: 0.9197 - val_acc: 0.5352\n",
            "Epoch 48/100\n",
            "429/429 [==============================] - 0s 846us/step - loss: 0.6410 - acc: 0.5711 - val_loss: 0.8923 - val_acc: 0.5352\n",
            "Epoch 49/100\n",
            "429/429 [==============================] - 0s 869us/step - loss: 0.6733 - acc: 0.5758 - val_loss: 0.9074 - val_acc: 0.5915\n",
            "Epoch 50/100\n",
            "429/429 [==============================] - 0s 834us/step - loss: 0.6694 - acc: 0.5828 - val_loss: 0.9273 - val_acc: 0.5634\n",
            "Epoch 51/100\n",
            "429/429 [==============================] - 0s 836us/step - loss: 0.6546 - acc: 0.5688 - val_loss: 0.9666 - val_acc: 0.5634\n",
            "Epoch 52/100\n",
            "429/429 [==============================] - 0s 850us/step - loss: 0.6790 - acc: 0.5431 - val_loss: 0.9539 - val_acc: 0.3803\n",
            "Epoch 53/100\n",
            "429/429 [==============================] - 0s 845us/step - loss: 0.6553 - acc: 0.6247 - val_loss: 0.8852 - val_acc: 0.4930\n",
            "Epoch 54/100\n",
            "429/429 [==============================] - 0s 853us/step - loss: 0.6619 - acc: 0.6177 - val_loss: 0.8851 - val_acc: 0.4225\n",
            "Epoch 55/100\n",
            "429/429 [==============================] - 0s 859us/step - loss: 0.6744 - acc: 0.5594 - val_loss: 0.8945 - val_acc: 0.4366\n",
            "Epoch 56/100\n",
            "429/429 [==============================] - 0s 840us/step - loss: 0.6724 - acc: 0.5897 - val_loss: 0.8852 - val_acc: 0.4225\n",
            "Epoch 57/100\n",
            "429/429 [==============================] - 0s 865us/step - loss: 0.6695 - acc: 0.5944 - val_loss: 0.8629 - val_acc: 0.4366\n",
            "Epoch 58/100\n",
            "429/429 [==============================] - 0s 835us/step - loss: 0.6711 - acc: 0.5758 - val_loss: 0.8784 - val_acc: 0.5915\n",
            "Epoch 59/100\n",
            "429/429 [==============================] - 0s 843us/step - loss: 0.6431 - acc: 0.5664 - val_loss: 0.8830 - val_acc: 0.4507\n",
            "Epoch 60/100\n",
            "429/429 [==============================] - 0s 853us/step - loss: 0.6629 - acc: 0.5851 - val_loss: 0.9201 - val_acc: 0.4225\n",
            "Epoch 61/100\n",
            "429/429 [==============================] - 0s 838us/step - loss: 0.6814 - acc: 0.5758 - val_loss: 0.9015 - val_acc: 0.5634\n",
            "Epoch 62/100\n",
            "429/429 [==============================] - 0s 847us/step - loss: 0.6564 - acc: 0.5781 - val_loss: 0.8503 - val_acc: 0.5634\n",
            "Epoch 63/100\n",
            "429/429 [==============================] - 0s 844us/step - loss: 0.6745 - acc: 0.5711 - val_loss: 0.8241 - val_acc: 0.6056\n",
            "Epoch 64/100\n",
            "429/429 [==============================] - 0s 839us/step - loss: 0.6714 - acc: 0.5571 - val_loss: 0.8104 - val_acc: 0.5634\n",
            "Epoch 65/100\n",
            "429/429 [==============================] - 0s 851us/step - loss: 0.6800 - acc: 0.5688 - val_loss: 0.8283 - val_acc: 0.5634\n",
            "Epoch 66/100\n",
            "429/429 [==============================] - 0s 858us/step - loss: 0.6622 - acc: 0.6014 - val_loss: 0.8053 - val_acc: 0.5915\n",
            "Epoch 67/100\n",
            "429/429 [==============================] - 0s 844us/step - loss: 0.6523 - acc: 0.5758 - val_loss: 0.8203 - val_acc: 0.5634\n",
            "Epoch 68/100\n",
            "429/429 [==============================] - 0s 839us/step - loss: 0.6374 - acc: 0.6037 - val_loss: 0.8830 - val_acc: 0.5915\n",
            "Epoch 69/100\n",
            "429/429 [==============================] - 0s 837us/step - loss: 0.6878 - acc: 0.5431 - val_loss: 0.8878 - val_acc: 0.5915\n",
            "Epoch 70/100\n",
            "429/429 [==============================] - 0s 840us/step - loss: 0.6636 - acc: 0.5408 - val_loss: 0.9036 - val_acc: 0.5915\n",
            "Epoch 71/100\n",
            "429/429 [==============================] - 0s 856us/step - loss: 0.6719 - acc: 0.5711 - val_loss: 0.8823 - val_acc: 0.5915\n",
            "Epoch 72/100\n",
            "429/429 [==============================] - 0s 838us/step - loss: 0.6779 - acc: 0.5734 - val_loss: 0.8386 - val_acc: 0.5634\n",
            "Epoch 73/100\n",
            "429/429 [==============================] - 0s 841us/step - loss: 0.6577 - acc: 0.5828 - val_loss: 0.8302 - val_acc: 0.6056\n",
            "Epoch 74/100\n",
            "429/429 [==============================] - 0s 855us/step - loss: 0.6668 - acc: 0.5688 - val_loss: 0.8408 - val_acc: 0.5634\n",
            "Epoch 75/100\n",
            "429/429 [==============================] - 0s 856us/step - loss: 0.6823 - acc: 0.5571 - val_loss: 0.8538 - val_acc: 0.5634\n",
            "Epoch 76/100\n",
            "429/429 [==============================] - 0s 843us/step - loss: 0.6762 - acc: 0.5431 - val_loss: 0.8639 - val_acc: 0.5634\n",
            "Epoch 77/100\n",
            "429/429 [==============================] - 0s 854us/step - loss: 0.6581 - acc: 0.5571 - val_loss: 0.8866 - val_acc: 0.5634\n",
            "Epoch 78/100\n",
            "429/429 [==============================] - 0s 846us/step - loss: 0.6612 - acc: 0.5851 - val_loss: 0.8642 - val_acc: 0.5915\n",
            "Epoch 79/100\n",
            "429/429 [==============================] - 0s 852us/step - loss: 0.6524 - acc: 0.5874 - val_loss: 0.8971 - val_acc: 0.5775\n",
            "Epoch 80/100\n",
            "429/429 [==============================] - 0s 858us/step - loss: 0.6725 - acc: 0.5618 - val_loss: 0.8824 - val_acc: 0.5915\n",
            "Epoch 81/100\n",
            "429/429 [==============================] - 0s 835us/step - loss: 0.6649 - acc: 0.5991 - val_loss: 0.8825 - val_acc: 0.5775\n",
            "Epoch 82/100\n",
            "429/429 [==============================] - 0s 840us/step - loss: 0.6630 - acc: 0.5548 - val_loss: 0.8517 - val_acc: 0.5493\n",
            "Epoch 83/100\n",
            "429/429 [==============================] - 0s 839us/step - loss: 0.6599 - acc: 0.5501 - val_loss: 0.9090 - val_acc: 0.4085\n",
            "Epoch 84/100\n",
            "429/429 [==============================] - 0s 837us/step - loss: 0.6709 - acc: 0.5431 - val_loss: 0.9055 - val_acc: 0.3944\n",
            "Epoch 85/100\n",
            "429/429 [==============================] - 0s 841us/step - loss: 0.6653 - acc: 0.5828 - val_loss: 0.9407 - val_acc: 0.4225\n",
            "Epoch 86/100\n",
            "429/429 [==============================] - 0s 846us/step - loss: 0.6595 - acc: 0.5758 - val_loss: 0.9705 - val_acc: 0.4366\n",
            "Epoch 87/100\n",
            "429/429 [==============================] - 0s 850us/step - loss: 0.6760 - acc: 0.5781 - val_loss: 0.8825 - val_acc: 0.4225\n",
            "Epoch 88/100\n",
            "429/429 [==============================] - 0s 848us/step - loss: 0.6524 - acc: 0.5711 - val_loss: 0.8672 - val_acc: 0.5775\n",
            "Epoch 89/100\n",
            "429/429 [==============================] - 0s 841us/step - loss: 0.6790 - acc: 0.5524 - val_loss: 0.9009 - val_acc: 0.5634\n",
            "Epoch 90/100\n",
            "429/429 [==============================] - 0s 840us/step - loss: 0.6693 - acc: 0.5478 - val_loss: 0.9503 - val_acc: 0.5634\n",
            "Epoch 91/100\n",
            "429/429 [==============================] - 0s 850us/step - loss: 0.6686 - acc: 0.5828 - val_loss: 0.9389 - val_acc: 0.4366\n",
            "Epoch 92/100\n",
            "429/429 [==============================] - 0s 851us/step - loss: 0.6743 - acc: 0.5548 - val_loss: 0.9338 - val_acc: 0.4507\n",
            "Epoch 93/100\n",
            "429/429 [==============================] - 0s 868us/step - loss: 0.6538 - acc: 0.5711 - val_loss: 0.9295 - val_acc: 0.5775\n",
            "Epoch 94/100\n",
            "429/429 [==============================] - 0s 871us/step - loss: 0.6517 - acc: 0.6154 - val_loss: 0.9220 - val_acc: 0.4789\n",
            "Epoch 95/100\n",
            "429/429 [==============================] - 0s 843us/step - loss: 0.6537 - acc: 0.5641 - val_loss: 0.9681 - val_acc: 0.5634\n",
            "Epoch 96/100\n",
            "429/429 [==============================] - 0s 843us/step - loss: 0.6947 - acc: 0.5478 - val_loss: 0.9520 - val_acc: 0.5352\n",
            "Epoch 97/100\n",
            "429/429 [==============================] - 0s 847us/step - loss: 0.6522 - acc: 0.5781 - val_loss: 0.8896 - val_acc: 0.5634\n",
            "Epoch 98/100\n",
            "429/429 [==============================] - 0s 847us/step - loss: 0.6490 - acc: 0.5828 - val_loss: 0.8848 - val_acc: 0.4225\n",
            "Epoch 99/100\n",
            "429/429 [==============================] - 0s 842us/step - loss: 0.6337 - acc: 0.6061 - val_loss: 0.8957 - val_acc: 0.4085\n",
            "Epoch 100/100\n",
            "429/429 [==============================] - 0s 851us/step - loss: 0.6633 - acc: 0.5641 - val_loss: 0.9234 - val_acc: 0.4085\n",
            "[[11 21]\n",
            " [21 18]]\n",
            "Accuracy :  0.4084507042253521\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.34      0.34      0.34        32\n",
            "           1       0.46      0.46      0.46        39\n",
            "\n",
            "    accuracy                           0.41        71\n",
            "   macro avg       0.40      0.40      0.40        71\n",
            "weighted avg       0.41      0.41      0.41        71\n",
            "\n",
            "\n",
            "\n",
            "Sincerity\n",
            "[0.8611111111111112, 0.8611111111111112, 0.8611111111111112, 0.8611111111111112, 0.8732394366197183, 0.8732394366197183, 0.8714285714285714] \n",
            "Mean :  0.8660502698732075 \n",
            "Standard deviation :  0.0057305636938820605 \n",
            "Precision Score :  0.8660502698732075 \n",
            "Recall Score :  1.0 \n",
            "F1 Score :  0.9282074144817763\n",
            "\n",
            "\n",
            "Excitement\n",
            "[0.6944444444444444, 0.6944444444444444, 0.6805555555555556, 0.676056338028169, 0.676056338028169, 0.676056338028169, 0.6901408450704225] \n",
            "Mean :  0.6839649005141963 \n",
            "Standard deviation :  0.00808034376891394 \n",
            "Precision Score :  0.6828902677625449 \n",
            "Recall Score :  0.9970845481049563 \n",
            "F1 Score :  0.8105529619047507\n",
            "\n",
            "\n",
            "Competence\n",
            "[0.9315068493150684, 0.9305555555555556, 0.9436619718309859, 0.9436619718309859, 0.9436619718309859, 0.9436619718309859, 0.9436619718309859] \n",
            "Mean :  0.9400531805750791 \n",
            "Standard deviation :  0.005711661387783277 \n",
            "Precision Score :  0.9400531805750791 \n",
            "Recall Score :  1.0 \n",
            "F1 Score :  0.9690914639769616\n",
            "\n",
            "\n",
            "Sophistication\n",
            "[0.5555555555555556, 0.5694444444444444, 0.4444444444444444, 0.4225352112676056, 0.43661971830985913, 0.5211267605633803, 0.4084507042253521] \n",
            "Mean :  0.4797395484015202 \n",
            "Standard deviation :  0.06206843716732873 \n",
            "Precision Score :  0.5213005320186052 \n",
            "Recall Score :  0.585989010989011 \n",
            "F1 Score :  0.5474693479300946\n",
            "\n",
            "\n",
            "Ruggedness\n",
            "[0.6164383561643836, 0.625, 0.38028169014084506, 0.38028169014084506, 0.38028169014084506, 0.38028169014084506, 0.38028169014084506] \n",
            "Mean :  0.44897811526694414 \n",
            "Standard deviation :  0.1086426845291707 \n",
            "Precision Score :  0.2716297786720322 \n",
            "Recall Score :  0.7142857142857143 \n",
            "F1 Score :  0.3935860058309038\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-4uDE2rzzXL",
        "colab_type": "code",
        "outputId": "def0824f-17d6-4d34-e508-9336547a5b28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4466
        }
      },
      "source": [
        "#transfer learning on heldout\n",
        "\n",
        "import os \n",
        "import numpy as np\n",
        "import csv\n",
        "import pandas as pd\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Model,load_model,Sequential\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Activation, Dense, Dropout,Input,Add,concatenate\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split,StratifiedKFold\n",
        "from keras.layers import Conv1D,MaxPooling1D,Embedding,GlobalMaxPooling1D\n",
        "from keras.initializers import Constant\n",
        "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix,precision_score,recall_score,f1_score\n",
        "import pickle\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "\n",
        "vocab_size = 30000\n",
        "batch_size = 25\n",
        "embedding_dim = 300\n",
        "max_len = 3000\n",
        "\n",
        "#loading the pickled test files\n",
        "pickle_in = open(\"ht_test_text.pickle\",\"rb\")\n",
        "X = pickle.load(pickle_in)\n",
        "\n",
        "pickle_in = open(\"ht_test_data.pickle\",\"rb\")\n",
        "data = pickle.load(pickle_in)\n",
        "\n",
        "test_X = pickle.load(open('/content/drive/My Drive/ML_Datasets/genData/test_text.pickle',\"rb\"))\n",
        "test_data = pickle.load(open('/content/drive/My Drive/ML_Datasets/genData/test_data.pickle',\"rb\"))\n",
        "\n",
        "#tokenizing the text\n",
        "tokenizer = Tokenizer(num_words = vocab_size)\n",
        "tokenizer.fit_on_texts(X)\n",
        "word_index = tokenizer.word_index\n",
        "train_sentences_tokenized = tokenizer.texts_to_sequences(X)\n",
        "\n",
        "X = pad_sequences(train_sentences_tokenized, maxlen=max_len)\n",
        "\n",
        "test_sentences_tokenized = tokenizer.texts_to_sequences(test_X)\n",
        "\n",
        "test_X = pad_sequences(test_sentences_tokenized, maxlen=max_len)\n",
        "\n",
        "tags = ['y','n']\n",
        "\n",
        "label_enc = LabelBinarizer()\n",
        "label_enc.fit(tags)\n",
        "Y = label_enc.transform(data['cRUG'])\n",
        "\n",
        "#oversampling using SMOTE\n",
        "sm = SMOTE(random_state=4991, n_jobs=8, ratio={1:500, 0:500})\n",
        "X,Y = sm.fit_sample(X,Y)\n",
        "Y = to_categorical(Y)\n",
        "\n",
        "test_Y = label_enc.transform(test_data['cRUG'])\n",
        "\n",
        "test_Y = to_categorical(test_Y)\n",
        "\n",
        "#loading the model\n",
        "model5 = load_model('my_model_cRUG_tag');\n",
        "a,b = 0,2\n",
        "print('\\n\\nRuggedness')\n",
        "\n",
        "\n",
        "#setting the layers non-trainable except the last 3 \n",
        "for layer in model5.layers[:-3]:\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(model5)\n",
        "model.summary()\n",
        "\n",
        "#saving the model\n",
        "model.save('DL_Final_RUG')\n",
        "adam = Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=0.0001, decay=0.0001)\n",
        "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy']) \n",
        "model.fit(X,Y,epochs = 100,batch_size = batch_size,validation_data = (test_X,test_Y))\n",
        "pred = model.predict(test_X)\n",
        "pred = pred.argmax(axis=1)\n",
        "c_matrix = confusion_matrix(test_Y.argmax(axis=1),pred)\n",
        "print(c_matrix)\n",
        "accuracy = accuracy_score(test_Y.argmax(axis=1),pred)\n",
        "print('Accuracy : ',accuracy)\n",
        "# precision = true positive / total predicted positive(True positive + False positive)\n",
        "# recall = true positive / total actual positive(True positive + False Negative)\n",
        "\n",
        "#printing the classification metrics\n",
        "print(classification_report(test_Y.argmax(axis=1),pred))\n",
        "print(accuracy)\n",
        "print(precision_score(test_Y.argmax(axis=1),pred))\n",
        "print(recall_score(test_Y.argmax(axis=1),pred))\n",
        "print(f1_score(test_Y.argmax(axis=1),pred))\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:257: UserWarning: After over-sampling, the number of samples (500) in class 1 will be larger than the number of samples in the majority class (class #0 -> 310)\n",
            "  n_samples_majority))\n",
            "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:257: UserWarning: After over-sampling, the number of samples (500) in class 0 will be larger than the number of samples in the majority class (class #0 -> 310)\n",
            "  n_samples_majority))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "\n",
            "\n",
            "Ruggedness\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "model_2 (Model)              (None, 2)                 9148782   \n",
            "=================================================================\n",
            "Total params: 9,148,782\n",
            "Trainable params: 8,386\n",
            "Non-trainable params: 9,140,396\n",
            "_________________________________________________________________\n",
            "Train on 1000 samples, validate on 336 samples\n",
            "Epoch 1/100\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 5.5198 - acc: 0.5410 - val_loss: 6.4877 - val_acc: 0.5357\n",
            "Epoch 2/100\n",
            "1000/1000 [==============================] - 1s 891us/step - loss: 5.5473 - acc: 0.5190 - val_loss: 6.4766 - val_acc: 0.5298\n",
            "Epoch 3/100\n",
            "1000/1000 [==============================] - 1s 877us/step - loss: 4.4382 - acc: 0.5020 - val_loss: 5.5572 - val_acc: 0.5327\n",
            "Epoch 4/100\n",
            "1000/1000 [==============================] - 1s 871us/step - loss: 2.7547 - acc: 0.5250 - val_loss: 3.3044 - val_acc: 0.5298\n",
            "Epoch 5/100\n",
            "1000/1000 [==============================] - 1s 887us/step - loss: 2.5937 - acc: 0.4760 - val_loss: 3.9469 - val_acc: 0.5327\n",
            "Epoch 6/100\n",
            "1000/1000 [==============================] - 1s 877us/step - loss: 2.6717 - acc: 0.5000 - val_loss: 2.7597 - val_acc: 0.5595\n",
            "Epoch 7/100\n",
            "1000/1000 [==============================] - 1s 884us/step - loss: 1.4233 - acc: 0.5110 - val_loss: 1.0411 - val_acc: 0.6131\n",
            "Epoch 8/100\n",
            "1000/1000 [==============================] - 1s 877us/step - loss: 1.1238 - acc: 0.4810 - val_loss: 1.3564 - val_acc: 0.5893\n",
            "Epoch 9/100\n",
            "1000/1000 [==============================] - 1s 882us/step - loss: 1.3309 - acc: 0.5150 - val_loss: 1.9166 - val_acc: 0.5863\n",
            "Epoch 10/100\n",
            "1000/1000 [==============================] - 1s 884us/step - loss: 1.5018 - acc: 0.5160 - val_loss: 1.7102 - val_acc: 0.5774\n",
            "Epoch 11/100\n",
            "1000/1000 [==============================] - 1s 885us/step - loss: 1.0747 - acc: 0.4900 - val_loss: 1.2239 - val_acc: 0.5685\n",
            "Epoch 12/100\n",
            "1000/1000 [==============================] - 1s 883us/step - loss: 0.9654 - acc: 0.5120 - val_loss: 0.8447 - val_acc: 0.5982\n",
            "Epoch 13/100\n",
            "1000/1000 [==============================] - 1s 883us/step - loss: 0.8113 - acc: 0.4850 - val_loss: 0.7383 - val_acc: 0.5952\n",
            "Epoch 14/100\n",
            "1000/1000 [==============================] - 1s 886us/step - loss: 0.7227 - acc: 0.4850 - val_loss: 0.7402 - val_acc: 0.4018\n",
            "Epoch 15/100\n",
            "1000/1000 [==============================] - 1s 883us/step - loss: 0.7682 - acc: 0.4740 - val_loss: 0.7417 - val_acc: 0.4018\n",
            "Epoch 16/100\n",
            "1000/1000 [==============================] - 1s 883us/step - loss: 0.7296 - acc: 0.4810 - val_loss: 0.7380 - val_acc: 0.5952\n",
            "Epoch 17/100\n",
            "1000/1000 [==============================] - 1s 885us/step - loss: 0.7159 - acc: 0.5050 - val_loss: 0.7431 - val_acc: 0.4018\n",
            "Epoch 18/100\n",
            "1000/1000 [==============================] - 1s 892us/step - loss: 0.7226 - acc: 0.4970 - val_loss: 0.7377 - val_acc: 0.5952\n",
            "Epoch 19/100\n",
            "1000/1000 [==============================] - 1s 897us/step - loss: 0.7128 - acc: 0.4900 - val_loss: 0.7388 - val_acc: 0.5952\n",
            "Epoch 20/100\n",
            "1000/1000 [==============================] - 1s 901us/step - loss: 0.7220 - acc: 0.4930 - val_loss: 0.7367 - val_acc: 0.5952\n",
            "Epoch 21/100\n",
            "1000/1000 [==============================] - 1s 895us/step - loss: 0.7029 - acc: 0.4880 - val_loss: 0.7014 - val_acc: 0.5952\n",
            "Epoch 22/100\n",
            "1000/1000 [==============================] - 1s 898us/step - loss: 0.6925 - acc: 0.4810 - val_loss: 0.6905 - val_acc: 0.6012\n",
            "Epoch 23/100\n",
            "1000/1000 [==============================] - 1s 890us/step - loss: 0.7277 - acc: 0.4980 - val_loss: 0.6915 - val_acc: 0.6012\n",
            "Epoch 24/100\n",
            "1000/1000 [==============================] - 1s 895us/step - loss: 0.6920 - acc: 0.5010 - val_loss: 0.6946 - val_acc: 0.4018\n",
            "Epoch 25/100\n",
            "1000/1000 [==============================] - 1s 895us/step - loss: 0.6927 - acc: 0.5020 - val_loss: 0.6940 - val_acc: 0.4048\n",
            "Epoch 26/100\n",
            "1000/1000 [==============================] - 1s 901us/step - loss: 0.6942 - acc: 0.4850 - val_loss: 0.6938 - val_acc: 0.4048\n",
            "Epoch 27/100\n",
            "1000/1000 [==============================] - 1s 895us/step - loss: 0.7027 - acc: 0.5030 - val_loss: 0.6901 - val_acc: 0.5982\n",
            "Epoch 28/100\n",
            "1000/1000 [==============================] - 1s 894us/step - loss: 0.6961 - acc: 0.4880 - val_loss: 0.6925 - val_acc: 0.5982\n",
            "Epoch 29/100\n",
            "1000/1000 [==============================] - 1s 893us/step - loss: 0.6993 - acc: 0.4670 - val_loss: 0.6891 - val_acc: 0.5982\n",
            "Epoch 30/100\n",
            "1000/1000 [==============================] - 1s 892us/step - loss: 0.6948 - acc: 0.4870 - val_loss: 0.6934 - val_acc: 0.4018\n",
            "Epoch 31/100\n",
            "1000/1000 [==============================] - 1s 896us/step - loss: 0.6932 - acc: 0.4860 - val_loss: 0.6961 - val_acc: 0.4018\n",
            "Epoch 32/100\n",
            "1000/1000 [==============================] - 1s 899us/step - loss: 0.7063 - acc: 0.4800 - val_loss: 0.6913 - val_acc: 0.5982\n",
            "Epoch 33/100\n",
            "1000/1000 [==============================] - 1s 891us/step - loss: 0.7027 - acc: 0.4970 - val_loss: 0.6937 - val_acc: 0.4018\n",
            "Epoch 34/100\n",
            "1000/1000 [==============================] - 1s 894us/step - loss: 0.6934 - acc: 0.4990 - val_loss: 0.6924 - val_acc: 0.5982\n",
            "Epoch 35/100\n",
            "1000/1000 [==============================] - 1s 900us/step - loss: 0.6928 - acc: 0.4860 - val_loss: 0.6934 - val_acc: 0.4018\n",
            "Epoch 36/100\n",
            "1000/1000 [==============================] - 1s 900us/step - loss: 0.6933 - acc: 0.5110 - val_loss: 0.6913 - val_acc: 0.5982\n",
            "Epoch 37/100\n",
            "1000/1000 [==============================] - 1s 898us/step - loss: 0.6926 - acc: 0.4820 - val_loss: 0.6920 - val_acc: 0.5982\n",
            "Epoch 38/100\n",
            "1000/1000 [==============================] - 1s 904us/step - loss: 0.6936 - acc: 0.5000 - val_loss: 0.6900 - val_acc: 0.5982\n",
            "Epoch 39/100\n",
            "1000/1000 [==============================] - 1s 898us/step - loss: 0.6928 - acc: 0.4900 - val_loss: 0.6970 - val_acc: 0.4018\n",
            "Epoch 40/100\n",
            "1000/1000 [==============================] - 1s 898us/step - loss: 0.7013 - acc: 0.5090 - val_loss: 0.6902 - val_acc: 0.5982\n",
            "Epoch 41/100\n",
            "1000/1000 [==============================] - 1s 903us/step - loss: 0.7021 - acc: 0.4860 - val_loss: 0.6930 - val_acc: 0.5982\n",
            "Epoch 42/100\n",
            "1000/1000 [==============================] - 1s 912us/step - loss: 0.6936 - acc: 0.4770 - val_loss: 0.6929 - val_acc: 0.5982\n",
            "Epoch 43/100\n",
            "1000/1000 [==============================] - 1s 899us/step - loss: 0.6979 - acc: 0.4910 - val_loss: 0.6951 - val_acc: 0.4018\n",
            "Epoch 44/100\n",
            "1000/1000 [==============================] - 1s 908us/step - loss: 0.6939 - acc: 0.5070 - val_loss: 0.6896 - val_acc: 0.5982\n",
            "Epoch 45/100\n",
            "1000/1000 [==============================] - 1s 906us/step - loss: 0.6997 - acc: 0.4970 - val_loss: 0.6959 - val_acc: 0.4018\n",
            "Epoch 46/100\n",
            "1000/1000 [==============================] - 1s 904us/step - loss: 0.6924 - acc: 0.4950 - val_loss: 0.6921 - val_acc: 0.5982\n",
            "Epoch 47/100\n",
            "1000/1000 [==============================] - 1s 908us/step - loss: 0.6954 - acc: 0.4920 - val_loss: 0.6938 - val_acc: 0.4018\n",
            "Epoch 48/100\n",
            "1000/1000 [==============================] - 1s 905us/step - loss: 0.7066 - acc: 0.4960 - val_loss: 0.7323 - val_acc: 0.5982\n",
            "Epoch 49/100\n",
            "1000/1000 [==============================] - 1s 907us/step - loss: 0.7508 - acc: 0.5080 - val_loss: 0.6960 - val_acc: 0.5952\n",
            "Epoch 50/100\n",
            "1000/1000 [==============================] - 1s 904us/step - loss: 0.6950 - acc: 0.5030 - val_loss: 0.6969 - val_acc: 0.5893\n",
            "Epoch 51/100\n",
            "1000/1000 [==============================] - 1s 910us/step - loss: 0.6931 - acc: 0.4830 - val_loss: 0.7049 - val_acc: 0.4018\n",
            "Epoch 52/100\n",
            "1000/1000 [==============================] - 1s 910us/step - loss: 0.6957 - acc: 0.5040 - val_loss: 0.6988 - val_acc: 0.5952\n",
            "Epoch 53/100\n",
            "1000/1000 [==============================] - 1s 904us/step - loss: 0.6945 - acc: 0.4870 - val_loss: 0.6982 - val_acc: 0.5952\n",
            "Epoch 54/100\n",
            "1000/1000 [==============================] - 1s 901us/step - loss: 0.7085 - acc: 0.4870 - val_loss: 0.6945 - val_acc: 0.4018\n",
            "Epoch 55/100\n",
            "1000/1000 [==============================] - 1s 908us/step - loss: 0.7047 - acc: 0.4900 - val_loss: 0.6927 - val_acc: 0.5982\n",
            "Epoch 56/100\n",
            "1000/1000 [==============================] - 1s 912us/step - loss: 0.6963 - acc: 0.4870 - val_loss: 0.6922 - val_acc: 0.5982\n",
            "Epoch 57/100\n",
            "1000/1000 [==============================] - 1s 914us/step - loss: 0.6935 - acc: 0.4890 - val_loss: 0.6942 - val_acc: 0.4018\n",
            "Epoch 58/100\n",
            "1000/1000 [==============================] - 1s 914us/step - loss: 0.6933 - acc: 0.4890 - val_loss: 0.6931 - val_acc: 0.5982\n",
            "Epoch 59/100\n",
            "1000/1000 [==============================] - 1s 911us/step - loss: 0.6934 - acc: 0.4870 - val_loss: 0.6922 - val_acc: 0.5982\n",
            "Epoch 60/100\n",
            "1000/1000 [==============================] - 1s 910us/step - loss: 0.6939 - acc: 0.4800 - val_loss: 0.6955 - val_acc: 0.4018\n",
            "Epoch 61/100\n",
            "1000/1000 [==============================] - 1s 912us/step - loss: 0.6933 - acc: 0.4970 - val_loss: 0.6921 - val_acc: 0.5982\n",
            "Epoch 62/100\n",
            "1000/1000 [==============================] - 1s 911us/step - loss: 0.6933 - acc: 0.5000 - val_loss: 0.6924 - val_acc: 0.5982\n",
            "Epoch 63/100\n",
            "1000/1000 [==============================] - 1s 915us/step - loss: 0.6979 - acc: 0.4920 - val_loss: 0.6968 - val_acc: 0.4018\n",
            "Epoch 64/100\n",
            "1000/1000 [==============================] - 1s 915us/step - loss: 0.6982 - acc: 0.4940 - val_loss: 0.6916 - val_acc: 0.5982\n",
            "Epoch 65/100\n",
            "1000/1000 [==============================] - 1s 924us/step - loss: 0.6936 - acc: 0.4870 - val_loss: 0.6939 - val_acc: 0.4018\n",
            "Epoch 66/100\n",
            "1000/1000 [==============================] - 1s 920us/step - loss: 0.6934 - acc: 0.4940 - val_loss: 0.6921 - val_acc: 0.5982\n",
            "Epoch 67/100\n",
            "1000/1000 [==============================] - 1s 913us/step - loss: 0.6934 - acc: 0.5000 - val_loss: 0.6922 - val_acc: 0.5982\n",
            "Epoch 68/100\n",
            "1000/1000 [==============================] - 1s 914us/step - loss: 0.6935 - acc: 0.4700 - val_loss: 0.6920 - val_acc: 0.5982\n",
            "Epoch 69/100\n",
            "1000/1000 [==============================] - 1s 911us/step - loss: 0.6935 - acc: 0.4830 - val_loss: 0.6962 - val_acc: 0.4018\n",
            "Epoch 70/100\n",
            "1000/1000 [==============================] - 1s 913us/step - loss: 0.6934 - acc: 0.4880 - val_loss: 0.6931 - val_acc: 0.4048\n",
            "Epoch 71/100\n",
            "1000/1000 [==============================] - 1s 909us/step - loss: 0.6934 - acc: 0.4840 - val_loss: 0.6966 - val_acc: 0.4048\n",
            "Epoch 72/100\n",
            "1000/1000 [==============================] - 1s 911us/step - loss: 0.7105 - acc: 0.4740 - val_loss: 0.6934 - val_acc: 0.4048\n",
            "Epoch 73/100\n",
            "1000/1000 [==============================] - 1s 910us/step - loss: 0.6939 - acc: 0.4830 - val_loss: 0.6961 - val_acc: 0.4048\n",
            "Epoch 74/100\n",
            "1000/1000 [==============================] - 1s 910us/step - loss: 0.6938 - acc: 0.4660 - val_loss: 0.6926 - val_acc: 0.5982\n",
            "Epoch 75/100\n",
            "1000/1000 [==============================] - 1s 906us/step - loss: 0.6933 - acc: 0.5000 - val_loss: 0.6917 - val_acc: 0.5982\n",
            "Epoch 76/100\n",
            "1000/1000 [==============================] - 1s 908us/step - loss: 0.6930 - acc: 0.4890 - val_loss: 0.6939 - val_acc: 0.4077\n",
            "Epoch 77/100\n",
            "1000/1000 [==============================] - 1s 900us/step - loss: 0.6942 - acc: 0.4930 - val_loss: 0.6927 - val_acc: 0.5982\n",
            "Epoch 78/100\n",
            "1000/1000 [==============================] - 1s 906us/step - loss: 0.6938 - acc: 0.4970 - val_loss: 0.6969 - val_acc: 0.4018\n",
            "Epoch 79/100\n",
            "1000/1000 [==============================] - 1s 909us/step - loss: 0.6933 - acc: 0.5000 - val_loss: 0.6928 - val_acc: 0.5982\n",
            "Epoch 80/100\n",
            "1000/1000 [==============================] - 1s 905us/step - loss: 0.6936 - acc: 0.5000 - val_loss: 0.6910 - val_acc: 0.5982\n",
            "Epoch 81/100\n",
            "1000/1000 [==============================] - 1s 909us/step - loss: 0.6939 - acc: 0.4750 - val_loss: 0.6940 - val_acc: 0.4018\n",
            "Epoch 82/100\n",
            "1000/1000 [==============================] - 1s 907us/step - loss: 0.6940 - acc: 0.5000 - val_loss: 0.6946 - val_acc: 0.4018\n",
            "Epoch 83/100\n",
            "1000/1000 [==============================] - 1s 900us/step - loss: 0.6936 - acc: 0.5020 - val_loss: 0.6925 - val_acc: 0.5982\n",
            "Epoch 84/100\n",
            "1000/1000 [==============================] - 1s 901us/step - loss: 0.6934 - acc: 0.5030 - val_loss: 0.6934 - val_acc: 0.4018\n",
            "Epoch 85/100\n",
            "1000/1000 [==============================] - 1s 906us/step - loss: 0.6935 - acc: 0.5000 - val_loss: 0.6939 - val_acc: 0.4018\n",
            "Epoch 86/100\n",
            "1000/1000 [==============================] - 1s 912us/step - loss: 0.6935 - acc: 0.4680 - val_loss: 0.6923 - val_acc: 0.5982\n",
            "Epoch 87/100\n",
            "1000/1000 [==============================] - 1s 906us/step - loss: 0.6942 - acc: 0.4990 - val_loss: 0.6941 - val_acc: 0.4018\n",
            "Epoch 88/100\n",
            "1000/1000 [==============================] - 1s 912us/step - loss: 0.6937 - acc: 0.5000 - val_loss: 0.6945 - val_acc: 0.4018\n",
            "Epoch 89/100\n",
            "1000/1000 [==============================] - 1s 917us/step - loss: 0.6940 - acc: 0.4910 - val_loss: 0.6936 - val_acc: 0.4018\n",
            "Epoch 90/100\n",
            "1000/1000 [==============================] - 1s 906us/step - loss: 0.6934 - acc: 0.5000 - val_loss: 0.6949 - val_acc: 0.4018\n",
            "Epoch 91/100\n",
            "1000/1000 [==============================] - 1s 907us/step - loss: 0.6936 - acc: 0.4910 - val_loss: 0.6904 - val_acc: 0.5982\n",
            "Epoch 92/100\n",
            "1000/1000 [==============================] - 1s 903us/step - loss: 0.6938 - acc: 0.4990 - val_loss: 0.6943 - val_acc: 0.4018\n",
            "Epoch 93/100\n",
            "1000/1000 [==============================] - 1s 913us/step - loss: 0.6941 - acc: 0.4840 - val_loss: 0.6941 - val_acc: 0.4018\n",
            "Epoch 94/100\n",
            "1000/1000 [==============================] - 1s 907us/step - loss: 0.6935 - acc: 0.5000 - val_loss: 0.6936 - val_acc: 0.4018\n",
            "Epoch 95/100\n",
            "1000/1000 [==============================] - 1s 908us/step - loss: 0.6934 - acc: 0.4770 - val_loss: 0.6924 - val_acc: 0.5982\n",
            "Epoch 96/100\n",
            "1000/1000 [==============================] - 1s 903us/step - loss: 0.6928 - acc: 0.4850 - val_loss: 0.6910 - val_acc: 0.5982\n",
            "Epoch 97/100\n",
            "1000/1000 [==============================] - 1s 896us/step - loss: 0.6935 - acc: 0.4710 - val_loss: 0.6939 - val_acc: 0.4018\n",
            "Epoch 98/100\n",
            "1000/1000 [==============================] - 1s 895us/step - loss: 0.6939 - acc: 0.4990 - val_loss: 0.6929 - val_acc: 0.5982\n",
            "Epoch 99/100\n",
            "1000/1000 [==============================] - 1s 904us/step - loss: 0.6935 - acc: 0.4950 - val_loss: 0.6949 - val_acc: 0.4018\n",
            "Epoch 100/100\n",
            "1000/1000 [==============================] - 1s 900us/step - loss: 0.6936 - acc: 0.4950 - val_loss: 0.6915 - val_acc: 0.5982\n",
            "[[201   0]\n",
            " [135   0]]\n",
            "Accuracy :  0.5982142857142857\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      1.00      0.75       201\n",
            "           1       0.00      0.00      0.00       135\n",
            "\n",
            "    accuracy                           0.60       336\n",
            "   macro avg       0.30      0.50      0.37       336\n",
            "weighted avg       0.36      0.60      0.45       336\n",
            "\n",
            "0.5982142857142857\n",
            "0.0\n",
            "0.0\n",
            "0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}